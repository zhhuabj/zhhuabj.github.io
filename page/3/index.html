<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="blog.csdn.net/quqi99">
<meta property="og:type" content="website">
<meta property="og:title" content="技术并艺术着">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="blog.csdn.net/quqi99">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="技术并艺术着">
<meta name="twitter:description" content="blog.csdn.net/quqi99">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/"/>





  <title>技术并艺术着</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">技术并艺术着</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">张华的技术博客 - blog.csdn.net/quqi99</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/22/Root-Mi-note-lte-with-SuperSU-without-flashing-TWRP-Recovery-permanently/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/22/Root-Mi-note-lte-with-SuperSU-without-flashing-TWRP-Recovery-permanently/" itemprop="url">Root Mi note lte with SuperSU without flashing TWRP Recovery permanently</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-22T11:50:03+08:00">
                2019-08-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="作者：张华-发表于：2017-06-23"><a href="#作者：张华-发表于：2017-06-23" class="headerlink" title="作者：张华 发表于：2017-06-23"></a>作者：张华 发表于：2017-06-23</h2><p>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> ) ##</p>
<p>I have two Meizu MX4 ubuntu cellphones, now I will re-install Flyme or native google android on them. All softwares can be downloaded from the link: <a href="https://pan.baidu.com/s/1bpo0xbx" target="_blank" rel="external">https://pan.baidu.com/s/1bpo0xbx</a></p>
<p>1, Start MX4 Ubuntu, and enable ‘Developer Mode’ from ‘System Setting -&gt; About Cellphone’ menu.</p>
<p>2, Install the tools adb and fastboot from the link <a href="http://esausilva.com/wp-content/plugins/cimy-counter/cc_redirect.php?cc=platform-tools-linux&amp;fn=http://esausilva.com/misc/android/platform-tools-linux.tar.gz" target="_blank" rel="external">http://esausilva.com/wp-content/plugins/cimy-counter/cc_redirect.php?cc=platform-tools-linux&amp;fn=http://esausilva.com/misc/android/platform-tools-linux.tar.gz</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/bak/java/platform-tools:$PATH</span><br></pre></td></tr></table></figure>
<p>3, Make sure your cellphone can connect to compute (Ubuntu) via USB and adb</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lsusb |grep Meizu</span><br><span class="line">  Bus 003 Device 010: ID 2a45:0c02 Meizu Corp. MX Phone (MTP &amp; ADB)</span><br><span class="line">$ cat /etc/udev/rules.d/51-android.rules</span><br><span class="line">  SUBSYSTEM==&quot;usb&quot;, ATTR&#123;idVendor&#125;==&quot;2a45&quot;, MODE=&quot;0666&quot;, SYMLINK+=&quot;android_adb&quot;</span><br><span class="line">$ cat ~/.android/adb_usb.ini</span><br><span class="line">  2a45</span><br><span class="line">$ sudo udevadm control --reload-rules &amp;&amp; sudo udevadm trigger</span><br><span class="line">$ adb kill-server &amp;&amp; adb start-server</span><br><span class="line">$ adb devices</span><br><span class="line">  List of devices attached</span><br><span class="line">  75HABLMCYUR3	device</span><br><span class="line">$ sudo apt-get install go-mtpfs mtp-tools gmtp</span><br><span class="line">$ sudo mtp-detect</span><br><span class="line">  libmtp version: 1.1.10</span><br><span class="line">  Listing raw device(s)</span><br><span class="line">  Device 0 (VID=2a45 and PID=0c02) is a Meizu MX Phone (MTP+ADB).</span><br><span class="line">  Found 1 device(s):</span><br><span class="line">  Meizu: MX Phone (MTP+ADB) (2a45:0c02) @ bus 3, dev 10</span><br></pre></td></tr></table></figure>
<p>4, Brush the thirty party recovery. Shutdown your cellphone, and press POWER + VOL-DOWN to enter fastboot mode. Use usb to connect cellphone and compute, than run:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hua@node1:/bak/tools/mx4 $ fastboot flash recovery recovery.img</span><br><span class="line">sending &apos;recovery&apos; (10000 KB)...</span><br><span class="line">OKAY [  0.506s]</span><br><span class="line">writing &apos;recovery&apos;...</span><br><span class="line">OKAY [  0.410s]</span><br><span class="line">finished. total time: 0.916s</span><br></pre></td></tr></table></figure></p>
<p>5, Press POWER + VOL-UP to enter above recoerty, and Click ‘Install Zip -&gt; Install zip from sideload’, then run:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hua@node1:/bak/java/platform-tools$ adb sideload update.zip</span><br><span class="line">sending: &apos;sideload&apos;  100%</span><br></pre></td></tr></table></figure>
<p>NOTE: if you want to install raw google android, just run ‘adb sideload cm-13.0-20160820-UNOFFICIAL-mx4.zip’ instead.</p>
<p>6, Reboot the cellphone. OK.</p>
<h2 id="附录-小米手机线刷开发版-国际版"><a href="#附录-小米手机线刷开发版-国际版" class="headerlink" title="附录 - 小米手机线刷开发版/国际版"></a>附录 - 小米手机线刷开发版/国际版</h2><p>现在, 小米不再允许行货和国际版互刷ROM, 它加入了防回滚保护（Anti-Rollback Protection）机制. 这意味着，如果手机当前处于较高的MIUI版本，降级刷机大概率会变砖。实测发现，行货机刷国际版ROM将卡死在Recovery界面，显示“this MIUI version can’t be installed on this device”。当然，想要绕过官方的限制也有办法，前提是解锁bootloader，然后用TWRP、fastboot或者MiFlash刷机。使用MiFlash时切记勾选“Clean All”，不要选“clean all and lock”。如果你不幸刷在国际版和国行版ROM之间刷机成砖，只有进入EDL（紧急下载）模式自救。然而，EDL模式仅对极为有限的小米账号开放权限。本文测试的手机是mi note lte不再之列.</p>
<p>1, 下载dev rom是virgo_images_5.12.4_20151126.0000.5_4.4_cn_eb14b0eb8d.tgz (<a href="http://pan.baidu.com/s/1bfGxVg" target="_blank" rel="external">http://pan.baidu.com/s/1bfGxVg</a>). rom里的内容如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">NOTE: 这步应该在解锁, 以及在开发模式打开充许OEM之后运行</span><br><span class="line">$ ls virgo_images_5.12.4_20151126.0000.5_4.4_cn</span><br><span class="line">flash_all.bat  flash_all_except_data_storage.bat  flash_all_except_data_storage.sh  flash_all_except_storage.bat  flash_all_except_storage.sh  flash_all.sh  images  misc.txt</span><br><span class="line">$ ls virgo_images_5.12.4_20151126.0000.5_4.4_cn/images/</span><br><span class="line">8974_msimage.mbn  cache.img  emmc_appsboot.mbn  gpt_backup0.bin  gpt_main0.bin  MPRG8974.mbn  patch0.xml   rawprogram0.xml  rpm.mbn   sdi.mbn     tz.mbn</span><br><span class="line">boot.img          dummy.img  flash.xml          gpt_both0.bin    misc.img       NON-HLOS.bin  persist.img  recovery.img     sbl1.mbn  system.img  userdata.img</span><br><span class="line"></span><br><span class="line">$ cat flash_all.sh</span><br><span class="line">fastboot $* getvar product 2&gt;&amp;1 | grep &quot;^product: *MSM8974$&quot;</span><br><span class="line">if [ $? -ne 0 ] ; then echo &quot;Missmatching image and device&quot;; exit 1; fi</span><br><span class="line">fastboot $* getvar board_version 2&gt;&amp;1 | grep &quot;^board_version: *5.[^5]&quot;</span><br><span class="line">if [ $? -ne 0 ] ; then echo &quot;Missmatching board version&quot;; exit 1; fi</span><br><span class="line"></span><br><span class="line">fastboot $* flash tz `dirname $0`/images/tz.mbn</span><br><span class="line">fastboot $* flash dbi `dirname $0`/images/sdi.mbn</span><br><span class="line">fastboot $* flash sbl1 `dirname $0`/images/sbl1.mbn</span><br><span class="line">fastboot $* flash rpm `dirname $0`/images/rpm.mbn</span><br><span class="line">fastboot $* flash aboot `dirname $0`/images/emmc_appsboot.mbn</span><br><span class="line">fastboot $* erase boot</span><br><span class="line">fastboot $* erase DDR</span><br><span class="line">fastboot $* flash misc `dirname $0`/images/misc.img</span><br><span class="line">fastboot $* flash modem+modem1 `dirname $0`/images/NON-HLOS.bin</span><br><span class="line">fastboot $* flash system+system1 `dirname $0`/images/system.img</span><br><span class="line">fastboot $* flash cache `dirname $0`/images/cache.img</span><br><span class="line">fastboot $* flash userdata `dirname $0`/images/userdata.img</span><br><span class="line">fastboot $* flash recovery `dirname $0`/images/recovery.img</span><br><span class="line">fastboot $* flash boot+boot1 `dirname $0`/images/boot.img</span><br><span class="line">fastboot $* reboot</span><br></pre></td></tr></table></figure></p>
<p>2, 手机通过MTP模式连接电脑, 通过lsusb找到设备号为: Bus 003 Device 029: ID 2717:0360<br>3, adb连接手机<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># sudo apt-get install android-tools-adb android-tools-fastboot</span><br><span class="line">$ cat /etc/udev/rules.d/51-android.rules</span><br><span class="line">SUBSYSTEM==&quot;usb&quot;, ATTR&#123;idVendor&#125;==&quot;2717&quot;, MODE=&quot;0666&quot;, SYMLINK+=&quot;android_adb&quot;</span><br><span class="line">sudo udevadm control --reload-rules &amp;&amp; sudo udevadm trigger</span><br><span class="line">adb kill-server &amp;&amp; adb start-server</span><br><span class="line">sudo mtp-detect</span><br><span class="line">$ adb devices</span><br><span class="line">List of devices attached</span><br><span class="line">d6b38a3a	device</span><br></pre></td></tr></table></figure></p>
<p>如果不出来, 是需要 狂按”设置我的设备 -&gt; 全部参数 -&gt; MINU版本”进入开发者模式, 然后”设置 -&gt; 更多设置 -&gt; 开发者选项”打开USB调试”和”FASTBOOT刷机模式”<br>4, 和Meizu是一样的, 也是音量下+电源键进入fastboot模式, 不连电脑，音量下+电源键长按进入fastboot,USB线连接电脑. 注: 同样, 也是音量上+电源键可安装第三方recovery, 见 [5].<br>5, 刷机<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chmod +x flash_all.sh</span><br><span class="line">./flash_all.sh</span><br><span class="line">#./flash_all_except_storage.sh  #clean cache, but not clean data</span><br></pre></td></tr></table></figure></p>
<p>6, 继续root, 刷机成功之后, 已经是开发版, 进入手机，安全中心 -&gt; 授权管理 -&gt; ROOT,反复确认后，手机会下载对应的ROOT包安装后重启。机后，安全中心 -&gt; 授权管理已经可以进入. 这时候就可以使用’adb root’了.</p>
<p>注: 遗憾地是, 机子刚好音量下键损坏, 这样借助如刷机精灵里的实用工具进入fastboot或recovery模式. 好吧, 又得整到windows上了. 照着文档[4]. (注: 其实不用转到windows, 直接在linux下使用”adb reboot bootloader”也可以重启至fastboot模式”<br>1, 安装小米助手, 当手机连上win7电脑时会自动安装驱动 - <a href="http://zhushou.xiaomi.com/" target="_blank" rel="external">http://zhushou.xiaomi.com/</a><br>2, 安装线刷工具 - <a href="http://bigota.d.miui.com/tools/MiPhone20141107.exe" target="_blank" rel="external">http://bigota.d.miui.com/tools/MiPhone20141107.exe</a><br>3, 线刷包解压 - <a href="http://pan.baidu.com/s/1bfGxVg" target="_blank" rel="external">http://pan.baidu.com/s/1bfGxVg</a><br>4, 安装刷机精灵, 使用里面的fastboot实用工具根本无法进入fastboot, 所以直接采用刷机精灵的一键刷机功能上传线刷包线刷. 但出错了, 说是刷入的版本比机子已有的版本低会线刷失败.<br>5, 但上一步一键刷机功能代替音量减键成功让手机进入了fastboot模式, 所以此时切换成小米的刷机工具再试, 结果小米的刷机工具也有bug, 报找不到远程分区.<br>6, 试图找到小米原生的线刷包恢复, 但官网上找不着.<br>7, 还好, 手机进入fastboot模式之后, 没有刷机成功, 只要手机还有电, 再重启还是进入的是flashboot模式, 这样避免了坏的音量键及进不了系统. 继续找啊找试啊试, 终于发现这个包是好的(Xiaomi_Mi_Note_LTE_V9.5.1.0.MXEMIFA_20180406.0000.00_Global_6.0_XFT.zip, <a href="https://firmwarefile.com/xiaomi-mi-note-lte" target="_blank" rel="external">https://firmwarefile.com/xiaomi-mi-note-lte</a> )<br>8, 这个网站(<a href="https://xiaomiflashtool.com/)下载的最新的xiaomiflashtool反而不行说找不着设备" target="_blank" rel="external">https://xiaomiflashtool.com/)下载的最新的xiaomiflashtool反而不行说找不着设备</a>. 注: 这个tool也可在driver菜单自动安装驱动.<br>9, 这样成功换上了Xiaomi_Mi_Note_LTE_V9.5.1.0.MXEMIFA_20180406.0000.00_Global_6.0_XFT.zip, 这似乎是国际稳定版哦.</p>
<p>如何将国际稳定版转成国际开发版呢? 再线刷一遍. 这次都在linux下进行.<br>1,Install Global Developer ROM for Redmi Note 4G<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># search in google by &apos;eveloper bigota.d.miui.com redmi note 4g -stable&apos;, and download fastboot rom - https://c.mi.com/thread-510369-1-0.html</span><br><span class="line">#NOTE: this recovery - http://bigota.d.miui.com/7.11.6/miui_MINoteGlobal_7.11.6_ce58816710_6.0.zip</span><br><span class="line">wget http://bigota.d.miui.com/7.11.6/virgo_global_images_7.11.6_20171106.0000.00_6.0_global_be457b58a3.tgz</span><br><span class="line">tar -xf virgo_global_images_7.11.6_20171106.0000.00_6.0_global_be457b58a3.tgz</span><br><span class="line">cd virgo_global_images_7.11.6_20171106.0000.00_6.0_global</span><br><span class="line">adb reboot bootloader</span><br><span class="line">chmod +x flash_all.sh</span><br><span class="line">./flash_all.sh</span><br><span class="line">运行./flash_all.sh相当于:</span><br><span class="line">#https://blog.csdn.net/quqi99/article/details/51636869</span><br><span class="line">fastboot flash boot boot.img</span><br><span class="line">fastboot flash recovery recovery.img</span><br><span class="line">fastboot erase system</span><br><span class="line">fastboot flash system system.img</span><br><span class="line">#fastboot flash userdata userdata.img</span><br><span class="line">#fastboot flash cache cache.img</span><br></pre></td></tr></table></figure></p>
<p>2, Custom TWRP for Xiaomi Redmi Note 4G (twrp-3.3.1-0-dior.img - <a href="https://twrp.me/xiaomi/xiaomiredminote4gsinglesim.html" target="_blank" rel="external">https://twrp.me/xiaomi/xiaomiredminote4gsinglesim.html</a>),<br>注: 目前小米也关闭了解锁功能(<a href="https://www.miui.com/unlock/index.html)不允许行货和国际版互刷ROM" target="_blank" rel="external">https://www.miui.com/unlock/index.html)不允许行货和国际版互刷ROM</a>, 小米增加了一段区域对照码, 想绕开限制, 只有先不互刷先解锁(即国行版先刷国内ROM骗过解锁), 然后再用TWRP, fastboot或mifalsh刷机.<br>但mi note lte无须解锁, 因为’fastboot oem device-info’显示’Device unloced: true”<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ adb reboot bootloader</span><br><span class="line">$ fastboot oem device-info</span><br><span class="line">...</span><br><span class="line">(bootloader) 	Device tampered: true</span><br><span class="line">(bootloader) 	Device unlocked: true</span><br><span class="line">(bootloader) 	Charger screen enabled: false</span><br><span class="line">(bootloader) 	Display panel:</span><br><span class="line">OKAY [  0.006s]</span><br><span class="line">finished. total time: 0.006s</span><br></pre></td></tr></table></figure></p>
<p>继续刷TWRP:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://dl.twrp.me/dior/twrp-3.3.1-0-dior.img</span><br><span class="line">adb reboot bootloader              #enter fastboot mode</span><br><span class="line">#fastboot devices                     #just for case when locking BL lock</span><br><span class="line"># fastboot flash unlock unlock.key  #if need to unlock, eg https://www.techmesto.com/guide-unlock-bootloader-nokia-android-phones/</span><br><span class="line">#fastboot oem unlock</span><br><span class="line">fastboot flash recovery twrp-3.3.1-0-dior.img</span><br><span class="line">fastboot reboot</span><br></pre></td></tr></table></figure></p>
<p>但是上面刷了之后不work,, 刷了TWRP之后’adb reboot recovery’进入的还是Mi-Recovery 2.0.1模式, 官网说:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://twrp.me/xiaomi/xiaomiredminote4gsinglesim.html</span><br><span class="line">Note many devices will replace your custom recovery automatically during first boot. To prevent this, use Google to find the proper key combo to enter recovery. After typing fastboot reboot, hold the key combo and boot to TWRP. Once TWRP is booted, TWRP will patch the stock ROM to prevent the stock ROM from replacing TWRP. If you don&apos;t follow this step, you will have to repeat the install.</span><br></pre></td></tr></table></figure></p>
<p>但运行完’fastboot reboot’再按音量上键+电源键根本就进不了recovery模式, 可能是我的音量键有问题的原因吧. 此路不通.这个网页说:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://www.reddit.com/r/Xiaomi/comments/bdurg8/replace_mi_recovery_with_twrp/</span><br><span class="line">With the new protection you need to boot from adb to twrp, by fastboot boot twrp.img. When boot in twrp transfer the image and flash inside from twrp. Now, it will reboot on TWRP recovery.</span><br></pre></td></tr></table></figure></p>
<p>所以我们可以先’fastboot boot’来启动TWRP, 再将TWRP持久化. 但是试了很多多twrp版本都报下列错”dtb not found”.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ fastboot boot twrp-3.3.1-0-dior.img</span><br><span class="line">downloading &apos;boot.img&apos;...</span><br><span class="line">OKAY [  0.433s]</span><br><span class="line">booting...</span><br><span class="line">FAILED (remote: dtb not found)</span><br><span class="line">finished. total time: 0.449s</span><br></pre></td></tr></table></figure></p>
<p>无奈下载网页(<a href="http://en.miui.com/thread-213264-1-1.html" target="_blank" rel="external">http://en.miui.com/thread-213264-1-1.html</a>) 或这个网页(<a href="http://en.miui.com/thread-628692-1-1.html)上提到的twrp均可成功" target="_blank" rel="external">http://en.miui.com/thread-628692-1-1.html)上提到的twrp均可成功</a>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastboot boot twrp.img</span><br></pre></td></tr></table></figure></p>
<p>但语言却不是英语看不懂啊, 没办法, 只好在网上找一个有图的, 照着大致的位置点了.<br><img src="https://img-blog.csdnimg.cn/20190822112723313.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly96aGh1YWJqLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20190822112742744.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly96aGh1YWJqLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>上面需要事先将supersu下载放到手机上, 注意: 只有/sdcard/Download是可写的. (其他目录需要root权限运行”adb remount  #mount -o remount,rw /system”才行”.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">adb push SR5-SuperSU-v2.82-SR5-20171001224502.zip /sdcard/Download/</span><br></pre></td></tr></table></figure>
<p>这样就完成了在不替换现有的mi-recovery的情况下同时又使用TWRP安装supersu, 可参考 - <a href="https://in.c.mi.com/thread-79402-1-1.html" target="_blank" rel="external">https://in.c.mi.com/thread-79402-1-1.html</a></p>
<p>3, 可选  - 本来正常情况TWRP能直接flash的话, 应该可以这样安装supersu的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">adb reboot recovery        #enter recovery mode</span><br><span class="line">adb sideload adb sideload SR5-SuperSU-v2.82-SR5-20171001224502.zip</span><br></pre></td></tr></table></figure></p>
<p>4, 安装必要的软件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># use adb via wifi</span><br><span class="line">/su/bin/su root</span><br><span class="line">setprop service.adb.tcp.port 5555</span><br><span class="line">setprop persist.adb.tcp.port 5555</span><br><span class="line">start adbd</span><br><span class="line">adb connect 192.168.99.249:5555</span><br><span class="line">adb install Complete\ Linux\ Installer_v3.0\ BETA_apkpure.com.apk</span><br><span class="line"></span><br><span class="line">adb shell</span><br><span class="line">su</span><br><span class="line"></span><br><span class="line"># grep &apos;system&apos; /proc/mounts</span><br><span class="line">mount -o rw,remount -t ext4 /dev/block/platform/msm_sdcc.1/by-name/system /system</span><br><span class="line"></span><br><span class="line"># ssh server -  by install SSHDroid and use supersu to give it root</span><br><span class="line"></span><br><span class="line"># ssh client</span><br><span class="line">ln -s /data/data/berserker.android.apps.sshdroid/dropbear/ssh /system/bin/ssh</span><br><span class="line">chmod o+rx /system/bin/ssh</span><br><span class="line"></span><br><span class="line"># key</span><br><span class="line">cd /data/data/berserker.android.apps.sshdroid/dropbear/</span><br><span class="line">./dropbearkey -t rsa -f ../home/.ssh/id_rsa &gt; ../home/.ssh/id_rsa.pub</span><br><span class="line">cd /data/data/berserker.android.apps.sshdroid/home</span><br><span class="line">echo &apos;ssh hua@t440p -i ~/.ssh/id_rsa&apos; &gt; ./ssht440p.sh</span><br><span class="line">sh ssht440p.sh</span><br><span class="line"></span><br><span class="line"># use vi in adb shell, we don&apos;t need to add busybox prefix in ssh</span><br><span class="line">busybox vi /etc/hosts</span><br></pre></td></tr></table></figure></p>
<p>5, run ubuntu 18.04 on android by using linuxdeploy<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">#run ubuntu 18.04 on android by using linuxdeploy</span><br><span class="line">#https://www.maketecheasier.com/install-ubuntu-on-android-linux-deploy/</span><br><span class="line">wget https://github.com/meefik/busybox/releases/download/1.30.1/busybox-1.30.1-41.apk</span><br><span class="line">adb install busybox-1.30.1-41.apk  #install into /system/xbin</span><br><span class="line">wget https://github.com/meefik/linuxdeploy/releases/download/2.4.0/linuxdeploy-2.4.0-251.apk</span><br><span class="line">adb install linuxdeploy-2.4.0-251.apk</span><br><span class="line">adb install vnc_viewer_remote_desktop.apk</span><br><span class="line"></span><br><span class="line">#enter linuxdeploy</span><br><span class="line">telnet 192.168.99.249 5023</span><br><span class="line"></span><br><span class="line">#but hit the error: chroot: can&apos;t execute &apos;/bin/su&apos;: No such file or directory</span><br><span class="line">/su/bin/su root</span><br><span class="line">/data/user/0/ru.meefik.linuxdeploy/files/bin/linuxdeploy shell</span><br><span class="line">mkdir /data/local/mnt/&#123;dev,sys,proc&#125;</span><br><span class="line">#for d in dev sys proc; do mount -o bind /$d /data/local/mnt/$d; done</span><br><span class="line">#umount /data/local/mnt/&#123;dev,proc,sys&#125;</span><br><span class="line">chroot /data/local/mnt/ /bin/pwd</span><br><span class="line">ls /data/local/mnt/bin/su</span><br><span class="line"></span><br><span class="line">上面的chroot错误实际上是image文件没有创建的原因</span><br><span class="line">ls /data/data/ru.meefik.linuxdeploy/files/config/linux.conf</span><br><span class="line">rm -rf /sdcard/linux.img</span><br><span class="line">vi /data/user/0/ru.meefik.linuxdeploy/files/include/bootstrap/rootfs/deploy.sh</span><br><span class="line"></span><br><span class="line">20191012更新</span><br><span class="line">架构使用armhf，源使用http://mirrors.ustc.edu.cn/ubuntu-ports/时可以进入debootstrap了， 但是在lsb_base这步总是出错， 怀疑是科大的源有问题， 所以换成腾讯的源https://mirrors.cloud.tencent.com/ubuntu-ports/后可以debootstrap成功， 但是在chroot /data/local/mnt bin/su - root -c &apos;DEBIAN_FRONTEND=nointeractive apt-get install -yfq --no-install-recommends dbus&apos;这步也是相当地慢(才0.10k/s)，不得已， 又退回使用http://ports.ubuntu.com/ubuntu-ports/， 然后就成功了， 在手机上通过‘ssh ubuntu@localhost’登录bionic。</span><br><span class="line">1, 但ubuntu里的chrome仍然无法在外面使用，而使用android版本的chrome又无法打开SF(需要设置浏览器中的查看桌面版网页，但仍然无法选择sf owner), 试试microsoft edge</span><br><span class="line">2, 下面adb或者ssh两种方式连接手机</span><br><span class="line">/su/bin/su root</span><br><span class="line">setprop service.adb.tcp.port 5555</span><br><span class="line">setprop persist.adb.tcp.port 5555</span><br><span class="line">start adbd</span><br><span class="line">adb connect 192.168.99.249:5555</span><br><span class="line">adb devices</span><br><span class="line">3, 手机外接大屏幕的话，采用android中的”无线投屏&quot;或者在连接好adb之后运行“sudo snap install --channel=edge scrcpy &amp;&amp; scrcpy --fullscreen --show-touches --bit-rate 2M --max-size 800&quot; (注：若电脑的scrcpy容器是黑屏的话是因为手机是黑屏的）</span><br><span class="line"></span><br><span class="line">若手机未root的话, 可以这个投屏:</span><br><span class="line">将手机与电脑连接至相同wifi 记录WLAN设置中手机的IP地址</span><br><span class="line">连接数据线并允许调试</span><br><span class="line">终端执行 adb tcpip 5555 并在手机上点击“ 确定 ” ( 即在手机上开启5555端口 )</span><br><span class="line">终端执行 adb connect [手机IP]:5555 并在手机上点击“ 确定 ”( 此处可用 adb devices 检查连接情况 )</span><br><span class="line">拔掉数据线</span><br><span class="line">终端执行 adb reconnect offline 强制未授权设备重新连接</span><br><span class="line">终端执行 adb connect [手机IP]:5555 重新进行连接 ( 此处可用 adb devices 检查连接情况 )</span><br><span class="line">scrcpy --fullscreen --show-touches --bit-rate 2M --max-size 800</span><br><span class="line">想用声音的话, 可结合usbaudio - https://github.com/rom1v/usbaudio , 但是似乎usbaudio不支持android 8.1以上版本了</span><br></pre></td></tr></table></figure></p>
<h2 id="root-redmi4x-20200618更新"><a href="#root-redmi4x-20200618更新" class="headerlink" title="root redmi4x - 20200618更新"></a>root redmi4x - 20200618更新</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">安装要用到的软件</span><br><span class="line">1, xiaomi redmi 4x usb driver (Universal ADB Driver V6.0.zip - https://www.skyneel.com/xiaomi-usb-driver)</span><br><span class="line">2, xiaomi redmi 4x unlock bootloader (miflash_unlock-en-4.5.514.47.zip - https://en.miui.com/unlock/）</span><br><span class="line">3, xiaomi redmi 4x TWRP recovery (twrp-3.3.1-0-santoni.img - https://www.skyneel.com/supersu-zip-app)</span><br><span class="line">4, xiaomi redmi 4x supersu (UPDATE-SuperSU-v2.82-20170528234214.zip - https://www.skyneel.com/supersu-zip-app)</span><br><span class="line">5, xiaomi redmi 4x adb/fast-boot tool (platform-tools_r30.0.2-windows.zip - https://developer.android.com/studio/releases/platform-tools)</span><br><span class="line">6, [option] mi flash (https://www.skyneel.com/xiaomi-mi-flash-tool)</span><br><span class="line"></span><br><span class="line">unlock bootloader</span><br><span class="line">#https://www.skyneel.com/unlock-bootloader-xiaomi-devices</span><br><span class="line">1, 打开开发者模式， 并在开发者模式中打开USB调试， 并同时打开充许OEM解锁</span><br><span class="line">2, 先关机，USB线连上， 然后长按音量下+电源键进入fastboot模式, ( 注: 音量上+电源键是安装第三方recovery)</span><br><span class="line">3 , 并用这个手机的小米帐号登录后解锁手机。</span><br><span class="line">注: 目前小米也关闭了解锁功能(https://www.miui.com/unlock/index.html)不允许行货和国际版互刷ROM, 小米增加了一段区域对照码, 想绕开限制, 只有先不互刷先解锁(即国行版先刷国内ROM骗过解锁), 然后再用TWRP, fastboot或mifalsh刷机. 见我之前的一篇博客.</span><br><span class="line">mi note lte无须解锁, 因为’fastboot oem device-info’显示’Device unloced: true&quot;</span><br><span class="line">redmi 4x采用此段方法解锁</span><br><span class="line"></span><br><span class="line">flash TWRP</span><br><span class="line">1, usb连接手机，并在手机上点击信任后， 就可以使用adb命令了</span><br><span class="line">D:\&gt;adb devices</span><br><span class="line">List of devices attached</span><br><span class="line">aa89d2927d93    device</span><br><span class="line">2, 进入bootloader模式： adb reboot bootloader</span><br><span class="line">3, 因为上面我们已经unlock bootloader了， 所以&apos;fastboot devices&apos;能看到东西</span><br><span class="line">E:\tools\redmi4x&gt;fastboot devices</span><br><span class="line">aa89d2927d93    fastboot</span><br><span class="line">4， fastboot.exe flash recovery twrp-3.3.1-0-santoni.img - fastboot.exe flash recovery twrp-3.3.1-0-santoni.img</span><br><span class="line">5, fastboot reboot</span><br><span class="line">6, 刷TWRP成功后， 再使用&apos;adb reboot recovery&apos;命令(相当于音量上+电源键的recovery模式)就能看到TWRP界面了， 而不是mi-recovery 3.0了</span><br><span class="line">但上面recovery twrp-3.3.1-0-santoni.img刷了之后不work, 进入的还是mi-recovery, 这时就又相当于我之前的一篇博客遇到的问题了（https://blog.csdn.net/quqi99/article/details/73613138), 所以得在不替换现有的mi-recovery的情况下同时又使用TWRP（fastboot boot twrp-3.3.1-0-santoni.img）安装supersu（可参考 - https://in.c.mi.com/thread-79402-1-1.html）</span><br></pre></td></tr></table></figure>
<p>完整步骤:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">1, set up adb</span><br><span class="line"></span><br><span class="line">sudo apt-get install android-tools-adb android-tools-fastboot</span><br><span class="line">sudo bash -c &apos;cat &gt; /etc/udev/rules.d/51-android.rules&apos; &lt;&lt; EOF</span><br><span class="line">EOF</span><br><span class="line">sudo udevadm control --reload-rules &amp;&amp; sudo udevadm trigger</span><br><span class="line">adb kill-server &amp;&amp; adb start-server</span><br><span class="line">sudo mtp-detect</span><br><span class="line">adb devices</span><br><span class="line"></span><br><span class="line">2, enable developer mode, and enable usb debugging and OEM unlock in developer mode</span><br><span class="line"></span><br><span class="line">3, unlock bootloader in the page https://www.miui.com/unlock/index.html</span><br><span class="line"></span><br><span class="line">4, install global developer firmware because supersu can only be used in developer version</span><br><span class="line"></span><br><span class="line">#click &apos;Global -&gt; Fast boot Developer&apos; in https://mifirm.net/model/santoni.ttt to find download link</span><br><span class="line">axel http://bigota.d.miui.com/9.6.27/santoni_global_images_9.6.27_20190627.0000.00_7.1_global_67dc2b29e2.tgz</span><br><span class="line">tar -xf santoni_global_images_9.6.27_20190627.0000.00_7.1_global_67dc2b29e2.tgz</span><br><span class="line">adb reboot bootloader</span><br><span class="line">cd santoni_global_images_9.6.27_20190627.0000.00_7.1_global_67dc2b29e2 &amp;&amp; ./flash_all.sh</span><br><span class="line"></span><br><span class="line">5, then repeat the step 2 in new global deveoper version</span><br><span class="line"></span><br><span class="line">6, copy supersu into your cellphone</span><br><span class="line"></span><br><span class="line">adb push UPDATE-SuperSU-v2.82-20170528234214.zip /sdcard/Download/</span><br><span class="line">adb shell -- ls /sdcard/Download/</span><br><span class="line"></span><br><span class="line">7, boot from twrp instead of mi-recovery temporaily one time to install supersu</span><br><span class="line"></span><br><span class="line">adb reboot bootloader</span><br><span class="line">fastboot oem device-info   #double confim uncloked=true</span><br><span class="line">fastboot boot twrp-3.2.3-0-santoni.img</span><br><span class="line">#then install supersu from the GUI</span><br><span class="line"></span><br><span class="line">8, use supersu</span><br><span class="line"></span><br><span class="line">adb root</span><br><span class="line">/su/bin/su root</span><br><span class="line">setprop service.adb.tcp.port 5555</span><br><span class="line">setprop persist.adb.tcp.port 5555</span><br><span class="line">start adbd</span><br><span class="line">adb connect 192.168.99.249:5555</span><br><span class="line">adb devices</span><br></pre></td></tr></table></figure>
<p>[1] <a href="https://news.mydrivers.com/1/596/596856.htm" target="_blank" rel="external">https://news.mydrivers.com/1/596/596856.htm</a><br>[2] <a href="http://en.miui.com/thread-140154-1-1.html" target="_blank" rel="external">http://en.miui.com/thread-140154-1-1.html</a><br>[3] <a href="http://www.miui.com/thread-9286730-1-1.html" target="_blank" rel="external">http://www.miui.com/thread-9286730-1-1.html</a><br>[4] <a href="https://mrxn.net/other/xiaominote-shuaji.html" target="_blank" rel="external">https://mrxn.net/other/xiaominote-shuaji.html</a><br>[5] <a href="http://en.miui.com/forum.php?mod=viewthread&amp;tid=279802" target="_blank" rel="external">http://en.miui.com/forum.php?mod=viewthread&amp;tid=279802</a><br>[6] <a href="http://www.miui.com/thread-9286730-1-1.html" target="_blank" rel="external">http://www.miui.com/thread-9286730-1-1.html</a><br>[7] <a href="https://www.getdroidtips.com/custom-rom-redmi-note-4g/" target="_blank" rel="external">https://www.getdroidtips.com/custom-rom-redmi-note-4g/</a><br>[8] <a href="https://www.getdroidtips.com/official-twrp-recovery-for-xiaomi-redmi-note-4g/" target="_blank" rel="external">https://www.getdroidtips.com/official-twrp-recovery-for-xiaomi-redmi-note-4g/</a><br>[9] <a href="https://mi-globe.com/miui-firmware-rom-builder/" target="_blank" rel="external">https://mi-globe.com/miui-firmware-rom-builder/</a><br>[10] <a href="https://xiaomi.eu/community/threads/9-8-15.51822/" target="_blank" rel="external">https://xiaomi.eu/community/threads/9-8-15.51822/</a><br>[11] <a href="https://aubykhan.wordpress.com/2013/07/21/android-tip-boot-into-twrp-or-cwm-recovery-without-flashing/" target="_blank" rel="external">https://aubykhan.wordpress.com/2013/07/21/android-tip-boot-into-twrp-or-cwm-recovery-without-flashing/</a><br>[11] <a href="https://qc5.androidfilehost.com/dl/hhcuqmQO_jb6GzZK8aDvbw/1566669181/24421527759888026/TWRP_virgo.zip" target="_blank" rel="external">https://qc5.androidfilehost.com/dl/hhcuqmQO_jb6GzZK8aDvbw/1566669181/24421527759888026/TWRP_virgo.zip</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/24/如何让OpenStack支持多个FIP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/24/如何让OpenStack支持多个FIP/" itemprop="url">如何让OpenStack支持多个FIP</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-24T20:24:20+08:00">
                2019-04-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2019-04-24)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>OpenStack可以支持多个公网IP吗?<br>OpenStack CLI不支持将同一个子网的多个FIPs分配给同一个fixed_ip的接口. 最简单的方法是直接分配FIP后手工配置在qrouter-xxx上, 并且手工做DNAT/SNAT. 但还有其他更好的方法吗?</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo ip netns exec qrouter-9843a7c4-f1e7-4ea0-b031-c1a0428795be ip addr add 10.5.150.15 dev qg-60d62ebb-47</span><br><span class="line"></span><br><span class="line">sudo ip netns exec qrouter-9843a7c4-f1e7-4ea0-b031-c1a0428795be iptables -t nat -A neutron-l3-agent-OUTPUT -d 10.5.150.15/32 -j DNAT --to-destination 192.168.22.53</span><br><span class="line">sudo ip netns exec qrouter-9843a7c4-f1e7-4ea0-b031-c1a0428795be iptables -t nat -A neutron-l3-agent-PREROUTING -d 10.5.150.15/32 -j DNAT --to-destination 192.168.22.53</span><br><span class="line">sudo ip netns exec qrouter-9843a7c4-f1e7-4ea0-b031-c1a0428795be iptables -t nat -A neutron-l3-agent-float-snat -s 192.168.22.53/32 -j SNAT --to-source 10.5.150.15</span><br><span class="line"></span><br><span class="line">ubuntu@juju-54f223-pike-5:~$ ping 10.5.150.15</span><br><span class="line">PING 10.5.150.15 (10.5.150.15) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.5.150.15: icmp_seq=1 ttl=63 time=3.25 ms</span><br></pre></td></tr></table></figure>
<h2 id="创建多个tenant子网"><a href="#创建多个tenant子网" class="headerlink" title="创建多个tenant子网"></a>创建多个tenant子网</h2><p>创建多个tenant子网(fixed_ip), 将这些子网分配给VM, 然后再将多个FIP分别和这些tenant port关联. 结果是虚机内部多个网卡造成了不对称路由问题, 引入policy route之后解决了outbound的问题, 但仍然无法解决inbound的问题.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">step 1, created a test VM with the network private (192.168.21.0/24) and a fix_ip 192.168.21.5 and a FIP 10.5.150.2</span><br><span class="line"></span><br><span class="line">openstack server create --wait --image bionic --flavor m1.small --key-name mykey --nic net-id=e4074ac4-3c48-41f2-81e2-5a798468bf88 --min 1 --max 1 test</span><br><span class="line">fix_ip=&quot;192.168.21.5&quot;</span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address $fix_ip --port $(openstack port list --fixed-ip ip-address=$fix_ip -c id -f value)</span><br><span class="line"></span><br><span class="line">step 2, created another network private2 (192.168.22.0/24) and attach another interface into the test VM, then allocated a FIP (192.168.22.53) for it (192.168.22.51)</span><br><span class="line"></span><br><span class="line">openstack network create private2</span><br><span class="line">openstack subnet create --subnet-range 192.168.22.0/24 --network private2 --allocation-pool start=192.168.22.50,end=192.168.22.100 --gateway 192.168.22.1 priavte2-subnet</span><br><span class="line">openstack router add subnet provider-router priavte2-subnet</span><br><span class="line">nova interface-attach $(openstack server list -f value |awk &apos;/test/ &#123;print $1&#125;&apos;) --net-id=$(openstack network list -f value |awk &apos;/private2/ &#123;print $1&#125;&apos;)</span><br><span class="line">ssh ubuntu@10.5.150.2 -- sudo ifconfig ens5 up</span><br><span class="line"># then connection is disconnect because the default route moves from ens2 to ens5</span><br><span class="line">ssh ubuntu@10.5.150.2 -- dhcpclient ens5</span><br><span class="line"></span><br><span class="line">Finally it looks like - https://paste.ubuntu.com/p/yMJpJXYqDY/</span><br><span class="line"></span><br><span class="line">step 3, now the default gw is in ens5 so we can ping external inside test VM</span><br><span class="line"></span><br><span class="line">root@test:~# ping -I ens2 10.230.65.38</span><br><span class="line">PING 10.230.65.38 (10.230.65.38) from 192.168.21.5 ens2: 56(84) bytes of data.</span><br><span class="line">root@test:~# ping -I ens5 10.230.65.38</span><br><span class="line">PING 10.230.65.38 (10.230.65.38) from 192.168.22.53 ens5: 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.230.65.38: icmp_seq=1 ttl=62 time=3.34 ms</span><br><span class="line"></span><br><span class="line">step 4, outbound traffic works after adding policy router rules.</span><br><span class="line"></span><br><span class="line">echo &quot;1 t21&quot; &gt;&gt; /etc/iproute2/rt_tables</span><br><span class="line">ip route add 192.168.21.0/24 dev ens2 src 192.168.21.5 table t21</span><br><span class="line">ip route add default via 192.168.21.5 dev ens2 table t21</span><br><span class="line">ip rule add from 192.168.21.5/24 table t21</span><br><span class="line"></span><br><span class="line">root@test:~# ping -I ens2 10.230.65.38</span><br><span class="line">PING 10.230.65.38 (10.230.65.38) from 192.168.21.5 ens2: 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.230.65.38: icmp_seq=1 ttl=62 time=6.28 ms</span><br><span class="line">root@test:~# ping -I ens5 10.230.65.38</span><br><span class="line">PING 10.230.65.38 (10.230.65.38) from 192.168.22.53 ens5: 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.230.65.38: icmp_seq=1 ttl=62 time=4.90 ms</span><br><span class="line"></span><br><span class="line">step 5, but inbound traffic for two FIPs can&apos;t work at the same time</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ ping -c 1 10.5.150.2</span><br><span class="line">PING 10.5.150.2 (10.5.150.2) 56(84) bytes of data.</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ ping -c 1 10.5.150.8</span><br><span class="line">PING 10.5.150.8 (10.5.150.8) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.5.150.8: icmp_seq=1 ttl=63 time=3.41 ms</span><br></pre></td></tr></table></figure></p>
<h2 id="创建多个FIP子网"><a href="#创建多个FIP子网" class="headerlink" title="创建多个FIP子网"></a>创建多个FIP子网</h2><p>创建多个外部网络的方法也不可行, 因为多个外部网络意味着多个router, 但无法将一个tenant subnet添加到多个routers中去:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ neutron router-interface-add provider-router2 private_subnet</span><br><span class="line">IP address 192.168.21.1 already allocated in subnet ada0b5b0-6780-4131-b07b-cee7069eab8d</span><br><span class="line">Neutron server returns request_ids: [&apos;req-8110ac5c-94ca-4b15-bf72-e199b635aa6f&apos;]</span><br></pre></td></tr></table></figure></p>
<p>这样在为一个port关联多个FIPs时报下列错误<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ neutron floatingip-associate $(neutron floatingip-list |grep $fip2 |awk &apos;&#123;print $2&#125;&apos;) $(neutron port-list |grep $fix_ip |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">External network 30769889-a664-4d99-8035-047773d2031c is not reachable from subnet ada0b5b0-6780-4131-b07b-cee7069eab8d.  Therefore, cannot associate Port 7e8d017b-8e1d-4f8f-98cd-9de3fe52c687 with a Floating IP.</span><br><span class="line">Neutron server returns request_ids: [&apos;req-76951e0d-aff8-4106-826c-72d99fe03c2d&apos;]</span><br></pre></td></tr></table></figure></p>
<p>具体测试方法如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"># Created another FIP network for test</span><br><span class="line"></span><br><span class="line"># first provides the physical network in the underlying OpenStack of sts-stack</span><br><span class="line">source ~/novarc</span><br><span class="line">openstack router create zhhuabj_router2</span><br><span class="line">openstack network create --disable-port-security zhhuabj_admin_net2</span><br><span class="line">openstack subnet create --subnet-range 10.10.0.0/24 --network zhhuabj_admin_net2 --allocation-pool start=10.10.0.50,end=10.10.0.100 --gateway 10.10.0.1 zhhuabj_admin_net2_subnet</span><br><span class="line">openstack router add subnet zhhuabj_router2 zhhuabj_admin_net2</span><br><span class="line">openstack router set --external-gateway zhhuabj_admin_net2 zhhuabj_router2</span><br><span class="line"></span><br><span class="line"># For convenience of management, add a ip address from this network into bastion</span><br><span class="line">source ~/novarc</span><br><span class="line">nova interface-attach $(nova list |grep zhhuabj-bastion |awk &apos;&#123;print $2&#125;&apos;) --net-id=$(neutron net-show zhhuabj_admin_net2 -c id -f value)</span><br><span class="line">sudo ip addr add 10.10.0.58/24 dev ens9</span><br><span class="line">sudo ip link set dev ens9 up</span><br><span class="line"></span><br><span class="line"># then defines the flat provider network in the upper OpenStack of sts-stack</span><br><span class="line">juju deploy ./b/openstack.yaml</span><br><span class="line">./configre</span><br><span class="line">source ~/novarc &amp;&amp; nova interface-attach $(nova list |grep $(juju ssh neutron-gateway/0 -- hostname) |awk &apos;&#123;print $2&#125;&apos;) --net-id=$(neutron net-show zhhuabj_admin_net2 -c id -f value)</span><br><span class="line">juju ssh neutron-gateway/0 -- sudo ovs-vsctl add-br br-data2</span><br><span class="line">juju ssh neutron-gateway/0 -- sudo ovs-vsctl add-port br-data2 ens7</span><br><span class="line">juju ssh neutron-gateway/0 -- sudo ifconfig ens7 up</span><br><span class="line">juju config neutron-gateway bridge-mappings=&quot;physnet1:br-data physnet2:br-data2&quot;</span><br><span class="line">juju config neutron-gateway data-port=&quot;br-data:fa:16:3e:45:fc:23 br-data2:ens7&quot;</span><br><span class="line">juju config neutron-api flat-network-providers=&quot;physnet1 physnet2&quot;</span><br><span class="line">juju ssh neutron-gateway/0 -- sudo systemctl restart neutron-openvswitch-agent.service</span><br><span class="line"></span><br><span class="line">source stsstack-bundles/openstack/novarc</span><br><span class="line">neutron net-create --shared --router:external --provider:network_type flat --provider:physical_network physnet2 ext_net2</span><br><span class="line">neutron subnet-create --name ext_net2_subnet --gateway 10.10.0.1 --allocation-pool start=10.10.0.60,end=10.10.0.70 --disable-dhcp ext_net2 10.10.0.0/24</span><br><span class="line">neutron router-create provider-router2</span><br><span class="line">neutron router-gateway-set provider-router2 ext_net2</span><br><span class="line"># OpenStack doesn&apos;t support add the same subnet into multiple routers</span><br><span class="line"># neutron router-interface-add provider-router2 private_subnet</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ neutron router-interface-add provider-router2 private_subnet</span><br><span class="line">IP address 192.168.21.1 already allocated in subnet ada0b5b0-6780-4131-b07b-cee7069eab8d</span><br><span class="line">Neutron server returns request_ids: [&apos;req-8110ac5c-94ca-4b15-bf72-e199b635aa6f&apos;]</span><br><span class="line"></span><br><span class="line"># Create a test VM and allocate two FIPs to it from two FIP pool</span><br><span class="line">./tools/instance_launch.sh 1 xenial</span><br><span class="line">./tools/sec_groups.sh</span><br><span class="line">fix_ip=$(openstack server list -f value |awk &apos;/xenial/ &#123;print $4&#125;&apos; |awk -F &apos;=&apos; &apos;&#123;print $2&#125;&apos; |awk -F &apos;,&apos; &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">ext_net=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $ext_net -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address $fix_ip --port $(openstack port list --fixed-ip ip-address=$fix_ip -c id -f value)</span><br><span class="line">ext_net2=$(openstack network show ext_net2 -f value -c id)</span><br><span class="line">fip2=$(openstack floating ip create $ext_net2 -f value -c floating_ip_address)</span><br><span class="line">neutron floatingip-associate $(neutron floatingip-list |grep $fip2 |awk &apos;&#123;print $2&#125;&apos;) $(neutron port-list |grep $fix_ip |awk &apos;&#123;print $2&#125;&apos;)</span><br></pre></td></tr></table></figure>
<h2 id="使用flat-provider-network"><a href="#使用flat-provider-network" class="headerlink" title="使用flat provider network"></a>使用flat provider network</h2><p>使用flat provider network, 虚机内虽然也有多个网卡, 但因为虚机内的网卡和虚机外的网卡属于同一相flat网络并不存在路径选择问题, 结果证明可行.<br>第一步, 继续需要为计算结点准备外部网卡<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">source ~/novarc &amp;&amp; nova interface-attach $(nova list |grep $(juju ssh nova-compute/0 -- hostname) |awk &apos;&#123;print $2&#125;&apos;) --net-id=$(neutron net-show zhhuabj_admin_net2 -c id -f value)</span><br><span class="line">juju ssh nova-compute/0 -- sudo ovs-vsctl add-br br-data2</span><br><span class="line">juju ssh nova-compute/0 -- sudo ovs-vsctl add-port br-data2 ens7</span><br><span class="line">juju ssh nova-compute/0 -- sudo ifconfig ens7 up</span><br><span class="line">juju config neutron-openvswitch bridge-mappings=&quot;physnet1:br-data physnet2:br-data2&quot;</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data2:ens7&quot;</span><br><span class="line">#juju config neutron-api flat-network-providers=&quot;physnet1 physnet2&quot;</span><br><span class="line"></span><br><span class="line">source ~/novarc &amp;&amp; nova interface-attach $(nova list |grep $(juju ssh nova-compute/0 -- hostname) |awk &apos;&#123;print $2&#125;&apos;) --net-id=$(neutron net-show zhhuabj_admin_net -c id -f value)</span><br><span class="line">#juju ssh nova-compute/0 -- sudo ovs-vsctl add-br br-data</span><br><span class="line">juju ssh nova-compute/0 -- sudo ovs-vsctl add-port br-data ens9</span><br><span class="line">juju ssh nova-compute/0 -- sudo ifconfig ens9 up</span><br><span class="line">#juju config neutron-openvswitch bridge-mappings=&quot;physnet1:br-data physnet2:br-data2&quot;</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens9 br-data2:ens7&quot;</span><br><span class="line">#juju config neutron-api flat-network-providers=&quot;physnet1 physnet2&quot;</span><br></pre></td></tr></table></figure></p>
<p>第二步, 创建flat网络</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">neutron net-create ext_net2 --provider:network_type flat --provider:physical_network physnet2 --router:external=True --shared</span><br><span class="line">neutron subnet-create --name ext_net2_subnet --enable_dhcp=False --allocation_pool start=10.10.0.60,end=10.10.0.70 --gateway=10.10.0.1 ext_net2 10.10.0.0/24</span><br></pre></td></tr></table></figure>
<p>第三步, 创建测试虚机, 记得使用一个tenant private network避免引入metadata的问题.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nova keypair-add --pub-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">openstack server create --wait --image xenial --flavor m1.small --key-name mykey --network=private i1</span><br><span class="line">nova interface-attach $(nova list |grep i1 |awk &apos;&#123;print $2&#125;&apos;) --net-id=$(neutron net-show ext_net -c id -f value)</span><br><span class="line">nova interface-attach $(nova list |grep i1 |awk &apos;&#123;print $2&#125;&apos;) --net-id=$(neutron net-show ext_net2 -c id -f value)</span><br></pre></td></tr></table></figure></p>
<p>第四步, 因为我们的外部网络都没有使用dhcp, 所以需要登录虚机手动设置IP.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ nova list</span><br><span class="line">+--------------------------------------+------+--------+------------+-------------+----------------------------------------------------------------+</span><br><span class="line">| ID                                   | Name | Status | Task State | Power State | Networks                                                       |</span><br><span class="line">+--------------------------------------+------+--------+------------+-------------+----------------------------------------------------------------+</span><br><span class="line">| 45083dc2-c72e-4201-b35c-6d0f6ef3712a | i1   | ACTIVE | -          | Running     | ext_net=10.5.150.8; ext_net2=10.10.0.64; private=192.168.21.13 |</span><br><span class="line">+--------------------------------------+------+--------+------------+-------------+----------------------------------------------------------------+</span><br><span class="line">juju ssh neutron-gateway/0</span><br><span class="line">sudo ip netns exec qrouter-8b597dd0-49b3-40e3-8e0e-c035d8535cae ssh -i /home/ubuntu/id_rsa ubuntu@192.168.21.13</span><br><span class="line">$ sudo ifconfig ens5 up</span><br><span class="line">$ sudo ifconfig ens6 up</span><br><span class="line">$ sudo ip addr add 10.5.150.8/16 dev ens5</span><br><span class="line">$ sudo ip addr add 10.10.0.64/24 dev ens6</span><br></pre></td></tr></table></figure>
<p>第五步, 测试.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ ping 10.5.150.8</span><br><span class="line">PING 10.5.150.8 (10.5.150.8) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.5.150.8: icmp_seq=1 ttl=64 time=5.07 ms</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ ping 10.10.0.64</span><br><span class="line">PING 10.10.0.64 (10.10.0.64) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.10.0.64: icmp_seq=1 ttl=64 time=4.16 ms</span><br><span class="line"></span><br><span class="line">ubuntu@i1:~$ ping -c 1 10.10.0.58</span><br><span class="line">PING 10.10.0.58 (10.10.0.58) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.10.0.58: icmp_seq=1 ttl=64 time=2.21 ms</span><br><span class="line">ubuntu@i1:~$ ping -c 1 10.5.0.8</span><br><span class="line">PING 10.5.0.8 (10.5.0.8) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.5.0.8: icmp_seq=1 ttl=64 time=2.18 ms</span><br></pre></td></tr></table></figure></p>
<p>注: 若报下列这种错误, 是因为没有做第一步创建br-data2及相关的NIC.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ nova interface-attach $(nova list |grep i1 |awk &apos;&#123;print $2&#125;&apos;) --net-id=$(neutron net-show ext_net2 -c id -f value)</span><br><span class="line">neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.</span><br><span class="line">ERROR (ClientException): Unexpected API Error. Please report this at http://bugs.launchpad.net/nova/ and attach the Nova API log if possible.</span><br><span class="line">&lt;class &apos;PortBindingFailed_Remote&apos;&gt; (HTTP 500) (Request-ID: req-38c9faad-872c-43c4-921d-798b31bff548)</span><br></pre></td></tr></table></figure></p>
<h2 id="更近一步考虑"><a href="#更近一步考虑" class="headerlink" title="更近一步考虑"></a>更近一步考虑</h2><p>如果设置”juju config neutron-openvswitch enable-local-dhcp-and-metadata=True”这样可以省掉计算节点的网卡, 这样计算节点原先用于连l3-agent的网卡(现在不需要l3-agent了, 同时dhcp-agent与metadata-agent挪到了计算节点上)可以挪出来用于provider network. (<strong>注意: 至少需要两个网卡的, 一个管理用的, 一个用来做data-port的, data-port最终用在bridge-mapping中用在vlan与flat之类的provider network中, 但是对在dvr这种provider network是必须要一个的</strong>) 所以对于flat之前的:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">juju config neutron-openvswitch enable-local-dhcp-and-metadata=False</span><br><span class="line">juju config neutron-openvswitch bridge-mappings=&quot;physnet1:br-data physnet2:br-data2&quot;</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens9 br-data2:ens7&quot;</span><br><span class="line">juju config neutron-api flat-network-providers=&quot;physnet1 physnet2&quot;</span><br></pre></td></tr></table></figure></p>
<p>变成了:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">juju config neutron-openvswitch enable-local-dhcp-and-metadata=True</span><br><span class="line">juju config neutron-openvswitch bridge-mappings=&quot;physnet1:br-data&quot;</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens9&quot;</span><br><span class="line">juju config neutron-api flat-network-providers=&quot;physnet1&quot;</span><br></pre></td></tr></table></figure></p>
<p>或者:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./generate-bundle.sh --name octavia --create-model --run --octavia -r stein --dvr-snat --num-compute 2</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens7&quot;</span><br><span class="line">./bin/add-data-ports.sh</span><br></pre></td></tr></table></figure></p>
<p>如果是vlan, 则:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">juju config neutron-openvswitch enable-local-dhcp-and-metadata=True</span><br><span class="line">juju config neutron-openvswitch bridge-mappings=&quot;physnet1:br-data&quot;</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens9&quot;</span><br><span class="line">juju config neutron-api vlan-ranges=&quot;physnet1:1000:2000&quot;</span><br><span class="line"># must configure external switch to truck mode to allow vlan 1000 to 2000</span><br><span class="line">neutron net-create net1 --provider:network_type vlan --provider:physical_network physnet1 --provider:segmentation_id 1001</span><br><span class="line">neutron net-create net1 --provider:network_type vlan --provider:physical_network physnet1 --provider:segmentation_id 1002</span><br></pre></td></tr></table></figure></p>
<p>如果将provider network 共享给其他tenant的话, 可以加–shared参数:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">neutron net-create ext_net2 --provider:network_type flat --provider:physical_network physnet2 --router:external=True --shared</span><br></pre></td></tr></table></figure></p>
<p>或者使用rbac特性 (<a href="https://docs.openstack.org/neutron/pike/admin/config-rbac.html" target="_blank" rel="external">https://docs.openstack.org/neutron/pike/admin/config-rbac.html</a> )<br>如果使用dvr, 还可以让l3ha与dvr共存, 并且使用use-dvr-snat=true充许将网关运行在计算节点(<strong>dvr_snat模式会在计算节点上也创建snat-xxx名空间作为主, 同时neutron-gateway上的snat-xxx由l3ha特性作为副</strong> )上. 见: <a href="https://review.opendev.org/#/c/624495/" target="_blank" rel="external">https://review.opendev.org/#/c/624495/</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">juju config neutron-api enable-dvr=True</span><br><span class="line">juju config neutron-api enable-l3ha=true</span><br><span class="line">juju config neutron-openvswitch use-dvr-snat=True</span><br></pre></td></tr></table></figure></p>
<p>测试DVR的情况如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">./generate-bundle.sh --series xenial --release queens</span><br><span class="line">juju add-model dvr-lp1825966</span><br><span class="line">juju deploy ./b/openstack.yaml</span><br><span class="line"># just flat/vlan need this extra NIC</span><br><span class="line">#source ~/novarc &amp;&amp; nova interface-attach $(nova list |grep $(juju ssh nova-compute/1 -- hostname) |awk &apos;&#123;print $2&#125;&apos;) --net-id=$(neutron net-show zhhuabj_admin_net -c id -f value)</span><br><span class="line">./bin/add-data-ports.sh</span><br><span class="line"></span><br><span class="line">#juju config neutron-openvswitch bridge-mappings=&quot;physnet1:br-data&quot;</span><br><span class="line">#juju config neutron-api flat-network-providers=&quot;physnet1&quot;</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens7&quot;</span><br><span class="line"></span><br><span class="line">juju config neutron-api flat-network-providers=&quot;physnet1&quot;</span><br><span class="line"># vlan - must configure external switch to truck mode to allow vlan 1000 to 2000</span><br><span class="line">#juju config neutron-api vlan-ranges=&quot;physnet1:1000:2000&quot;</span><br><span class="line">#neutron net-create net1 --provider:network_type vlan --provider:physical_network physnet1 --provider:segmentation_id 1001</span><br><span class="line">#neutron net-create net1 --provider:network_type vlan --provider:physical_network physnet1 --provider:segmentation_id 1002</span><br><span class="line"></span><br><span class="line">git clone https://github.com/openstack/charm-neutron-openvswitch.git neutron-openvswitch</span><br><span class="line">cd neutron-openvswitch/</span><br><span class="line">patch -p1 &lt; 0001-Enable-keepalived-VRRP-health-check.patch</span><br><span class="line">juju upgrade-charm neutron-openvswitch --path $PWD</span><br><span class="line"></span><br><span class="line">juju config neutron-api enable-dvr=True</span><br><span class="line">juju config neutron-openvswitch use-dvr-snat=True</span><br><span class="line">juju config neutron-api enable-l3ha=true</span><br><span class="line">juju config neutron-openvswitch enable-local-dhcp-and-metadata=True</span><br><span class="line"></span><br><span class="line">./configure</span><br><span class="line">./tools/sec_groups.sh</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line"># non-flat tenant router</span><br><span class="line">neutron router-show provider-router</span><br><span class="line">#neutron router-update --admin-state-up False provider-router</span><br><span class="line">#neutron router-update provider-router --distributed True --ha=True</span><br><span class="line">#neutron router-update --admin-state-up True provider-router</span><br><span class="line"></span><br><span class="line"># can use flat network ext_net directly by using enable-local-dhcp-and-metadata=True to bypass metadata feature instead of using tenant network</span><br><span class="line"># but ext_net without dhcp, so vm can&apos;t get IP</span><br><span class="line">openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">nova boot --key-name mykey --image xenial --flavor m1.small --nic net-id=$(neutron net-list |grep &apos; ext_net &apos; |awk &apos;&#123;print $2&#125;&apos;) i1</span><br><span class="line">nova boot --key-name mykey --image xenial --flavor m1.small --nic net-id=$(neutron net-list |grep &apos; private &apos; |awk &apos;&#123;print $2&#125;&apos;) --nic net-id=$(neutron net-list |grep &apos; ext_net &apos; |awk &apos;&#123;print $2&#125;&apos;) i1</span><br><span class="line"></span><br><span class="line"># in nova-compute/1 unit. compute node will have snat-xxx namespace due to use-dvr-snat=True</span><br><span class="line">wget https://gist.githubusercontent.com/dosaboy/cf8422f16605a76affa69a8db47f0897/raw/8e045160440ecf0f9dc580c8927b2bff9e9139f6/check_router_vrrp_transitions.sh</span><br><span class="line">chmod +x check_router_vrrp_transitions.sh</span><br><span class="line"># https://paste.ubuntu.com/p/PYPptZRhrn/</span><br><span class="line">date; neutron l3-agent-list-hosting-router $(neutron router-show provider-router -c id -f value); juju ssh nova-compute/1 -- bash /home/ubuntu/check_router_vrrp_transitions.sh; juju ssh nova-compute/1 -- bash /home/ubuntu/check_router_vrrp_transitions.sh; sleep 40; date; neutron l3-agent-list-hosting-router $(neutron router-show provider-router -c id -f value); juju ssh nova-compute/1 -- bash /home/ubuntu/check_router_vrrp_transitions.sh; juju ssh nova-compute/1 -- bash /home/ubuntu/check_router_vrrp_transitions.sh;</span><br></pre></td></tr></table></figure>
<h2 id="更新-20190717"><a href="#更新-20190717" class="headerlink" title="更新 20190717"></a>更新 20190717</h2><p>dpdk环境, 没neutron-gateway, dhcp-agent与metadata-agent均在计算节点上, 计算节点上因为memory不足导致ovs死掉, 在迁移一些虚机到其他机器并重启这台计算节点之后仍然发现虚机无法从dhcp处获取IP, 在使用config-drive静态指定IP后无问题, 所以后来发现原来是服务这些虚机的dhcp已经迁移到其他host, 在重启这个host后问题解决.</p>
<h2 id="20200110更新-dmz测试"><a href="#20200110更新-dmz测试" class="headerlink" title="20200110更新 - dmz测试"></a>20200110更新 - dmz测试</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">openstack router create externalrouter</span><br><span class="line">openstack network create dmznet --external</span><br><span class="line">openstack subnet create --subnet-range 172.21.8.0/24 --network dmznet --allocation-pool start=172.21.8.86,end=172.21.8.100 --gateway 172.21.8.1 dmzsubnetinternal</span><br><span class="line">openstack subnet create --subnet-range 193.169.205.0/24 --network dmznet --allocation-pool start=193.169.205.87,end=193.169.205.100 --gateway 193.169.205.1 dmzsubnetexternal</span><br><span class="line">openstack router add subnet externalrouter dmzsubnetinternal</span><br><span class="line">openstack router add subnet externalrouter dmzsubnetexternal</span><br><span class="line"></span><br><span class="line">openstack router create dmzrouterinternal</span><br><span class="line">openstack network create tenantnet</span><br><span class="line">openstack subnet create --subnet-range 192.168.4.0/24 --network tenantnet --allocation-pool start=192.168.4.87,end=192.168.4.100 --gateway 192.168.4.1 tenantsubnet</span><br><span class="line">openstack router add subnet dmzrouterinternal tenantsubnet</span><br><span class="line">openstack router set --external-gateway dmznet --fixed-ip subnet=dmzsubnetinternal,ip-address=172.21.8.87 dmzrouterinternal</span><br><span class="line">#openstack router set --enable dmzrouterinternal</span><br><span class="line"></span><br><span class="line">openstack router create dmzrouterexternal</span><br><span class="line">openstack router set --external-gateway dmznet --fixed-ip subnet=dmzsubnetexternal,ip-address=193.169.205.100 dmzrouterexternal</span><br><span class="line"></span><br><span class="line">openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">openstack server create --wait --image cirros2 --flavor m1.small --key-name mykey --nic net-id=$(openstack network show dmznet -c id -f value),v4-fixed-ip=193.169.205.99 externaldns</span><br><span class="line">openstack server create --wait --image cirros2 --flavor m1.small --key-name mykey --network=$(openstack network show tenantnet -c id -f value) i1</span><br><span class="line">dmznet_id=$(openstack network show dmznet -f value -c id)</span><br><span class="line">dmzsubnetinternal_id=$(openstack subnet show dmzsubnetinternal -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create --subnet $dmzsubnetinternal_id $dmznet_id -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address 192.168.4.100 --port $(openstack port list --fixed-ip ip-address=192.168.4.100 -c id -f value)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/15/手机作为显示器及键鼠控制电脑棒/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/15/手机作为显示器及键鼠控制电脑棒/" itemprop="url">手机作为显示器及键鼠控制电脑棒</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-15T08:56:05+08:00">
                2019-04-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2019-04-14)</strong></p>
<p>买了一款Intel compute stick core m3, 具有HDMI接口输出音频, 但如何使用手机临时地作为显示器及键盘鼠标控制它呢?</p>
<h2 id="屏幕共享-vnc-amp-teamviewer-amp-anydesk"><a href="#屏幕共享-vnc-amp-teamviewer-amp-anydesk" class="headerlink" title="屏幕共享 - vnc &amp; teamviewer &amp; anydesk"></a>屏幕共享 - vnc &amp; teamviewer &amp; anydesk</h2><p>windows上有一款叫spacedesk的软件, 电脑和手机上都安装它之后, 在同一个局域网可以很方便地从手机控制电脑棒.<br>Ubuntu上可以使用vnc, teamviewer, anydesk.</p>
<ul>
<li>ubuntu上安装VNC<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># https://medium.com/@aldo_mx/simplest-way-to-configure-vnc-server-in-xubuntu-16-04-lts-and-newer-6c0b3ae21fe5</span><br><span class="line">sudo apt-get install vino</span><br><span class="line">gsettings list-recursively org.gnome.Vino</span><br><span class="line"># some clients like TightVNC for Windows do not work with encryption anymore</span><br><span class="line"># because older protocols like SSLv3 and TLSv1 have been deprecated.</span><br><span class="line"># dconf-editor - ORG &gt; GNOME &gt; DESKTOP &gt; REMOTE ACCESS</span><br><span class="line">gsettings set org.gnome.Vino require-encryption false</span><br><span class="line"># activate at startup, or set &quot;Settings -&gt; Sharing -&gt; screen Sharing&quot; in ubuntu</span><br><span class="line">sudo cp /usr/share/applications/vino-server.desktop /etc/xdg/autostart/vino-server.desktop</span><br><span class="line"># #enable &quot;Application Autostart -&gt; Desktop Sharing(Gnome Desktop Sharing Server)&quot;</span><br><span class="line">xfce4-session-settings</span><br><span class="line">/usr/lib/vino/vino-server --sm-disable</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>需注意两点：一是要<strong>设置require-encryption=false</strong>, 二是手机上使用realvnc client时不应该登陆，因为没用realvnc server，而是用的vino server</p>
<ul>
<li>安装使用anydesk使用屏幕, 鼠标, 键盘.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://download.anydesk.com/linux/anydesk_4.0.1-1_amd64.deb</span><br><span class="line">sudo dpkg -i anydesk_4.0.1-1_amd64.deb</span><br><span class="line">sudo apt --fix-broken install</span><br><span class="line">sudo dpkg -i anydesk_4.0.1-1_amd64.deb</span><br><span class="line">sudo systemctl enable anydesk.service</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>最后, 设置anydesk, 设置允许随时连接查询, 并设置密码, 禁用掉声音传输.<br>但又遇到一个问题, 在笔记本上测试anydesk似乎没有问题. 但移到电脑棒上后, 电脑棒启动后经常无故死机. (<strong>无故死机的问题找到了, 一次是因为电源没插好接触不良, 另一次是应用了平时给手机充电的Type-A USB输出的充电器, 应该使用自带的APD亚源科技的Type-C输出口的充电器(输出则是5.2V 2.2A（Type-C对机身）、5V 0.9A（对两个Type-A）</strong>，这个问题真难查). 但仍然遇到一个问题 (手机上的anydesk发起连接时报: 连接已终止,. 状态: result_invalid_state，暂不清楚原因)</p>
<ul>
<li>切换为teamviewer, 也是遇到类似问题, 曾经成功过, 但之后手机上的teamviewer就一起报: teamviewer正在启动, 请稍候. （该问题原因已找到， 因为墙，用4G网络可以， 见： <a href="https://github.com/ywb94/openwrt-ssr/issues/31" target="_blank" rel="external">https://github.com/ywb94/openwrt-ssr/issues/31</a> 及 <a href="https://zvv.me/z/1366.html" target="_blank" rel="external">https://zvv.me/z/1366.html</a> ）</li>
</ul>
<p>还存在一个问题: **如果电脑棒不通过HDMI接口接一个显示器, 电脑棒重启之后通过远程桌面连接过去看到的是一屏黑色. 那是因为Linux服务器一般是不接显示器的，用ssh等文字界面连接管理即可, 可是有些软件需要GUI管理，若不接显示器，xwindows是默认无法启动的，从而导致vnc server连接失败, 可配置一块fake显示器解决:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># https://askubuntu.com/questions/453109/add-fake-display-when-no-monitor-is-plugged-in</span><br><span class="line">sudo apt-get install xserver-xorg-video-dummy</span><br><span class="line">sudo bash -c &apos;cat &gt; /usr/share/X11/xorg.conf.d/xorg.conf&apos; &lt;&lt;EOF</span><br><span class="line">Section &quot;Device&quot;</span><br><span class="line">    Identifier  &quot;Configured Video Device&quot;</span><br><span class="line">    Driver      &quot;dummy&quot;</span><br><span class="line">EndSection</span><br><span class="line"></span><br><span class="line">Section &quot;Monitor&quot;</span><br><span class="line">    Identifier  &quot;Configured Monitor&quot;</span><br><span class="line">    HorizSync 31.5-48.5</span><br><span class="line">    VertRefresh 50-70</span><br><span class="line">EndSection</span><br><span class="line"></span><br><span class="line">Section &quot;Screen&quot;</span><br><span class="line">    Identifier  &quot;Default Screen&quot;</span><br><span class="line">    Monitor     &quot;Configured Monitor&quot;</span><br><span class="line">    Device      &quot;Configured Video Device&quot;</span><br><span class="line">    DefaultDepth 24</span><br><span class="line">    SubSection &quot;Display&quot;</span><br><span class="line">    Depth 24</span><br><span class="line">    Modes &quot;1024x800&quot;</span><br><span class="line">    EndSubSection</span><br><span class="line">EndSection</span><br><span class="line">EOF</span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure></p>
<p>但是使用上述的软件模拟的显示器, 会造成即使接了真显示器, 还是用得虚拟的, 所以不方便啊. 网上有硬件的Dummy HDMI可用.</p>
<h2 id="kdeconnect"><a href="#kdeconnect" class="headerlink" title="kdeconnect"></a>kdeconnect</h2><p>kdeconnect可以用来在ubuntu与androd之间双向传输数据, 例如电脑使用手机的键盘鼠标, 电脑与手机相互传输数据, 手机上的短信通知发给电脑显示.<br>直接在电脑与手机上安装kdeconnect即可使用.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install kdeconnect</span><br></pre></td></tr></table></figure></p>
<p>但kdeconnectd进程 (/etc/xdg/autostart/kdeconnectd.desktop)在ubuntu未登录之前是不会启动的, 所以禁用掉电脑棒的密码登录设置它为自动登录即可.</p>
<h2 id="gsconnect-gshell-extension"><a href="#gsconnect-gshell-extension" class="headerlink" title="gsconnect gshell extension"></a>gsconnect gshell extension</h2><p>gsconnect与kdeconnect是类似的东西, 它不依赖kde的一些包, 但它依赖Gnome desk与chrome, 电脑棒启动后没有自动启动chrome的话用不了. 所以实际我用的还是kdeconnect, 但这里记录使用gsconnect的过程.</p>
<ul>
<li>安装gnome-shell-extension与chrome-gnome-shell<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gnome-shell --version</span><br><span class="line">sudo apt install gnome-shell-extensions</span><br><span class="line">sudo apt install chrome-gnome-shell</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>离个题, 例如想显示各个不同时区的team member的上班时间的话, 可以添加~/people.json将每个人的时区按下列格式添加进去即可.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim ~/people.json</span><br><span class="line">[</span><br><span class="line">&#123;</span><br><span class="line">      &quot;name&quot;: &quot;your name&quot;,</span><br><span class="line">      &quot;github&quot;: &quot;your lauchpd id&quot;,</span><br><span class="line">      &quot;city&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;tz&quot;: &quot;Asia/Shanghai&quot;</span><br><span class="line">&#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
<ul>
<li>访问这个网址<a href="https://extensions.gnome.org/extension/1319/gsconnect/" target="_blank" rel="external">https://extensions.gnome.org/extension/1319/gsconnect/</a> 方便地安装gsconnect即可 (注意: 如果出错, 多半是因为没有在chrome里访问 chrome://extensions/ 将GNOME Shell integration打开的原因).</li>
<li>手机上在play里搜索安装KDE Connect, 并打开它, 和gsconnect为pair配对.</li>
<li>还可以支持电脑上Nautilus来mount手机上的文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python-nautilus gir1.2-nautilus-3.0 sshfs</span><br><span class="line"># then send file to Android by first open the nautilus then right click one file &quot;Send to Mobile Device -&gt; Nokia&quot;</span><br></pre></td></tr></table></figure>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/18/Set-ip-IPv6-env/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/18/Set-ip-IPv6-env/" itemprop="url">Set ip IPv6 env</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-18T13:44:20+08:00">
                2019-01-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="基础-ND协议的三个位"><a href="#基础-ND协议的三个位" class="headerlink" title="基础 - ND协议的三个位"></a>基础 - ND协议的三个位</h2><p>ND协议包中有三个位(Auto, Managed, Other)：</p>
<ul>
<li>M bit (Managed Address Configuration), M bit如果是1,表示Clients要另外再去跟DHCPv6要IPv6 Prefix</li>
<li>O bit (Other Configuration), O bit如果是1,表示Clients要去跟DHCPv6要DNS(RDNSS)等其他信息<br>这样：</li>
<li>slaas, Stateless autoconfiguration, A=1, M=0, O=0, 主机將只得到Router給的 Prefix, 无法取得DNS等资讯, 其他必须自己填写.</li>
<li>dhcpv6-stateful, A=0, M=1, O=1, 所有信息（IPv6 prefix, DNS等)都通过DHCPv6获得,客戶端主要使用UDP port 546, 而服務器端使用 UDP port 547</li>
<li>dhcpv6-stateless,A=1, M=0, O=1, 除了使用RA裡面的Prefix,其他如DNS等等信息会由DHCPv6 取得.<h2 id="基础-Neutron-IPv6"><a href="#基础-Neutron-IPv6" class="headerlink" title="基础 - Neutron IPv6"></a>基础 - Neutron IPv6</h2>Neutron中有两个重要属性来支持IPv6 (ipv6_address_mode 与 ipv6_ra_mode):</li>
<li>ipv6_ra_mode, 如果设置表示由Neutron来使用radvd来模拟软件IPv6路由器, 如果不设置表示使用外部IPv6路由器</li>
<li>ipv6_address_mode, 对应上述ND协议中的三个位(Auto, Managed, Other), 例如: 对于dhcpv6-stateless, 3比特应该是: A=1, M=0, O=1.</li>
</ul>
<p>下面是创建一个使用外部IPv6路由器并使用dhcpv6-stateless的例子:<br>neutron net-create –provider:network_type flat –provider:physical_network physnet1 –router:external=True ext_net<br>neutron subnet-create ext_net –name external-subnet-v6 –ip_version 6 –ipv6_address_mode dhcpv6-stateless –allocation-pool start=2001:db8:0:1::2,end=2001:db8:0:1:ffff:ffff:ffff:ffff 2001:db8:0:1::/64</p>
<h2 id="基础-Ubuntu中手工配置IPv6的注意点"><a href="#基础-Ubuntu中手工配置IPv6的注意点" class="headerlink" title="基础 - Ubuntu中手工配置IPv6的注意点"></a>基础 - Ubuntu中手工配置IPv6的注意点</h2><p>Ubuntu中配置IPv6可以采用network-manager, 也可采用在/etc/network/interface中手工配置, 也可以使用最新的netplan. 这里描述的是采用手工配置的方法.<br>先看一个遇到的实际问题:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">下面配置不work</span><br><span class="line">iface eth0 inet6 auto</span><br><span class="line">   # use SLAAC to get global IPv6 address from the router</span><br><span class="line">   # we may not enable ipv6 forwarding, otherwise SLAAC gets disabled</span><br><span class="line">   up sleep 5</span><br><span class="line">   dhcp 1</span><br><span class="line">   autoconf 1</span><br><span class="line">   accept_ra 2</span><br><span class="line"></span><br><span class="line">下列配置work</span><br><span class="line">iface eth0 inet6 static</span><br><span class="line">address 2001:192:168:99::135</span><br><span class="line">   gateway 2001:192:168:99::1</span><br><span class="line">   netmask 64</span><br><span class="line">且改成network-manager也work, 这是为什么呢?</span><br><span class="line"></span><br><span class="line">测试方法是:</span><br><span class="line">#it will flush link-local address as well</span><br><span class="line">#ip addr flush br-eth0</span><br><span class="line"># avoid the error: can&apos;t get a link-local address</span><br><span class="line">sudo ip link set dev eth0 down</span><br><span class="line">sudo ip link set dev eth0 up</span><br><span class="line">ifdown br-eth0</span><br><span class="line">ifup --force --verbose br-eth0</span><br></pre></td></tr></table></figure></p>
<p>采用”ifup –force –verbose br-eth0”命令看到的错误是”can’t get a link-local address”.<br>为什么static模式与network-manager模式没有这个错误呢? 原来是这两者默认执行了:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br></pre></td></tr></table></figure></p>
<p>并且之前Linux网桥br-eth0上一直没有IPv6地址的原因也是这个, 且上面”sudo ip link set dev eth0 up”这句也会自动设置disable_ipv6=0, 但不会对br-eth0作同样的设置.<br>所以添加”up echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6”后问题解决, 完整配置如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">root@node1:~# cat /etc/network/interfaces</span><br><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line">auto eth0</span><br><span class="line">iface eth0 inet manual</span><br><span class="line">auto br-eth0</span><br><span class="line">iface br-eth0 inet static</span><br><span class="line">    address 192.168.99.124/24</span><br><span class="line">    gateway 192.168.99.1</span><br><span class="line">    bridge_ports eth0</span><br><span class="line">    dns-nameservers 192.168.99.1</span><br><span class="line">    bridge_stp on</span><br><span class="line">    bridge_fd 0</span><br><span class="line">    bridge_maxwait 0</span><br><span class="line">    up echo -n 0 &gt; /sys/devices/virtual/net/$IFACE/bridge/multicast_snooping</span><br><span class="line"># for stateless it&apos;s &apos;inet6 auto&apos;, for stateful it&apos;s &apos;inet6 dhcp&apos;</span><br><span class="line">iface br-eth0 inet6 auto</span><br><span class="line">    #iface eth0 inet6 static</span><br><span class="line">    #address 2001:192:168:99::135</span><br><span class="line">    #gateway 2001:192:168:99::1</span><br><span class="line">    #netmask 64</span><br><span class="line">    # use SLAAC to get global IPv6 address from the router</span><br><span class="line">    # we may not enable ipv6 forwarding, otherwise SLAAC gets disabled</span><br><span class="line">    # sleep 5 is due a bug and &apos;dhcp 1&apos; indicates that info should be obtained from dhcpv6 server for stateless</span><br><span class="line">    up echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br><span class="line">    up sleep 5</span><br><span class="line">    autoconf 1</span><br><span class="line">    accept_ra 2</span><br><span class="line">    dhcp 1</span><br></pre></td></tr></table></figure></p>
<p>此外, 最好设置accept_ra=2, 因为经常会遇到自动配置的IPv6地址丢失或者不能获取的问题。一般情况是都是启用了IPv6转发功能(sudo sysctl -w net.ipv6.conf.all.forwarding=1)引起的。<br>为了配置IPv6 address和default gateway, client/host都会默认去listen或者solicit RA广播, 并且host作为router时会忽略RA, 这由accept_ra设置:</p>
<ul>
<li>0 Do not accept RouterAdvertisements.</li>
<li>1 Accept Router Advertisements if forwarding is disabled.</li>
<li>2 Overrule forwarding behavior. Accept Router Advertisements  even if forwarding is enabled.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv6.conf.all.forwarding=1</span><br><span class="line">sudo sysctl -w net.ipv6.conf.all.accept_ra=2</span><br><span class="line">sudo sysctl -w net.ipv6.conf.br-lan.disable_ipv6=0</span><br><span class="line">#echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="IPv6中的防火墙"><a href="#IPv6中的防火墙" class="headerlink" title="IPv6中的防火墙"></a>IPv6中的防火墙</h2><p>IPv6 Router端:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># Clear all ip6tables rules</span><br><span class="line">ip6tables -t nat -X</span><br><span class="line">ip6tables -t nat -P PREROUTING ACCEPT</span><br><span class="line">ip6tables -t nat -P POSTROUTING ACCEPT</span><br><span class="line">ip6tables -t nat -P OUTPUT ACCEPT</span><br><span class="line">ip6tables -t mangle -F</span><br><span class="line">ip6tables -t mangle -X</span><br><span class="line">ip6tables -t mangle -P PREROUTING ACCEPT</span><br><span class="line">ip6tables -t mangle -P INPUT ACCEPT</span><br><span class="line">ip6tables -t mangle -P FORWARD ACCEPT</span><br><span class="line">ip6tables -t mangle -P OUTPUT ACCEPT</span><br><span class="line">ip6tables -t mangle -P POSTROUTING ACCEPT</span><br><span class="line">ip6tables -F</span><br><span class="line">ip6tables -X</span><br><span class="line">ip6tables -P FORWARD ACCEPT</span><br><span class="line">ip6tables -P INPUT ACCEPT</span><br><span class="line">ip6tables -P OUTPUT ACCEPT</span><br><span class="line">ip6tables -t raw -F</span><br><span class="line">ip6tables -t raw -X</span><br><span class="line">ip6tables -t raw -P PREROUTING ACCEPT</span><br><span class="line">ip6tables -t raw -P OUTPUT ACCEPT</span><br><span class="line"></span><br><span class="line"># Default DROP rules</span><br><span class="line">ip6tables -P INPUT   DROP</span><br><span class="line">ip6tables -P OUTPUT  ACCEPT</span><br><span class="line">ip6tables -P FORWARD DROP</span><br><span class="line"></span><br><span class="line"># Allow established connections</span><br><span class="line">ip6tables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br><span class="line">ip6tables -A FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br><span class="line"></span><br><span class="line"># For IPv6</span><br><span class="line"># it&apos;s not required due to ipv6-icmp</span><br><span class="line"># sudo ip6tables -A INPUT -p udp --dport 547 -j ACCEPT</span><br><span class="line">#ip6tables -A INPUT -p icmpv6 --icmpv6-type echo-request -j ACCEPT</span><br><span class="line">ip6tables -A INPUT -p ipv6-icmp -j ACCEPT</span><br><span class="line">ip6tables -A FORWARD -p ipv6-icmp -j ACCEPT</span><br><span class="line"></span><br><span class="line"># Ajust MTU</span><br><span class="line">ip6tables -t mangle -A POSTROUTING -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br></pre></td></tr></table></figure></p>
<p>IPv6 Client端:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ip6tables -t filter -A INPUT -p udp -m udp --sport 547 --dport 546 -j ACCEPT</span><br><span class="line">ip6tables -t filter -A INPUT -p ipv6-icmp -j ACCEPT</span><br><span class="line"></span><br><span class="line"># or security group</span><br><span class="line">https://bugs.launchpad.net/neutron/+bug/1335984</span><br><span class="line">openstack security group rule create $secgroup --protocol udp --dst-port 546 --ethertype IPv6</span><br><span class="line">openstack security group rule create $secgroup --protocol icmpv6 --ethertype IPv6</span><br><span class="line"></span><br><span class="line"># Flow based firewall</span><br><span class="line">hard_timeout=0,idle_timeout=0,priority=4,udp,tp_dst=546/0xffff,table=32,tp_src=547/0xffff,nw_src=fe80::f816:3eff:fea3:ec40,actions=learn(table=33,priority=5,hard_timeout=120,eth_type=0x800,nw_proto=17,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],NXM_OF_IP_SRC[]=NXM_OF_IP_DST[],NXM_OF_UDP_SRC[]=NXM_OF_UDP_DST[], NXM_OF_UDP_DST[]=NXM_OF_UDP_SRC[],output:NXM_OF_IN_PORT[]),normal</span><br></pre></td></tr></table></figure></p>
<p>另外, 别忘了禁用掉ufw或者SELinux之类的.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ufw disable</span><br></pre></td></tr></table></figure></p>
<h2 id="Statefull-DHCPv6"><a href="#Statefull-DHCPv6" class="headerlink" title="Statefull DHCPv6"></a>Statefull DHCPv6</h2><p>采用isc-dhcp-server搭建DHCPv6 Server:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">https://jochen.kirstaetter.name/dhcpv6-ipv6-in-your-local-network/</span><br><span class="line">hua@t440p:~$ ip addr show eth0 |grep inet6 |grep global</span><br><span class="line">    inet6 2001:192:168:99::430/128 scope global</span><br><span class="line">echo &apos;Acquire::ForceIPv4 &quot;true&quot;;&apos; | sudo tee /etc/apt/apt.conf.d/99force-ipv4</span><br><span class="line">sudo apt install isc-dhcp-server</span><br><span class="line">grep -v ^# /etc/dhcp/dhcpd6.conf</span><br><span class="line">sudo cp /etc/dhcp/dhcpd6.conf /etc/dhcp/dhcpd6.conf_bak</span><br><span class="line">sudo bash -c &apos;cat &gt;/etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">authoritative;</span><br><span class="line">default-lease-time 14400;</span><br><span class="line">max-lease-time 86400;</span><br><span class="line">log-facility local7;</span><br><span class="line">subnet6 2001:192:168:99::/64 &#123;</span><br><span class="line">    option dhcp6.name-servers 2001:4860:4860::8888, 2001:4860:4860::8844;</span><br><span class="line">    option dhcp6.domain-search &quot;quqi.com&quot;;</span><br><span class="line">    range6 2001:192:168:99::100 2001:192:168:99::199;</span><br><span class="line">    range6 2001:192:168:99::/64 temporary;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo touch /var/lib/dhcp/dhcpd6.leases</span><br><span class="line">sudo /usr/sbin/dhcpd -6 -d -cf /etc/dhcp/dhcpd6.conf eth0</span><br><span class="line">sudo chown dhcpd:dhcpd /var/lib/dhcp/dhcpd6.leases</span><br><span class="line">sudo service isc-dhcp-server6 restart</span><br></pre></td></tr></table></figure></p>
<p>然后记得照上节说的设置DHCPv6 Server与Client上的防火墙规则. 接着在另一台机器上作client测试:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># need to use &apos;inet6 dhcp&apos; in client side for statefull DHCPv6</span><br><span class="line">iface br-eth0 inet6 dhcp</span><br><span class="line">    #iface eth0 inet6 static</span><br><span class="line">    #address 2001:192:168:99::135</span><br><span class="line">    #gateway 2001:192:168:99::1</span><br><span class="line">    #netmask 64</span><br><span class="line">    # use SLAAC to get global IPv6 address from the router</span><br><span class="line">    # we may not enable ipv6 forwarding, otherwise SLAAC gets disabled</span><br><span class="line">    # sleep 5 is due a bug and &apos;dhcp 1&apos; indicates that info should be obtained from dhcpv6 server for stateless</span><br><span class="line">    up echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br><span class="line">    up sleep 5</span><br><span class="line">    autoconf 1</span><br><span class="line">    accept_ra 2</span><br><span class="line">    dhcp 1</span><br><span class="line"></span><br><span class="line"># test command</span><br><span class="line">dhclient -6 -d br-eth0</span><br><span class="line"></span><br><span class="line"># verity</span><br><span class="line">hua@node1:~$ sudo tcpdump -ni eth0 ip6 host fe80::d5a3:10a3:6161:5b2e</span><br><span class="line">12:44:00.868609 IP6 fe80::d5a3:10a3:6161:5b2e.547 &gt; fe80::fa32:e4ff:febe:87cd.546: dhcp6 advertise</span><br><span class="line">12:44:01.946548 IP6 fe80::d5a3:10a3:6161:5b2e.547 &gt; fe80::fa32:e4ff:febe:87cd.546: dhcp6 reply</span><br><span class="line">root@node1:~# cat /etc/resolv.conf</span><br><span class="line"># Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)</span><br><span class="line">#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN</span><br><span class="line">nameserver 192.168.99.1</span><br><span class="line">#nameserver 211.136.17.107</span><br><span class="line">#nameserver 114.114.114.114</span><br><span class="line">#nameserver 223.5.5.5</span><br><span class="line">nameserver 2001:4860:4860::8888</span><br><span class="line">nameserver 2001:4860:4860::8844</span><br><span class="line">nameserver 2001:db8::1:6a1:51ff:fe8a:2ca7</span><br><span class="line">search quqi.com lan</span><br></pre></td></tr></table></figure>
<p>另外, 使用BIND9的例子可参见 - <a href="https://jochen.kirstaetter.name/enabling-dns-for-ipv6-infrastructure/" target="_blank" rel="external">https://jochen.kirstaetter.name/enabling-dns-for-ipv6-infrastructure/</a></p>
<h2 id="SLAAC-Stateless-Address-Auto-Configuration"><a href="#SLAAC-Stateless-Address-Auto-Configuration" class="headerlink" title="SLAAC (Stateless Address Auto Configuration)"></a>SLAAC (Stateless Address Auto Configuration)</h2><p>radvd来提供RA部分, SLAAC只有RA部分. RA只能设置IPv6 prefix与DNS (RDNSS).<br>Historically the software package radvd was commonly used for just the RA-part of this. But dnsmasq offers a more complete setup.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv6.conf.all.forwarding=1</span><br><span class="line">sudo ip addr add 2001:db8:0:1::1/64 dev eth0</span><br><span class="line">sudo apt-get install radvd</span><br><span class="line">$ cat /etc/radvd.conf</span><br><span class="line">    interface eth0</span><br><span class="line">    &#123;</span><br><span class="line">       AdvSendAdvert on;</span><br><span class="line">       prefix 2001:db8:0:1::/64</span><br><span class="line">       &#123;</span><br><span class="line">            AdvOnLink on;</span><br><span class="line">            AdvAutonomous on;</span><br><span class="line">       &#125;;</span><br><span class="line">       #Send DNS Server setting</span><br><span class="line">       #RDNSS fd5d:12c9:2201:1::2&#123;</span><br><span class="line">    &#125;;</span><br><span class="line">sudo /etc/init.d/radvd restart</span><br><span class="line">sudo ip6tables -F</span><br><span class="line"></span><br><span class="line">neutron subnet-create --ip-version=6 --name=ext-v6-subnet --gateway 2001:db8:0:1::1 --allocation-pool start=2001:db8:0:1::5,end=2001:db8:0:1:ffff:ffff:ffff:fffe --disable-dhcp ext_net 2001:db8:0:1::/64</span><br><span class="line">neutron net-create private</span><br><span class="line">neutron subnet-create --ip-version=6 --name=private_v6_subnet --ipv6-address-mode=slaac --ipv6-ra-mode=slaac private 2001:db8:0:2::/64</span><br><span class="line">neutron router-interface-add provider-router private_v6_subnet</span><br></pre></td></tr></table></figure></p>
<h2 id="SLAAS-with-Stateless-DHCPv6"><a href="#SLAAS-with-Stateless-DHCPv6" class="headerlink" title="SLAAS with Stateless DHCPv6"></a>SLAAS with Stateless DHCPv6</h2><p>Stateless意味着:</p>
<ul>
<li>radvd提供RA (AdvManagedFlag=off)</li>
<li>client使用radvd RA提供的IPv6 prefix配置IPv6 address</li>
<li>client的其他信息如DNS等从DHCPv6获得<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">sudo bash -c &apos;cat &gt; /etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">interface eth0</span><br><span class="line">&#123;</span><br><span class="line">    AdvSendAdvert on;</span><br><span class="line">    MinRtrAdvInterval 30;</span><br><span class="line">    MaxRtrAdvInterval 100;</span><br><span class="line">    AdvManagedFlag off;</span><br><span class="line">    AdvOtherConfigFlag on;</span><br><span class="line">    prefix 2001:192:168:99::/64</span><br><span class="line">    &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">        AdvRouterAddr off;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; /etc/radvd.conf&apos; &lt;&lt;EOF</span><br><span class="line">default-lease-time 600;</span><br><span class="line">max-lease-time 7200;</span><br><span class="line">log-facility local7;</span><br><span class="line">option dhcp6.name-servers 2001:4860:4860::8888;</span><br><span class="line">option dhcp6.domain-search &quot;&quot;;</span><br><span class="line">subnet6 2001:192:168:99::/64 &#123;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="SLAAS-with-Statefull-DHCPv6"><a href="#SLAAS-with-Statefull-DHCPv6" class="headerlink" title="SLAAS with Statefull DHCPv6"></a>SLAAS with Statefull DHCPv6</h2><p>Statefull意味着:</p>
<ul>
<li>radvd不提供RA (AdvManagedFlag=on)</li>
<li>client使用DHCPv6去配置IPv6 address</li>
<li>client的其他信息如DNS等也从DHCPv6获得<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">sudo bash -c &apos;cat &gt; /etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">interface eth0</span><br><span class="line">&#123;</span><br><span class="line">    AdvSendAdvert on;</span><br><span class="line">    MinRtrAdvInterval 30;</span><br><span class="line">    MaxRtrAdvInterval 100;</span><br><span class="line">    AdvManagedFlag on;</span><br><span class="line">    AdvOtherConfigFlag on;</span><br><span class="line">    prefix 2001:192:168:99::/64</span><br><span class="line">    &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">        AdvRouterAddr off;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt;/etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">authoritative;</span><br><span class="line">default-lease-time 14400;</span><br><span class="line">max-lease-time 86400;</span><br><span class="line">log-facility local7;</span><br><span class="line">subnet6 2001:192:168:99::/64 &#123;</span><br><span class="line">    option dhcp6.name-servers 2001:4860:4860::8888, 2001:4860:4860::8844;</span><br><span class="line">    option dhcp6.domain-search &quot;quqi.com&quot;;</span><br><span class="line">    range6 2001:192:168:99::100 2001:192:168:99::199;</span><br><span class="line">    range6 2001:192:168:99::/64 temporary;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="实际问题"><a href="#实际问题" class="headerlink" title="实际问题"></a>实际问题</h2><p>例如, 使用OpenStack根据外部IPv6 stateless router定义的IPv6网络, 虚机分配了IP, 但是网卡上去没配置, 一般地, 理论上问题出在:<br>1, 既然有外部路由器, Openstack CLI中不应该定义ipv6_ra_mode, 不指定ipv6_ra_mode, neutron就不会创建radvd, 那样就会直接使用外部的IPv6路由器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">neutron net-create IPv6 (vlan1809) --shared --provider:physical_network physnet2 --provider:network_type vlan --provider:segmentation_id 1809 --router:external True</span><br><span class="line">neutron subnet-create ipv6-pd --name external-subnet-v6 --ip_version 6 --ipv6_address_mode dhcp-stateless --allocation-pool start=2001:1284:ff:18::2,end=2001:1284:ff:18:ffff:ffff:ffff:ffff --dns-nameserver 2001:1284:ff02::243 2001:1284:ff:18::/64</span><br></pre></td></tr></table></figure></p>
<p>2, 外部IPv6路由器的防火墙规则打开了没:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo ip6tables -A INPUT -p icmpv6 -j ACCEPT</span><br><span class="line">sudo ip6tables -A OUTPUT -p icmpv6 -j ACCEPT</span><br><span class="line">sudo ip6tables -A FORWARD -p icmpv6 -j ACCEPT</span><br><span class="line">sudo ufw allow proto udp from fe80::/64 to any port 547</span><br><span class="line">sudo ufw disable</span><br></pre></td></tr></table></figure></p>
<p>3, 虚机这边虚机定义security group rule将其所有的计算节点上的防火墙规则打开:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">https://bugs.launchpad.net/neutron/+bug/1335984</span><br><span class="line"></span><br><span class="line">openstack security group rule create $secgroup --protocol udp --dst-port 546 --ethertype IPv6</span><br><span class="line">openstack security group rule create $secgroup --protocol icmpv6 --ethertype IPv6</span><br><span class="line"></span><br><span class="line">For iptables driver, above equals:</span><br><span class="line">ip6tables -t filter -A INPUT -p udp -m udp --sport 547 --dport 546 -j ACCEPT</span><br><span class="line">ip6tables -t filter -A INPUT -p ipv6-icmp -j ACCEPT</span><br><span class="line"></span><br><span class="line">For ovs flow based driver, above equals:</span><br><span class="line">hard_timeout=0,idle_timeout=0,priority=4,udp,tp_dst=546/0xffff,table=32,tp_src=547/0xffff,nw_src=fe80::f816:3eff:fea3:ec40,actions=learn(table=33,priority=5,hard_timeout=120,eth_type=0x800,nw_proto=17,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],NXM_OF_IP_SRC[]=NXM_OF_IP_DST[],NXM_OF_UDP_SRC[]=NXM_OF_UDP_DST[], NXM_OF_UDP_DST[]=NXM_OF_UDP_SRC[],output:NXM_OF_IN_PORT[]),normal</span><br></pre></td></tr></table></figure></p>
<p>3, 外部路由器因为启用了forwarding应该设置accept_ra=2而不是accept_ra=1:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv6.conf.all.accept_ra=2</span><br></pre></td></tr></table></figure></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="http://asdkda.github.io/2016/02/05/ipv6/" target="_blank" rel="external">http://asdkda.github.io/2016/02/05/ipv6/</a><br>[2] <a href="http://tldp.org/HOWTO/html_single/Linux+IPv6-HOWTO/#idp57787920" target="_blank" rel="external">http://tldp.org/HOWTO/html_single/Linux+IPv6-HOWTO/#idp57787920</a><br>[3] <a href="https://jochen.kirstaetter.name/dhcpv6-ipv6-in-your-local-network/" target="_blank" rel="external">https://jochen.kirstaetter.name/dhcpv6-ipv6-in-your-local-network/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/02/Using-kubeadm-to-deploy-k8s/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/02/Using-kubeadm-to-deploy-k8s/" itemprop="url">Using kubeadm to deploy k8s</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-02T11:08:22+08:00">
                2019-01-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-07-13)</strong></p>
<h2 id="Bootstrapping-master-with-kubeadm"><a href="#Bootstrapping-master-with-kubeadm" class="headerlink" title="Bootstrapping master with kubeadm"></a>Bootstrapping master with kubeadm</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">https://kubernetes.io/docs/setup/independent/install-kubeadm/</span><br><span class="line">Create a VM (ubuntu 18.04) joshuazhang1c.mylabserver.com in linuxacademy.com, then run:</span><br><span class="line"></span><br><span class="line"># Reset env</span><br><span class="line">kubectl drain joshuazhang1c.mylabserver.com --delete-local-data --force --ignore-daemonsets</span><br><span class="line">kubectl get node</span><br><span class="line">kubectl delete node joshuazhang1c.mylabserver.com</span><br><span class="line">sudo kubeadm reset</span><br><span class="line"></span><br><span class="line"># Installing kubeadm, kubelet, kubectl, docker</span><br><span class="line">sudo apt update &amp;&amp; sudo apt install -y apt-transport-https curl</span><br><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</span><br><span class="line">sudo bash -c &apos;cat &gt;/etc/apt/sources.list.d/kubernetes.list&apos; &lt;&lt;EOF</span><br><span class="line">deb https://apt.kubernetes.io/ kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y kubelet kubeadm kubectl</span><br><span class="line">sudo apt-mark hold kubelet kubeadm kubectl</span><br><span class="line">cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br><span class="line">sudo apt install -y docker.io</span><br><span class="line">sudo systemctl enable docker.service</span><br><span class="line"></span><br><span class="line"># Creating a single master cluster with kubeadm</span><br><span class="line"># For flannle to work correctly, you must pass --pod-network-cidr=10.244.0.0/16</span><br><span class="line">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</span><br><span class="line">sudo kubeadm init --pod-network-cidr=10.244.0.0/16</span><br><span class="line">kubectl describe ds kube-flannel-ds-amd64 --namespace kube-system</span><br><span class="line">cat /etc/cni/net.d/10-flannel.conflist</span><br><span class="line"></span><br><span class="line"># the following commands come from the output of &apos;kubeadm init&apos;</span><br><span class="line"># export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">rm -rf ~/.kube/config &amp;&amp; sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line">kubectl cluster-info</span><br><span class="line"></span><br><span class="line"># configure kubectl completion</span><br><span class="line">kubectl completion bash | sudo tee /etc/bash_completion.d/k8s</span><br><span class="line"></span><br><span class="line"># Installing a pod network add-on</span><br><span class="line">sudo bash -c &apos;cat &gt;&gt; /etc/sysctl.conf&apos; &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">EOF</span><br><span class="line">sysctl -p</span><br><span class="line">sysctl net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml</span><br><span class="line">kubectl get daemonsets --all-namespaces</span><br><span class="line">kubectl get nodes --all-namespaces -o wide</span><br><span class="line"></span><br><span class="line"># Joining your nodes with kubeadm way, we will aslo try tls bootstrap way below</span><br><span class="line">ssh cloud_user@joshuazhang3c.mylabserver.com -v</span><br><span class="line">sudo -i</span><br><span class="line">apt install -y docker.io</span><br><span class="line">systemctl enable docker.service</span><br><span class="line">apt update &amp;&amp; apt install -y apt-transport-https curl</span><br><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">deb https://apt.kubernetes.io/ kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">apt update</span><br><span class="line">apt install -y kubeadm</span><br><span class="line"></span><br><span class="line"># kubeadm token list</span><br><span class="line"># openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &apos;s/^.* //&apos;</span><br><span class="line"># kubectl get secrets --namespace=kube-system bootstrap-token-9k9xoo -o jsonpath=&apos;&#123;.data.token-id&#125;&apos; |base64 -d</span><br><span class="line"># kubectl get secrets --namespace=kube-system bootstrap-token-9k9xoo -o jsonpath=&apos;&#123;.data.token-secret&#125;&apos; |base64 -d</span><br><span class="line">kubeadm join 172.31.19.84:6443 --token 0c4fdy.xptpmgh4eqihxh66 --discovery-token-ca-cert-hash sha256:b227cfd35c9d1ad42d8692576c0a453271741f59e5052c98674bc075b0789a17</span><br></pre></td></tr></table></figure>
<h2 id="Bootstrapping-workerwith-tls-bootstrapping"><a href="#Bootstrapping-workerwith-tls-bootstrapping" class="headerlink" title="Bootstrapping workerwith tls bootstrapping"></a>Bootstrapping workerwith tls bootstrapping</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line">https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/</span><br><span class="line">Just need to copy two files(/var/lib/kubelet/config.yaml and ca.crt) to new worker node, then use bootstrap token (temporary auth) and ca.crt to generate kubeconfig, finally restart kubelet with &apos;kubelet --bootstrap-kubeconfig=&quot;/etc/kubelet/bootstrap-kubelet.conf&quot; --kubeconfig=&quot;/etc/kubelet/kubeconfig.conf&quot; --config=&quot;/var/lib/kubelet/config.yaml&quot;&apos;, then master will create the certificate(for non-temporary auth) for worker and auto approve them.</span><br><span class="line"></span><br><span class="line">a, Principle behind. kubeadm has created bootstrap token with the auth-extra-groups &apos;system:bootstrappers:kubeadm:default-node-token&apos; for us. You can change the group name &apos;system:bootstrappers:kubeadm:default-node-token&apos; to another, eg: system:bootstrappers:myworkers</span><br><span class="line"></span><br><span class="line">$ kubectl get --namespace=kube-system secrets bootstrap-token-9k9xoo -o jsonpath=&apos;&#123;.data.auth-extra-groups&#125;&apos; |base64 -d</span><br><span class="line">system:bootstrappers:kubeadm:default-node-token</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; bootstrap-token.yaml&apos; &lt;&lt;EOF</span><br><span class="line"># https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  # Name MUST be of form &quot;bootstrap-token-&lt;token id&gt;&quot;</span><br><span class="line">  name: bootstrap-token-07401b</span><br><span class="line">  namespace: kube-system</span><br><span class="line"># Type MUST be &apos;bootstrap.kubernetes.io/token&apos;</span><br><span class="line">type: bootstrap.kubernetes.io/token</span><br><span class="line">stringData:</span><br><span class="line">  # Human readable description. Optional.</span><br><span class="line">  description: &quot;The default bootstrap token generated by &apos;kubeadm init&apos;.&quot;</span><br><span class="line">  # Token ID and secret. Required.</span><br><span class="line">  token-id: 07401b</span><br><span class="line">  token-secret: f395accd246ae52d</span><br><span class="line">  # Expiration. Optional.</span><br><span class="line">  expiration: 2019-03-10T03:22:11Z</span><br><span class="line">  # Allowed usages.</span><br><span class="line">  usage-bootstrap-authentication: &quot;true&quot;</span><br><span class="line">  usage-bootstrap-signing: &quot;true&quot;</span><br><span class="line">  # Extra groups to authenticate the token as. Must start with &quot;system:bootstrappers:&quot;</span><br><span class="line">  auth-extra-groups: system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f bootstrap-token.yaml</span><br><span class="line">kubectl describe secrets --namespace=kube-system bootstrap-token-07401b</span><br><span class="line">kubectl get secrets --namespace=kube-system bootstrap-token-07401b -o jsonpath=&#123;.data.token-id&#125; |base64 -d</span><br><span class="line">kubectl get secrets --namespace=kube-system bootstrap-token-07401b -o jsonpath=&#123;.data.token-secret&#125; |base64 -d</span><br><span class="line"></span><br><span class="line">So the following &apos;kubeadm token create&apos; will create a new token with the auth-extra-groups &apos;system:bootstrappers:kubeadm:default-node-token&apos;.</span><br><span class="line">$ kubeadm token create</span><br><span class="line">iate9c.v9qhw2dyngxfcsig</span><br><span class="line">TOKEN_ID=$(kubectl get secrets --namespace=kube-system bootstrap-token-iate9c -o jsonpath=&apos;&#123;.data.token-id&#125;&apos; |base64 -d)</span><br><span class="line">TOKEN_SECRET=$(kubectl get secrets --namespace=kube-system bootstrap-token-iate9c -o jsonpath=&apos;&#123;.data.token-secret&#125;&apos; |base64 -d)</span><br><span class="line"></span><br><span class="line">b, Principle behind. kubeadm has also create the following 3 clusterrolebindings to map the group &apos;system:bootstrappers:kubeadm:default-node-token&apos; for us. If you are using the new group &apos;system:bootstrappers:myworkers&apos;, here you need to change to &apos;system:bootstrappers:myworkers&apos; or &apos;system:bootstrappers&apos;.</span><br><span class="line"></span><br><span class="line">#Authorize kubelet to create CSR by mapping the clusterrole &apos;system:node-bootstrapper&apos; to the group &apos;system:bootstrappers&apos; or &apos;system:bootstrappers:joshuazhang2c.mylabserver.com&apos;</span><br><span class="line">kubectl create clusterrolebinding create-csrs-for-bootstrapping --group=system:bootstrappers:kubeadm:default-node-token --clusterrole=system:node-bootstrapper</span><br><span class="line"></span><br><span class="line">#Auto approve all CSRs by mapping the clusterrole &apos;selfnodeclient&apos; to the group &quot;system:bootstrappers&quot; or &apos;system:bootstrappers:joshuazhang2c.mylabserver.com&apos;</span><br><span class="line">kubectl create clusterrolebinding auto-approve-csrs-for-group --group=system:bootstrappers:kubeadm:default-node-token --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line"></span><br><span class="line">#Auto approve renewal CSRs by mapping the clusterrole &apos;selfnodeclient&apos; to the group &quot;system:nodes&quot;</span><br><span class="line">kubectl create clusterrolebinding auto-approve-renewals-csrs-for-group --group=system:nodes --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line"></span><br><span class="line">So we can use the following CertificateSigningRequest to self-test it.</span><br><span class="line"></span><br><span class="line">openssl genrsa -out joshuazhang2c.mylabserver.com.key</span><br><span class="line">openssl req -new -key joshuazhang2c.mylabserver.com.key -out joshuazhang2c.mylabserver.com.csr -subj &quot;/CN=system:node:joshuazhang2c.mylabserver.com/O=system:nodes&quot;</span><br><span class="line">openssl x509 -req -in joshuazhang2c.mylabserver.com.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out joshuazhang4c.mylabserver.com.crt -days 45</span><br><span class="line">cat &lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: certificates.k8s.io/v1beta1</span><br><span class="line">kind: CertificateSigningRequest</span><br><span class="line">metadata:</span><br><span class="line">  name: system:node:joshuazhang2c.mylabserver.com</span><br><span class="line">spec:</span><br><span class="line">  groups:</span><br><span class="line">    - system:nodes</span><br><span class="line">  request: $(cat joshuazhang2c.mylabserver.com.csr | base64 | tr -d &apos;\n&apos;)</span><br><span class="line">  usages:</span><br><span class="line">    - key encipherment</span><br><span class="line">    - digital signature</span><br><span class="line">    - client auth</span><br><span class="line">EOF</span><br><span class="line">kubectl get csr</span><br><span class="line"></span><br><span class="line">c, Generate kubeconfig with bootstrap token and ca</span><br><span class="line">ENDPOINT=$(kubectl describe service kubernetes |grep -i endpoints |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">CLUSTER=$(kubectl config view |grep &apos;  cluster:&apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">TOKEN_ID=$(kubectl get secrets --namespace=kube-system bootstrap-token-iate9c -o jsonpath=&apos;&#123;.data.token-id&#125;&apos; |base64 -d)</span><br><span class="line">TOKEN_SECRET=$(kubectl get secrets --namespace=kube-system bootstrap-token-iate9c -o jsonpath=&apos;&#123;.data.token-secret&#125;&apos; |base64 -d)</span><br><span class="line">sudo kubectl config --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf set-cluster $&#123;CLUSTER&#125; --server=https://$&#123;ENDPOINT&#125; --certificate-authority=/etc/kubernetes/pki/ca.crt</span><br><span class="line">sudo kubectl config --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf set-credentials kubelet-bootstrap --token=$&#123;TOKEN_ID&#125;.$&#123;TOKEN_SECRET&#125;</span><br><span class="line">sudo kubectl config --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf set-context bootstrap --user=kubelet-bootstrap --cluster=$&#123;CLUSTER&#125;</span><br><span class="line">sudo kubectl config --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf use-context bootstrap</span><br><span class="line"></span><br><span class="line"># Copy the following files from master to the new node</span><br><span class="line">scp joshuazhang1c.mylabserver.com:/etc/kubernetes/bootstrap-kubelet.conf . &amp;&amp; sudo mv bootstrap-kubelet.conf /etc/kubernetes/</span><br><span class="line">scp joshuazhang1c.mylabserver.com:/etc/kubernetes/pki/ca.crt . &amp;&amp; sudo mv ca.crt /etc/kubernetes/pki/</span><br><span class="line">scp joshuazhang1c.mylabserver.com:/var/lib/kubelet/config.yaml . &amp;&amp; sudo mv config.yaml /var/lib/kubelet/</span><br><span class="line"></span><br><span class="line">c, Install kubelet in the new node joshuazhang2c.mylabserver.com</span><br><span class="line"></span><br><span class="line">sudo apt update &amp;&amp; sudo apt install -y apt-transport-https curl</span><br><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</span><br><span class="line">sudo bash -c &apos;cat &gt;/etc/apt/sources.list.d/kubernetes.list&apos; &lt;&lt;EOF</span><br><span class="line">deb https://apt.kubernetes.io/ kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y kubelet kubeadm kubectl</span><br><span class="line">sudo apt-mark hold kubelet kubeadm kubectl</span><br><span class="line">cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br><span class="line">sudo apt install -y docker.io</span><br><span class="line">sudo systemctl enable docker.service</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt;/lib/systemd/system/kubelet.service&apos; &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=kubelet: The Kubernetes Node Agent</span><br><span class="line">Documentation=https://kubernetes.io/docs/home/</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line">[Service]</span><br><span class="line">#ExecStart=/usr/bin/kubelet --bootstrap-kubeconfig=&quot;/etc/kubernetes/bootstrap-kubelet.conf&quot; --kubeconfig=&quot;/etc/kubernetes/kubeconfig.conf&quot; --config=&quot;/var/lib/kubernetes/config.yaml&quot;</span><br><span class="line">ExecStart=/usr/bin/kubelet --bootstrap-kubeconfig=&quot;/etc/kubernetes/bootstrap-kubelet.conf&quot; --kubeconfig=&quot;/etc/kubernetes/kubeconfig.conf&quot; --pod-manifest-path=&quot;/etc/kubernetes/manifests/&quot; --feature-gates=RotateKubeletClientCertificate=true</span><br><span class="line">Restart=always</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">RestartSec=10</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload; sudo systemctl restart kubelet</span><br><span class="line">sudo systemctl status kubelet</span><br><span class="line"></span><br><span class="line"># Verify</span><br><span class="line">kubectl get nodes joshuazhang2c.mylabserver.com</span><br><span class="line"># kubectl get csr</span><br><span class="line">NAME                                                   AGE   REQUESTOR                 CONDITION</span><br><span class="line">node-csr-mdou0axSg2vlk5wx2_a1uA0-buvaC-PsiF69Jvjg110   87s   system:bootstrap:iate9c   Approved,Issued</span><br><span class="line"># ls /var/lib/kubelet/pki/</span><br><span class="line">kubelet-client-2018-12-04-08-50-51.pem  kubelet-client-current.pem  kubelet.crt  kubelet.key</span><br><span class="line"># openssl x509 -noout -text -in /var/lib/kubelet/pki/kubelet-client-current.pem |grep system:node</span><br><span class="line">        Subject: O = system:nodes, CN = system:node:joshuazhang4c.mylabserver.com</span><br></pre></td></tr></table></figure>
<h2 id="附件-RBAC-authentication"><a href="#附件-RBAC-authentication" class="headerlink" title="附件 - RBAC authentication"></a>附件 - RBAC authentication</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line">kubectl create ns development</span><br><span class="line">kubectl create ns production</span><br><span class="line">$ kubectl config get-contexts</span><br><span class="line">CURRENT   NAME           CLUSTER        AUTHINFO   NAMESPACE</span><br><span class="line">*         juju-context   juju-cluster   admin</span><br><span class="line"></span><br><span class="line">sudo useradd -s /bin/bash DevHua</span><br><span class="line">sudo passwd DevHua</span><br><span class="line"></span><br><span class="line"># Generate a private key, then Certificate Signing Request (CSR) for DevHua</span><br><span class="line">openssl genrsa -out DevHua.key</span><br><span class="line">openssl req -new -key DevHua.key -out DevHua.csr -subj &quot;/CN=DevHua/O=development&quot;</span><br><span class="line"># Using the newly created request generate a self-signed certificate using the x509 protocol</span><br><span class="line">openssl x509 -req -in DevHua.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out DevHua.crt -days 45</span><br><span class="line"></span><br><span class="line">kubectl config view</span><br><span class="line">kubectl config set-credentials --help</span><br><span class="line">kubectl config set-credentials DevHua --client-certificate=./DevHua.crt --client-key=./DevHua.key</span><br><span class="line">kubectl config set-context --help</span><br><span class="line">kubectl config set-context DevHua-context --cluster=juju-cluster --namespace=development --user=DevHua</span><br><span class="line">kubectl --context=DevHua-context get pods</span><br><span class="line">#kubectl config use-context DevHua-context</span><br><span class="line">kubectl config get-contexts</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; role-dev.yaml&apos; &lt;&lt;EOF</span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: development</span><br><span class="line">  name: developer</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;, &quot;extensions&quot;, &quot;apps&quot;]</span><br><span class="line">  resources: [&quot;deployments&quot;, &quot;replicasets&quot;, &quot;pods&quot;]</span><br><span class="line">  verbs: [&quot;list&quot;, &quot;get&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f role-dev.yaml</span><br><span class="line">kubectl -n development describe roles developer</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; rolebind.yaml&apos; &lt;&lt;EOF</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: developer-role-binding</span><br><span class="line">  namespace: development</span><br><span class="line">subjects:</span><br><span class="line">  - kind: User</span><br><span class="line">    name: DevHua</span><br><span class="line">    apiGroup: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: developer</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line">EOF</span><br><span class="line">kubectl apply -f rolebind.yaml</span><br><span class="line">kubectl -n development describe rolebinding developer-role-binding</span><br><span class="line"></span><br><span class="line">kubectl --context=DevHua-context run nginx --image=nginx</span><br><span class="line">kubectl --context=DevHua-context get pods</span><br><span class="line">kubectl --context=DevHua-context delete deploy nginx</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; adminrolebind.yaml&apos; &lt;&lt;EOF</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: developer-adminrole-binding</span><br><span class="line">  namespace: development</span><br><span class="line">subjects:</span><br><span class="line">  - kind: User</span><br><span class="line">    name: DevHua</span><br><span class="line">    apiGroup: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line">EOF</span><br><span class="line">kubectl apply -f adminrolebind.yaml</span><br><span class="line">kubectl --context=DevHua-context get pods</span><br><span class="line"></span><br><span class="line">kubectl apply -f role-prod.yaml</span><br><span class="line">vim role-prod.yaml</span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: production #&lt;&lt;- This line</span><br><span class="line">  name: dev-prod #&lt;&lt;- and this line</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;, &quot;extensions&quot;, &quot;apps&quot;]</span><br><span class="line">  resources: [&quot;deployments&quot;, &quot;replicasets&quot;, &quot;pods&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;] #&lt;&lt;- and this one</span><br><span class="line"></span><br><span class="line">kubectl apply -f rolebindprod.yaml</span><br><span class="line">vim rolebindprod.yaml</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: production-role-binding</span><br><span class="line">  namespace: production</span><br><span class="line">subjects:</span><br><span class="line">- kind: User</span><br><span class="line">  name: DevDan</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: dev-prod</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line"></span><br><span class="line">kubectl config set-context ProdHua-context --cluster=kubernetes --namespace=production --user=DevHua</span><br><span class="line">kubectl --context=ProdHua-context run nginx --image=nginx</span><br></pre></td></tr></table></figure>
<h2 id="附件-RBAC-authentication-in-Dashboard"><a href="#附件-RBAC-authentication-in-Dashboard" class="headerlink" title="附件 - RBAC authentication in Dashboard"></a>附件 - RBAC authentication in Dashboard</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"># Use default anonymous user</span><br><span class="line"># generate client-certificate-data</span><br><span class="line">grep &apos;client-certificate-data&apos; /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.crt</span><br><span class="line"># generate client-key-data</span><br><span class="line">grep &apos;client-key-data&apos; /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.key</span><br><span class="line"># generate p12</span><br><span class="line">openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name &quot;kubernetes-client&quot;</span><br><span class="line"></span><br><span class="line">kubectl get secret -n kube-system | grep dashboard</span><br><span class="line">kubectlh -n kube-system  get secret kubernetes-dashboard-token-kglhd -o jsonpath=&#123;.data.token&#125;| base64 -d</span><br><span class="line"></span><br><span class="line"># Use admin user</span><br><span class="line">cat &gt; /tmp/admin-user.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line">cat &gt; /tmp/admin-user-role-binding.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f /tmp/admin-user.yaml</span><br><span class="line">kubectl create -f /tmp/admin-user-role-binding.yaml</span><br><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin | awk &apos;&#123;print $1&#125;&apos;)</span><br></pre></td></tr></table></figure>
<h2 id="附件-TLS-bootstrapping"><a href="#附件-TLS-bootstrapping" class="headerlink" title="附件 - TLS bootstrapping"></a>附件 - TLS bootstrapping</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/</span><br><span class="line">https://www.codercto.com/a/23740.html</span><br><span class="line">Workers must use a certificate issued by masters to communicatate with masters. To save the workload of creating certificates each time the worker is added, kubelet in worker will use a predefined certificate bootstrap-kubelet.conf to request masters to apply for cerfificate for this worker dynamically.</span><br><span class="line">kubelet has two ports, one is 10250 used to provide read/write tls private api, one is 10255 used to provide read-only non-tls private api.</span><br><span class="line">Bootstrap Token Secret (kubectl describe secrets --namespace=kube-system bootstrap-signer-token-8xsmh) will replace the previous token.csv.</span><br><span class="line"></span><br><span class="line">kube-apiserver side receives the requests for certificates from the kubelet and authenticates those requests:</span><br><span class="line">a, Recognizing CA that signs the client certificate</span><br><span class="line">   kube-apiserver --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-bootstrap-token-auth=true ...</span><br><span class="line">b, Authenticating the bootstrapping kubelet to the system:bootstrappers group</span><br><span class="line"># Create Bootstrap Token</span><br><span class="line">echo &quot;$(head -c 6 /dev/urandom | md5sum | head -c 6)&quot;.&quot;$(head -c 16 /dev/urandom | md5sum | head -c 16)&quot;</span><br><span class="line">vdb9xb.jiqhz35y355g1ngx</span><br><span class="line">vdb9xb.jiqhz35y355g1ngx,kubelet-bootstrap,10001,&quot;system:bootstrappers&quot;  #token.csv</span><br><span class="line">c, Authorize the bootstrapping kubelet to create a certificate signing request (CSR)</span><br><span class="line">kubectl describe roles.rbac.authorization.k8s.io --namespace=kube-system system:controller:bootstrap-signer</span><br><span class="line">sudo bash -c &apos;cat &lt; rolebinding.yaml&apos; &lt;&lt;EOF</span><br><span class="line"># enable bootstrapping nodes to create CSR</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: create-csrs-for-bootstrapping</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:node-bootstrapper</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kube-controller-manager side is responsible for issuing actual signed certificates:</span><br><span class="line">a, access to the “kuberetes CA key and certificate” that you created and distributed</span><br><span class="line">kube-controller-manager --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt --cluster-signing-key-file=/etc/kubernetes/pki/ca.key ...</span><br><span class="line">b, approve CSR signing automatically</span><br><span class="line">sudo bash -c &apos;cat &lt; certificatesigningrequests.yaml&apos; &lt;&lt;EOF</span><br><span class="line"># Approve all CSRs for the group &quot;system:bootstrappers&quot;</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-approve-csrs-for-group</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line">sudo bash -c &apos;cat &lt; renewal.yaml&apos; &lt;&lt;EOF</span><br><span class="line"># Approve renewal CSRs for the group &quot;system:nodes&quot;</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-approve-renewals-for-nodes</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubelet side:</span><br><span class="line">kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf ...</span><br><span class="line"># cat /etc/kubernetes/bootstrap-kubelet.conf</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: [xxx]</span><br><span class="line">    server: https://172.31.43.252:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: tls-bootstrap-token-user</span><br><span class="line">  name: tls-bootstrap-token-user@kubernetes</span><br><span class="line">current-context: tls-bootstrap-token-user@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: tls-bootstrap-token-user</span><br><span class="line">  user:</span><br><span class="line">    token: vdb9xb.jiqhz35y355g1ngx</span><br><span class="line"></span><br><span class="line">In Summary:</span><br><span class="line">kubectl get secrets -n kube-system |grep -i bootstrap</span><br><span class="line">kubectl -n kube-system get secret bootstrap-signer-token-8xsmh -o jsonpath=&#123;.data.token&#125;| base64 -d</span><br></pre></td></tr></table></figure>
<h2 id="附件-microk8s"><a href="#附件-microk8s" class="headerlink" title="附件 - microk8s"></a>附件 - microk8s</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#sudo snap install microk8s --beta --classic</span><br><span class="line">sudo snap install microk8s --edge --classic</span><br><span class="line">snap list</span><br><span class="line">journalctl -u snap.microk8s.daemon-apiserver.service</span><br><span class="line">microk8s.kubectl get no</span><br><span class="line">microk8s.enable dns dashboard</span><br><span class="line">microk8s.kubectl get all --all-namespaces</span><br><span class="line">lynx http://xxxx</span><br></pre></td></tr></table></figure>
<h2 id="附件-其他"><a href="#附件-其他" class="headerlink" title="附件 - 其他"></a>附件 - 其他</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br></pre></td><td class="code"><pre><span class="line"># How to generate yaml template</span><br><span class="line">kubectl run --restart=Always # creates a Deployment</span><br><span class="line">kubectl run --restart=Never # creates bare pod</span><br><span class="line">kubectl run --restart=OnFailure # creates a Job.</span><br><span class="line"></span><br><span class="line">https://kubernetes.io/docs/reference/kubectl/conventions/#generators</span><br><span class="line">pod template:</span><br><span class="line">  kubectl run --help |grep generator</span><br><span class="line">  kubectl run --generator=run-pod/v1 nginx --image=nginx --dry-run -o yaml</span><br><span class="line">service and deployment template:</span><br><span class="line">  kubectl run nginx --service-generator=&apos;service/v2&apos; --image=nginx --dry-run --expose --port 80 -o yaml</span><br><span class="line">job template:</span><br><span class="line">  kubectl run --generator=job/v1 nginx --image=nginx --dry-run -o yaml</span><br><span class="line"></span><br><span class="line"># jq, jsonpath, sort-by, kubectl top etc</span><br><span class="line">kubectl delete pods,services -l name=myLabel --include-uninitialized</span><br><span class="line">kubectl get pods --field-selector=status.phase=Running</span><br><span class="line">kubectl get pod ubuntu -o yaml |sed &apos;s/\(image: ubuntu\):.*$/\1:18.04/&apos; |kubectl replace -f -</span><br><span class="line">kubectl top pod -l name=nginx-ingress-kubernetes-worker</span><br><span class="line">kubectl get pods --sort-by=.metadata.name</span><br><span class="line"></span><br><span class="line">kubectl get -o template pod/web-pod-13je7 --template=&#123;&#123;.status.phase&#125;&#125;</span><br><span class="line"></span><br><span class="line">kubectl get nodes -o jsonpath=&apos;&#123;.items[*].metadata.name&#125;&apos; equals kubectl get nodes -o jsonpath=&apos;&#123;.items..metadata.name&#125;&apos;</span><br><span class="line">kubectl get nodes -o jsonpath=&apos;&#123;.items[].metadata.name&#125;&apos; equals kubectl get nodes -o jsonpath=&apos;&#123;.items[0].metadata.name&#125;&apos;</span><br><span class="line">kubectl get nodes -o jsonpath=&apos;&#123;.items[*].status.addresses[?(@.type==&quot;InternalIP&quot;)].address&#125;&apos;</span><br><span class="line"></span><br><span class="line">kubectl get pods -o json |jq &apos;.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name&apos; |grep -v null |sort |uniq</span><br><span class="line"></span><br><span class="line"># just get pod&apos;s names</span><br><span class="line">kubectl get pod -l app=nginx -o json |jq &apos;.items[].metadata.name&apos;</span><br><span class="line">kubectl get pods -l app=nginx -o=custom-columns=NAME:.metadata.name</span><br><span class="line">kubectl get pods -l app=nginx -o=name</span><br><span class="line"></span><br><span class="line"># dont&apos;s forget --record</span><br><span class="line">#kubectl rollout pause deployment/scale-deploy</span><br><span class="line">#kubectl set resources deployment/scale-deploy -c=nginx --limits=cpu=200m,memory=512Mi</span><br><span class="line">#kubectl rollout resume deployment/scale-deploy</span><br><span class="line">deployment.apps/nginx-deployment resource requirements updated</span><br><span class="line">kubectl set image deploy scale-deploy nginx=nginx:1.9.1 --record</span><br><span class="line">kubectl rollout history deployment/scale-deploy</span><br><span class="line">kubectl rollout history deployment/scale-deploy --revision=1</span><br><span class="line">kubectl rollout undo deployment/scale-deploy</span><br><span class="line">kubectl rollout undo deployment/scale-deploy --to-revision=2</span><br><span class="line">kubectl scale deployment/scale-deploy --replicas=2</span><br><span class="line">kubectl autoscale deployment/scale-deploy --min=3 --max=4 --cpu-percent=80</span><br><span class="line"></span><br><span class="line"># volume template</span><br><span class="line">cat &gt; test_pod.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pod</span><br><span class="line">spec:</span><br><span class="line">  #initContainers:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test</span><br><span class="line">      name: secret-volume</span><br><span class="line">    env:</span><br><span class="line">    - name: PASS</span><br><span class="line">      valueFrom:</span><br><span class="line">        secretKeyRef:</span><br><span class="line">          name: test-secret</span><br><span class="line">          key: passwd</span><br><span class="line">  volumes:</span><br><span class="line">  - name: hostpath-volume</span><br><span class="line">    hostPath:</span><br><span class="line">      path: /data</span><br><span class="line">  - name: emptydir-volume</span><br><span class="line">    emptyDir: &#123;&#125;</span><br><span class="line">  - name: secret-volume</span><br><span class="line">    secret:</span><br><span class="line">      secretName: test-secret</span><br><span class="line">EOF</span><br><span class="line">kubectl create --save-config -f test_pod.yaml</span><br><span class="line">kubectl apply --record -f test_pod.yaml</span><br><span class="line"></span><br><span class="line"># initcontainers</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: init-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: workdir</span><br><span class="line">      mountPath: /usr/share/nginx/html</span><br><span class="line">  initContainers:</span><br><span class="line">  - name: touch</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command: [&apos;touch&apos;, &apos;/work-dir/index.html&apos;]</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: workdir</span><br><span class="line">      mountPath: &quot;/work-dir&quot;</span><br><span class="line">  volumes:</span><br><span class="line">  - name: workdir</span><br><span class="line">    emptyDir: &#123;&#125;</span><br><span class="line"></span><br><span class="line"># Create a pod that uses secrets</span><br><span class="line">kubectl create secret generic test-secret --from-literal=usename=hua --from-literal=passwd=password --dry-run -o yaml</span><br><span class="line">kubectl create secret generic test-secret --from-literal=usename=hua --from-literal=passwd=password</span><br><span class="line">kubectl get pods --namespace=kube-system kube-flannel-ds-amd64-4mt82 -o yaml &gt; pod_template.yaml</span><br><span class="line">cat &gt; pod-secret.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: question1</span><br><span class="line">  name: pod-secret</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /mnt/secret</span><br><span class="line">      name: test-secret-vol</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-secret-vol</span><br><span class="line">    secret:</span><br><span class="line">      secretName: test-secret</span><br><span class="line">EOF</span><br><span class="line">kubectl exec pod-secret -- cat /mnt/secret/passwd</span><br><span class="line">cat &gt; pod_secret_env.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: question1</span><br><span class="line">  name: pod-secret-env</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx</span><br><span class="line">    env:</span><br><span class="line">    - name: PASS</span><br><span class="line">      valueFrom:</span><br><span class="line">        secretKeyRef:</span><br><span class="line">          name: test-secret</span><br><span class="line">          key: passwd</span><br><span class="line">EOF</span><br><span class="line">kubectl exec pod-secret-env -- env |grep PASS</span><br><span class="line"></span><br><span class="line"># etcd 3</span><br><span class="line">ETCDCTL_API=3 etcdctl --help |grep snap</span><br><span class="line">ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/apiserver-etcd-client.crt --key=/etc/kubernetes/pki/apiserver-etcd-client.key member list</span><br><span class="line">ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/apiserver-etcd-client.crt --key=/etc/kubernetes/pki/apiserver-etcd-client.key snapshot save snapshot.db</span><br><span class="line">etcdctl --endpoints=https://[127.0.0.1]:2379 --ca-file=/etc/kubernetes/pki/etcd/ca.crt --cert-file=/etc/kubernetes/pki/apiserver-etcd-client.crt --key-file=/etc/kubernetes/pki/apiserver-etcd-client.key cluster-health</span><br><span class="line"></span><br><span class="line"># PV &amp; PVC &amp; Pod</span><br><span class="line">cat &gt; pv.yaml &lt;&lt;EOF</span><br><span class="line">pv + hostpath</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: task-pv-volume</span><br><span class="line">  labels:</span><br><span class="line">    type: local</span><br><span class="line">spec:</span><br><span class="line">  storageClassName: manual</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 2Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  hostPath:</span><br><span class="line">    path: &quot;/mnt/data&quot;</span><br><span class="line">EOF</span><br><span class="line">cat &gt; pv.yaml &lt;&lt;EOF</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: task-pv-claim</span><br><span class="line">spec:</span><br><span class="line">  storageClassName: manual</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">EOF</span><br><span class="line">cat &gt; pv.yaml &lt;&lt;EOF</span><br><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: task-pv-pod</span><br><span class="line">spec:</span><br><span class="line">  volumes:</span><br><span class="line">    - name: task-pv-storage</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">       claimName: task-pv-claim</span><br><span class="line">  containers:</span><br><span class="line">    - name: task-pv-container</span><br><span class="line">      image: nginx</span><br><span class="line">      ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">          name: &quot;http-server&quot;</span><br><span class="line">      volumeMounts:</span><br><span class="line">        - mountPath: &quot;/usr/share/nginx/html&quot;</span><br><span class="line">          name: task-pv-storage</span><br><span class="line">EOF</span><br><span class="line"># NOTE: the following command should be runned in the pod which ship pod</span><br><span class="line">echo &apos;hello&apos; &gt; /mnt/data/index.html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># custom install master (TBD)</span><br><span class="line"># install kube* and etcd binary - https://kubernetes.io/docs/setup/scratch/</span><br><span class="line">wget https://github.com/kubernetes/kubernetes/releases/download/v1.13.0/kubernetes.tar.gz</span><br><span class="line">tar -xf kubernetes.tar.gz</span><br><span class="line">./kubernetes/cluster/get-kube-binaries.sh</span><br><span class="line">tar -xf kubernetes/server/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">sudo cp kubernetes/server/bin/&#123;kube-apiserver,kube-scheduler,kube-controller-manager,kube-proxy,kubectl,kubelet&#125; /usr/bin/</span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.3.10/etcd-v3.3.10-linux-amd64.tar.gz</span><br><span class="line">tar -xf etcd-v3.3.10-linux-amd64.tar.gz</span><br><span class="line">sudo cp etcd-v3.3.10-linux-amd64/&#123;etcd,etcdctl&#125; /usr/bin/</span><br><span class="line"></span><br><span class="line"># create cert</span><br><span class="line">sudo -i</span><br><span class="line">mkdir -p /etc/kubernetes &amp;&amp; cd /etc/kubernetes</span><br><span class="line">openssl genrsa -out ca.key</span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=quqi.cluster&quot; -days 5000 -out ca.crt</span><br><span class="line"># openssl x509 -in ca.crt -out ca.pem  #convert CRT to PEM</span><br><span class="line"></span><br><span class="line">#Create key pair for kube-master. NOTE: kube-master should be the same as it&apos;s hostname</span><br><span class="line">openssl genrsa -out server.key</span><br><span class="line">openssl req -new -key server.key -out server.csr -subj &quot;/CN=system:node:172.31.20.224/O=system:nodes&quot;</span><br><span class="line">openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 5000</span><br><span class="line">openssl x509  -noout -text -in ./server.crt</span><br><span class="line"></span><br><span class="line"># Create key pair for every kube-worker, here we will just create one for all-workers</span><br><span class="line">openssl genrsa -out client.key</span><br><span class="line">openssl req -new -key client.key -out client.csr -subj &quot;/CN=system:node:worker/O=system:nodes&quot;</span><br><span class="line">openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 5000</span><br><span class="line">openssl x509  -noout -text -in ./client.crt</span><br><span class="line"></span><br><span class="line"># static pod way</span><br><span class="line">sudo apt install -y docker.io</span><br><span class="line">sudo mkdir -p /etc/kubernetes/manifests</span><br><span class="line">sudo kubelet --register-node=false --pod-manifest-path=/etc/kubernetes/manifests</span><br><span class="line">https://medium.com/containerum/4-ways-to-bootstrap-a-kubernetes-cluster-de0d5150a1e4</span><br><span class="line"></span><br><span class="line"># systemd way - https://medium.com/containerum/4-ways-to-bootstrap-a-kubernetes-cluster-de0d5150a1e4</span><br><span class="line">git clone https://github.com/kubernetes/contrib.git</span><br><span class="line">cd ./contrib/init/systemd/</span><br><span class="line">sudo useradd kube</span><br><span class="line">sudo mv *.service /etc/systemd/system/</span><br><span class="line">sudo mv ./environ/* /etc/kubernetes/</span><br><span class="line">sudo mkdir -p  /var/run/kubernetes</span><br><span class="line">sudo systemctl enable kube-apiserver</span><br><span class="line">sudo systemctl restart kube-apiserver</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"># install etcd - https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/</span><br><span class="line">sudo touch /var/log/etcd.log &amp;&amp; sudo chown -R $(id -u) /var/log/etcd.log</span><br><span class="line">sudo etcd --listen-client-urls=http://0.0.0.0:2379 --advertise-client-urls=http://172.31.20.224:2379 &gt;&gt; /var/log/etcd.log 2&gt;&amp;1 &amp;</span><br><span class="line">sudo ETCDCTL_API=2 etcdctl --endpoints=http://172.31.20.224:2379 cluster-health</span><br><span class="line">sudo ETCDCTL_API=3 etcdctl --endpoints=http://172.31.20.224:2379 member list</span><br><span class="line">sudo ETCDCTL_API=3 etcdctl --endpoints=http://172.31.20.224:2379 snapshot save snapshot.save</span><br><span class="line"></span><br><span class="line"># run kube-apiserver</span><br><span class="line">sudo touch /var/log/kube-apiserver.log &amp;&amp; sudo chown -R $(id -u) /var/log/kube-apiserver.log</span><br><span class="line">#sudo kube-apiserver --logtostderr --v=0 --etcd-servers=http://172.31.20.224:2379 --insecure-bind-address=0.0.0.0 --insecure-port=8080 --service-cluster-ip-range=10.244.0.0/16 --admission-control=ServiceAccount,LimitRanger,ResourceQuota --bind-address=0.0.0.0 --secure-port=6443 --client-ca-file=/etc/kubernetes/ca.crt --tls-private-key-file=/etc/kubernetes/server.key --tls-cert-file=/etc/kubernetes/server.crt &gt;&gt; /var/log/kube-apiserver.log 2&gt;&amp;1 &amp;</span><br><span class="line">sudo kube-apiserver --logtostderr --v=0 --etcd-servers=http://172.31.20.224:2379 --insecure-bind-address=0.0.0.0 --insecure-port=8080 --service-cluster-ip-range=10.244.0.0/16 --admission-control=ServiceAccount,LimitRanger,ResourceQuota &gt;&gt; /var/log/kube-apiserver.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"># run kube-controller-manager</span><br><span class="line">sudo touch /var/log/kube-controller-manager.log &amp;&amp; sudo chown -R $(id -u) /var/log/kube-controller-manager.log</span><br><span class="line">#sudo kube-controller-manager --logtostderr --v=0 --master=https://172.31.20.224:6443 --service-account-private-key-file=/etc/kubernetes/server.key --root-ca-file=/etc/kubernetes/ca.crt</span><br><span class="line">sudo kube-controller-manager --logtostderr --v=0 --master=http://172.31.20.224:8080  &gt;&gt; /var/log/kube-controller-manager.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"># run kube-scheduler</span><br><span class="line">sudo touch /var/log/kube-scheduler.log &amp;&amp; sudo chown -R $(id -u) /var/log/kube-scheduler.log</span><br><span class="line">sudo kube-scheduler --logtostderr --v=0 --master=http://172.31.20.224:8080  &gt;&gt; /var/log/kube-scheduler.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"># verity master</span><br><span class="line">kubectl -s http://172.31.20.224:8080 get componentstatus</span><br><span class="line">kubectl -s http://172.31.20.224:8080 get node</span><br><span class="line"></span><br><span class="line"># run kube-proxy, docker and kubelet</span><br><span class="line">sudo touch /var/log/kube-proxy.log &amp;&amp; sudo chown -R $(id -u) /var/log/kube-proxy.log</span><br><span class="line">sudo kube-proxy --logtostderr --v=0 --master=http://172.31.20.224:8080  &gt;&gt; /var/log/kube-proxy.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line">sudo apt install docker.io</span><br><span class="line">sudo systemctl enable docker</span><br><span class="line"></span><br><span class="line">kubectl config view</span><br><span class="line">kubectl config set-credentials admin --username=admin --password=password</span><br><span class="line">kubectl config set-cluster quqi.cluster --insecure-skip-tls-verify=true --server=http://172.31.20.224:8080</span><br><span class="line">kubectl config set-context quqi.context --user=admin --namespace=default --cluster=quqi.cluster</span><br><span class="line">kubectl config use-context quqi.context</span><br><span class="line">sudo cp .kube/config /etc/kubernetes/kubeconfig</span><br><span class="line"></span><br><span class="line">sudo touch /var/log/kubelet.log &amp;&amp; sudo chown -R $(id -u) /var/log/kubelet.log</span><br><span class="line">sudo kubelet --logtostderr --v=0 --kubeconfig=/etc/kubernetes/kubeconfig  &gt;&gt; /var/log/kubelet.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"># self-hosted way</span><br><span class="line"># create kubeconfig</span><br><span class="line">NOTE: Put the kubeconfig(s) on every node. eg: in /var/lib/kube-proxy/kubeconfig and /var/lib/kubelet/kubeconfig.</span><br><span class="line">CLUSTER_NAME=quqicluster</span><br><span class="line">CA_CERT=/etc/kubernetes/pki/ca.crt</span><br><span class="line">CLI_CERT=/etc/kubernetes/pki/client.crt</span><br><span class="line">CLI_KEY=/etc/kubernetes/pki/client.key</span><br><span class="line">TOKEN=$(dd if=/dev/urandom bs=128 count=1 2&gt;/dev/null | base64 | tr -d &quot;=+/[:space:]&quot; | dd bs=32 count=1 2&gt;/dev/null)</span><br><span class="line">USER=admin</span><br><span class="line">CONTEXT_NAME=admin_context</span><br><span class="line">MASTER_IP=172.31.29.147</span><br><span class="line">sudo kubectl config set-cluster $CLUSTER_NAME --certificate-authority=$CA_CERT --embed-certs=true --server=https://$MASTER_IP</span><br><span class="line">sudo kubectl config set-credentials $USER --client-certificate=$CLI_CERT --client-key=$CLI_KEY --embed-certs=true --token=$TOKEN</span><br><span class="line">sudo kubectl config set-context $CONTEXT_NAME --cluster=$CLUSTER_NAME --user=$USER</span><br><span class="line">sudo kubectl config use-context $CONTEXT_NAME</span><br><span class="line"></span><br><span class="line"># install docker</span><br><span class="line">#iptables -t nat -F</span><br><span class="line">#ip link set docker0 down</span><br><span class="line">#ip link delete docker0</span><br><span class="line">sudo apt install -y docker.io</span><br><span class="line">sudo systemctl enable docker</span><br><span class="line"></span><br><span class="line"># Install kubelet</span><br><span class="line">sudo mkdir -p /var/lib/kubelet</span><br><span class="line">sudo cp ~/.kube/config /var/lib/kubelet/kubeconfig</span><br><span class="line">sudo kubelet --kubeconfig=/var/lib/kubelet/kubeconfig</span><br><span class="line"></span><br><span class="line">kubelet --kubeconfig=/var/lib/kubelet/kubeconfig --cgroup-driver=cgroupfs --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.1</span><br><span class="line"></span><br><span class="line"># Install kube-proxy</span><br><span class="line">sudo mkdir -p /var/lib/kube-proxy</span><br><span class="line">sudo cp ~/.kube/config /var/lib/kube-proxy/kubeconfig</span><br><span class="line">sudo kube-proxy --master=https://$MASTER_IP --kubeconfig=/var/lib/kube-proxy/kubeconfig</span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="http://blog.spider.im/2018/06/26/cka-exam/" target="_blank" rel="external">http://blog.spider.im/2018/06/26/cka-exam/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/31/Use-Octavia-to-Implement-HTTPS-Health-Monitors/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/31/Use-Octavia-to-Implement-HTTPS-Health-Monitors/" itemprop="url">Use Octavia to Implement HTTPS Health Monitors</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-31T16:29:50+08:00">
                2018-12-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="几张图感性认识ocatvia"><a href="#几张图感性认识ocatvia" class="headerlink" title="几张图感性认识ocatvia"></a>几张图感性认识ocatvia</h2><p><img src="https://img-blog.csdnimg.cn/20200216105554797.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200216105645469.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200624104629442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>采用Neutron LBaaS v2实现HTTPS Health Monitors时的配置如下(步骤见附件 - Neutron LBaaS v2)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">    mode tcp</span><br><span class="line">    balance leastconn</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    option ssl-hello-chk</span><br><span class="line">    server 37a1f5a8-ec7e-4208-9c96-27d2783a594f 192.168.21.13:443 weight 1 check inter 5s fall 2</span><br><span class="line">    server 8e722b4b-08b8-4089-bba5-8fa5dd26a87f 192.168.21.8:443 weight 1 check inter 5s fall 2</span><br></pre></td></tr></table></figure></p>
<p>这种配置会有一个问题, 当使用自定义签名证书时一切正常, 但使用机构颁发的证书时反而有问题.<br>1, 对于ssl check, 严格一点的是check-ssl, 但haproxy没有证书不支持严格的客户端认证, 所以需添加”check check-ssl verify none”参数禁止对客户端参数进行验证. lbaasv2由于久远不支持(那时都还是haproxy 1.7以前必须不支持), ocatavia则有对ssl check的支持.(<a href="https://github.com/openstack/octavia/blob/master/octavia/common/jinja/haproxy/templates/macros.j2" target="_blank" rel="external">https://github.com/openstack/octavia/blob/master/octavia/common/jinja/haproxy/templates/macros.j2</a>)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">154         &#123;% if pool.health_monitor.type == constants.HEALTH_MONITOR_HTTPS %&#125;</span><br><span class="line">155             &#123;% set monitor_ssl_opt = &quot; check-ssl verify none&quot; %&#125;</span><br></pre></td></tr></table></figure></p>
<p>下面的配置works<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">backend 79024d4d-4de4-492c-a3e2-21730b096a37</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 317e4dea-5a62-4df0-a2f1-ea7bad4a9c5d 192.168.21.7:443 weight 1 check check-ssl verify none inter 5s fall 3 rise 4</span><br></pre></td></tr></table></figure></p>
<p>但是似乎ocatavia的client有点问题, 它设置出来的是:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    option httpchk None None</span><br><span class="line">    http-check expect rstatus None</span><br><span class="line">    server 317e4dea-5a62-4df0-a2f1-ea7bad4a9c5d 192.168.21.7:443 weight 1 check check-ssl verify none inter 5s fall 3 rise 4</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTPS --name https-monitor --http-method GET --url-path / --expected-codes 200 pool1</span><br><span class="line">http_method is not a valid option for health monitors of type HTTPS (HTTP 400) (Request-ID: req-2d81bafa-1240-4f73-8e2e-cb0dd7691fdb)</span><br></pre></td></tr></table></figure></p>
<p>2, ssl backend side采用了严格的客户端认证的话, 需改用TLS-HELLO check (<a href="https://docs.openstack.org/octavia/latest/user/guides/basic-cookbook.html)其实已经有说明" target="_blank" rel="external">https://docs.openstack.org/octavia/latest/user/guides/basic-cookbook.html)其实已经有说明</a>, 如下:<br>HTTPS health monitors operate exactly like HTTP health monitors, but with ssl back-end servers. Unfortunately, this causes problems if the servers are performing client certificate validation, as HAProxy won’t have a valid cert. In this case, using TLS-HELLO type monitoring is an alternative.<br>TLS-HELLO health monitors simply ensure the back-end server responds to SSLv3 client hello messages. It will not check any other health metrics, like status code or body contents.<br><a href="https://review.openstack.org/#/c/475944/" target="_blank" rel="external">https://review.openstack.org/#/c/475944/</a></p>
<p>实际上客户并未使用客户端认证, 所以不是上面的原因, 应该是SNI所致. 因为后端有SNI认证, haproxy端需传入hostname, 但haproxy端无法传入hostname, 所以出错.<strong>但octavia-worker应该可以传SNI到后端</strong>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --cacert ca.crt https://10.5.150.5</span><br><span class="line">curl: (51) SSL: certificate subject name (www.server1.com) does not match target host name &apos;10.5.150.5&apos;</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server1.com:443:10.5.150.5 -k https://www.server1.com</span><br><span class="line">test1</span><br></pre></td></tr></table></figure></p>
<p>什么是SNI, 就是ssl server端可能会根据每个节点的hostname生成不同的cert, 并启用SNI. 这样ssl client访问ssl server端时也应该将hostname也传过去. (注: SNIProxy是一个适用于 HTTPS 和 HTTP 的类似于透明代理的反向代理工具。它可以在 TCP 层直接将流量在不解包的情况下转发出来，实现不需要在代理服务器配置证书就能反向代理 HTTPS 网站的功能)<br>‘curl -k’的方式测试无法很好的测试SNI, 最好是通过’openstack s_client’测试:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#Ideal Test to connect with SSLv3/No SNI</span><br><span class="line">openssl s_client -ssl3 -connect 103.245.215.4:443</span><br><span class="line">#openssl s_client -connect 192.168.254.214:9443 | openssl x509 -noout -text | grep DNS</span><br><span class="line">#We can also send SNI using -servername:</span><br><span class="line">openssl s_client -ssl3 -servername CERT_HOSTNAME -connect 103.245.215.4:443</span><br></pre></td></tr></table></figure></p>
<p>这个文档 (<a href="https://cbonte.github.io/haproxy-dconv/1.7/configuration.html#option%20ssl-hello-chk" target="_blank" rel="external">https://cbonte.github.io/haproxy-dconv/1.7/configuration.html#option%20ssl-hello-chk</a> )指出ssl-hello-chk只检查SSLv3不检查HTTP, 事实上, HTTPS health check也不检查HTTP只是多了个SSL negotiation. check-ssl check似乎能做更多.<br>LBaas v2模板目前只支持”httpchk”与”ssl-hello-chk”, 这只有SSL check, 没有HTTP check. 所以问题很可能是出在SSLv3 hello (without SNI)有问题.做个SNI相关的实验验证一下:<br>首先, charm应该将ca传给octavia, ocavia应该根据ca再去创建SNI证书, 并且传SNI证书到backend, octavia-worker的相关处理代码如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">    LOG.debug(&quot;request url %s&quot;, path)</span><br><span class="line">    _request = getattr(self.session, method.lower())</span><br><span class="line">    _url = self._base_url(amp.lb_network_ip) + path</span><br><span class="line">    LOG.debug(&quot;request url %s&quot;, _url)</span><br><span class="line">    reqargs = &#123;</span><br><span class="line">        &apos;verify&apos;: CONF.haproxy_amphora.server_ca,</span><br><span class="line">        &apos;url&apos;: _url,</span><br><span class="line">        &apos;timeout&apos;: (req_conn_timeout, req_read_timeout), &#125;</span><br><span class="line">    reqargs.update(kwargs)</span><br><span class="line">    headers = reqargs.setdefault(&apos;headers&apos;, &#123;&#125;)</span><br><span class="line">    headers[&apos;User-Agent&apos;] = OCTAVIA_API_CLIENT</span><br><span class="line">    self.ssl_adapter.uuid = amp.id</span><br><span class="line">    exception = None</span><br><span class="line">    # Keep retrying</span><br><span class="line"></span><br><span class="line">def get_create_amphora_flow(self):</span><br><span class="line">    &quot;&quot;&quot;Creates a flow to create an amphora.</span><br><span class="line"></span><br><span class="line">    :returns: The flow for creating the amphora</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    create_amphora_flow = linear_flow.Flow(constants.CREATE_AMPHORA_FLOW)</span><br><span class="line">    create_amphora_flow.add(database_tasks.CreateAmphoraInDB(</span><br><span class="line">                            provides=constants.AMPHORA_ID))</span><br><span class="line">    create_amphora_flow.add(lifecycle_tasks.AmphoraIDToErrorOnRevertTask(</span><br><span class="line">        requires=constants.AMPHORA_ID))</span><br><span class="line">    if self.REST_AMPHORA_DRIVER:</span><br><span class="line">        create_amphora_flow.add(cert_task.GenerateServerPEMTask(</span><br><span class="line"></span><br><span class="line">        create_amphora_flow.add(</span><br><span class="line">            database_tasks.UpdateAmphoraDBCertExpiration(</span><br><span class="line">                requires=(constants.AMPHORA_ID, constants.SERVER_PEM)))</span><br><span class="line"></span><br><span class="line">        create_amphora_flow.add(compute_tasks.CertComputeCreate(</span><br><span class="line">            requires=(constants.AMPHORA_ID, constants.SERVER_PEM,</span><br><span class="line">                      constants.BUILD_TYPE_PRIORITY, constants.FLAVOR),</span><br><span class="line">            provides=constants.COMPUTE_ID))</span><br></pre></td></tr></table></figure></p>
<p>1, 两个证书, 略. lb_tls_secret_1的hostname是www.server1.com, lb_tls_secret_2的hostname是www.server2.com<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">secret1_id=$(openstack secret list |grep lb_tls_secret_1 |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">secret2_id=$(openstack secret list |grep lb_tls_secret_2 |awk &apos;&#123;print $2&#125;&apos;)</span><br></pre></td></tr></table></figure></p>
<p>2, 创建listener时使用( –sni-container-refs $secret1_id $secret2_id )加入了两个域名的SNI<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">IP=192.168.21.7</span><br><span class="line">secret1_id=$(openstack secret list |grep lb_tls_secret_1 |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">secret2_id=$(openstack secret list |grep lb_tls_secret_2 |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">subnetid=$(openstack subnet show private_subnet -f value -c id); echo $subnetid</span><br><span class="line">lb_id=$(openstack loadbalancer show lb3 -f value -c id)</span><br><span class="line">#lb_id=$(openstack loadbalancer create --name test_tls_termination --vip-subnet-id $subnetid -f value -c id); echo $lb_id</span><br><span class="line">listener_id=$(openstack loadbalancer listener create $lb_id --name https_listener --protocol-port 443 --protocol TERMINATED_HTTPS --default-tls-container=$secret1_id --sni-container-refs $secret1_id $secret2_id -f value -c id); echo $listener_id</span><br><span class="line">pool_id=$(openstack loadbalancer pool create --protocol HTTP --listener $listener_id --lb-algorithm ROUND_ROBIN -f value -c id); echo $pool_id</span><br><span class="line">openstack loadbalancer member create --address $&#123;IP&#125; --subnet-id $subnetid --protocol-port 80 $pool_id</span><br><span class="line"></span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">vip=$(openstack loadbalancer show $lb_id -c vip_address -f value)</span><br><span class="line">vip_port=$(openstack port list --fixed-ip ip-address=$vip -c ID -f value)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address $vip --port $vip_port</span><br></pre></td></tr></table></figure></p>
<p>3, 测试, client传入www.server1.com或www.server2.com两个域名时, server端能正常响应, 但传入一个域名www.server3.com时就报了这个错:’does not match target host name ‘www.server3.com’’</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server1.com:443:10.5.150.5 --cacert ca.crt https://www.server1.com</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server2.com:443:10.5.150.5 --cacert ca.crt https://www.server2.com</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server3.com:443:10.5.150.5 --cacert ca.crt https://www.server3.com</span><br><span class="line">curl: (51) SSL: certificate subject name (www.server1.com) does not match target host name &apos;www.server3.com&apos;</span><br></pre></td></tr></table></figure>
<p>为什么会这样呢?</p>
<p>LBaaS v2中的ssl check将在haproxy中添加下列配置, 实际上有ssl-hello-chk时httpchk将被覆盖(haproxy忽略的). haproxy 1.7开始添加了更高级的check-ssl(xenial使用haproxy 1.6, 不支持), 估计就是早期的lbaas为ssl check添加ssl-hello-chk的原因<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mode tcp</span><br><span class="line">option httpchk GET /</span><br><span class="line">http-check expect rstatus 303</span><br><span class="line">option ssl-hello-chk</span><br></pre></td></tr></table></figure></p>
<p>haproxy(<a href="http://cbonte.github.io/haproxy-dconv/1.6/configuration.html#4-option%20ssl-hello-chk)将为ssl-hello-chk伪造SSLv3包" target="_blank" rel="external">http://cbonte.github.io/haproxy-dconv/1.6/configuration.html#4-option%20ssl-hello-chk)将为ssl-hello-chk伪造SSLv3包</a>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">When some SSL-based protocols are relayed in TCP mode through HAProxy, it is</span><br><span class="line">possible to test that the server correctly talks SSL instead of just testing</span><br><span class="line">that it accepts the TCP connection. When &quot;option ssl-hello-chk&quot; is set, pure</span><br><span class="line">SSLv3 client hello messages are sent once the connection is established to</span><br><span class="line">the server, and the response is analyzed to find an SSL server hello message.</span><br><span class="line">The server is considered valid only when the response contains this server</span><br><span class="line">hello message.</span><br><span class="line">All servers tested till there correctly reply to SSLv3 client hello messages,</span><br><span class="line">and most servers tested do not even log the requests containing only hello</span><br><span class="line">messages, which is appreciable.</span><br><span class="line">Note that this check works even when SSL support was not built into haproxy</span><br><span class="line">because it forges the SSL message. When SSL support is available, it is best</span><br><span class="line">to use native SSL health checks instead of this one.</span><br></pre></td></tr></table></figure></p>
<p>这是haproxy相关处理的源代码, 它没使用SSL libray, 先发硬编码的SSLv3 hello消息, 然后从response里找0x15 (SSL3_RT_ALERT) or 0x16 (SSL3_RT_HANDSHAKE), 若没找着就返回HCHK_STATUS_L6RSP(Layer6 invalid response) - <a href="https://github.com/haproxy/haproxy/blob/master/src/checks.c#L915" target="_blank" rel="external">https://github.com/haproxy/haproxy/blob/master/src/checks.c#L915</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">case PR_O2_SSL3_CHK:</span><br><span class="line">	if (!done &amp;&amp; b_data(&amp;check-&gt;bi) &lt; 5)</span><br><span class="line">		goto wait_more_data;</span><br><span class="line"></span><br><span class="line">	/* Check for SSLv3 alert or handshake */</span><br><span class="line">	if ((b_data(&amp;check-&gt;bi) &gt;= 5) &amp;&amp; (*b_head(&amp;check-&gt;bi) == 0x15 || *b_head(&amp;check-&gt;bi) == 0x16))</span><br><span class="line">		set_server_check_status(check, HCHK_STATUS_L6OK, NULL);</span><br><span class="line">	else</span><br><span class="line">		set_server_check_status(check, HCHK_STATUS_L6RSP, NULL);</span><br><span class="line">	break;</span><br></pre></td></tr></table></figure></p>
<p>错误’Layer6 invalid response’正是从客户日志中看到的:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Oct 25 04:50:34 neut002 haproxy[54990]: Server aaa0a533-073b-4b0f-8b81-777b6a8f3900/f2dc685f-58f7-4201-8060-3409d2d73a0d is DOWN, reason: Layer6 invalid response, check duration: 4ms. 0 active and 0 backup servers left. 0 sessions active, 0 requeued, 0 remaining in queue.</span><br></pre></td></tr></table></figure></p>
<p>所以backend ssl server端应该返回0x15, 客户究竟在haproxy之前运行什么ssl backend端, 我们不清楚. 假设它们运行的是apache2. 我们搭建一个测试环境, apache2采用默认的tls1.2, 而haproxy里还使用老的sslv3 hello时, apache2 ssl backend将返回下列的ssl协商错误:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openssl s_client -ssl3 -connect www.server1.com:443</span><br><span class="line">140306875094680:error:140A90C4:SSL routines:SSL_CTX_new:null ssl method passed:ssl_lib.c:1878:</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openssl s_client -ssl3 -servername www.server1.com -connect www.server1.com:443</span><br><span class="line">139626113296024:error:140A90C4:SSL routines:SSL_CTX_new:null ssl method passed:ssl_lib.c:1878:</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openssl s_client -ssl3 -servername www.server2.com -connect www.server1.com:443</span><br><span class="line">140564176807576:error:140A90C4:SSL routines:SSL_CTX_new:null ssl method passed:ssl_lib.c:1878:</span><br></pre></td></tr></table></figure></p>
<p>为什么ssl backend端不返回0x15或0x16呢, 理论上可能有以下几个原因<br>a, SSLv3现在已经被废弃了, 主流http server已经禁用了SSLv3支持, apach2收到haproxy过来的SSLv3 hello包时, apache2的SSL实现可能会响应别的消息而不是0x15/0x15<br>b, 因为haproxy过来的SSLv3 hello请求里没有SNI, 这样若启用了SNI的backend端(如apache2)就会ssl协商失败了, 这样也就未返回0x15/0x16<br>c, 其他原因<br>具体原因还需继续在backend抓包(tcpdump -eni ens3 -w ssl-test.pcap -s 0 port 443 or port 8443)确认.</p>
<p><strong>更新, 原因已找到:</strong><br>octavia/0会创建amphorae service vm, octavia/0上的/usr/lib/python3/dist-packages/octavia/amphorae/drivers/haproxy/rest_api_driver.py采用python requests模块去连接service vm上的9443端口. 这块代码类似下面这句所以不work:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl --cacert /etc/octavia/certs/issuing_ca.pem 192.168.254.31:9443</span><br></pre></td></tr></table></figure></p>
<p>改试下面的都work , 其中26835e25-7c4f-4776-940f-209eb9a9e826是SNI (loadbalance-id).<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">curl -k 192.168.254.31:9443</span><br><span class="line">openssl s_client -connect 192.168.254.31:9443 -key /etc/octavia/certs/issuing_ca_key.pem</span><br><span class="line">curl --cacert /etc/octavia/certs/issuing_ca.pem https://26835e25-7c4f-4776-940f-209eb9a9e826:9443 --resolve 26835e25-7c4f-4776-940f-209eb9a9e826:9443:192.168.254.31</span><br><span class="line"></span><br><span class="line">#ipv6</span><br><span class="line">#tlsv13 alert certificate required, it shows ssh client verfication is required</span><br><span class="line">curl -6 -k https://[fc00:ea96:ae23:2d4f:f816:3eff:fe76:d87a]:9443/</span><br><span class="line">#no alternative certificate subject name matches target host name, it shows it&apos;s about sni</span><br><span class="line">curl -6 --cacert /etc/octavia/certs/issuing_ca.pem https://[fc00:ea96:ae23:2d4f:f816:3eff:fe76:d87a]:9443/</span><br><span class="line">curl -6 --cacert /etc/octavia/certs/issuing_ca.pem --resolve backend1.domain:9443:[fc00:ea96:ae23:2d4f:f816:3eff:fe76:d87a] https://backend1.domain:9443 -v</span><br></pre></td></tr></table></figure></p>
<p>在octavia/0上测试:<br>openssl s_client -connect 192.168.254.31:9443 -key /etc/octavia/certs/issuing_ca_key.pem<br>最后的原因是, 创建证书时未指明CN=$DOMAIN1:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=$DOMAIN1&quot;</span><br><span class="line">openssl req -new -nodes -subj $SUBJECT -key $DOMAIN1.key -out $DOMAIN1.csr</span><br></pre></td></tr></table></figure>
<p>我们知道, python requests module中的assert_hostname用来往backend传递SNI, 见 - <a href="https://medium.com/@yzlin/python-requests-ssl-ip-binding-6df25a9a8f6a" target="_blank" rel="external">https://medium.com/@yzlin/python-requests-ssl-ip-binding-6df25a9a8f6a</a><br>而下列代码(<a href="https://github.com/openstack/octavia/blob/master/octavia/amphorae/drivers/haproxy/rest_api_driver.py#L542" target="_blank" rel="external">https://github.com/openstack/octavia/blob/master/octavia/amphorae/drivers/haproxy/rest_api_driver.py#L542</a>), 将传self.uuid(self.ssl_adapter.uuid = amp.id)到conn.asser_hostname.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class CustomHostNameCheckingAdapter(requests.adapters.HTTPAdapter):</span><br><span class="line">    def cert_verify(self, conn, url, verify, cert):</span><br><span class="line">        conn.assert_hostname = self.uuid</span><br><span class="line">        return super(CustomHostNameCheckingAdapter,</span><br><span class="line">                     self).cert_verify(conn, url, verify, cert)</span><br></pre></td></tr></table></figure></p>
<p>见设计文档: <a href="https://docs.openstack.org/octavia/ocata/specs/version0.5/tls-data-security.html" target="_blank" rel="external">https://docs.openstack.org/octavia/ocata/specs/version0.5/tls-data-security.html</a></p>
<h2 id="安装Octavia"><a href="#安装Octavia" class="headerlink" title="安装Octavia"></a>安装Octavia</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./generate-bundle.sh --name octavia --create-model --run --octavia -r stein --dvr-snat --num-compute 2   #can also use br-data:ens7 here</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens7&quot;</span><br><span class="line">./bin/add-data-ports.sh                      #it will add another NIC ens7 for every nova-compute nodes</span><br></pre></td></tr></table></figure>
<p>或者:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># https://blog.ubuntu.com/2019/01/28/taking-octavia-for-a-ride-with-kubernetes-on-openstack</span><br><span class="line">sudo snap install --classic charm</span><br><span class="line">charm pull cs:openstack-base</span><br><span class="line">cd openstack-base/</span><br><span class="line">curl https://raw.githubusercontent.com/openstack-charmers/openstack-bundles/master/stable/overlays/loadbalancer-octavia.yaml -o loadbalancer-octavia.yaml</span><br><span class="line">juju deploy ./bundle.yaml --overlay loadbalancer-octavia.yaml</span><br></pre></td></tr></table></figure></p>
<p>或者<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">sudo bash -c &apos;cat &gt;overlays/octavia.yaml&quot; &lt;&lt;EOF</span><br><span class="line">debug:                      &amp;debug                     True</span><br><span class="line">openstack_origin:           &amp;openstack_origin          cloud:bionic-rocky</span><br><span class="line">applications:</span><br><span class="line">  octavia:</span><br><span class="line">    #series: bionic</span><br><span class="line">    charm: cs:octavia</span><br><span class="line">    num_units: 1</span><br><span class="line">    constraints: mem=2G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">  octavia-dashboard:</span><br><span class="line">    charm: cs:octavia-dashboard</span><br><span class="line">relations:</span><br><span class="line">- - mysql:shared-db</span><br><span class="line">  - octavia:shared-db</span><br><span class="line">- - keystone:identity-service</span><br><span class="line">  - octavia:identity-service</span><br><span class="line">- - rabbitmq-server:amqp</span><br><span class="line">  - octavia:amqp</span><br><span class="line">- - neutron-api:neutron-load-balancer</span><br><span class="line">  - octavia:neutron-api</span><br><span class="line">- - neutron-openvswitch:neutron-plugin</span><br><span class="line">  - octavia:neutron-openvswitch</span><br><span class="line">- - openstack-dashboard:dashboard-plugin</span><br><span class="line">  - octavia-dashboard:dashboard</span><br><span class="line">EOF</span><br><span class="line">sudo bash -c &apos;cat &gt;overlays/octavia.yaml&quot; &lt;&lt;EOF</span><br><span class="line">debug:                      &amp;debug                     True</span><br><span class="line">verbose:                    &amp;verbose                   True</span><br><span class="line">openstack_origin:           &amp;openstack_origin</span><br><span class="line">applications:</span><br><span class="line">  barbican:</span><br><span class="line">    charm: cs:~openstack-charmers-next/barbican</span><br><span class="line">    num_units: 1</span><br><span class="line">    constraints: mem=1G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">relations:</span><br><span class="line">  - [ barbican, rabbitmq-server ]</span><br><span class="line">  - [ barbican, mysql ]</span><br><span class="line">  - [ barbican, keystone ]</span><br><span class="line">EOF</span><br><span class="line">./generate-bundle.sh --series bionic --release rocky --barbican</span><br><span class="line">juju deploy ./b/openstack.yaml --overlay ./b/o/barbican.yaml --overlay overlays/octavia.yaml</span><br></pre></td></tr></table></figure></p>
<p>或者:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">juju add-model bionic-barbican-octavia</span><br><span class="line">./generate-bundle.sh --series bionic --barbican</span><br><span class="line">#./generate-bundle.sh --series bionic --release rocky --barbican</span><br><span class="line">juju deploy ./b/openstack.yaml --overlay ./b/o/barbican.yaml</span><br><span class="line">#https://github.com/openstack-charmers/openstack-bundles/blob/master/stable/overlays/loadbalancer-octavia.yaml</span><br><span class="line">#NOTE: need to comment to:lxd related lines from loadbalancer-octavia.yaml, and change nova-compute num to 3</span><br><span class="line">juju deploy ./b/openstack.yaml --overlay ./overlays/loadbalancer-octavia.yaml</span><br><span class="line"></span><br><span class="line"># Or we can:</span><br><span class="line"># 2018-12-25 03:30:39 DEBUG update-status fatal error: runtime: out of memory</span><br><span class="line">juju deploy octavia --config openstack-origin=cloud:bionic:queens --constraints mem=4G</span><br><span class="line">juju deploy octavia-dashboard</span><br><span class="line">juju add-relation octavia-dashboard openstack-dashboard</span><br><span class="line">juju add-relation octavia rabbitmq-server</span><br><span class="line">juju add-relation octavia mysql</span><br><span class="line">juju add-relation octavia keystone</span><br><span class="line">juju add-relation octavia neutron-openvswitch</span><br><span class="line">juju add-relation octavia neutron-api</span><br><span class="line"></span><br><span class="line"># Initialize and unseal vault</span><br><span class="line"># https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-vault.html</span><br><span class="line"># https://lingxiankong.github.io/2018-07-16-barbican-introduction.html</span><br><span class="line"># /snap/vault/1315/bin/vault server -config /var/snap/vault/common/vault.hcl</span><br><span class="line">sudo snap install vault</span><br><span class="line">export VAULT_ADDR=&quot;http://$(juju run --unit vault/0 unit-get private-address):8200&quot;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ vault operator init -key-shares=5 -key-threshold=3</span><br><span class="line">Unseal Key 1: UB7XDri5FRcMLirKBIysdUb2PN7Ia5EVMP0Z9wD9Hyll</span><br><span class="line">Unseal Key 2: mD8Gnr3hdB2LjjNB4ugxvvsvb8+EQQ/0AXm2p+c2qYFT</span><br><span class="line">Unseal Key 3: vymYLAdou3qky24IEKDufYsZXAIPLWtErAKy/RkfgghS</span><br><span class="line">Unseal Key 4: xOwDbqgNLLipsZbp+FAmVhBc3ZxA8CI3DchRc4AClRyQ</span><br><span class="line">Unseal Key 5: nRlZ8WX6CS9nOw2ct5U9o0Za5jlUAtjN/6XLxjf62CnR</span><br><span class="line">Initial Root Token: s.VJKGhNvIFCTgHVbQ6WvL0OLe</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vault operator unseal UB7XDri5FRcMLirKBIysdUb2PN7Ia5EVMP0Z9wD9Hyll</span><br><span class="line">vault operator unseal mD8Gnr3hdB2LjjNB4ugxvvsvb8+EQQ/0AXm2p+c2qYFT</span><br><span class="line">vault operator unseal vymYLAdou3qky24IEKDufYsZXAIPLWtErAKy/RkfgghS</span><br><span class="line">export VAULT_TOKEN=s.VJKGhNvIFCTgHVbQ6WvL0OLe</span><br><span class="line">vault token create -ttl=10m</span><br><span class="line">$ vault token create -ttl=10m</span><br><span class="line">Key                  Value</span><br><span class="line">---                  -----</span><br><span class="line">token                s.7ToXh9HqE6FiiJZybFhevL9v</span><br><span class="line">token_accessor       6dPkFpsPmx4D7g8yNJXvEpKN</span><br><span class="line">token_duration       10m</span><br><span class="line">token_renewable      true</span><br><span class="line">token_policies       [&quot;root&quot;]</span><br><span class="line">identity_policies    []</span><br><span class="line">policies             [&quot;root&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Authorize vault charm to use a root token to be able to create secrets storage back-ends and roles to allow other app to access vault</span><br><span class="line">juju run-action vault/0 authorize-charm token=s.7ToXh9HqE6FiiJZybFhevL9v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># upload Amphora image</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">http_proxy=http://squid.internal:3128 wget http://tarballs.openstack.org/octavia/test-images/test-only-amphora-x64-haproxy-ubuntu-xenial.qcow2</span><br><span class="line">#openstack image create --tag octavia-amphora --disk-format=qcow2 --container-format=bare --private amphora-haproxy-xenial --file ./test-only-amphora-x64-haproxy-ubuntu-xenial.qcow2</span><br><span class="line">glance image-create --tag octavia-amphora --disk-format qcow2 --name amphora-haproxy-xenial --file ./test-only-amphora-x64-haproxy-ubuntu-xenial.qcow2 --visibility public --container-format bare --progress</span><br><span class="line"></span><br><span class="line">cd stsstack-bundles/openstack/</span><br><span class="line">./configure</span><br><span class="line">./tools/sec_groups.sh</span><br><span class="line">./tools/instance_launch.sh 2 xenial</span><br><span class="line">neutron floatingip-create ext_net</span><br><span class="line">neutron floatingip-associate $(neutron floatingip-list |grep 10.5.150.4 |awk &apos;&#123;print $2&#125;&apos;) $(neutron port-list |grep &apos;192.168.21.3&apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">or</span><br><span class="line">fix_ip=192.168.21.3</span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address $fix_ip --port $(openstack port list --fixed-ip ip-address=$fix_ip -c id -f value)</span><br><span class="line"></span><br><span class="line">cd ~/ca  #https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-octavia.html</span><br><span class="line">juju config octavia \</span><br><span class="line">    lb-mgmt-issuing-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-private-key=&quot;$(base64 controller_ca_key.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-key-passphrase=foobar \</span><br><span class="line">    lb-mgmt-controller-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-controller-cert=&quot;$(base64 controller_cert_bundle.pem)&quot;</span><br><span class="line"></span><br><span class="line">注: 也遇到一个问题, 上述命令没有更新service vm里的cert, ssh登录service vm之后查看/etc/octavia/certs/目录发现证书不同. 证书不对, 会导致service vm里的amphora-agent在9443端口起不来. service vm是通过cloud-init来写的证书, 那错误出在哪个环节呢?</span><br></pre></td></tr></table></figure></p>
<p>配置资源:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># the code search &apos;configure_resources&apos;</span><br><span class="line">juju config octavia create-mgmt-network</span><br><span class="line">juju run-action --wait octavia/0 configure-resources</span><br><span class="line"></span><br><span class="line"># some deubg ways:</span><br><span class="line">openstack security group rule create $(openstack security group show lb-mgmt-sec-grp -f value -c id) --protocol udp --dst-port 546 --ethertype IPv6</span><br><span class="line">openstack security group rule create $(openstack security group show lb-mgmt-sec-grp -f value -c id) --protocol icmp --ethertype IPv6</span><br><span class="line">neutron security-group-rule-create --protocol icmpv6 --direction egress --ethertype IPv6 lb-mgmt-sec-grp</span><br><span class="line">neutron security-group-rule-create --protocol icmpv6 --direction ingress --ethertype IPv6 lb-mgmt-sec-grp</span><br><span class="line"></span><br><span class="line">neutron port-show octavia-health-manager-octavia-0-listen-port -f value -c status</span><br><span class="line">neutron port-update --admin-state-up True octavia-health-manager-octavia-0-listen-port</span><br><span class="line">AGENT=$(neutron l3-agent-list-hosting-router lb-mgmt -f value -c id)</span><br><span class="line">neutron l3-agent-router-remove $AGENT lb-mgmt</span><br><span class="line">neutron l3-agent-router-add $AGENT lb-mgmt</span><br></pre></td></tr></table></figure></p>
<p>上面configure-resources命令 (juju run-action –wait octavia/0 configure-resources)将会自动配置IPv6管理网段, 并且会配置一个binding:host在octavia/0节点上的名为octavia-health-manager-octavia-0-listen-port的port.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ neutron router-list |grep mgmt</span><br><span class="line">| 0a839377-6b19-419b-9868-616def4d749f | lb-mgmt         | null                                                                                                                                                                                    | False       | False |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ neutron net-list |grep mgmt</span><br><span class="line">| ae580dc8-31d6-4ec3-9d44-4a9c7b9e80b6 | lb-mgmt-net | ea9c7d5c-d224-4dd3-b40c-3acae9690657 fc00:4a9c:7b9e:80b6::/64 |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ neutron subnet-list |grep mgmt</span><br><span class="line">| ea9c7d5c-d224-4dd3-b40c-3acae9690657 | lb-mgmt-subnetv6 | fc00:4a9c:7b9e:80b6::/64 | &#123;&quot;start&quot;: &quot;fc00:4a9c:7b9e:80b6::2&quot;, &quot;end&quot;: &quot;fc00:4a9c:7b9e:80b6:ffff:ffff:ffff:ffff&quot;&#125; |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ neutron port-list |grep fc00</span><br><span class="line">| 5cb6e3f3-ebe5-4284-9c05-ea272e8e599b |                                                      | fa:16:3e:9e:82:6a | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6::1&quot;&#125;                  |</span><br><span class="line">| 983c56d2-46dd-416c-abc8-5096d76f75e2 | octavia-health-manager-octavia-0-listen-port         | fa:16:3e:99:8c:ab | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6:f816:3eff:fe99:8cab&quot;&#125; |</span><br><span class="line">| af38a60d-a370-4ddb-80ac-517fda175535 |                                                      | fa:16:3e:5f:cd:ae | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6:f816:3eff:fe5f:cdae&quot;&#125; |</span><br><span class="line">| b65f90d1-2e1f-4994-a0e9-2bb13ead4cab |                                                      | fa:16:3e:10:34:84 | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6:f816:3eff:fe10:3484&quot;&#125; |</span><br></pre></td></tr></table></figure></p>
<p>并且在octavia/0上会创建一个名为o-hm0的接口, 此接口的IP地址与octavia-health-manager-octavia-0-listen-port port同.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ juju ssh octavia/0 -- ip addr show o-hm0 |grep global</span><br><span class="line">Connection to 10.5.0.110 closed.</span><br><span class="line">    inet6 fc00:4a9c:7b9e:80b6:f816:3eff:fe99:8cab/64 scope global dynamic mngtmpaddr noprefixroute</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ juju ssh octavia/0 -- sudo ovs-vsctl show</span><br><span class="line">490bbb36-1c7d-412d-8b44-31e6f796306a</span><br><span class="line">    Manager &quot;ptcp:6640:127.0.0.1&quot;</span><br><span class="line">        is_connected: true</span><br><span class="line">    Bridge br-tun</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;gre-0a05006b&quot;</span><br><span class="line">            Interface &quot;gre-0a05006b&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.110&quot;, out_key=flow, remote_ip=&quot;10.5.0.107&quot;&#125;</span><br><span class="line">        Port br-tun</span><br><span class="line">            Interface br-tun</span><br><span class="line">                type: internal</span><br><span class="line">        Port patch-int</span><br><span class="line">            Interface patch-int</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-tun&#125;</span><br><span class="line">        Port &quot;gre-0a050016&quot;</span><br><span class="line">            Interface &quot;gre-0a050016&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.110&quot;, out_key=flow, remote_ip=&quot;10.5.0.22&quot;&#125;</span><br><span class="line">    Bridge br-data</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port phy-br-data</span><br><span class="line">            Interface phy-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=int-br-data&#125;</span><br><span class="line">        Port br-data</span><br><span class="line">            Interface br-data</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-int</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port patch-tun</span><br><span class="line">            Interface patch-tun</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-int&#125;</span><br><span class="line">        Port &quot;o-hm0&quot;</span><br><span class="line">            tag: 1</span><br><span class="line">            Interface &quot;o-hm0&quot;</span><br><span class="line">                type: internal</span><br><span class="line">        Port br-int</span><br><span class="line">            Interface br-int</span><br><span class="line">                type: internal</span><br><span class="line">        Port int-br-data</span><br><span class="line">            Interface int-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=phy-br-data&#125;</span><br><span class="line">    Bridge br-ex</span><br><span class="line">        Port br-ex</span><br><span class="line">            Interface br-ex</span><br><span class="line">                type: internal</span><br><span class="line">    ovs_version: &quot;2.10.0&quot;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ juju ssh neutron-gateway/0 -- sudo ovs-vsctl show</span><br><span class="line">ec3e2cb6-5261-4c22-8afd-5bacb0e8ce85</span><br><span class="line">    Manager &quot;ptcp:6640:127.0.0.1&quot;</span><br><span class="line">        is_connected: true</span><br><span class="line">    Bridge br-ex</span><br><span class="line">        Port br-ex</span><br><span class="line">            Interface br-ex</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-int</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;tap62c03d3b-b1&quot;</span><br><span class="line">            tag: 2</span><br><span class="line">            Interface &quot;tap62c03d3b-b1&quot;</span><br><span class="line">        Port &quot;tapb65f90d1-2e&quot;</span><br><span class="line">            tag: 3</span><br><span class="line">            Interface &quot;tapb65f90d1-2e&quot;</span><br><span class="line">        Port int-br-data</span><br><span class="line">            Interface int-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=phy-br-data&#125;</span><br><span class="line">        Port patch-tun</span><br><span class="line">            Interface patch-tun</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-int&#125;</span><br><span class="line">        Port &quot;tap6f1478be-b1&quot;</span><br><span class="line">            tag: 1</span><br><span class="line">            Interface &quot;tap6f1478be-b1&quot;</span><br><span class="line">        Port &quot;tap01efd82b-53&quot;</span><br><span class="line">            tag: 2</span><br><span class="line">            Interface &quot;tap01efd82b-53&quot;</span><br><span class="line">        Port &quot;tap5cb6e3f3-eb&quot;</span><br><span class="line">            tag: 3</span><br><span class="line">            Interface &quot;tap5cb6e3f3-eb&quot;</span><br><span class="line">        Port br-int</span><br><span class="line">            Interface br-int</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-data</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;ens7&quot;</span><br><span class="line">            Interface &quot;ens7&quot;</span><br><span class="line">        Port br-data</span><br><span class="line">            Interface br-data</span><br><span class="line">                type: internal</span><br><span class="line">        Port phy-br-data</span><br><span class="line">            Interface phy-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=int-br-data&#125;</span><br><span class="line">    Bridge br-tun</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port patch-int</span><br><span class="line">            Interface patch-int</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-tun&#125;</span><br><span class="line">        Port &quot;gre-0a05007a&quot;</span><br><span class="line">            Interface &quot;gre-0a05007a&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.122&quot;&#125;</span><br><span class="line">        Port &quot;gre-0a05006b&quot;</span><br><span class="line">            Interface &quot;gre-0a05006b&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.107&quot;&#125;</span><br><span class="line">        Port br-tun</span><br><span class="line">            Interface br-tun</span><br><span class="line">                type: internal</span><br><span class="line">        Port &quot;gre-0a050079&quot;</span><br><span class="line">            Interface &quot;gre-0a050079&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.121&quot;&#125;</span><br><span class="line">        Port &quot;gre-0a05006e&quot;</span><br><span class="line">            Interface &quot;gre-0a05006e&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.110&quot;&#125;</span><br><span class="line">    ovs_version: &quot;2.10.0&quot;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ juju ssh neutron-gateway/0 -- cat /var/lib/neutron/ra/0a839377-6b19-419b-9868-616def4d749f.radvd.conf</span><br><span class="line">interface qr-5cb6e3f3-eb</span><br><span class="line">&#123;</span><br><span class="line">   AdvSendAdvert on;</span><br><span class="line">   MinRtrAdvInterval 30;</span><br><span class="line">   MaxRtrAdvInterval 100;</span><br><span class="line">   AdvLinkMTU 1458;</span><br><span class="line">   prefix fc00:4a9c:7b9e:80b6::/64</span><br><span class="line">   &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">   &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-health-mgr-sec-grp</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| 09a92cb2-9942-44d4-8a96-9449a6758967 | None        | None     |            | None                  |</span><br><span class="line">| 20daa06c-9de6-4c91-8a1e-59645f23953a | udp         | None     | 5555:5555  | None                  |</span><br><span class="line">| 8f7b9966-c255-4727-a172-60f22f0710f9 | None        | None     |            | None                  |</span><br><span class="line">| 90f86b27-12f8-4a9a-9924-37b31d26cbd8 | icmpv6      | None     |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-mgmt-sec-grp</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| 54f79f92-a6c5-411d-a309-a02b39cc384b | icmpv6      | None     |            | None                  |</span><br><span class="line">| 574f595e-3d96-460e-a3f2-329818186492 | None        | None     |            | None                  |</span><br><span class="line">| 5ecb0f58-f5dd-4d52-bdfa-04fd56968bd8 | tcp         | None     | 22:22      | None                  |</span><br><span class="line">| 7ead3a3a-bc45-4434-b7a2-e2a6c0dc3ce9 | None        | None     |            | None                  |</span><br><span class="line">| cf82d108-e0f8-4916-95d4-0c816b6eb156 | tcp         | None     | 9443:9443  | None                  |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ source ~/novarc</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list default</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+--------------------------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range  | Port Range | Remote Security Group                |</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+--------------------------------------+</span><br><span class="line">| 15b56abd-c2af-4c0a-8585-af68a8f09e3c | icmpv6      | None      |            | None                                 |</span><br><span class="line">| 2ad77fa3-32c7-4a20-a572-417bea782eff | icmp        | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">| 2c2aec15-e4ad-4069-abd2-0191fe80f9bb | None        | None      |            | None                                 |</span><br><span class="line">| 3b775807-3c61-45a3-9677-aaf9631db677 | udp         | 0.0.0.0/0 | 3389:3389  | None                                 |</span><br><span class="line">| 3e9a6e7f-b9a2-47c9-97ca-042b22fbf308 | icmpv6      | None      |            | None                                 |</span><br><span class="line">| 42a3c09e-91c8-471d-b4a8-c1fe87dab066 | None        | None      |            | None                                 |</span><br><span class="line">| 47f9cec2-4bc0-4d71-9a02-3a27d46b59f8 | icmp        | None      |            | None                                 |</span><br><span class="line">| 94297175-9439-4df2-8c93-c5576e52e138 | udp         | None      | 546:546    | None                                 |</span><br><span class="line">| 9c6ac9d2-3b9e-4bab-a55a-04a1679b66be | None        | None      |            | c48a1bf5-7b7e-4337-afdf-8057ae8025af |</span><br><span class="line">| b6e95f76-1b64-4135-8b62-b058ec989f7e | None        | None      |            | c48a1bf5-7b7e-4337-afdf-8057ae8025af |</span><br><span class="line">| de5132a5-72e2-4f03-8b6a-dcbc2b7811c3 | tcp         | 0.0.0.0/0 | 3389:3389  | None                                 |</span><br><span class="line">| e72bea9f-84ce-4e3a-8597-c86d40b9b5ef | tcp         | 0.0.0.0/0 | 22:22      | None                                 |</span><br><span class="line">| ecf1415c-c6e9-4cf6-872c-4dac1353c014 | tcp         | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+--------------------------------------+</span><br></pre></td></tr></table></figure></p>
<p>底层OpenStack环境(OpenStack Over Openstack)需要做 (见: <a href="https://blog.csdn.net/quqi99/article/details/78437988" target="_blank" rel="external">https://blog.csdn.net/quqi99/article/details/78437988</a> ):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openstack security group rule create $secgroup --protocol udp --dst-port 546 --ethertype IPv6</span><br></pre></td></tr></table></figure></p>
<p>最容易出现的问题是health-manager-octavia-0-listen-port port为DOWN, 从而o-hm0网络不通而无法从dhcp server处获得IP, 网段不通多半是br-int上的flow rules的问题, 我多次遇到这种情况, 但后来重建环境不知为什么又好了.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-11:~# ovs-ofctl dump-flows br-int</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.932s, table=0, n_packets=978, n_bytes=76284, priority=10,icmp6,in_port=&quot;o-hm0&quot;,icmp_type=136 actions=resubmit(,24)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.930s, table=0, n_packets=0, n_bytes=0, priority=10,arp,in_port=&quot;o-hm0&quot; actions=resubmit(,24)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.219s, table=0, n_packets=0, n_bytes=0, priority=2,in_port=&quot;int-br-data&quot; actions=drop</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.943s, table=0, n_packets=10939, n_bytes=2958167, priority=9,in_port=&quot;o-hm0&quot; actions=resubmit(,25)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.898s, table=0, n_packets=10032, n_bytes=1608826, priority=0 actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.903s, table=23, n_packets=0, n_bytes=0, priority=0 actions=drop</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.940s, table=24, n_packets=675, n_bytes=52650, priority=2,icmp6,in_port=&quot;o-hm0&quot;,icmp_type=136,nd_target=fc00:4a9c:7b9e:80b6:f816:3eff:fe99:8cab actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.938s, table=24, n_packets=0, n_bytes=0, priority=2,icmp6,in_port=&quot;o-hm0&quot;,icmp_type=136,nd_target=fe80::f816:3eff:fe99:8cab actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.879s, table=24, n_packets=303, n_bytes=23634, priority=0 actions=drop</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.951s, table=25, n_packets=10939, n_bytes=2958167, priority=2,in_port=&quot;o-hm0&quot;,dl_src=fa:16:3e:99:8c:ab actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.896s, table=60, n_packets=21647, n_bytes=4620009, priority=3 actions=NORMAL</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-11:~# ovs-ofctl dump-flows br-data</span><br><span class="line"> cookie=0xb41c0c7781ded568, duration=426779.130s, table=0, n_packets=16816, n_bytes=3580386, priority=2,in_port=&quot;phy-br-data&quot; actions=drop</span><br><span class="line"> cookie=0xb41c0c7781ded568, duration=426779.201s, table=0, n_packets=0, n_bytes=0, priority=0 actions=NORMAL</span><br></pre></td></tr></table></figure></p>
<p>如果o-hm0总是无法获得IP, 我们也可以手工配置一个IPv4管理网段试试.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">neutron router-gateway-clear lb-mgmt</span><br><span class="line">neutron router-interface-delete lb-mgmt lb-mgmt-subnetv6</span><br><span class="line">neutron subnet-delete lb-mgmt-subnetv6</span><br><span class="line">neutron port-list |grep fc00</span><br><span class="line">#neutron port-delete 464e6d47-9830-4966-a2b7-e188c19c407a</span><br><span class="line">openstack subnet create --subnet-range 192.168.0.0/24 --allocation-pool start=192.168.0.2,end=192.168.0.200 --network lb-mgmt-net lb-mgmt-subnet</span><br><span class="line">neutron router-interface-add lb-mgmt lb-mgmt-subnet</span><br><span class="line">#neutron router-gateway-set lb-mgmt ext_net</span><br><span class="line">neutron port-list |grep 192.168.0.1</span><br><span class="line"></span><br><span class="line">#openstack security group create lb-mgmt-sec-grp --project $(openstack security group show lb-mgmt-sec-grp -f value -c project_id)</span><br><span class="line">openstack security group rule create --protocol udp --dst-port 5555 lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol tcp --dst-port 22 lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol tcp --dst-port 9443 lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol icmp lb-mgmt-sec-grp</span><br><span class="line">openstack security group show lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol udp --dst-port 5555 lb-health-mgr-sec-grp</span><br><span class="line">openstack security group rule create --protocol icmp lb-health-mgr-sec-grp</span><br><span class="line"></span><br><span class="line"># create a management port o-hm0 on octavia/0 node, first use neutron to allocate a port, then call ovs-vsctl to add-port</span><br><span class="line">LB_HOST=$(juju ssh octavia/0 -- hostname)</span><br><span class="line">juju ssh octavia/0 -- sudo ovs-vsctl del-port br-int o-hm0</span><br><span class="line"># Use LB_HOST to replace juju-70ea4e-bionic-barbican-octavia-11, don&apos;t know why it said &apos;bind failed&apos; when using $LB_HOST directly</span><br><span class="line">neutron port-create --name mgmt-port --security-group $(openstack security group show lb-health-mgr-sec-grp -f value -c id) --device-owner Octavia:health-mgr --binding:host_id=juju-acadb9-bionic-rocky-barbican-octavia-without-vault-9 lb-mgmt-net --tenant-id $(openstack security group show lb-health-mgr-sec-grp -f value -c project_id)</span><br><span class="line"></span><br><span class="line">juju ssh octavia/0 -- sudo ovs-vsctl --may-exist add-port br-int o-hm0 -- set Interface o-hm0 type=internal -- set Interface o-hm0 external-ids:iface-status=active -- set Interface o-hm0 external-ids:attached-mac=$(neutron port-show mgmt-port -f value -c mac_address) -- set Interface o-hm0 external-ids:iface-id=$(neutron port-show mgmt-port -f value -c id)</span><br><span class="line">juju ssh octavia/0 -- sudo ip link set dev o-hm0 address $(neutron port-show mgmt-port -f value -c mac_address)</span><br><span class="line">ping 192.168.0.2</span><br></pre></td></tr></table></figure></p>
<h2 id="测试虚机中安装HTTPS测试服务"><a href="#测试虚机中安装HTTPS测试服务" class="headerlink" title="测试虚机中安装HTTPS测试服务"></a>测试虚机中安装HTTPS测试服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># Prepare CA and ssl pairs for lb server</span><br><span class="line">openssl genrsa -passout pass:password -out ca.key</span><br><span class="line">openssl req -x509 -passin pass:password -new -nodes -key ca.key -days 3650 -out ca.crt -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl genrsa -passout pass:password -out lb.key</span><br><span class="line">openssl req -new -key lb.key -out lb.csr -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl x509 -req -in lb.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out lb.crt -days 3650</span><br><span class="line">cat lb.crt lb.key &gt; lb.pem</span><br><span class="line">#openssl pkcs12 -export -inkey lb.key -in lb.crt -certfile ca.crt -passout pass:password -out lb.p12</span><br><span class="line"></span><br><span class="line"># Create two test servers and run</span><br><span class="line">sudo apt install python-minimal -y</span><br><span class="line">sudo bash -c &apos;cat &gt;simple-https-server.py&apos; &lt;&lt;EOF</span><br><span class="line">#!/usr/bin/env python</span><br><span class="line"># coding=utf-8</span><br><span class="line">import BaseHTTPServer, SimpleHTTPServer</span><br><span class="line">import ssl</span><br><span class="line">httpd = BaseHTTPServer.HTTPServer((&apos;0.0.0.0&apos;, 443), SimpleHTTPServer.SimpleHTTPRequestHandler)</span><br><span class="line">httpd.socket = ssl.wrap_socket (httpd.socket, certfile=&apos;./lb.pem&apos;, server_side=True)</span><br><span class="line">httpd.serve_forever()</span><br><span class="line">EOF</span><br><span class="line">sudo bash -c &apos;cat &gt;index.html&apos; &lt;&lt;EOF</span><br><span class="line">test1</span><br><span class="line">EOF</span><br><span class="line">nohup sudo python simple-https-server.py &amp;</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl -k https://10.5.150.4</span><br><span class="line">test1</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl -k https://10.5.150.5</span><br><span class="line">test2</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl --cacert ~/ca/ca.crt https://10.5.150.4</span><br><span class="line">curl: (51) SSL: certificate subject name (www.quqi.com) does not match target host name &apos;10.5.150.4&apos;</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl --resolve www.quqi.com:443:10.5.150.4 --cacert ~/ca/ca.crt https://www.quqi.com</span><br><span class="line">test1</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl --resolve www.quqi.com:443:10.5.150.4 -k https://www.quqi.com</span><br><span class="line">test1</span><br></pre></td></tr></table></figure>
<p>20191109更新, 上面的方法使用–cacert时并不work, 改成下列方法works<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl req -new -x509 -keyout lb.pem -out lb.pem -days 365 -nodes -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">$ curl --resolve www.quqi.com:443:192.168.99.135 --cacert ./lb.pem https://www.quqi.com</span><br><span class="line">test1</span><br></pre></td></tr></table></figure></p>
<p>经进一步调试, 原来是因为 这一句”curl –resolve www.quqi.com:443:10.5.150.4 –cacert ~/ca/ca.crt <a href="https://www.quqi.com&quot;应该是&quot;curl" target="_blank" rel="external">https://www.quqi.com&quot;应该是&quot;curl</a> –resolve www.quqi.com:443:10.5.150.4 –cacert ~/ca/lb.pem <a href="https://www.quqi.com" target="_blank" rel="external">https://www.quqi.com</a>“</p>
<p>或者使用apache2安装ssl<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/apache2/sites-available/default-ssl.conf</span><br><span class="line">  ServerName server1.com</span><br><span class="line">  ServerAlias www.server1.com</span><br><span class="line">  SSLCertificateFile      /home/ubuntu/www.server1.com.crt</span><br><span class="line">  SSLCertificateKeyFile /home/ubuntu/www.server1.com.key</span><br><span class="line"></span><br><span class="line">vim /etc/apache2/sites-available/000-default.conf</span><br><span class="line">  ServerName server1.com</span><br><span class="line">  ServerAlias www.server1.com</span><br><span class="line"></span><br><span class="line">sudo apachectl configtest</span><br><span class="line">sudo a2enmod ssl</span><br><span class="line">sudo a2ensite default-ssl</span><br><span class="line">sudo systemctl restart apache2.service</span><br></pre></td></tr></table></figure></p>
<h2 id="测试虚机中安装HTTP测试服务"><a href="#测试虚机中安装HTTP测试服务" class="headerlink" title="测试虚机中安装HTTP测试服务"></a>测试虚机中安装HTTP测试服务</h2><p>下面的这种HTTP测试服务实际上有问题, 会导致haproxy对backend作check时报下列错误.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ae847e94-5aeb-4da6-9b66-07e1a385465b is UP, reason: Layer7 check passed, code: 200, info: &quot;HTTP status check returned code &lt;3C&gt;200&lt;3E&gt;&quot;, check duration: 7ms. 1 active and 0 backup servers online. 0 sessions requeued, 0 total in queue.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1, deploy http server in backend</span><br><span class="line">MYIP=$(ifconfig ens2|grep &apos;inet addr&apos;|awk -F: &apos;&#123;print $2&#125;&apos;| awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">while true; do echo -e &quot;HTTP/1.0 200 OK\r\n\r\nWelcome to $MYIP&quot; | sudo nc -l -p 80 ; done</span><br><span class="line">2, test it</span><br><span class="line">sudo ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b curl http://192.168.21.7:80</span><br><span class="line">3, add it into haproxy</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.7 --protocol-port 80 pool1</span><br></pre></td></tr></table></figure>
<p>并且还会导致在作haproxy vip作curl测试时返回Bad Gateway的错误.<br>所以最后在backend上运行”sudo python -m SimpleHTTPServer 80”之后解决.</p>
<h2 id="How-to-ssh-into-amphora-service-vm"><a href="#How-to-ssh-into-amphora-service-vm" class="headerlink" title="How to ssh into amphora service vm"></a>How to ssh into amphora service vm</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># NOTE： (base64 -w 0 $HOME/.ssh/id_amphora.pub)</span><br><span class="line">sudo mkdir -p /etc/octavia/.ssh &amp;&amp; sudo chown -R $(id -u):$(id -g) /etc/octavia/.ssh</span><br><span class="line">ssh-keygen -b 2048 -t rsa -N &quot;&quot; -f /etc/octavia/.ssh/octavia_ssh_key</span><br><span class="line">openstack user list --domain service_domain</span><br><span class="line"># NOTE: we must add &apos;--user&apos; option to avoid the error &apos;Invalid key_name provided&apos;</span><br><span class="line">nova keypair-add --pub-key=/etc/octavia/.ssh/octavia_ssh_key.pub octavia_ssh_key --user $(openstack user show octavia --domain service_domain -f value -c id)</span><br><span class="line"># openstack cli doesn&apos;t support to list user scope keypairs</span><br><span class="line">nova keypair-list --user $(openstack user show octavia --domain service_domain -f value -c id)</span><br><span class="line"></span><br><span class="line">vim /etc/octavia/octavia.conf</span><br><span class="line">vim /var/lib/juju/agents/unit-octavia-0/charm/templates/rocky/octavia.conf</span><br><span class="line">vim /usr/lib/python3/dist-packages/octavia/compute/drivers/nova_driver.py</span><br><span class="line">vim /usr/lib/python3/dist-packages/octavia/controller/worker/tasks/compute_tasks.py  #import pdb;pdb.set_trace()</span><br><span class="line">[controller_worker]</span><br><span class="line">amp_ssh_key_name = octavia_ssh_key   #for sts, name is called amphora-backdoor</span><br><span class="line">sudo ip netns exec qrouter-0a839377-6b19-419b-9868-616def4d749f ssh -6 -i</span><br><span class="line">~/octavia_ssh_key ubuntu@fc00:4a9c:7b9e:80b6:f816:3eff:fe5f:cdae</span><br><span class="line"></span><br><span class="line">NOTE:</span><br><span class="line">we can&apos;t ssh by: ssh -i /etc/octavia/octavia_ssh_key ubuntu@10.5.150.15</span><br><span class="line">but we can ssh by:</span><br><span class="line">sudo ip netns exec qrouter-0a839377-6b19-419b-9868-616def4d749f ssh -i ~/octavia_ssh_key ubuntu@192.168.0.12 -v</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ nova list --all</span><br><span class="line">+--------------------------------------+----------------------------------------------+----------------------------------+--------+------------+-------------+-------------------------------------------------------------+</span><br><span class="line">| ID                                   | Name                                         | Tenant ID                        | Status | Task State | Power State | Networks                                                    |</span><br><span class="line">+--------------------------------------+----------------------------------------------+----------------------------------+--------+------------+-------------+-------------------------------------------------------------+</span><br><span class="line">| 1f50fa16-bbbe-47a7-b66b-86de416d0c5e | amphora-2fae038f-08b5-4bce-a2b7-f7bd543c0314 | 5165bc7f79304f67a135fcde3cd78ae1 | ACTIVE | -          | Running     | lb-mgmt-net=192.168.0.12; private=192.168.21.6, 10.5.150.15 |</span><br><span class="line"></span><br><span class="line">openstack security group rule create lb-300e5ee7-2793-4df3-b901-17ce76da0b09 --protocol icmp --remote-ip 0.0.0.0/0</span><br><span class="line">openstack security group rule create lb-300e5ee7-2793-4df3-b901-17ce76da0b09 --protocol tcp --dst-port 22</span><br></pre></td></tr></table></figure>
<h2 id="Deploy-a-non-terminated-HTTPS-load-balancer"><a href="#Deploy-a-non-terminated-HTTPS-load-balancer" class="headerlink" title="Deploy a non-terminated HTTPS load balancer"></a>Deploy a non-terminated HTTPS load balancer</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python-octaviaclient python3-octaviaclient</span><br><span class="line">openstack complete |sudo tee /etc/bash_completion.d/openstack</span><br><span class="line">source &lt;(openstack complete)</span><br><span class="line">#No module named &apos;oslo_log&apos;</span><br><span class="line">openstack loadbalancer create --name lb1 --vip-subnet-id private_subnet</span><br><span class="line">#lb_vip_port_id=$(openstack loadbalancer create -f value -c vip_port_id --name lb1 --vip-subnet-id private_subnet)</span><br><span class="line"># Re-run the following until lb1 shows ACTIVE and ONLINE statuses:</span><br><span class="line">openstack loadbalancer show lb1</span><br><span class="line">nova list --all</span><br><span class="line">openstack loadbalancer listener create --name listener1 --protocol HTTPS --protocol-port 443 lb1</span><br><span class="line">openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTPS</span><br><span class="line">#openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTPS --url-path / pool1</span><br><span class="line">openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type TLS-HELLO pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.10 --protocol-port 443 pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.12 --protocol-port 443 pool1</span><br><span class="line">openstack loadbalancer member list pool1</span><br><span class="line"></span><br><span class="line">root@amphora-a9cf0b97-7f30-4b9c-b16a-7bc54526e0d0:~# ps -ef |grep haproxy</span><br><span class="line">root      1459     1  0 04:34 ?        00:00:00 /usr/sbin/haproxy-systemd-wrapper -f /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.pid -L UlKGE8M_cxJTcktjV8M-eKJkh-g</span><br><span class="line">nobody    1677  1459  0 04:35 ?        00:00:00 /usr/sbin/haproxy -f /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.pid -L UlKGE8M_cxJTcktjV8M-eKJkh-g -Ds -sf 1625</span><br><span class="line">nobody    1679  1677  0 04:35 ?        00:00:00 /usr/sbin/haproxy -f /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.pid -L UlKGE8M_cxJTcktjV8M-eKJkh-g -Ds -sf 1625</span><br><span class="line">root      1701  1685  0 04:36 pts/0    00:00:00 grep --color=auto haproxy</span><br><span class="line">root@amphora-a9cf0b97-7f30-4b9c-b16a-7bc54526e0d0:~#</span><br><span class="line">root@amphora-a9cf0b97-7f30-4b9c-b16a-7bc54526e0d0:~# cat /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer eda3efa5-dd91-437c-81d9-b73d28b5312f</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">frontend b9d5a192-1a6a-4df7-83d4-fe96ac9574c0</span><br><span class="line">    option tcplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    bind 192.168.21.16:443</span><br><span class="line">    mode tcp</span><br><span class="line">    default_backend 502b6689-40ad-4201-b704-f221e0fddd58</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend 502b6689-40ad-4201-b704-f221e0fddd58</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option ssl-hello-chk</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 49f16402-69f4-49bb-8dc0-5ec13a0f1791 192.168.21.10:443 weight 1 check inter 5s fall 3 rise 4</span><br><span class="line">    server 1ab624e1-9cd8-49f3-9297-4fa031a3ca58 192.168.21.12:443 weight 1 check inter 5s fall 3 rise 4</span><br></pre></td></tr></table></figure>
<p>有时候service vm已经创建好, 但octavia-worker因为下列原因退出导致”openstack loadbalancer create –name lb1 –vip-subnet-id private_subnet”这步执行后状态总不对.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2019-01-04 06:30:45.574 8173 INFO cotyledon._service [-] Caught SIGTERM signal, graceful exiting of service ConsumerService(0) [8173]</span><br><span class="line">2019-01-04 06:30:45.573 7983 INFO cotyledon._service_manager [-] Caught SIGTERM signal, graceful exiting of master process</span><br><span class="line">2019-01-04 06:30:45.581 8173 INFO octavia.controller.queue.consumer [-] Stopping consumer...</span><br><span class="line">2019-01-04 06:30:45.593 8173 INFO cotyledon._service [-] Caught SIGTERM signal, graceful exiting of service ConsumerService(0) [8173]</span><br></pre></td></tr></table></figure>
<h2 id="Deploy-a-TLS-terminated-HTTPS-load-balancer"><a href="#Deploy-a-TLS-terminated-HTTPS-load-balancer" class="headerlink" title="Deploy a TLS-terminated HTTPS load balancer"></a>Deploy a TLS-terminated HTTPS load balancer</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 确实不能加密码：　https://opendev.org/openstack/octavia/commit/a501714a76e04b33dfb24c4ead9956ed4696d1df</span><br><span class="line">openssl genrsa -passout pass:password -out ca.key</span><br><span class="line">openssl req -x509 -passin pass:password -new -nodes -key ca.key -days 3650 -out ca.crt -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl genrsa -passout pass:password -out lb.key</span><br><span class="line">openssl req -new -key lb.key -out lb.csr -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl x509 -req -in lb.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out lb.crt -days 3650</span><br><span class="line">cat lb.crt lb.key &gt; lb.pem</span><br><span class="line">openssl pkcs12 -export -inkey lb.key -in lb.crt -certfile ca.crt -passout pass:password -out lb.p12</span><br><span class="line"></span><br><span class="line">sudo apt install python-barbicanclient</span><br><span class="line">#openstack secret delete $(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;)</span><br><span class="line">openstack secret store --name=&apos;tls_lb_secret&apos; -t &apos;application/octet-stream&apos; -e &apos;base64&apos; --payload=&quot;$(base64 &lt; lb.p12)&quot;</span><br><span class="line">openstack acl user add -u $(openstack user show octavia --domain service_domain -f value -c id) $(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;)</span><br><span class="line">openstack secret list</span><br><span class="line">openstack loadbalancer create --name lb1 --vip-subnet-id private_subnet</span><br><span class="line"># Re-run the following until lb1 shows ACTIVE and ONLINE statuses:</span><br><span class="line">openstack loadbalancer show lb1</span><br><span class="line"></span><br><span class="line">openstack loadbalancer member list pool1</span><br><span class="line">openstack loadbalancer member delete pool1 &lt;member&gt;</span><br><span class="line">openstack loadbalancer pool delete pool1</span><br><span class="line">openstack loadbalancer listener delete listener1</span><br><span class="line">openstack loadbalancer listener create --protocol-port 443 --protocol TERMINATED_HTTPS --name listener1 --default-tls-container=$(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;) lb1</span><br><span class="line">openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTP</span><br><span class="line">openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.10 --protocol-port 80 pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.12 --protocol-port 80 pool1</span><br></pre></td></tr></table></figure>
<p>但是出错了:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca⟫ openstack loadbalancer listener create --protocol-port 443 --protocol TERMINATED_HTTPS --name listener1 --default-tls-container=$(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;) lb1</span><br><span class="line">Could not retrieve certificate: [&apos;http://10.5.0.25:9312/v1/secrets/7c706fb2-4319-46fc-b78d-81f34393f581&apos;] (HTTP 400) (Request-ID: req-c0c0e4d5-f395-424c-9aab-5c4c4e72fb3d)</span><br></pre></td></tr></table></figure>
<p>出错的原因找到, 是创建密钥时不能加密码:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out ca.key</span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -days 3650 -out ca.crt -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl genrsa -out lb.key</span><br><span class="line">openssl req -new -key lb.key -out lb.csr -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl x509 -req -in lb.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out lb.crt -days 3650</span><br><span class="line">cat lb.crt lb.key &gt; lb.pem</span><br><span class="line">openssl pkcs12 -export -inkey lb.key -in lb.crt -certfile ca.crt -passout pass: -out lb.p12</span><br></pre></td></tr></table></figure></p>
<p>但是仍然不成功, 原因已查明, 与密钥无关, 而是之前没有执行这一句(octavia_user_id=$(openstack user show octavia –domain service_domain -f value -c id); openstack acl user add -u $octavia_user_id $secret_id) 所致, 一个完整的脚本如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">#https://wiki.openstack.org/wiki/Network/LBaaS/docs/how-to-create-tls-loadbalancer#Update_neutron_config</span><br><span class="line">#https://lingxiankong.github.io/2018-04-29-octavia-tls-termination-test.html</span><br><span class="line">DOMAIN1=www.server1.com</span><br><span class="line">DOMAIN2=www.server2.com</span><br><span class="line"></span><br><span class="line">echo &quot;Create CA cert(self-signed) and key...&quot;</span><br><span class="line">CA_SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=CA&quot;</span><br><span class="line">openssl req -new -x509 -nodes -days 3650 -newkey rsa:2048 -keyout ca.key -out ca.crt -subj $CA_SUBJECT</span><br><span class="line"></span><br><span class="line">openssl genrsa -des3 -out $DOMAIN1_encrypted.key 1024</span><br><span class="line">openssl rsa -in $DOMAIN1_encrypted.key -out $DOMAIN1.key</span><br><span class="line">openssl genrsa -des3 -out $DOMAIN2_encrypted.key 1024</span><br><span class="line">openssl rsa -in $DOMAIN2_encrypted.key -out $DOMAIN2.key</span><br><span class="line"></span><br><span class="line">echo &quot;Create server certificate signing request...&quot;</span><br><span class="line">SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=$DOMAIN1&quot;</span><br><span class="line">openssl req -new -nodes -subj $SUBJECT -key $DOMAIN1.key -out $DOMAIN1.csr</span><br><span class="line">SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=$DOMAIN2&quot;</span><br><span class="line">openssl req -new -nodes -subj $SUBJECT -key $DOMAIN2.key -out $DOMAIN2.csr</span><br><span class="line"></span><br><span class="line">echo &quot;Sign SSL certificate...&quot;</span><br><span class="line">openssl x509 -req -days 3650 -in $DOMAIN1.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out $DOMAIN1.crt</span><br><span class="line">openssl x509 -req -days 3650 -in $DOMAIN2.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out $DOMAIN2.crt</span><br><span class="line"></span><br><span class="line"># NOTE: must without password when using barbican to save p12</span><br><span class="line">openssl pkcs12 -export -inkey www.server1.com.key -in www.server1.com.crt -certfile ca.crt -passout pass: -out www.server1.com.p12</span><br><span class="line">openssl pkcs12 -export -inkey www.server2.com.key -in www.server2.com.crt -certfile ca.crt -passout pass: -out www.server2.com.p12</span><br><span class="line"></span><br><span class="line">secret1_id=$(openstack secret store --name=&apos;lb_tls_secret_1&apos; -t &apos;application/octet-stream&apos; -e &apos;base64&apos; --payload=&quot;$(base64 &lt; www.server1.com.p12)&quot; -f value -c &quot;Secret href&quot;)</span><br><span class="line">secret2_id=$(openstack secret store --name=&apos;lb_tls_secret_2&apos; -t &apos;application/octet-stream&apos; -e &apos;base64&apos; --payload=&quot;$(base64 &lt; www.server2.com.p12)&quot; -f value -c &quot;Secret href&quot;)</span><br><span class="line"></span><br><span class="line"># allow octavia service user to visit the cert saved in barbican by the user in the novarc</span><br><span class="line">octavia_user_id=$(openstack user show octavia --domain service_domain -f value -c id); echo $octavia_user_id;</span><br><span class="line">openstack acl user add -u $octavia_user_id $secret1_id</span><br><span class="line">openstack acl user add -u $octavia_user_id $secret2_id</span><br><span class="line"></span><br><span class="line">IP=192.168.21.7</span><br><span class="line">subnetid=$(openstack subnet show private_subnet -f value -c id); echo $subnetid</span><br><span class="line">#lb_id=$(openstack loadbalancer create --name lb3 --vip-subnet-id $subnetid -f value -c id); echo $lb_id</span><br><span class="line">lb_id=22ce64e5-585d-43bd-80eb-5c3ff22abacd</span><br><span class="line">listener_id=$(openstack loadbalancer listener create $lb_id --name https_listener --protocol-port 443 --protocol TERMINATED_HTTPS --default-tls-container=$secret1_id --sni-container-refs $secret1_id $secret2_id -f value -c id); echo $listener_id</span><br><span class="line">pool_id=$(openstack loadbalancer pool create --protocol HTTP --listener $listener_id --lb-algorithm ROUND_ROBIN -f value -c id); echo $pool_id</span><br><span class="line">openstack loadbalancer member create --address $&#123;IP&#125; --subnet-id $subnetid --protocol-port 80 $pool_id</span><br><span class="line"></span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">vip=$(openstack loadbalancer show $lb_id -c vip_address -f value)</span><br><span class="line">vip_port=$(openstack port list --fixed-ip ip-address=$vip -c ID -f value)</span><br><span class="line">#openstack floating ip set $fip --fixed-ip-address $vip --port $vip_port</span><br><span class="line">neutron floatingip-associate $fip $vip_port</span><br><span class="line"></span><br><span class="line">curl -k https://$fip</span><br><span class="line">curl --resolve www.server1.com:443:$fip --cacert ~/ca3/ca.crt https://www.server1.com</span><br><span class="line">curl --resolve www.server2.com:443:$fip --cacert ~/ca3/ca.crt https://www.server2.com</span><br><span class="line"></span><br><span class="line">nobody    2202  2200  0 07:23 ?        00:00:00 /usr/sbin/haproxy -f /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523/dfa44538-2c12-411b-b3b3-c709bc139523.pid -L 1_a8OAWpvKuB7hMNzt8UwaJ2M00 -Ds -sf 2148</span><br><span class="line"></span><br><span class="line">root@amphora-2fae038f-08b5-4bce-a2b7-f7bd543c0314:~# cat /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer 22ce64e5-585d-43bd-80eb-5c3ff22abacd</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">frontend dfa44538-2c12-411b-b3b3-c709bc139523</span><br><span class="line">    option httplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    redirect scheme https if !&#123; ssl_fc &#125;</span><br><span class="line">    bind 192.168.21.16:443 ssl crt /var/lib/octavia/certs/dfa44538-2c12-411b-b3b3-c709bc139523/b16771bdb053d138575d60e3035d77fa0598ef5c.pem crt /var/lib/octavia/certs/dfa44538-2c12-411b-b3b3-c709bc139523</span><br><span class="line">    mode http</span><br><span class="line">    default_backend e6c4444a-a06e-4c1c-80d4-389516059d46</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend e6c4444a-a06e-4c1c-80d4-389516059d46</span><br><span class="line">    mode http</span><br><span class="line">    balance roundrobin</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 234ff0d3-5196-4536-bd49-dfbab94732d4 192.168.21.7:80 weight 1</span><br></pre></td></tr></table></figure></p>
<p>目前剩下的问题是service vm无法访问backend 192.168.21.7, 原理应该是:<br>octavia通过_plug_amphora_vip方法添加一个vip port (octavia-lb-vrrp-7e56de03-298e-43dd-a78f-33aa8d4af735), 它应该往amphora虚机上再添加一个port, 然后为此vip添加allowed_address_pairs. 但是在amphora虚机上我们没有发现这块新添的vip NIC, 重新运行下列’nova interface-attach’也不好使<br>nova list –all<br>nova interface-attach –port-id $(neutron port-show octavia-lb-vrrp-f63f0c5b-a541-442a-929c-b8ed7f7b3604 -f value -c id) 044f42c9-d205-4a11-aa8f-6b9aea896861<br>使用下列方法也不好使:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">lb_id=$(openstack loadbalancer show lb3 -f value -c id)</span><br><span class="line">old_vip=$(openstack loadbalancer show lb3 -f value -c vip_address)</span><br><span class="line">private_subnet_id=$(neutron subnet-show private_subnet -f value -c id)</span><br><span class="line"># delete old vip port (named &apos;octavia-lb-$lb_id&apos;)</span><br><span class="line">neutron port-delete octavia-lb-$lb_id</span><br><span class="line"># create new vip port with the same name and vip and binding:host_id is amphora service vm&apos;s host</span><br><span class="line"># nova show $(nova list --all |grep amphora |awk &apos;&#123;print $2&#125;&apos;) |grep OS-EXT-SRV-ATTR:host</span><br><span class="line">neutron port-create --name octavia-lb-$lb_id --device-owner Octavia --binding:host_id=juju-50fb86-bionic-rocky-barbican-octavia-8 --fixed-ip subnet_id=$&#123;private_subnet_id&#125;,ip_address=$&#123;old_vip&#125; private</span><br><span class="line">mac=$(neutron port-show octavia-lb-$lb_id -f value -c mac_address)</span><br><span class="line">nova interface-attach --port-id $(neutron port-show octavia-lb-$lb_id -f value -c id) $(nova list --all |grep amphora |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line"></span><br><span class="line">接着发现admin-state-up为False, 但enable(neutron port-update --admin-state-up True 6dc5b0bd-d0b7-4b29-9fce-b8f7b23c7914)后status仍然为DOWN. 继续检查设置如下;</span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /etc/netns/amphora-haproxy/network/interfaces</span><br><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line">source /etc/netns/amphora-haproxy/network/interfaces.d/*.cfg</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /etc/netns/amphora-haproxy/network/interfaces.d/eth1.cfg</span><br><span class="line"># Generated by Octavia agent</span><br><span class="line">auto eth1 eth1:0</span><br><span class="line">iface eth1 inet static</span><br><span class="line">address 192.168.21.34</span><br><span class="line">broadcast 192.168.21.255</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 192.168.21.1</span><br><span class="line">mtu 1458</span><br><span class="line">iface eth1:0 inet static</span><br><span class="line">address 192.168.21.5</span><br><span class="line">broadcast 192.168.21.255</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line"># Add a source routing table to allow members to access the VIP</span><br><span class="line">post-up /sbin/ip route add default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">post-down /sbin/ip route del default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">post-up /sbin/ip route add 192.168.21.0/24 dev eth1 src 192.168.21.5 scope link table 1</span><br><span class="line">post-down /sbin/ip route del 192.168.21.0/24 dev eth1 src 192.168.21.5 scope link table 1</span><br><span class="line">post-up /sbin/ip rule add from 192.168.21.5/32 table 1 priority 100</span><br><span class="line">post-down /sbin/ip rule del from 192.168.21.5/32 table 1 priority 100</span><br><span class="line">post-up /sbin/iptables -t nat -A POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line">post-down /sbin/iptables -t nat -D POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /var/lib/octavia/plugged_interfaces</span><br><span class="line">fa:16:3e:e2:3a:7f eth1</span><br><span class="line"></span><br><span class="line">ip netns exec amphora-haproxy ifdown eth1</span><br><span class="line">ip netns exec amphora-haproxy ifup eth1</span><br><span class="line">ip netns exec amphora-haproxy ifup eth1.0</span><br><span class="line">ip netns exec amphora-haproxy ip addr show</span><br><span class="line"></span><br><span class="line">但发现无法ifup eth1.0:</span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# ip netns exec amphora-haproxy ifup eth1.0</span><br><span class="line">Unknown interface eth1.0</span><br><span class="line"></span><br><span class="line">手工执行它:</span><br><span class="line">ip netns exec amphora-haproxy ifdown eth1</span><br><span class="line">ip netns exec amphora-haproxy ip addr add 192.168.21.34/24 dev eth1</span><br><span class="line">ip netns exec amphora-haproxy ip addr add 192.168.21.5/24 dev eth1</span><br><span class="line">ip netns exec amphora-haproxy ifconfig eth1 up</span><br><span class="line">ip netns exec amphora-haproxy ip route add default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">ip netns exec amphora-haproxy ip route add 192.168.21.0/24 dev eth1 src 192.168.21.5 scope link table 1</span><br><span class="line">ip netns exec amphora-haproxy ip rule add from 192.168.21.5/32 table 1 priority 100</span><br><span class="line">ip netns exec amphora-haproxy iptables -t nat -A POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line"></span><br><span class="line">注: 要重做image的话, 可以参考: https://github.com/openstack/octavia/tree/master/diskimage-create</span><br><span class="line"></span><br><span class="line">此时, 可以从amphora-haproxy ping backedn vm 192.168.21.7</span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# ip netns exec amphora-haproxy ping -c 1 192.168.21.7</span><br><span class="line">PING 192.168.21.7 (192.168.21.7) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.21.7: icmp_seq=1 ttl=64 time=3.83 ms</span><br><span class="line"></span><br><span class="line">但是从neutron-gateway节点仍然无法ping vip 192.168.21.5</span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-6:~# ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b ping 192.168.21.5</span><br><span class="line">PING 192.168.21.5 (192.168.21.5) 56(84) bytes of data.</span><br><span class="line"></span><br><span class="line">继续为这个ha port添加allowed-address-pairs port, 但仍然无果.</span><br><span class="line">neutron port-update 6dc5b0bd-d0b7-4b29-9fce-b8f7b23c7914 --allowed-address-pairs type=dict list=true mac_address=fa:16:3e:e2:3a:7f,ip_address=192.168.21.5</span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# iptables-save |grep &apos;IP/MAC pairs&apos;</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.5/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.34/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-sfad3d0f9-3 -s 192.168.0.16/32 -m mac --mac-source FA:16:3E:EA:54:4F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# iptables-save |grep &apos;IP/MAC pairs&apos;</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.5/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.34/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-sfad3d0f9-3 -s 192.168.0.16/32 -m mac --mac-source FA:16:3E:EA:54:4F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# ovs-appctl bridge/dump-flows br-int |grep 192.168.21</span><br><span class="line">table_id=24, duration=513s, n_packets=6, n_bytes=252, priority=2,arp,in_port=4,arp_spa=192.168.21.5,actions=goto_table:25</span><br><span class="line">table_id=24, duration=513s, n_packets=1, n_bytes=42, priority=2,arp,in_port=4,arp_spa=192.168.21.34,actions=goto_table:25</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# ovs-appctl bridge/dump-flows br-int |grep 25,</span><br><span class="line">table_id=25, duration=48s, n_packets=0, n_bytes=0, priority=2,in_port=4,dl_src=fa:16:3e:e2:3a:7f,actions=goto_table:60</span><br><span class="line">table_id=25, duration=48s, n_packets=6, n_bytes=1396, priority=2,in_port=3,dl_src=fa:16:3e:ea:54:4f,actions=goto_table:60</span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# ovs-appctl bridge/dump-flows br-int |grep 60,</span><br><span class="line">table_id=60, duration=76s, n_packets=20, n_bytes=3880, priority=3,actions=NORMAL</span><br></pre></td></tr></table></figure></p>
<p>继续查找原因, 既然从service vm能ping backend说明网络都没问题, 现在只是无法从gateway ping service vm那说明应该还是防火墙的问题. 采用’neutron port-show <ha-vip-port>‘查看该vip port关联的是一个新security group, 添加之后问题解决:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openstack security group rule create --protocol tcp --dst-port 22 lb-7f2985f0-c0d5-47ab-b805-7f5dafe20d3e</span><br><span class="line">openstack security group rule create --protocol icmp lb-7f2985f0-c0d5-47ab-b805-7f5dafe20d3e</span><br></pre></td></tr></table></figure></ha-vip-port></p>
<p>接着就是报这个错, 后来确认是上面在backend模拟HTTP服务的方法有问题, 后改成”sudo python -m SimpleHTTPServer 80”后问题解决 .<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-6:~# ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b curl -k https://192.168.21.5</span><br><span class="line">&lt;html&gt;&lt;body&gt;&lt;h1&gt;502 Bad Gateway&lt;/h1&gt;</span><br><span class="line">Jan  6 05:14:38 amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af haproxy[2688]: 192.168.21.1:41372 [06/Jan/2019:05:14:38.038] a5b442f3-7d40-4849-8b88-7f02697bfd5b~ e25b432a-ea45-4191-9448-c364661326dc/ae847e94-5aeb-4da6-9b66-07e1a385465b 28/0/9/-1/40 502 250 - - PH-- 0/0/0/0/0 0/0 &quot;GET / HTTP/1.1</span><br></pre></td></tr></table></figure></p>
<p>整个实验结果见链接- <a href="https://paste.ubuntu.com/p/PPHv9Zfdf6/" target="_blank" rel="external">https://paste.ubuntu.com/p/PPHv9Zfdf6/</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~⟫ curl -k https://10.5.150.5</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ curl --resolve www.quqi.com:443:10.5.150.5 --cacert ~/ca2_without_pass/ca.crt https://www.quqi.com</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ curl --resolve www.quqi.com:443:10.5.150.5 -k https://www.quqi.com</span><br><span class="line">Hello World!</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-6:~# ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b curl -k https://192.168.21.5</span><br><span class="line">Hello World!</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# ip netns exec amphora-haproxy curl 192.168.21.7</span><br><span class="line">Hello World!</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /var/lib/octavia/a5b442f3-7d40-4849-8b88-7f02697bfd5b/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer 7f2985f0-c0d5-47ab-b805-7f5dafe20d3e</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/a5b442f3-7d40-4849-8b88-7f02697bfd5b.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">frontend a5b442f3-7d40-4849-8b88-7f02697bfd5b</span><br><span class="line">    option httplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    redirect scheme https if !&#123; ssl_fc &#125;</span><br><span class="line">    bind 192.168.21.5:443 ssl crt /var/lib/octavia/certs/a5b442f3-7d40-4849-8b88-7f02697bfd5b/4aa85f186d19a766c29109577d88734a8fca6385.pem crt /var/lib/octavia/certs/a5b442f3-7d40-4849-8b88-7f02697bfd5b</span><br><span class="line">    mode http</span><br><span class="line">    default_backend e25b432a-ea45-4191-9448-c364661326dc</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend e25b432a-ea45-4191-9448-c364661326dc</span><br><span class="line">    mode http</span><br><span class="line">    balance roundrobin</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server ae847e94-5aeb-4da6-9b66-07e1a385465b 192.168.21.7:80 weight 1 check inter 5s fall 3 rise 4</span><br></pre></td></tr></table></figure>
<h2 id="附件-Neutron-LBaaS-v2"><a href="#附件-Neutron-LBaaS-v2" class="headerlink" title="附件 - Neutron LBaaS v2"></a>附件 - Neutron LBaaS v2</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">https://docs.openstack.org/mitaka/networking-guide/config-lbaas.html</span><br><span class="line">neutron lbaas-loadbalancer-create --name test-lb private_subnet</span><br><span class="line">neutron lbaas-listener-create --name test-lb-https --loadbalancer test-lb --protocol HTTPS --protocol-port 443</span><br><span class="line">neutron lbaas-pool-create --name test-lb-pool-https --lb-algorithm LEAST_CONNECTIONS --listener test-lb-https --protocol HTTPS</span><br><span class="line">neutron lbaas-member-create --subnet private_subnet --address 192.168.21.13 --protocol-port 443 test-lb-pool-https</span><br><span class="line">neutron lbaas-member-create --subnet private_subnet --address 192.168.21.8 --protocol-port 443 test-lb-pool-https</span><br><span class="line">neutron lbaas-healthmonitor-create --delay 5 --max-retries 2 --timeout 10 --type HTTPS --pool test-lb-pool-https --name monitor1</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl -k  https://192.168.21.14</span><br><span class="line">test1</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl -k  https://192.168.21.14</span><br><span class="line">test2</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl --cacert /home/ubuntu/lb.pem  https://192.168.21.14</span><br><span class="line">curl: (51) SSL: certificate subject name (www.quqi.com) does not match target host name &apos;192.168.21.14&apos;</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl --cacert /home/ubuntu/lb.pem  --resolve www.quqi.com:443:192.168.21.14 https://www.quqi.com</span><br><span class="line">test1</span><br><span class="line"></span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# echo &apos;show stat;show table&apos; | socat stdio /var/lib/neutron/lbaas/v2/84fd9a6c-24a2-4c0f-912b-eedc254ac1f4/haproxy_stats.sock</span><br><span class="line"># pxname,svname,qcur,qmax,scur,smax,slim,stot,bin,bout,dreq,dresp,ereq,econ,eresp,wretr,wredis,status,weight,act,bck,chkfail,chkdown,lastchg,downtime,qlimit,pid,iid,sid,throttle,lbtot,tracked,type,rate,rate_lim,rate_max,check_status,check_code,check_duration,hrsp_1xx,hrsp_2xx,hrsp_3xx,hrsp_4xx,hrsp_5xx,hrsp_other,hanafail,req_rate,req_rate_max,req_tot,cli_abrt,srv_abrt,comp_in,comp_out,comp_byp,comp_rsp,lastsess,last_chk,last_agt,qtime,ctime,rtime,ttime,</span><br><span class="line">c2a42906-e160-44dd-8590-968af2077b4a,FRONTEND,,,0,0,2000,0,0,0,0,0,0,,,,,OPEN,,,,,,,,,1,2,0,,,,0,0,0,0,,,,,,,,,,,0,0,0,,,0,0,0,0,,,,,,,,</span><br><span class="line">52112201-05ce-4f4d-b5a8-9e67de2a895a,37a1f5a8-ec7e-4208-9c96-27d2783a594f,0,0,0,0,,0,0,0,,0,,0,0,0,0,no check,1,1,0,,,,,,1,3,1,,0,,2,0,,0,,,,,,,,,,0,,,,0,0,,,,,-1,,,0,0,0,0,</span><br><span class="line">52112201-05ce-4f4d-b5a8-9e67de2a895a,8e722b4b-08b8-4089-bba5-8fa5dd26a87f,0,0,0,0,,0,0,0,,0,,0,0,0,0,no check,1,1,0,,,,,,1,3,2,,0,,2,0,,0,,,,,,,,,,0,,,,0,0,,,,,-1,,,0,0,0,0,</span><br><span class="line">52112201-05ce-4f4d-b5a8-9e67de2a895a,BACKEND,0,0,0,0,200,0,0,0,0,0,,0,0,0,0,UP,2,2,0,,0,117,0,,1,3,0,,0,,1,0,,0,,,,,,,,,,,,,,0,0,0,0,0,0,-1,,,0,0,0,0,</span><br><span class="line"></span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# cat /var/lib/neutron/lbaas/v2/84fd9a6c-24a2-4c0f-912b-eedc254ac1f4/haproxy.conf</span><br><span class="line"># Configuration for test-lb</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    group nogroup</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    maxconn 2000</span><br><span class="line">    stats socket /var/lib/neutron/lbaas/v2/84fd9a6c-24a2-4c0f-912b-eedc254ac1f4/haproxy_stats.sock mode 0666 level user</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout client 50000</span><br><span class="line">    timeout server 50000</span><br><span class="line">frontend c2a42906-e160-44dd-8590-968af2077b4a</span><br><span class="line">    option tcplog</span><br><span class="line">    bind 192.168.21.14:443</span><br><span class="line">    mode tcp</span><br><span class="line">    default_backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">    mode tcp</span><br><span class="line">    balance leastconn</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    option ssl-hello-chk</span><br><span class="line">    server 37a1f5a8-ec7e-4208-9c96-27d2783a594f 192.168.21.13:443 weight 1 check inter 5s fall 2</span><br><span class="line">    server 8e722b4b-08b8-4089-bba5-8fa5dd26a87f 192.168.21.8:443 weight 1 check inter 5s fall 2</span><br><span class="line"></span><br><span class="line"># TCP monitor</span><br><span class="line">neutron lbaas-healthmonitor-delete monitor1</span><br><span class="line">neutron lbaas-healthmonitor-create --delay 5 --max-retries 2 --timeout 10 --type TCP --pool test-lb-pool-https --name monitor1 --url-path /</span><br><span class="line">backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">    mode tcp</span><br><span class="line">    balance leastconn</span><br><span class="line">    timeout check 10s</span><br><span class="line">    server 37a1f5a8-ec7e-4208-9c96-27d2783a594f 192.168.21.13:443 weight 1 check inter 5s fall 2</span><br><span class="line">    server 8e722b4b-08b8-4089-bba5-8fa5dd26a87f 192.168.21.8:443 weight 1 check inter 5s fall 2</span><br></pre></td></tr></table></figure>
<h2 id="附录-上层的k8s如何使用下层的openstack中的LBaaS资源"><a href="#附录-上层的k8s如何使用下层的openstack中的LBaaS资源" class="headerlink" title="附录 - 上层的k8s如何使用下层的openstack中的LBaaS资源"></a>附录 - 上层的k8s如何使用下层的openstack中的LBaaS资源</h2><p>如果在一个OpenStack云上面再创建K8S的话, 在k8s中使用下列命令创建LoadBalancer服务会永远Pending状态.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl run test-nginx --image=nginx --replicas=2 --port=80 --expose --service-overrides=&apos;&#123; &quot;spec&quot;: &#123; &quot;type&quot;: &quot;LoadBalancer&quot; &#125; &#125;&apos;</span><br><span class="line">kubectl get svc test-nginx</span><br></pre></td></tr></table></figure></p>
<p>那是因为k8s需要调用底层OpenStack  LBaaS服务创建VIP资源, 然后将所有后端服务的<nodeip:nodeport>作为backend. 那么该如何让k8s具有访问openstack lbaas资源的能力呢? 如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># https://blog.ubuntu.com/2019/01/28/taking-octavia-for-a-ride-with-kubernetes-on-openstack</span><br><span class="line"># openstack上部署k8s, &apos;juju trust openstack-integrator&apos;将让openstack-integrator具有访问bootstrap时所用的openstack credential的权限,</span><br><span class="line"># 之后, 因为cdk实现了interface-openstack-integration接口, 所以cdk k8s可以使用这些openstack credential来直接使用openstack里的LBaaS等资源</span><br><span class="line">juju deploy cs:~containers/openstack-integrator</span><br><span class="line">juju add-relation openstack-integrator kubernetes-master</span><br><span class="line">juju add-relation openstack-integrator kubernetes-worker</span><br><span class="line">juju config openstack-integrator subnet-id=&lt;UUID of subnet&gt;</span><br><span class="line">juju config openstack-integrator floating-network-id=&lt;UUID of ext_net&gt;</span><br><span class="line"></span><br><span class="line"># &apos;juju trust&apos; grants openstack-integrator access to the credential used in the bootstrap command, this charm acts as a proxy for the</span><br><span class="line">juju trust openstack-integrator</span><br><span class="line"></span><br><span class="line">测试yaml, 有时要提供loadbalancer.openstack.org/floating-network-id, 见:  https://github.com/kubernetes/cloud-provider-openstack/tree/master/examples/loadbalancers</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: external-http-nginx-service</span><br><span class="line">  annotations:</span><br><span class="line">    service.beta.kubernetes.io/openstack-internal-load-balancer: &quot;false&quot;</span><br><span class="line">    loadbalancer.openstack.org/floating-network-id: &quot;6f05a9de-4fc9-41f5-9c51-d5f43cd244b9&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 80</span><br></pre></td></tr></table></figure></nodeip:nodeport></p>
<p>同时也应该确保service tenant下的security group的quata别超了.quata超了的现象是例如对于FIP, 有时可以有时不可以.</p>
<p>后面继续搭建k8s可参见 - <a href="https://ubuntu.com/blog/taking-octavia-for-a-ride-with-kubernetes-on-openstack" target="_blank" rel="external">https://ubuntu.com/blog/taking-octavia-for-a-ride-with-kubernetes-on-openstack</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br></pre></td><td class="code"><pre><span class="line">juju add-model octavia stsstack/stsstack</span><br><span class="line">cd ~/stsstack-bundles/openstack</span><br><span class="line">##Quota exceeded for ram: Requested 8192, but already used 126976 of 131072 ram</span><br><span class="line">./generate-bundle.sh --name octavia --create-model --run --octavia -r stein --dvr-snat --num-compute 10</span><br><span class="line">#https://discourse.juju.is/t/cloud-image-metadata/1137</span><br><span class="line">#juju deploy cs:glance-simplestreams-sync-21</span><br><span class="line">#juju add-relation keystone glance-simplestreams-sync</span><br><span class="line">./bin/add-data-ports.sh     #juju config neutron-openvswitch data-port=&quot;br-data:ens7&quot;</span><br><span class="line">#refere this page to generate certs - https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-octavia.html</span><br><span class="line">juju config octavia \</span><br><span class="line">    lb-mgmt-issuing-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-private-key=&quot;$(base64 controller_ca_key.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-key-passphrase=foobar \</span><br><span class="line">    lb-mgmt-controller-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-controller-cert=&quot;$(base64 controller_cert_bundle.pem)&quot;</span><br><span class="line">juju run-action --wait octavia/0 configure-resources</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">./configure</span><br><span class="line">juju config octavia loadbalancer-topology=ACTIVE_STANDBY spare-pool-size=2</span><br><span class="line">#juju run-action octavia-diskimage-retrofit/0 --wait retrofit-image source-image=$(openstack image list |grep bionic |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">sudo snap install --edge --devmode octavia-diskimage-retrofit</span><br><span class="line">sudo -s</span><br><span class="line">wget https://cloud-images.ubuntu.com/minimal/releases/bionic/release/ubuntu-18.04-minimal-cloudimg-amd64.img</span><br><span class="line">mv ubuntu-18.04-minimal-cloudimg-amd64.img /var/snap/octavia-diskimage-retrofit/common</span><br><span class="line">octavia-diskimage-retrofit /var/snap/octavia-diskimage-retrofit/common/ubuntu-18.04-minimal-cloudimg-amd64.img /var/snap/octavia-diskimage-retrofit/common/ubuntu-amphora-haproxy-amd64.qcow2 -d u stein</span><br><span class="line">exit</span><br><span class="line">openstack image create --disk-format qcow2 --container-format bare --public --tag octavia-amphora --file /var/snap/octavia-diskimage-retrofit/common/ubuntu-amphora-haproxy-amd64.qcow2 amphora-bionic-x64-haproxy</span><br><span class="line">openstack image list</span><br><span class="line"></span><br><span class="line">#./tools/sec_groups.sh</span><br><span class="line">PROJECT_ID=$(openstack project show --domain admin_domain admin -f value -c id)</span><br><span class="line">SECGRP_ID=$(openstack security group list --project $&#123;PROJECT_ID&#125; | awk &apos;/default/ &#123;print $2&#125;&apos;)</span><br><span class="line">openstack security group rule create $&#123;SECGRP_ID&#125; --protocol any --ethertype IPv6 --ingress</span><br><span class="line">openstack security group rule create $&#123;SECGRP_ID&#125; --protocol any --ethertype IPv4 --ingress</span><br><span class="line"></span><br><span class="line">#https://wiki.opnfv.org/display/fds/Setting+unlimited+quotas+in+openstack+for+testing</span><br><span class="line">openstack quota set --instances -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --floating-ips -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --cores -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --ram -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --gigabytes -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --volumes -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --secgroups -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --secgroup-rules -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">neutron quota-update --network -1</span><br><span class="line">neutron quota-update --floatingip -1</span><br><span class="line">neutron quota-update --port -1</span><br><span class="line">neutron quota-update --router -1</span><br><span class="line">neutron quota-update --security-group -1</span><br><span class="line">neutron quota-update --security-group-rule -1</span><br><span class="line">neutron quota-update --subnet -1</span><br><span class="line">neutron quota-show</span><br><span class="line">GATEWAY_IP=$(openstack router show provider-router -f value -c external_gateway_info \</span><br><span class="line">    |awk &apos;/ip_address/ &#123; for (i=1;i&lt;NF;i++) if ($i~&quot;ip_address&quot;) print $(i+1)&#125;&apos; |cut -f2 -d\&apos;)</span><br><span class="line">CIDR=$(openstack subnet show private_subnet -f value -c cidr)</span><br><span class="line">sudo ip route add $&#123;CIDR&#125; via $&#123;GATEWAY_IP&#125;</span><br><span class="line">sudo bash -c &apos;cat &gt; mystack.yaml&apos; &lt;&lt; EOF</span><br><span class="line">clouds:</span><br><span class="line">  mystack:</span><br><span class="line">    type: openstack</span><br><span class="line">    auth-types: [ userpass ]</span><br><span class="line">    regions:</span><br><span class="line">      RegionOne:</span><br><span class="line">        endpoint: $OS_AUTH_URL</span><br><span class="line">EOF</span><br><span class="line">juju remove-cloud --local mystack</span><br><span class="line">juju add-cloud --local mystack mystack.yaml &amp;&amp; juju show-cloud mystack</span><br><span class="line">sudo bash -c &apos;cat &gt; mystack_credentials.txt&apos; &lt;&lt; EOF</span><br><span class="line">credentials:</span><br><span class="line">  mystack:</span><br><span class="line">    admin:</span><br><span class="line">      auth-type: userpass</span><br><span class="line">      password: openstack</span><br><span class="line">      tenant-name: admin</span><br><span class="line">      domain-name: &quot;&quot; # ensure we don&apos;t get a domain-scoped token</span><br><span class="line">      project-domain-name: admin_domain</span><br><span class="line">      user-domain-name: admin_domain</span><br><span class="line">      username: admin</span><br><span class="line">      version: &quot;3&quot;</span><br><span class="line">EOF</span><br><span class="line">juju remove-credential --local mystack admin</span><br><span class="line">juju add-credential --local mystack -f ./mystack_credentials.txt &amp;&amp; juju show-credential --local mystack admin</span><br><span class="line">juju show-credential --local mystack admin</span><br><span class="line"></span><br><span class="line">mkdir -p ~/simplestreams/images</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">IMAGE_ID=$(openstack image list -f value |grep &apos;bionic active&apos; |awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">OS_SERIES=$(openstack image list -f value |grep &apos;bionic active&apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">juju metadata generate-image -d ~/simplestreams -i $IMAGE_ID -s $OS_SERIES -r $OS_REGION_NAME -u $OS_AUTH_URL</span><br><span class="line">ls ~/simplestreams/*/streams/*</span><br><span class="line">NETWORK_ID=$(openstack network show private -f value -c id)</span><br><span class="line">vim ~/.local/share/juju/controllers.yaml</span><br><span class="line">#NOTE: above &apos;sudo ip route add $&#123;CIDR&#125; via $&#123;GATEWAY_IP&#125;&apos; is used here to make sure the network between bastion and controller is good</span><br><span class="line">juju bootstrap mystack --config network=$&#123;NETWORK_ID&#125; --model-default network=$&#123;NETWORK_ID&#125; --model-default use-default-secgroup=true --metadata-source /home/ubuntu/simplestreams</span><br><span class="line"></span><br><span class="line">#https://ubuntu.com/kubernetes/docs/openstack-integration</span><br><span class="line">juju add-model upperk8s</span><br><span class="line">#juju deploy charmed-kubernetes</span><br><span class="line">#for the error &quot;No valid host was found. change bundle.yaml, &apos;cores=4 mem=4G root-disk=16G&apos; -&gt; &apos;cores=2 mem=4G root-disk=16G&apos;</span><br><span class="line">wget https://api.jujucharms.com/charmstore/v5/bundle/canonical-kubernetes-933/archive/bundle.yaml</span><br><span class="line">juju deploy bundle.yaml</span><br><span class="line">juju deploy cs:~containers/openstack-integrator</span><br><span class="line">juju add-relation openstack-integrator kubernetes-master:openstack</span><br><span class="line">juju add-relation openstack-integrator kubernetes-worker:openstack</span><br><span class="line">#juju add-relation openstack-integrator kubernetes-master:loadbalancer</span><br><span class="line">juju config openstack-integrator subnet-id=$(openstack subnet show private_subnet -c id -f value)</span><br><span class="line">juju config openstack-integrator floating-network-id=$(openstack network show ext_net -c id -f value)</span><br><span class="line">juju trust openstack-integrator</span><br><span class="line"></span><br><span class="line">mkdir ~/.kube</span><br><span class="line">juju scp kubernetes-master/0:config ~/.kube/config</span><br><span class="line">sudo snap install kubectl --classic</span><br><span class="line">#kubectl run hello-world --replicas=3 --labels=&quot;run=load-balancer-example&quot; --image=gcr.io/google-samples/node-hello:1.0  --port=8080</span><br><span class="line">kubectl create deployment hello-world --image=gcr.io/google-samples/node-hello:1.0  -o yaml --dry-run &gt; helloworld.yaml</span><br><span class="line">sudo bash -c &apos;cat &gt; helloworld.yaml&apos; &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: hello-world</span><br><span class="line">  name: hello-world</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: hello-world</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-world</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: gcr.io/google-samples/node-hello:1.0</span><br><span class="line">        name: node-hello</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f ./helloworld.yaml</span><br><span class="line">kubectl get deployments hello-world</span><br><span class="line"></span><br><span class="line">#kubectl  delete svc hello</span><br><span class="line">#kubectl expose deployment hello-world --type=LoadBalancer --name=hello</span><br><span class="line">kubectl describe svc hello</span><br><span class="line">  Warning  SyncLoadBalancerFailed  53s (x5 over 2m)     service-controller  Error syncing load balancer: failed to ensure load balancer: error creating LB floatingip &#123;Description:Floating IP for Kubernetes external service default/hello from cluster kubernetes-n7cgun28wpbsfgiiza5qralulupdtspv FloatingNetworkID:54365c1c-1987-4607-8e98-4341cff4795f FloatingIP: PortID:9b578028-90c3-4118-9f08-1bdb70925fe2 FixedIP: SubnetID: TenantID: ProjectID:&#125;: Bad request with: [POST http://10.5.0.9:9696/v2.0/floatingips], error message: &#123;&quot;NeutronError&quot;: &#123;&quot;type&quot;: &quot;BadRequest&quot;, &quot;message&quot;: &quot;Bad floatingip request: Network 54365c1c-1987-4607-8e98-4341cff4795f is not a valid external network.&quot;, &quot;detail&quot;: &quot;&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; helloservice.yaml&apos; &lt;&lt; EOF</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: hello</span><br><span class="line">  annotations:</span><br><span class="line">    service.beta.kubernetes.io/openstack-internal-load-balancer: &quot;false&quot;</span><br><span class="line">    loadbalancer.openstack.org/floating-network-id: &quot;1a83b2d3-1c1b-4bc9-b882-f132b9ff9d87&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-world</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f ./helloservice.yaml</span><br><span class="line">watch kubectl get svc -o wide hello</span><br><span class="line">watch kubectl get svc -o wide --selector=app=hello-world</span><br><span class="line">NAME    TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE     SELECTOR</span><br><span class="line">hello   LoadBalancer   10.152.183.88   10.5.150.220   80:32315/TCP   2m47s   app=hello-world</span><br><span class="line">$ curl http://10.5.150.220:80</span><br><span class="line">Hello Kubernetes!</span><br><span class="line">kubectl describe svc hello-world</span><br><span class="line">openstack loadbalancer list            #use &apos;kubectl  delete svc hello&apos; to delete lb</span><br><span class="line">openstack loadbalancer amphora list</span><br><span class="line"></span><br><span class="line">$ openstack floating ip list</span><br><span class="line">+--------------------------------------+---------------------+------------------+--------------------------------------+--------------------------------------+----------------------------------+</span><br><span class="line">| ID                                   | Floating IP Address | Fixed IP Address | Port                                 | Floating Network                     | Project                          |</span><br><span class="line">+--------------------------------------+---------------------+------------------+--------------------------------------+--------------------------------------+----------------------------------+</span><br><span class="line">| c284dfc3-d294-48ae-8ccf-20a7e47fe039 | 10.5.150.220        | 192.168.21.26    | ded911a8-f213-4884-a387-7efcf14c8a89 | 1a83b2d3-1c1b-4bc9-b882-f132b9ff9d87 | 0d1886170941437fa46fb34508e67d24 |</span><br><span class="line">+--------------------------------------+---------------------+------------------+--------------------------------------+--------------------------------------+----------------------------------+</span><br><span class="line"></span><br><span class="line">$ openstack loadbalancer list</span><br><span class="line">+--------------------------------------+------------------------------------------------------------------------+----------------------------------+---------------+---------------------+----------+</span><br><span class="line">| id                                   | name                                                                   | project_id                       | vip_address   | provisioning_status | provider |</span><br><span class="line">+--------------------------------------+------------------------------------------------------------------------+----------------------------------+---------------+---------------------+----------+</span><br><span class="line">| 72d96673-8723-4dde-9035-66c3bd095632 | kube_service_kubernetes-n7cgun28wpbsfgiiza5qralulupdtspv_default_hello | 0d1886170941437fa46fb34508e67d24 | 192.168.21.26 | ACTIVE              | amphora  |</span><br><span class="line">+--------------------------------------+------------------------------------------------------------------------+----------------------------------+---------------+---------------------+----------+</span><br><span class="line"></span><br><span class="line">$ openstack loadbalancer amphora list</span><br><span class="line">+--------------------------------------+--------------------------------------+-----------+------------+-----------------------------------------+---------------+</span><br><span class="line">| id                                   | loadbalancer_id                      | status    | role       | lb_network_ip                           | ha_ip         |</span><br><span class="line">+--------------------------------------+--------------------------------------+-----------+------------+-----------------------------------------+---------------+</span><br><span class="line">| 068104f1-ffee-4b4a-88ab-2e46cee1cbbc | 72d96673-8723-4dde-9035-66c3bd095632 | ALLOCATED | STANDALONE | fc00:961f:bb53:993b:f816:3eff:fe0d:6433 | 192.168.21.26 |</span><br><span class="line">+--------------------------------------+--------------------------------------+-----------+------------+-----------------------------------------+---------------+</span><br><span class="line"></span><br><span class="line">$ nova list --all |grep amphora</span><br><span class="line">| 966f0ec0-b48a-48b9-8078-d7406ee08311 | amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc | 144901cff394489d9095b1361caa6872 | ACTIVE | -          | Running     | lb-mgmt-net=fc00:961f:bb53:993b:f816:3eff:fe0d:6433; private=192.168.21.174 |</span><br><span class="line"></span><br><span class="line">#nova keypair-add --pub-key=~/.ssh/id_amphora.pub amphora-backdoor --user $(openstack user show octavia --domain service_domain -f value -c id)</span><br><span class="line">$ nova keypair-list --user $(openstack user show octavia --domain service_domain -f value -c id)</span><br><span class="line">+------------------+------+-------------------------------------------------+</span><br><span class="line">| Name             | Type | Fingerprint                                     |</span><br><span class="line">+------------------+------+-------------------------------------------------+</span><br><span class="line">| amphora-backdoor | ssh  | d9:53:1e:eb:70:42:24:f3:01:e2:4c:9d:c9:97:bd:11 |</span><br><span class="line">+------------------+------+-------------------------------------------------+</span><br><span class="line"></span><br><span class="line">$ openstack router list</span><br><span class="line">+--------------------------------------+-----------------+--------+-------+----------------------------------+-------------+-------+</span><br><span class="line">| ID                                   | Name            | Status | State | Project                          | Distributed | HA    |</span><br><span class="line">+--------------------------------------+-----------------+--------+-------+----------------------------------+-------------+-------+</span><br><span class="line">| 05d8e256-ba53-4b32-b40d-17472ac09040 | provider-router | ACTIVE | UP    | 0d1886170941437fa46fb34508e67d24 | True        | False |</span><br><span class="line">| 6876c9c3-d8c5-4b31-876b-fe830d4b5f0b | lb-mgmt         | ACTIVE | UP    | 144901cff394489d9095b1361caa6872 | False       | False |</span><br><span class="line">+--------------------------------------+-----------------+--------+-------+----------------------------------+-------------+-------+</span><br><span class="line">$ openstack subnet list</span><br><span class="line">+--------------------------------------+------------------+--------------------------------------+--------------------------+</span><br><span class="line">| ID                                   | Name             | Network                              | Subnet                   |</span><br><span class="line">+--------------------------------------+------------------+--------------------------------------+--------------------------+</span><br><span class="line">| 401b11c1-b209-4545-81f2-81dc93674616 | private_subnet   | 2c927db4-ee05-4d4a-b35b-f106cbd785c4 | 192.168.21.0/24          |</span><br><span class="line">| 54365c1c-1987-4607-8e98-4341cff4795f | ext_net_subnet   | 1a83b2d3-1c1b-4bc9-b882-f132b9ff9d87 | 10.5.0.0/16              |</span><br><span class="line">| 56847939-4776-4b39-bdac-e04a4a9b6555 | lb-mgmt-subnetv6 | 983933d9-3078-47ce-b581-961fbb53993b | fc00:961f:bb53:993b::/64 |</span><br><span class="line">+--------------------------------------+------------------+--------------------------------------+--------------------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#nova list --all |grep amphora</span><br><span class="line">#juju scp ~/.ssh/id_amphora* nova-compute/5:/home/ubuntu/</span><br><span class="line">#amphora instance is on nova-compute/3 (juju-7917e4-octavia-9), but gateway for lb-mgmt-subnetv6 is on nova-compute/5</span><br><span class="line">juju ssh nova-compute/5 -- sudo ip netns exec qrouter-6876c9c3-d8c5-4b31-876b-fe830d4b5f0b ping6 fc00:961f:bb53:993b:f816:3eff:fe0d:6433</span><br><span class="line">juju ssh nova-compute/5 -- sudo ip netns exec qrouter-6876c9c3-d8c5-4b31-876b-fe830d4b5f0b ssh -6 -i ~/id_amphora ubuntu@fc00:961f:bb53:993b:f816:3eff:fe0d:6433 -v</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ sudo ip netns ls</span><br><span class="line">amphora-haproxy (id: 0)</span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ sudo ip netns exec amphora-haproxy ip addr show</span><br><span class="line">sudo: unable to resolve host amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1508 qdisc fq state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:df:d2:3b brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.21.174/24 brd 192.168.21.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 192.168.21.26/24 brd 192.168.21.255 scope global secondary eth1:0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ ps -ef |grep haproxy</span><br><span class="line">root      1546     1  0 01:18 ?        00:00:01 /usr/sbin/haproxy -Ws -f /var/lib/octavia/72d96673-8723-4dde-9035-66c3bd095632/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/72d96673-8723-4dde-9035-66c3bd095632/72d96673-8723-4dde-9035-66c3bd095632.pid -L 7eAyDHfLMNtMDh0lrSe_vQODo0g -sf 1800</span><br><span class="line">nobody    1860  1546  0 01:19 ?        00:00:00 /usr/sbin/haproxy -Ws -f /var/lib/octavia/72d96673-8723-4dde-9035-66c3bd095632/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/72d96673-8723-4dde-9035-66c3bd095632/72d96673-8723-4dde-9035-66c3bd095632.pid -L 7eAyDHfLMNtMDh0lrSe_vQODo0g -sf 1800</span><br><span class="line">ubuntu    2198  2185  0 02:01 pts/0    00:00:00 grep --color=auto haproxy</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ sudo cat /var/lib/octavia/72d96673-8723-4dde-9035-66c3bd095632/haproxy.cfg</span><br><span class="line">sudo: unable to resolve host amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc</span><br><span class="line"># Configuration for loadbalancer 72d96673-8723-4dde-9035-66c3bd095632</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/72d96673-8723-4dde-9035-66c3bd095632.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">    option splice-request</span><br><span class="line">    option splice-response</span><br><span class="line">    option http-keep-alive</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend 7f26223c-63f8-490a-8aa3-0141b112bacb</span><br><span class="line">    option tcplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    bind 192.168.21.26:80</span><br><span class="line">    mode tcp</span><br><span class="line">    default_backend 632d6cf2-020f-4c63-9ca7-4bc952f8f324:7f26223c-63f8-490a-8aa3-0141b112bacb</span><br><span class="line">    timeout client 50000</span><br><span class="line"></span><br><span class="line">backend 632d6cf2-020f-4c63-9ca7-4bc952f8f324:7f26223c-63f8-490a-8aa3-0141b112bacb</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 150e2027-ec51-469d-b5f8-675575c76c79 192.168.21.114:32315 weight 1</span><br><span class="line">    server 9b42d8f0-5719-48fe-b17c-2e7cd2b29b10 192.168.21.232:32315 weight 1</span><br><span class="line">    server d9f1f6ba-895b-43c6-ad09-362f4993aa73 192.168.21.251:32315 weight 1</span><br><span class="line">    server e7485d2c-1de5-4438-8b3b-0f74ba870895 192.168.21.87:32315 weight 1</span><br><span class="line"></span><br><span class="line">$ kubectl get svc</span><br><span class="line">NAME         TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)        AGE</span><br><span class="line">hello        LoadBalancer   10.152.183.88   10.5.150.220   80:32315/TCP   51m</span><br><span class="line">kubernetes   ClusterIP      10.152.183.1    &lt;none&gt;         443/TCP        10h</span><br><span class="line">$ juju status |grep worker</span><br><span class="line">kubernetes-worker      1.18.4   waiting    4/5  kubernetes-worker      jujucharms  682  ubuntu  exposed</span><br><span class="line">kubernetes-worker/0       waiting   allocating  6        192.168.21.128                  waiting for machine</span><br><span class="line">kubernetes-worker/1*      active    idle        7        192.168.21.114  80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line">kubernetes-worker/2       active    idle        8        192.168.21.232  80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line">kubernetes-worker/3       active    idle        10       192.168.21.251  80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line">kubernetes-worker/4       active    idle        11       192.168.21.87   80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line"></span><br><span class="line">$ juju switch zhhuabj</span><br><span class="line">mystack-regionone:admin/k8s -&gt; zhhuabj:admin/octavia</span><br><span class="line">$ nova list</span><br><span class="line">+--------------------------------------+--------------------------+--------+------------+-------------+------------------------+</span><br><span class="line">| ID                                   | Name                     | Status | Task State | Power State | Networks               |</span><br><span class="line">+--------------------------------------+--------------------------+--------+------------+-------------+------------------------+</span><br><span class="line">| 5cbd03dc-9e6b-42ea-a8a2-9ca725144df0 | juju-68d107-k8s-0        | ACTIVE | -          | Running     | private=192.168.21.219 |</span><br><span class="line">| 5cc74c32-1547-44b3-8c2d-68fcf33e5080 | juju-68d107-k8s-1        | ACTIVE | -          | Running     | private=192.168.21.127 |</span><br><span class="line">| 46dc9a58-1a51-4b45-912c-8c768a4d5f28 | juju-68d107-k8s-10       | ACTIVE | -          | Running     | private=192.168.21.251 |</span><br><span class="line">| 773a845c-f87d-4352-9c74-b3f3d354590f | juju-68d107-k8s-11       | ACTIVE | -          | Running     | private=192.168.21.87  |</span><br><span class="line">| 211a6abd-bc97-4faf-984f-987fa90f21f3 | juju-68d107-k8s-2        | ACTIVE | -          | Running     | private=192.168.21.78  |</span><br><span class="line">| df6b642a-9af8-4468-b1bf-691401c4835f | juju-68d107-k8s-3        | ACTIVE | -          | Running     | private=192.168.21.158 |</span><br><span class="line">| c6f82159-98c9-4884-a7b1-eb9e950618bb | juju-68d107-k8s-4        | ACTIVE | -          | Running     | private=192.168.21.242 |</span><br><span class="line">| e81b9566-3627-4a05-9460-415e76db9483 | juju-68d107-k8s-5        | ACTIVE | -          | Running     | private=192.168.21.217 |</span><br><span class="line">| 569087bd-9ef8-4e6f-a898-72b69daef6ea | juju-68d107-k8s-6        | ACTIVE | -          | Running     | private=192.168.21.128 |</span><br><span class="line">| 38d8887c-54ae-4b2c-b0c4-7f64542af8f1 | juju-68d107-k8s-7        | ACTIVE | -          | Running     | private=192.168.21.114 |</span><br><span class="line">| 178c5eee-945a-4295-8c94-5ad5d821f251 | juju-68d107-k8s-8        | ACTIVE | -          | Running     | private=192.168.21.232 |</span><br><span class="line">| 09a9c0c1-c795-494b-ac21-49fa3a2ef070 | juju-68d107-k8s-9        | ACTIVE | -          | Running     | private=192.168.21.147 |</span><br><span class="line">| 2d5bff68-21f1-46e0-b6b8-c83d97c8cc27 | juju-bb6752-controller-0 | ACTIVE | -          | Running     | private=192.168.21.21  |</span><br><span class="line">+--------------------------------------+--------------------------+--------+------------+-------------+------------------------+</span><br><span class="line"></span><br><span class="line">$ nova show juju-68d107-k8s-7 |grep security</span><br><span class="line">| security_groups                      | default, juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107, juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107-7                                     |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group list --project $(openstack project list --domain admin_domain |grep admin |awk &apos;&#123;print $2&#125;&apos;) |grep default</span><br><span class="line">| bfc84b34-6f23-4561-87ff-58077f667bea | default                                                                           | Default security group | 0d1886170941437fa46fb34508e67d24 | []   |</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ sudo ip netns exec amphora-haproxy ping 192.168.21.114 -c 1</span><br><span class="line">sudo: unable to resolve host amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc</span><br><span class="line">PING 192.168.21.114 (192.168.21.114) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.21.114: icmp_seq=1 ttl=64 time=1.14 ms</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ sudo ip netns exec amphora-haproxy nc -w4 -vz 192.168.21.114 32315</span><br><span class="line">Connection to 192.168.21.114 32315 port [tcp/*] succeeded!</span><br><span class="line"></span><br><span class="line">#NOTE</span><br><span class="line">os security group rule create --ingress --protocol tcp --remote-group b1eff65c-b6c1-4f09-8ed6-1b163e447318 --dst-port 32315:32315 --ethertype ipv4 3f95d2fa-5ba5-4719-96ee-a0e6211c7c46&quot;</span><br><span class="line">Where remote-group is the sec group associated with the port on 192.168.100.xxx of the amphora VM</span><br><span class="line">And 3f95d2fa-5ba5-4719-96ee-a0e6211c7c46 is the default SG of the juju VMs in the k8s model</span><br><span class="line"></span><br><span class="line">$ nova list --all |grep amp</span><br><span class="line">| 966f0ec0-b48a-48b9-8078-d7406ee08311 | amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc | 144901cff394489d9095b1361caa6872 | ACTIVE | -          | Running     | lb-mgmt-net=fc00:961f:bb53:993b:f816:3eff:fe0d:6433; private=192.168.21.174 |</span><br><span class="line">$ nova show 966f0ec0-b48a-48b9-8078-d7406ee08311 |grep sec</span><br><span class="line">| security_groups                      | lb-72d96673-8723-4dde-9035-66c3bd095632, lb-mgmt-sec-grp          |</span><br><span class="line">$ openstack security group rule list lb-72d96673-8723-4dde-9035-66c3bd095632</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | Ethertype | IP Range  | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| 1197c266-015b-4967-8680-35f76328fa85 | tcp         | IPv4      | 0.0.0.0/0 | 1025:1025  | None                  |</span><br><span class="line">| 2f715ac6-f7fb-4823-871c-617559cf8d0d | tcp         | IPv4      | 0.0.0.0/0 | 80:80      | None                  |</span><br><span class="line">| dc0d368e-74f6-4cf0-a863-0e56e071ad46 | None        | IPv4      | 0.0.0.0/0 |            | None                  |</span><br><span class="line">| f38b32b6-3472-43bb-89dc-3f0ef221e95b | None        | IPv6      | ::/0      |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">$ openstack security group rule list lb-mgmt-sec-grp</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | Ethertype | IP Range  | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| 4e913725-bc6b-441f-be3e-8ea668d8d2bd | None        | IPv6      | ::/0      |            | None                  |</span><br><span class="line">| 698d9ee1-86d2-407f-8ec8-2f1453ad2427 | tcp         | IPv6      | ::/0      | 22:22      | None                  |</span><br><span class="line">| b7605acb-feb7-4a47-ba48-c6a395fca934 | tcp         | IPv6      | ::/0      | 9443:9443  | None                  |</span><br><span class="line">| c1b5fcc9-16ee-4f7a-9488-c2096b05941e | None        | IPv4      | 0.0.0.0/0 |            | None                  |</span><br><span class="line">| dcbdaaf2-140c-41e6-8f4e-f36624628047 | icmpv6      | IPv6      | ::/0      |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line"></span><br><span class="line">$ openstack server list |grep 114</span><br><span class="line">| 38d8887c-54ae-4b2c-b0c4-7f64542af8f1 | juju-68d107-k8s-7        | ACTIVE | private=192.168.21.114 | bionic | m1.medium |</span><br><span class="line">$ nova show 38d8887c-54ae-4b2c-b0c4-7f64542af8f1 |grep sec</span><br><span class="line">| security_groups                      | default, juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107, juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107-7                                     |</span><br><span class="line">$ openstack security group rule list juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+-------------+--------------------------------------+</span><br><span class="line">| ID                                   | IP Protocol | Ethertype | IP Range  | Port Range  | Remote Security Group                |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+-------------+--------------------------------------+</span><br><span class="line">| 00469e1d-109c-47ea-878a-403cc47f94f2 | tcp         | IPv6      | ::/0      | 1:65535     | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| 2134cf1f-a82d-43e4-a73f-8b1c06c2e400 | icmp        | IPv4      | 0.0.0.0/0 |             | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| 2a5e6886-4657-4227-b9e6-215a121c70c5 | tcp         | IPv6      | ::/0      | 22:22       | None                                 |</span><br><span class="line">| 430c12ff-0a15-4878-90b0-67ff18ef5cb7 | None        | IPv4      | 0.0.0.0/0 |             | None                                 |</span><br><span class="line">| 4a4644ef-6563-492f-8732-749a5b02eb78 | udp         | IPv4      | 0.0.0.0/0 | 1:65535     | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| 8435b75a-f40b-4adb-9eda-1bbef5aecca6 | icmp        | IPv6      | ::/0      |             | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| 9adf865c-04ed-40db-a506-6a9687efb1b0 | None        | IPv6      | ::/0      |             | None                                 |</span><br><span class="line">| a68fac61-ed0c-4027-96ff-e98d182a287d | tcp         | IPv6      | ::/0      | 17070:17070 | None                                 |</span><br><span class="line">| b475b293-b071-4ae9-a3ab-b8a29cbcce33 | tcp         | IPv4      | 0.0.0.0/0 | 17070:17070 | None                                 |</span><br><span class="line">| c5450f4c-7c82-45a2-a676-4fe3ee413ff5 | tcp         | IPv4      | 0.0.0.0/0 | 1:65535     | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| cf8dd9b6-f59f-4d90-9bbf-76eeb1754680 | udp         | IPv6      | ::/0      | 1:65535     | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| f8246bec-4d07-4764-8f37-dd2c204e80e4 | tcp         | IPv4      | 0.0.0.0/0 | 22:22       | None                                 |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+-------------+--------------------------------------+</span><br><span class="line">$ openstack security group rule list juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107-7</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | Ethertype | IP Range  | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| 115688b5-ab4d-4614-afc1-db1458d67ea5 | tcp         | IPv4      | 0.0.0.0/0 | 443:443    | None                  |</span><br><span class="line">| 77bb8ed0-2e7c-4e2f-8320-9acf59b50301 | tcp         | IPv4      | 0.0.0.0/0 | 80:80      | None                  |</span><br><span class="line">| 8c412473-74f0-410f-bd16-7851404743bc | None        | IPv4      | 0.0.0.0/0 |            | None                  |</span><br><span class="line">| ba9a07f9-07d6-4222-ae3c-57255d4a8f83 | None        | IPv6      | ::/0      |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">$ openstack security group list --project $(openstack project list --domain admin_domain |grep admin |awk &apos;&#123;print $2&#125;&apos;) |grep default</span><br><span class="line">| bfc84b34-6f23-4561-87ff-58077f667bea | default                                                                           | Default security group | 0d1886170941437fa46fb34508e67d24 | []   |</span><br><span class="line"> openstack security group rule list bfc84b34-6f23-4561-87ff-58077f667bea</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+--------------------------------------+</span><br><span class="line">| ID                                   | IP Protocol | Ethertype | IP Range  | Port Range | Remote Security Group                |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+--------------------------------------+</span><br><span class="line">| 12a3c6b3-a4c4-470d-a4d2-dcf6cde5b740 | tcp         | IPv4      | 0.0.0.0/0 | 443:443    | None                                 |</span><br><span class="line">| 13068f00-11d4-4cec-b145-a71b68ffc583 | icmp        | IPv4      | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">| 39ab4cb5-4bee-4272-9811-4e405ae568aa | None        | IPv6      | ::/0      |            | None                                 |</span><br><span class="line">| 3d005483-bd84-467b-8cc6-427771e68645 | tcp         | IPv4      | 0.0.0.0/0 | 80:80      | None                                 |</span><br><span class="line">| 436b644b-cf5f-4dfc-a5b0-f86159f8a3fb | None        | IPv4      | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">| 985dc09f-213c-426e-aedf-35b673fd5830 | tcp         | IPv4      | 0.0.0.0/0 | 53:53      | None                                 |</span><br><span class="line">| 9d936527-04c0-490f-9249-27e2f156d452 | None        | IPv6      | ::/0      |            | bfc84b34-6f23-4561-87ff-58077f667bea |</span><br><span class="line">| e7179f46-a322-43fd-aeef-fce38685e749 | tcp         | IPv4      | 0.0.0.0/0 | 22:22      | None                                 |</span><br><span class="line">| f5b12670-7c76-42e7-9cd8-e0fd1ba5eaef | None        | IPv4      | 0.0.0.0/0 |            | bfc84b34-6f23-4561-87ff-58077f667bea |</span><br><span class="line">| f9fdfe84-b239-4adf-96c5-94402debbf1c | None        | IPv6      | ::/0      |            | None                                 |</span><br><span class="line">| fdb8a39b-747b-4b52-96a3-e8cc0110d6b7 | None        | IPv4      | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+--------------------------------------+</span><br></pre></td></tr></table></figure></p>
<h2 id="20190904更新-octavia测试环境搭建全过程"><a href="#20190904更新-octavia测试环境搭建全过程" class="headerlink" title="20190904更新 - octavia测试环境搭建全过程"></a>20190904更新 - octavia测试环境搭建全过程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br></pre></td><td class="code"><pre><span class="line">juju kill-controller zhhuabj -y -t 1s  #or delete vm directly</span><br><span class="line">rm .local/share/juju/controllers.yaml</span><br><span class="line">#modify your ~/juju_config/2.x/bootstrap.sh to add &apos;container-networking-method=&quot;provider&quot;&apos; in model_defaults variable and comment proxy parts</span><br><span class="line">~/juju_config/2.x/gencloud.sh</span><br><span class="line"></span><br><span class="line">./generate-bundle.sh --name octavia --create-model --run --octavia -r stein --dvr-snat --num-compute 2</span><br><span class="line">./bin/add-data-ports.sh</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens7&quot;</span><br><span class="line">#refere here to create certs - https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-octavia.html</span><br><span class="line">juju config octavia \</span><br><span class="line">    lb-mgmt-issuing-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-private-key=&quot;$(base64 controller_ca_key.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-key-passphrase=foobar \</span><br><span class="line">    lb-mgmt-controller-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-controller-cert=&quot;$(base64 controller_cert_bundle.pem)&quot;</span><br><span class="line">juju run-action --wait octavia/0 configure-resources</span><br><span class="line">BARE_METAL=TRUE ./configure</span><br><span class="line">juju run-action octavia-diskimage-retrofit/0 --wait retrofit-image image-id=$(openstack image list |grep bionic |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line"></span><br><span class="line">wget https://people.canonical.com/~zhhuabj/amphora-x64-haproxy.qcow2  #ssh root@&lt;amphora-ip, password:123qwe</span><br><span class="line">#scp -i ~/.ssh/phykey amphora-x64-haproxy.qcow2 zhhuabj@people.canonical.com:/home/zhhuabj/public_html/</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">glance image-create --tag octavia-amphora --disk-format qcow2 --name amphora-haproxy-xenial --file ./amphora-x64-haproxy.qcow2 --visibility public --container-format bare --progress</span><br><span class="line">#注意, 20191206更新</span><br><span class="line"># 镜像应该由octavia-diskimage-retrofit来创建来操作apmphora client与api版本一致, 否则会造成service vm无法work</span><br><span class="line">#https://github.com/openstack-charmers/octavia-diskimage-retrofit</span><br><span class="line">#amphora vms have to be created using the uca that corresponds to the release of openstack deployed</span><br><span class="line">#so that amphora client and api versions match, you can build one with the octavia-diskimage-retrofit charm</span><br><span class="line">sudo snap install --edge --devmode octavia-diskimage-retrofit</span><br><span class="line">sudo -s</span><br><span class="line">wget https://cloud-images.ubuntu.com/minimal/releases/bionic/release/ubuntu-18.04-minimal-cloudimg-amd64.img</span><br><span class="line">- or -</span><br><span class="line">wget https://cloud-images.ubuntu.com/minimal/daily/bionic/current/bionic-minimal-cloudimg-amd64.img</span><br><span class="line">sudo mv ubuntu-18.04-minimal-cloudimg-amd64.img /var/snap/octavia-diskimage-retrofit/common</span><br><span class="line">sudo octavia-diskimage-retrofit /var/snap/octavia-diskimage-retrofit/common/ubuntu-18.04-minimal-cloudimg-amd64.img /var/snap/octavia-diskimage-retrofit/common/ubuntu-amphora-haproxy-amd64.qcow2 -d u stein</span><br><span class="line">openstack image create --disk-format qcow2 --container-format bare --public --tag octavia-amphora --file /var/snap/octavia-diskimage-retrofit/common/ubuntu-amphora-haproxy-amd64.qcow2 amphora-bionic-x64-haproxy</span><br><span class="line"></span><br><span class="line">#create a test backend</span><br><span class="line">./tools/instance_launch.sh 1 xenial</span><br><span class="line">./tools/sec_groups.sh</span><br><span class="line">fix_ip=$(openstack server list |grep &apos;private=&apos; |awk -F &apos;=&apos; &apos;&#123;print $2&#125;&apos; |awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">ext_net=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $ext_net -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address $fix_ip --port $(openstack port list --fixed-ip ip-address=$fix_ip -c id -f value)</span><br><span class="line">ssh -i ~/testkey.priv ubuntu@$fip -- sudo apt install python-minimal -y</span><br><span class="line">ssh -i ~/testkey.priv ubuntu@$fip -- sudo python -m SimpleHTTPServer 80 &amp;</span><br><span class="line">curl $fip</span><br><span class="line"></span><br><span class="line">#backend ip 192.168.21.252 (fip: 10.5.151.97)</span><br><span class="line">#service vm fc00:a895:61e6:b86f:f816:3eff:fef7:26f5/192.168.21.54  (vip: 192.168.21.117, fip: 10.5.151.155)</span><br><span class="line">sudo apt install python-octaviaclient python3-octaviaclient</span><br><span class="line">openstack complete |sudo tee /etc/bash_completion.d/openstack</span><br><span class="line">source &lt;(openstack complete)</span><br><span class="line">#No module named &apos;oslo_log&apos;</span><br><span class="line">openstack loadbalancer create --name lb1 --vip-subnet-id private_subnet</span><br><span class="line">#lb_vip_port_id=$(openstack loadbalancer create -f value -c vip_port_id --name lb1 --vip-subnet-id private_subnet)</span><br><span class="line"># Re-run the following until lb1 shows ACTIVE and ONLINE statuses:</span><br><span class="line">openstack loadbalancer show lb1</span><br><span class="line">nova list --all</span><br><span class="line">openstack loadbalancer listener create --name listener1 --protocol HTTP --protocol-port 80 lb1</span><br><span class="line">openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTP</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address $fix_ip --protocol-port 80 pool1</span><br><span class="line">openstack loadbalancer member list pool1</span><br><span class="line">vip=$(openstack loadbalancer show lb1 -f value -c vip_address)</span><br><span class="line">vip_fip=$(openstack floating ip create $ext_net -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $vip_fip --fixed-ip-address $vip --port $(openstack port list --fixed-ip ip-address=$vip -c id -f value)</span><br><span class="line">curl $vip_fip</span><br><span class="line"></span><br><span class="line">#ssh into service vm</span><br><span class="line">nova list --all</span><br><span class="line">juju ssh nova-compute/1 -- sudo ip netns exec qrouter-73d87977-2eaf-40ba-818d-6a17aecd1d16 ping6 fc00:a895:61e6:b86f:f816:3eff:fef7:26f5</span><br><span class="line">#password: 123qwe</span><br><span class="line">juju ssh nova-compute/1 -- sudo ip netns exec qrouter-73d87977-2eaf-40ba-818d-6a17aecd1d16 ssh -6 root@fc00:a895:61e6:b86f:f816:3eff:fef7:26f5</span><br><span class="line">#need to add icmp firewall rule by hand when using ipv4 address</span><br><span class="line">#juju ssh nova-compute/1 -- sudo ip netns exec qrouter-891c4da6-c03b-4a56-a901-a5efb1dbcd15 ssh root@192.168.21.54</span><br><span class="line">#openstack security group rule create lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2 --protocol icmp --remote-ip 0.0.0.0/0</span><br><span class="line">#openstack security group rule create lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2 --protocol tcp --dst-port 22</span><br><span class="line"></span><br><span class="line"># cat /var/lib/octavia/27057bca-c504-4ca2-9bff-89b342767afd/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer 4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/27057bca-c504-4ca2-9bff-89b342767afd.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">    option splice-request</span><br><span class="line">    option splice-response</span><br><span class="line">    option http-keep-alive</span><br><span class="line">frontend 27057bca-c504-4ca2-9bff-89b342767afd</span><br><span class="line">    option httplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    bind 192.168.21.117:80</span><br><span class="line">    mode http</span><br><span class="line">    default_backend 87d56822-1f5c-4a47-88d6-ddd5d038523d</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend 87d56822-1f5c-4a47-88d6-ddd5d038523d</span><br><span class="line">    mode http</span><br><span class="line">    http-reuse safe</span><br><span class="line">    balance roundrobin</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 4dcd830b-33b2-49e7-b50b-e91b2ce65afb 192.168.21.252:80 weight 1</span><br><span class="line"></span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# cat /etc/netns/amphora-haproxy/network/interfaces.d/eth1.cfg</span><br><span class="line"># Generated by Octavia agent</span><br><span class="line">auto eth1 eth1:0</span><br><span class="line">iface eth1 inet static</span><br><span class="line">address 192.168.21.54</span><br><span class="line">broadcast 192.168.21.255</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 192.168.21.1</span><br><span class="line">mtu 1458</span><br><span class="line">iface eth1:0 inet static</span><br><span class="line">address 192.168.21.117</span><br><span class="line">broadcast 192.168.21.255</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line"># Add a source routing table to allow members to access the VIP</span><br><span class="line">post-up /sbin/ip route add default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">post-down /sbin/ip route del default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">post-up /sbin/ip route add 192.168.21.0/24 dev eth1 src 192.168.21.117 scope link table 1</span><br><span class="line">post-down /sbin/ip route del 192.168.21.0/24 dev eth1 src 192.168.21.117 scope link table 1</span><br><span class="line">post-up /sbin/ip rule add from 192.168.21.117/32 table 1 priority 100</span><br><span class="line">post-down /sbin/ip rule del from 192.168.21.117/32 table 1 priority 100</span><br><span class="line">post-up /sbin/iptables -t nat -A POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line">post-down /sbin/iptables -t nat -D POSTROUTING -p udp -o eth1 -j MASQUERADEroot@amphora-91c5098c-7578-4de7-b38e-d3712711bb15</span><br><span class="line"></span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy ip -4 addr show eth1</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1458 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    inet 192.168.21.54/24 brd 192.168.21.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 192.168.21.117/24 brd 192.168.21.255 scope global secondary eth1:0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy ip route list</span><br><span class="line">default via 192.168.21.1 dev eth1 onlink</span><br><span class="line">192.168.21.0/24 dev eth1 proto kernel scope link src 192.168.21.54</span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy ip route list table 1</span><br><span class="line">default via 192.168.21.1 dev eth1 onlink</span><br><span class="line">192.168.21.0/24 dev eth1 scope link src 192.168.21.117</span><br><span class="line"></span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy ip route show table all</span><br><span class="line">default via 192.168.21.1 dev eth1 table 1 onlink</span><br><span class="line">192.168.21.0/24 dev eth1 table 1 scope link src 192.168.21.117</span><br><span class="line">default via 192.168.21.1 dev eth1 onlink</span><br><span class="line">192.168.21.0/24 dev eth1 proto kernel scope link src 192.168.21.54</span><br><span class="line">broadcast 192.168.21.0 dev eth1 table local proto kernel scope link src 192.168.21.54</span><br><span class="line">local 192.168.21.54 dev eth1 table local proto kernel scope host src 192.168.21.54</span><br><span class="line">local 192.168.21.117 dev eth1 table local proto kernel scope host src 192.168.21.54</span><br><span class="line">broadcast 192.168.21.255 dev eth1 table local proto kernel scope link src 192.168.21.54</span><br><span class="line">ff00::/8 dev eth1 table local metric 256 pref medium</span><br><span class="line"></span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy iptables-save</span><br><span class="line"># Generated by iptables-save v1.6.1 on Wed Sep  4 04:00:59 2019</span><br><span class="line">*nat</span><br><span class="line">:PREROUTING ACCEPT [3:448]</span><br><span class="line">:INPUT ACCEPT [3:448]</span><br><span class="line">:OUTPUT ACCEPT [1:60]</span><br><span class="line">:POSTROUTING ACCEPT [1:60]</span><br><span class="line">-A POSTROUTING -o eth1 -p udp -j MASQUERADE</span><br><span class="line">COMMIT</span><br><span class="line"># Completed on Wed Sep  4 04:00:59 2019</span><br><span class="line"></span><br><span class="line">#backend ip 192.168.21.252 (fip: 10.5.151.97)</span><br><span class="line">#service vm fc00:a895:61e6:b86f:f816:3eff:fef7:26f5/192.168.21.54  (vip: 192.168.21.117, fip: 10.5.151.155)</span><br><span class="line"></span><br><span class="line">#ping backend from service vm</span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy ping 192.168.21.252</span><br><span class="line">PING 192.168.21.252 (192.168.21.252) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.21.252: icmp_seq=1 ttl=64 time=3.45 ms</span><br><span class="line"></span><br><span class="line">#ping service vm vip from backend</span><br><span class="line">ubuntu@xenial-030345:~$ ping -c 1 192.168.21.54</span><br><span class="line">PING 192.168.21.54 (192.168.21.54) 56(84) bytes of data.</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ nova show aa09d2d0-a8fb-4a2f-bc8f-f39c6dff6713 |grep security_groups</span><br><span class="line">| security_groups                      | lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2, lb-mgmt-sec-grp      |</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-mgmt-sec-grp</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| 1bb77bae-6e4c-4982-8c00-8ebfafd896c7 | icmpv6      | None     |            | None                  |</span><br><span class="line">| 407d8dd6-a0c3-406f-b16d-2453ae4ad015 | tcp         | None     | 9443:9443  | None                  |</span><br><span class="line">| 4d927c00-b4aa-4033-ab66-b96fdb2d9722 | None        | None     |            | None                  |</span><br><span class="line">| 771122a1-ad5e-4842-8ba3-dcd0b950d47a | None        | None     |            | None                  |</span><br><span class="line">| 8b91fd37-dddf-4200-8835-261c203696d0 | tcp         | None     | 22:22      | None                  |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| 4eb66163-44dc-44d2-b969-a890d35986a6 | tcp         | None     | 80:80      | None                  |</span><br><span class="line">| 80e0d109-9f97-4559-bc20-de89c001725e | tcp         | None     | 1025:1025  | None                  |</span><br><span class="line">| 92c09499-c9ad-4682-8697-9c17cc33e785 | None        | None     |            | None                  |</span><br><span class="line">| feeb42a2-b49b-4f89-8b3e-5a30cee1e08f | None        | None     |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line"></span><br><span class="line">openstack security group rule create lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2 --protocol icmp --remote-ip 0.0.0.0/0</span><br><span class="line">openstack security group rule create lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2 --protocol tcp --dst-port 22</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range  | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+-----------------------+</span><br><span class="line">| 4eb66163-44dc-44d2-b969-a890d35986a6 | tcp         | None      | 80:80      | None                  |</span><br><span class="line">| 80e0d109-9f97-4559-bc20-de89c001725e | tcp         | None      | 1025:1025  | None                  |</span><br><span class="line">| 92c09499-c9ad-4682-8697-9c17cc33e785 | None        | None      |            | None                  |</span><br><span class="line">| 936b47f0-3897-4abe-89fe-37d7c11862ea | icmp        | 0.0.0.0/0 |            | None                  |</span><br><span class="line">| bd832940-7e80-414d-b43b-51042084b934 | tcp         | 0.0.0.0/0 | 22:22      | None                  |</span><br><span class="line">| feeb42a2-b49b-4f89-8b3e-5a30cee1e08f | None        | None      |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+-----------------------+</span><br><span class="line"></span><br><span class="line">ubuntu@xenial-030345:~$ ping -c 1 10.5.151.155</span><br><span class="line">PING 10.5.151.155 (10.5.151.155) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.5.151.155: icmp_seq=1 ttl=60 time=37.2 ms</span><br><span class="line"></span><br><span class="line">客户遇到的问题:</span><br><span class="line">1, arp issue - https://bugs.launchpad.net/neutron/+bug/1794991/comments/59</span><br><span class="line">2, fip issue - 对于octavia的计算节点使用了没有data-port的neutron-openvswitch charm, dvr-snat会在一堆计算节点中找一个来安装snat-xxx, 这样当恰好找了一个没有data-port的ocatavia计算节点就出问题了 (如使用了https://bugs.launchpad.net/charm-neutron-openvswitch/+bug/1822558中提到的neutron-openvswitch-octavia)</span><br><span class="line">3, https://bugs.launchpad.net/charm-neutron-openvswitch/+bug/1843557</span><br><span class="line">4, 最后建议使用一个existing provider network解决 （一个tenant看不见它的话需要使用rbac设置共享)</span><br></pre></td></tr></table></figure>
<h2 id="20191207更新"><a href="#20191207更新" class="headerlink" title="20191207更新"></a>20191207更新</h2><p>遇到又一例, service vm不work, 创建lb后, service vm是ACTIVE状态其管理网段IP也work, 但LB的状态是PENDING_STATE, 但LB有VIP也可以ssh, 但过一会之后, service vm变成ERROR状态且被删除. 查出来的原因是:<br>During verification of the agent update, It was also found that firewall changes introduced caused DNS to become unreachable for the octavia load balancer instances. These rules have been updated to allow access, which allowed DNS to work inside the amphora VMs, which in turn, in combination with disabling a host, and the update of the agent,returned the load balancers to a working ‘state.”</p>
<h2 id="20200220更新"><a href="#20200220更新" class="headerlink" title="20200220更新"></a>20200220更新</h2><p>用下列方法更新添加nbthread元素之后，LB创建成功后一会儿死掉，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">juju config octavia haproxy-template | base64 -d &gt; /tmp/haproxy-custom.j2</span><br><span class="line">vim /tmp/haproxy-custom.j2 # edit the nbthread option</span><br><span class="line">nbproc 1</span><br><span class="line">nbthread 2</span><br><span class="line">cpu-map auto:1/1-2 0-1</span><br><span class="line">maxconns=64000</span><br><span class="line">juju config octavia haproxy-template=&quot;$(base64 /tmp/haproxy-custom.j2)&quot;</span><br></pre></td></tr></table></figure></p>
<p>这种问题一般能从octavia-worker.log中找到答案：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2020-02-19 04:53:11.465 14180 ERROR octavia.controller.worker.controller_worker jinja2.exceptions.UndefinedError: &apos;dict object&apos; has no attribute &apos;listener&apos;</span><br></pre></td></tr></table></figure></p>
<p>原因是这个patch(<a href="https://review.opendev.org/#/c/673518/)引入了combined_listeners" target="_blank" rel="external">https://review.opendev.org/#/c/673518/)引入了combined_listeners</a>, combined_listeners是为了解决下列问题：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Since 1.8.x version, haproxy consumes at least 160MB at init time using the default configuration provided by octavia. When a LB is updated, haproxy configuration is updated and a signal is sent to haproxy to reload the configuration.</span><br><span class="line">When haproxy reloads its configuration, it creates a new worker, does some allocations (up to 160MB), then destroys the previous worker. So during a short time, memory consumption is increased, and if 2 processes reload a the same time, it may fail with a &quot;Cannot fork&quot; error.</span><br></pre></td></tr></table></figure></p>
<p>所以custom template (<a href="https://paste.ubuntu.com/p/PGvD7fzjd2/" target="_blank" rel="external">https://paste.ubuntu.com/p/PGvD7fzjd2/</a> )中的之前的split_listeners的中loadbalancer.listener.pools应该改成现在combined_listeners中的loadbalancer.listeners.pools</p>
<h2 id="20200427更新"><a href="#20200427更新" class="headerlink" title="20200427更新 -"></a>20200427更新 -</h2><p>另一个问题, 如下, socket.getfqdn在处理/etc/hosts里的fqdn(见: <a href="https://bugs.python.org/issue5004" target="_blank" rel="external">https://bugs.python.org/issue5004</a>), 所以还是要使用socket.getaddrinfo代替socket.getfqdn来处理fqdn (neutron agent现在改成使用fqdn注册), 但观察到socket.getaddrinfo时时而能获取到fqdn时而不能获取, 从而导致octavia里的出现binding error从而导致o-hm0无法获取IP.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@juju-5b1810-octavia-6:~$ python3 -c &apos;import socket; print(socket.getaddrinfo(&quot;juju-5b1810-octavia-6&quot;, None, 0, socket.SOCK_DGRAM, 0,</span><br><span class="line">socket.AI_CANONNAME)[0][3])&apos;</span><br><span class="line">juju-5b1810-octavia-6</span><br><span class="line"></span><br><span class="line">ubuntu@juju-5b1810-octavia-6:~$ python3 -c &apos;import socket; print(socket.getfqdn(&quot;juju-5b1810-octavia-6&quot;))&apos;</span><br><span class="line">juju-5b1810-octavia-6.cloud.sts</span><br><span class="line"></span><br><span class="line">ubuntu@juju-5b1810-octavia-6:~$ python3 -c &apos;import socket; print(socket.getaddrinfo(&quot;juju-5b1810-octavia-6&quot;, None, 0, socket.SOCK_DGRAM, 0,</span><br><span class="line">&gt; socket.AI_CANONNAME))&apos;</span><br><span class="line">[(&lt;AddressFamily.AF_INET: 2&gt;, &lt;SocketKind.SOCK_DGRAM: 2&gt;, 17, &apos;juju-5b1810-octavia-6&apos;, (&apos;10.5.0.14&apos;, 0)), (&lt;AddressFamily.AF_INET: 2&gt;, &lt;SocketKind.SOCK_DGRAM: 2&gt;, 17, &apos;&apos;, (&apos;252.0.14.1&apos;, 0)), (&lt;AddressFamily.AF_INET6: 10&gt;, &lt;SocketKind.SOCK_DGRAM: 2&gt;, 17, &apos;&apos;, (&apos;fe80::f816:3eff:fe8a:6e3&apos;, 0, 0, 0)), (&lt;AddressFamily.AF_INET6: 10&gt;, &lt;SocketKind.SOCK_DGRAM: 2&gt;, 17, &apos;&apos;, (&apos;fe80::34b8:fff:feea:4717&apos;, 0, 0, 0)), (&lt;AddressFamily.AF_INET6: 10&gt;, &lt;SocketKind.SOCK_DGRAM: 2&gt;, 17, &apos;&apos;, (&apos;fe80::34b8:fff:feea:4717&apos;, 0, 0, 0))]</span><br><span class="line"></span><br><span class="line">ubuntu@juju-5b1810-octavia-6:~$ hostname --fqdn</span><br><span class="line">juju-5b1810-octavia-6</span><br><span class="line">ubuntu@juju-5b1810-octavia-6:~$ hostname --all-fqdns</span><br><span class="line">juju-5b1810-octavia-6.cloud.sts juju-5b1810-octavia-6</span><br><span class="line">ubuntu@juju-5b1810-octavia-6:~$ hostname -f</span><br><span class="line">juju-5b1810-octavia-6</span><br></pre></td></tr></table></figure></p>
<p>尤其是vm里的/etc/resovle.conf里用到了如maas dns与neutron ml2-dns等多个search项时, ml2-dns的search项排到第一位时会导致octavia上的l2-agent无法正常处理fqdn从而导致 o-hm0无IP, 见: <a href="https://bugs.launchpad.net/charm-octavia/+bug/1845303/comments/15" target="_blank" rel="external">https://bugs.launchpad.net/charm-octavia/+bug/1845303/comments/15</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">while true; do for X in &#123;0..2&#125;; do juju ssh octavia/$X &quot;cat /etc/resolv.conf | grep -v &quot;^#&quot;; sudo python -c &apos;import socket; name=socket.gethostname(); addrs = socket.getaddrinfo(name, None, 0, socket.SOCK_DGRAM, 0, socket.AI_CANONNAME); print(addrs)&apos;&quot; 2&gt;/dev/null; done; done</span><br></pre></td></tr></table></figure></p>
<p>解决方法是在systemd-network中使用UseDomains=route<br>UseDomains接受布尔参数或特殊值“ route”。设置为true时，将从DHCP服务器(neutron dns)收到的域名用作DNS, 通过该链接搜索域。如果设置为“ route”，则从DHCP接收的域名 , 服务器将仅用于路由DNS查询.</p>
<h2 id="产生密钥"><a href="#产生密钥" class="headerlink" title="产生密钥"></a>产生密钥</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">#https://www.dazhuanlan.com/2019/12/15/5df63aed10999</span><br><span class="line">#generate ca key pairs</span><br><span class="line">mkdir -p ca/&#123;private,certs,newcerts&#125; &amp;&amp; cd ca</span><br><span class="line">openssl genrsa -aes256 -passout pass:password -out private/ca.key.pem 4096</span><br><span class="line">chmod 400 private/ca.key.pem</span><br><span class="line">wget https://jamielinux.com/docs/openssl-certificate-authority/_downloads/root-config.txt -O openssl.cnf</span><br><span class="line">sed -i &quot;s,/root/ca,.,g&quot; openssl.cnf</span><br><span class="line">openssl req -config ./openssl.cnf -key private/ca.key.pem -new -x509 -days 7300 -sha256 -extensions v3_ca -passin pass:password \</span><br><span class="line">     -subj &quot;/C=CN/ST=BJ/O=STS/OU=quqi.com/CN=quqi.com.rootca/emailAddress=quqi@mail.com&quot; -out certs/ca.cert.pem</span><br><span class="line">chmod 444 certs/ca.cert.pem</span><br><span class="line">openssl x509 -noout -text -in certs/ca.cert.pem #verify</span><br><span class="line"></span><br><span class="line">#generate intermediate key pairs</span><br><span class="line">mkdir -p intermediate/&#123;certs,crl,csr,newcerts,private&#125;</span><br><span class="line">chmod 744 intermediate/private</span><br><span class="line">touch index.txt &amp;&amp; echo 1000 &gt; serial &amp;&amp; echo 1000 &gt; crlnumber</span><br><span class="line">openssl genrsa -aes256 -passout pass:password -out intermediate/private/intermediate.key.pem 4096</span><br><span class="line">chmod 400 intermediate/private/intermediate.key.pem</span><br><span class="line">cp ./openssl.cnf ./openssl-im.cnf</span><br><span class="line">#modify the following section of openssl-im.cnf file</span><br><span class="line">[ CA_default ]</span><br><span class="line">dir             = .</span><br><span class="line">private_key     = $dir/private/intermediate.key.pem</span><br><span class="line">certificate     = $dir/certs/intermediate.cert.pem</span><br><span class="line">crl             = $dir/crl/intermediate.crl.pem</span><br><span class="line">policy          = policy_loose</span><br><span class="line">openssl req -config ./openssl-im.cnf -new -sha256 -passin pass:password \</span><br><span class="line">     -subj &quot;/C=CN/ST=BJ/O=STS/OU=quqi.com/CN=quqi.com.imca/emailAddress=quqi@mail.com&quot; \</span><br><span class="line">     -key intermediate/private/intermediate.key.pem -out intermediate/csr/intermediate.csr.pem</span><br><span class="line">openssl ca -config ./openssl.cnf -extensions v3_intermediate_ca -days 3650 -notext -md sha256 -passin pass:password \</span><br><span class="line">     -in intermediate/csr/intermediate.csr.pem -out intermediate/certs/intermediate.cert.pem</span><br><span class="line">chmod 444 intermediate/certs/intermediate.cert.pem</span><br><span class="line">openssl x509 -noout -text -in intermediate/certs/intermediate.cert.pem</span><br><span class="line">openssl verify -CAfile certs/ca.cert.pem intermediate/certs/intermediate.cert.pem</span><br><span class="line"></span><br><span class="line">#generate certificate chain</span><br><span class="line">cat intermediate/certs/intermediate.cert.pem certs/ca.cert.pem &gt; intermediate/certs/ca-chain.cert.pem</span><br><span class="line">chmod 444 intermediate/certs/ca-chain.cert.pem</span><br><span class="line"></span><br><span class="line">#generate clinet.quqi.com key pairs</span><br><span class="line">openssl genrsa -out intermediate/private/client.quqi.com.key.pem 2048</span><br><span class="line">chmod 444 intermediate/private/client.quqi.com.key.pem</span><br><span class="line">openssl req -config ./openssl-im.cnf -key intermediate/private/client.quqi.com.key.pem \</span><br><span class="line">     -subj &quot;/C=CN/ST=BJ/O=STS/OU=quqi.com/CN=client.quqi.com/emailAddress=quqi@mail.com&quot; \</span><br><span class="line">     -new -sha256 -out intermediate/csr/client.quqi.com.csr.pem</span><br><span class="line">openssl ca -config ./openssl.cnf -extensions server_cert -days 3650 -notext -md sha256 -passin pass:password\</span><br><span class="line">     -in intermediate/csr/client.quqi.com.csr.pem -out intermediate/certs/client.quqi.com.cert.pem</span><br><span class="line">chmod 444 intermediate/certs/client.quqi.com.cert.pem</span><br><span class="line">openssl x509 -noout -text -in intermediate/certs/client.quqi.com.cert.pem</span><br><span class="line">openssl verify -CAfile intermediate/certs/ca-chain.cert.pem intermediate/certs/client.quqi.com.cert.pem</span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="http://www.iceyao.com.cn/2017/11/19/Neutron-lbaas%E4%BB%A3%E7%90%86https%E5%AE%9E%E8%B7%B5/" target="_blank" rel="external">http://www.iceyao.com.cn/2017/11/19/Neutron-lbaas%E4%BB%A3%E7%90%86https%E5%AE%9E%E8%B7%B5/</a><br>[2] <a href="https://wiki.openstack.org/wiki/Network/LBaaS/docs/how-to-create-tls-loadbalancer#Update_neutron_config" target="_blank" rel="external">https://wiki.openstack.org/wiki/Network/LBaaS/docs/how-to-create-tls-loadbalancer#Update_neutron_config</a><br>[3] <a href="https://serversforhackers.com/c/using-ssl-certificates-with-haproxy" target="_blank" rel="external">https://serversforhackers.com/c/using-ssl-certificates-with-haproxy</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/29/为租户下的虚机提供IPv6-DNS服务/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/29/为租户下的虚机提供IPv6-DNS服务/" itemprop="url">为租户下的虚机提供IPv6 DNS服务</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-29T17:37:02+08:00">
                2018-10-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>当虚机运行下列代码时，我们需要考虑为tenant下的VM提供DNS服务:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import dns</span><br><span class="line">import dns.resolver</span><br><span class="line">answers = dns.resolver.query(&apos;node1&apos;, &apos;AAAA&apos;)</span><br><span class="line">print answers[0].address</span><br></pre></td></tr></table></figure>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>需要截获neutron port event把IP/MAC拿到写到DNS的record中去。neutron port表的fixed_ips字段（在neutron ipallocations表里）同时记录了VM的IPv4与IPv6(netaddr.IPNetwork(fixed_ip[‘ip_address’]).version == 6)地址 [1]，neutron dns_integration特性可以从这里面将IPv4与IPv6地址都取出来记录到neutron-dhcp-agent下的dnsmasq中从而实现ml2-dns内置DNS服务。</p>
<h2 id="IPv6"><a href="#IPv6" class="headerlink" title="IPv6"></a>IPv6</h2><p>如果只是让OpenStack tenant network支持IPv6的话，很简单，直接用下列命令（下列命令有两个重要属性：<strong>ipv6_address_mode 与 ipv6_ra_mode</strong>）。当然，如果是OpenStack Over Openstack环境的话，可以让底层provider network也支持IPv6。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">neutron subnet-create --ip-version=6 --name=zhhuabj_admin_subnet_v6 --ipv6-address-mode=slaac --ipv6-ra-mode=slaac zhhuabj_admin_net 2001:db8:0:1::/64</span><br><span class="line">neutron router-interface-add zhhuabj_router zhhuabj_admin_subnet_v6</span><br></pre></td></tr></table></figure>
<p>上面命令相当于：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ cat /var/lib/neutron/ra/5c33033b-a4e1-494d-ab20-e0498b423b6c.radvd.conf</span><br><span class="line">interface qr-10bb0b85-53</span><br><span class="line">&#123;</span><br><span class="line">   AdvSendAdvert on;</span><br><span class="line">   MinRtrAdvInterval 30;</span><br><span class="line">   MaxRtrAdvInterval 100;</span><br><span class="line">   AdvLinkMTU 1458;</span><br><span class="line">   prefix 2001:db8:0:1::/64</span><br><span class="line">   &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">   &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">$ sudo ip netns exec qdhcp-be442335-ec55-4df8-b68d-dd03fa6edf00 ps -ef|grep radvd</span><br><span class="line">root     16114     1  0 Nov01 ?        00:00:00 radvd -C /var/lib/neutron/ra/5c33033b-a4e1-494d-ab20-e0498b423b6c.radvd.conf -p /var/lib/neutron/external/pids/5c33033b-a4e1-494d-ab20-e0498b423b6c.pid.radvd -m syslog</span><br><span class="line">root     16115 16114  0 Nov01 ?        00:00:00 radvd -C /var/lib/neutron/ra/5c33033b-a4e1-494d-ab20-e0498b423b6c.radvd.conf -p /var/lib/neutron/external/pids/5c33033b-a4e1-494d-ab20-e0498b423b6c.pid.radvd -m syslog</span><br><span class="line">$ sudo ip netns exec qrouter-5c33033b-a4e1-494d-ab20-e0498b423b6c ip addr show qr-10bb0b85-53 |grep inet6 |grep global</span><br><span class="line">    inet6 2001:db8:0:2::1/64 scope global</span><br><span class="line">$ sudo ip netns exec qdhcp-be442335-ec55-4df8-b68d-dd03fa6edf00 ip addr show ns-af35afad-b2 |grep inet6 |grep global</span><br><span class="line">    inet6 2001:db8:0:2:f816:3eff:feef:5190/64 scope global</span><br></pre></td></tr></table></figure>
<p>如果它不work的话，多半两个原因：<br>1, 底层OpenStack环境 (openstack over openstack)计算节点上的security group应该disable掉, 因为它有类似这种固定的anti-dhcp-spoof for ipv6规则.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-A neutron-openvswi-od7c63bee-9 -p udp -m udp --sport 547 --dport 546 -j DROP                        #Anti-dhcp-spoof for IPv6</span><br></pre></td></tr></table></figure></p>
<p>2, radvd server端, 至少得有下列防火墙规则:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo ip6tables -A INPUT -p icmpv6 -j ACCEPT</span><br><span class="line">sudo ip6tables -A OUTPUT -p icmpv6 -j ACCEPT</span><br><span class="line">sudo ip6tables -A FORWARD -p icmpv6 -j ACCEPT</span><br><span class="line">sudo ip6tables -A INPUT -p udp --dport 546:547 -j ACCEPT</span><br><span class="line">sudo ufw allow proto udp from fe80::/64 to any port 547</span><br></pre></td></tr></table></figure></p>
<p>最好测试时先临时采用:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo ip6tables -F</span><br><span class="line">sudo ufw disable</span><br><span class="line">sudo sysctl -w net.ipv6.conf.all.forwarding=1</span><br></pre></td></tr></table></figure></p>
<p>3, radvd进程是否正常启动</p>
<p>附1： 若是juju搭建的OpenStack环境要enable IPv6支持的话直接在yaml里添加下列内容即可：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">overrides:</span><br><span class="line">  prefer-ipv6: true</span><br></pre></td></tr></table></figure>
<p>附2： 使用OpenStack IPv6环境时，直接设置OS_AUTH_URL环境变量指向keystone的IPv6地址即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export OS_AUTH_URL=$&#123;OS_AUTH_PROTOCOL:-http&#125;://[2001:db8:0:1:f816:3eff:fe3e:5e47]:5000/v2.0</span><br></pre></td></tr></table></figure>
<h2 id="Enable-ML2-DNS"><a href="#Enable-ML2-DNS" class="headerlink" title="Enable ML2-DNS"></a>Enable ML2-DNS</h2><p>该特性有dns_name与dns_domain两个重要的属性，dns_domain可用在network与floatingip中，dns_name可用在port和floatingip中。如创建network时指定dns_name (neutron port-create my-net –dns_name my-port), 这样该dns_name和IP会作为dns record。</p>
<p>检查OpenStack是否支持dns extention API。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">neutron ext-list |grep dns</span><br><span class="line">| dns-integration           | DNS Integration</span><br></pre></td></tr></table></figure>
<p>如果不支持，可以修改下列两个文件去支持，dns_domain相当于dnsmasq给不同组织的IP提供DNS服务时的一个区别标志。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/neutron/neutron.conf</span><br><span class="line">dns_domain = example.org.</span><br><span class="line">vi /etc/neutron/plugins/ml2/ml2_conf.ini</span><br><span class="line">[ml2]</span><br><span class="line">extension_drivers = port_security,dns</span><br></pre></td></tr></table></figure>
<p>如果OpenStack是由juju创建，直接使用下列命令即可enable上述两个配置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">juju config neutron-api enable-ml2-dns</span><br><span class="line">juju config neutron-api enable-ml2-dns=True</span><br></pre></td></tr></table></figure>
<h2 id="Test-ML2-DNS"><a href="#Test-ML2-DNS" class="headerlink" title="Test ML2-DNS"></a>Test ML2-DNS</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#sudo ip addr del 2001:db8:0:122::1/64 dev ens3</span><br><span class="line">dig google.com @&lt;DNS-SERVER&gt; -p 53 AAAA</span><br><span class="line">sudo tcpdump -ni ens3 ip6 host fe80::f816:3eff:feb4:8d1f</span><br><span class="line">#  tcpdump -n -i ens3 icmp6 and ip6[40] == 134</span><br><span class="line">sudo dhclient -6 -d ens3</span><br><span class="line"></span><br><span class="line">ubuntu@bionic:~$ sudo tcpdump -ni ens3 ip6 host fe80::f816:3eff:feb4:8d1f</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on ens3, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">13:35:28.263222 IP6 fe80::f816:3eff:feb4:8d1f.546 &gt; ff02::1:2.547: dhcp6 solicit</span><br></pre></td></tr></table></figure>
<h2 id="designate架构"><a href="#designate架构" class="headerlink" title="designate架构"></a>designate架构</h2><p><img src="https://img-blog.csdnimg.cn/20181029172830827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_27,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>designate的架构如上图:</p>
<ul>
<li>designate-api, 接收来自远端用户的HTTP/HTTPS请求，通过Keystone验证远端用户的合法性，将HTTP/HTTPS请求传递给Central模块。</li>
<li>designate-sink, 监听来自Nova和Neutron的某些事件，用于自动生成域名资源记录，比如当监听到Nova的compute.instance.create.end事件通知后，自动创建一条对应于刚创建的实例的A记录；当监听到Nuetron的floatingip.update.end事件通知后，自动更新一条相应的A记录。</li>
<li>designate-central, 业务逻辑处理核心。响应API请求以及处理Sink所监听到的来自Nova和Neutron的特定通知事件。同时会存取数据库，对业务逻辑处理所产生的数据进行持久化存储。</li>
<li>designate-mdns, 实现了标准的DNS Notify和Zone Transfer的处理. designate-mdns is the service that sends DNS NOTIFY and answers zone transfer (AXFR) requests. This allows Designate to integrate with any DNS server that supports these very standard methods of communicating. designate-mdns also encapsulates all other forms of DNS protocol that Designate performs. For example, sending SOA queries to check that a change is live.</li>
<li>designate-pool-manager, 连接后端驱动，管理DNS服务器池，与MiniDNS(即designate-mdns)配合同步DNS服务器的域名以及资源记录等数据。</li>
</ul>
<p>MiniDNS(designate-mdns)：Hidden Master设计<br><a href="https://blog.csdn.net/andyron/article/details/46053241" target="_blank" rel="external">https://blog.csdn.net/andyron/article/details/46053241</a><br>Hidden Master是DNS网络安全管理系统设计中所推荐的一种最佳实践。主DNS服务器“隐藏”在内网防火墙背后，负责DNS域名资源的管理并同步变更到从DNS服务器；从DNS服务器部署在DMZ区域，对外提供DNS查询服务。由于主DNS服务器不接受DNS查询，增强了安全性。Designate MiniDNS功能模块就采用了Hidden Master的设计思想。所有托管到Designate中的DNS域都将MiniDNS视为主DNS服务器，而其被委托的DNS服务器都作为从DNS服务器。MiniDNS实现了标准的DNS Notify和Zone Transfer协议，负责同步DNS域名资源记录到从DNS服务器上。<br>其工作流程如下图:<br><img src="https://img-blog.csdnimg.cn/20181029173149275.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li>首先，用户通过Desingate API创建一个example.com的DNS域；</li>
<li>Designate API将请求传递给Central，Central先将example.com域保存到数据库，接着发送RPC请求给Pool Manager；</li>
<li>Pool Manager收到来自Central的创建域名的请求之后，调用DNS后端驱动，在该域名被委托的服务器池中的所有服务器中创建example.com域。同时在这些服务器中，指定example.com的master服务器是MiniDNS；</li>
<li>Pool Manager完成所有从服务器上example.com域的创建之后，发送RPC请求给MiniDNS。</li>
<li>MiniDNS收到Pool Manager的RPC请求之后，向从服务器发送DNS Notify消息，告诉从服务器example.com有资源更新。</li>
<li>从服务器收到DNS Notify消息后，要求主从数据库启动Zone Transfer，域迁移的方式可以是AXFR，也可以是IXFR。</li>
<li>主服务器从数据库中读取为example.com域自动创建的SOA和NS记录，并将SOA和NS记录传送到从服务器。<br>后续任何对example.com域的变更操作都会遵循上述过程，由MiniDNS将变更同步到Designate所委派管理example.com域的DNS服务器上。</li>
</ul>
<p>看一下代码结构, designate支持很多backend(eg: bind), 安装bind服务的机器上可使用rndc命令行工具create/delete zone remotely. The traffic between rndc and bind/named(953/tcp) is authenticated with a key. designate将为每个pool生成下列配置, 这样就可以远程运行rndc命令了(rndc -s 10.5.0.29 -p 953 -k /etc/designate/rndc.key status), 其中5353是designate-mdns监听的端口:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/designate/pools.yaml</span><br><span class="line">- id: 794ccc2c-d751-44fe-b57f-8894c9f5c842</span><br><span class="line">  name: default</span><br><span class="line">  description: Pool genergated by Juju</span><br><span class="line">  ns_records:</span><br><span class="line">    - hostname: openstack-au-east-2.oc.xxx.com.</span><br><span class="line">      priority: 10</span><br><span class="line">  nameservers:</span><br><span class="line">    - host: 10.5.0.29</span><br><span class="line">      port: 53</span><br><span class="line">  targets:</span><br><span class="line">    - type: bind9</span><br><span class="line">      masters:</span><br><span class="line">        - host: 10.5.0.23</span><br><span class="line">          port: 5354</span><br><span class="line">      options:</span><br><span class="line">        host: 10.5.0.29</span><br><span class="line">        rndc_host: 10.5.0.29</span><br><span class="line">        rndc_key_file: /etc/designate/rndc.key</span><br><span class="line">  also_notifies: []</span><br></pre></td></tr></table></figure></p>
<p>在designate-bind节点上装有bind服务(运行在953端口, /usr/sbin/named -f -u bind), 需要确保bind能够访问/etc/bind/named.conf和/etc/bind/rndc.key, 并且能够接受从Pool Manager过来的rndc流量:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/bind/named.conf</span><br><span class="line">include &quot;/etc/bind/named.conf.options&quot;;</span><br><span class="line">include &quot;/etc/bind/named.conf.local&quot;;</span><br><span class="line">include &quot;/etc/bind/named.conf.default-zones&quot;;</span><br><span class="line">controls &#123;</span><br><span class="line">  inet 127.0.0.1 allow &#123;localhost;&#125;;</span><br><span class="line">  inet 10.5.0.29 allow &#123; 10.5.0.23; &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"># cat /etc/bind/named.conf.options</span><br><span class="line">options &#123;</span><br><span class="line">        directory &quot;/var/cache/bind&quot;;</span><br><span class="line">        dnssec-validation auto;</span><br><span class="line">        auth-nxdomain no;    # conform to RFC1035</span><br><span class="line">        listen-on-v6 &#123; any; &#125;;</span><br><span class="line">        allow-new-zones yes;</span><br><span class="line">        request-ixfr no;</span><br><span class="line">        recursion no;</span><br><span class="line">        statistics-file &quot;/var/cache/bind/named.stats&quot;;</span><br><span class="line">        zone-statistics yes;</span><br><span class="line">        allow-notify &#123; 10.5.0.23; &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>rndc命令:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rndc querylog</span><br><span class="line">rndc status</span><br><span class="line">dig -t A openstack-au-east-2.oc.xxx.com@10.5.0.23</span><br><span class="line">dig -t MX openstack-au-east-2.oc.xxx.com@10.5.0.23</span><br></pre></td></tr></table></figure></p>
<p>bind DNS服务器可作为缓存服务器, 主DNS服务器和辅助DNS服务器, 配置分配如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 缓存服务器, 不负责解析，仅为加速，不需要注册</span><br><span class="line">options &#123;</span><br><span class="line">       forward only;</span><br><span class="line">       forwarders &#123;</span><br><span class="line">               168.95.1.1;</span><br><span class="line">               139.175.10.20;</span><br><span class="line">       &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"># 主DNS服务器, 负责解析本地客户端请求</span><br><span class="line">zone &quot;test.com&quot; IN &#123;</span><br><span class="line">       type master;</span><br><span class="line">       file &quot;test.com.zone&quot;;</span><br><span class="line">&#125;;</span><br><span class="line"># 辅助DNS服务器, 辅助服务器的区域数据都是从主服务器复制而来，其数据都是只读的. 根据序列号大小决定是否复制</span><br><span class="line">zone &quot;test.com&quot; IN &#123;</span><br><span class="line">       type slave;</span><br><span class="line">       masters &#123;ip;&#125;;</span><br><span class="line">       file &quot;slaves/test.com.zone&quot;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>区域传送, 解析库文件同步的过程，即辅助DNS服务器从主DNS服务器或其他的辅助DNS服务器请求数据传输过程 。</p>
<ul>
<li>完全区域传送：传送区域的所有数据，简称AXFR</li>
<li>增量区域传送：传送区域中改变的数据部分，简称IXFR<br>bind配置中之DNS主从同步，区域安全传送<br><a href="http://www.it165.net/admin/html/201403/2548.html" target="_blank" rel="external">http://www.it165.net/admin/html/201403/2548.html</a><h2 id="附件-一个designate问题"><a href="#附件-一个designate问题" class="headerlink" title="附件 - 一个designate问题"></a>附件 - 一个designate问题</h2>可能因为designate不断地升级, 而且是多网卡, 这样导致每个designate-bind unit所指定的master ip (designate unit)不是同一子网. 这样会导致create zone的时候有时候会发两次rndc addzone命令.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- designate/7 only programs designate-bind/3 [172.18.248.94] (it does not know about designate-bind/2). It also uses the .247 subnet for the Master IPs instead of the correct 248 subnet.</span><br><span class="line">- designate/8 programs both bind9 servers [172.18.248.94, 172.18.248.99] and uses the correct .248 subnet</span><br><span class="line">- designate/9 only programs designate-bind/3 and also uses the wrong master IPs.</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>并且因为之前的DB问题, 导致bind cache里有很多stale zone, 这样当create zone的时候, 会说zone已存在.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">How to remove stale zones from bind9 dynamic zone configuration</span><br><span class="line"></span><br><span class="line">1,check the list of zones in bind9 like so:</span><br><span class="line">cat /var/cache/bind/*.nzf|grep ^zone|awk &apos;&#123;print $2&#125;&apos;|sed &apos;s/&quot;$/.&quot;,/g&apos; #the sed here adds a trailing dot so we can query the database for the same name</span><br><span class="line">2, check if this zone is currently active by querying the database:</span><br><span class="line">mysql -u root -p designate</span><br><span class="line">select * from zones where name=&quot;xxx.openstack-au-east-2.oc.xxx.com.&quot; WHERE deleted_at IS NOT NULL;</span><br><span class="line">3, rndc delzone xxx.openstack-au-east-2.oc.xx.com</span><br></pre></td></tr></table></figure></p>
<p>designate recovery service检测到一个zone长期为pending状态时, 再会继续create zone. 这样在日志中会看到一个zone被反复多次create</p>
<h2 id="附件-Designate环境搭建及测试"><a href="#附件-Designate环境搭建及测试" class="headerlink" title="附件 - Designate环境搭建及测试"></a>附件 - Designate环境搭建及测试</h2><p>ml2dns只能使用neutron.conf配置文件里的域名(如:ml2dns.example.),  network里可以配置外部多个顶级不固定的域名(如:neutron net-update private –dns_domain extdns.example.).<br>ml2dns只为internal fixed ip在dnsmasq里配置域名, designate只为external fip配置域名, dnsmasq里需要配置forwarder到designate-bind中去.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">juju add-model xenial-queens-designate</span><br><span class="line"># https://paste.ubuntu.com/p/y5NQwXB95R/</span><br><span class="line">juju deploy ./b/openstack.yaml --overlay ./b/o/memcached.yaml --overlay ./b/o/designate.yaml</span><br><span class="line">juju config neutron-api dns-domain=ml2dns.example.</span><br><span class="line">juju config neutron-api reverse-dns-lookup=True</span><br><span class="line">juju config neutron-api enable-ml2-dns=True</span><br><span class="line">juju config designate nameservers=ns1.extdns.example.</span><br><span class="line">./configure</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">./tools/sec_groups.sh</span><br><span class="line"></span><br><span class="line">  applications:</span><br><span class="line">    neutron-api:</span><br><span class="line">      charm: cs:~openstack-charmers-next/neutron-api</span><br><span class="line">      options:</span><br><span class="line">        enable-ml2-dns: True</span><br><span class="line">        dns-domain: ml2dns.example.</span><br><span class="line">        reverse-dns-lookup: True</span><br><span class="line">        ipv4-ptr-zone-prefix-size: 24</span><br><span class="line">    designate:</span><br><span class="line">      charm: cs:~openstack-charmers-next/designate</span><br><span class="line">      options:</span><br><span class="line">        nameservers: ns1.extdns.example.</span><br><span class="line">    designate-bind:</span><br><span class="line">      charm: cs:~openstack-charmers-next/designate-bind</span><br><span class="line">  relations:</span><br><span class="line">    - [ designate, designate-bind ]</span><br><span class="line">    - [ designate, neutron-api ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># https://docs.openstack.org/python-designateclient/latest/user/shell-v2.html</span><br><span class="line">sudo apt install -y python-openstackclient python-designateclient</span><br><span class="line"></span><br><span class="line"># create the zone for your external dns, the zone name must end in a &apos;.&apos;</span><br><span class="line">DOMAIN_NAME=extdns.example.</span><br><span class="line">openstack zone create --email extdns@example $DOMAIN_NAME</span><br><span class="line"></span><br><span class="line"># create an &apos;A&apos; record for the automaticall created NS record that points to one or more of the designate-bind units</span><br><span class="line">DESIGNATE_BIND_IP=$(juju status designate-bind --format short | awk &apos;/designate-bind/ &#123;print $3&#125;&apos;)</span><br><span class="line">openstack recordset create --record $DESIGNATE_BIND_IP --type A $DOMAIN_NAME ns1</span><br><span class="line">dig @$DESIGNATE_BIND_IP -type NS</span><br><span class="line"></span><br><span class="line"># tell neutron that for any floating IPs for our tenant network create the the hostname in a given DNS domain</span><br><span class="line">neutron net-update private --dns_domain $DOMAIN_NAME</span><br><span class="line"></span><br><span class="line"># tell neutron to use designate bind as it&apos;s forwarder by dnsmasq&apos;s configuration &apos;--server=10.5.0.16 --domain=ml2dns.example.&apos;</span><br><span class="line"># query path: Project instance -&gt; Neutron dnsmasq -&gt; Designate Bind -&gt; External DNS</span><br><span class="line"># NOTE: must DO NOT SET –dns-nameserver on the tenent subnet</span><br><span class="line">juju config neutron-gateway dns-servers=$DESIGNATE_BIND_IP</span><br><span class="line"></span><br><span class="line"># create a VM for integration test</span><br><span class="line">nova keypair-add --pub-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">openstack port create --network $(neutron net-show private -f value -c id) --dns-name i1 port_i1</span><br><span class="line">$ openstack port show port_i1 -f value -c dns_assignment</span><br><span class="line">fqdn=&apos;i1.ml2dns.example.&apos;, hostname=&apos;i1&apos;, ip_address=&apos;192.168.21.18&apos;</span><br><span class="line"></span><br><span class="line">openstack server create --wait --image cirros2 --flavor m1.tiny --key-name mykey --port $(openstack port show port_i1 -f value -c id) i1</span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address 192.168.21.18 --port $(openstack port list --fixed-ip ip-address=192.168.21.18 -c id -f value)</span><br><span class="line"></span><br><span class="line"># Neutron will create forward and reverse records in dnsmasq for the internal DNS.</span><br><span class="line"># NOTE: must DO NOT SET –dns-nameserver on the tenent subnet, By not setting the dns server</span><br><span class="line">#       the project network will default to using the dnsmasq service associated with the network.</span><br><span class="line">#       This is Neutron handling our project internal DNS records automatically.</span><br><span class="line">openstack subnet unset --dns-nameserver 10.230.64.2 private_subnet</span><br><span class="line">nova boot --hard i1</span><br><span class="line"></span><br><span class="line"># test dns inside VM, 192.168.21.2 is the IP inside qdhcp-xxx namespace</span><br><span class="line">$ ssh cirros@10.5.150.2 -- cat /etc/resolv.conf</span><br><span class="line">search ml2dns.example</span><br><span class="line">nameserver 192.168.21.2</span><br><span class="line"></span><br><span class="line">$ ssh cirros@10.5.150.2 -- nslookup i1.ml2dns.example 192.168.21.2</span><br><span class="line">Server:    192.168.21.2</span><br><span class="line">Address 1: 192.168.21.2 host-192-168-21-2.ml2dns.example</span><br><span class="line">Name:      i1.ml2dns.example</span><br><span class="line">Address 1: 192.168.21.18 i1.ml2dns.example</span><br><span class="line"></span><br><span class="line">$ juju ssh neutron-gateway/0 -- cat /var/lib/neutron/dhcp/bc66c327-265b-4491-95ab-2d2e14d801d2/host |grep i1</span><br><span class="line">fa:16:3e:09:b7:37,i1.ml2dns.example.,192.168.21.18</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Neutron will inform Designate to create the forward and reverse records for the floating IP in the external DNS</span><br><span class="line">dig @$DESIGNATE_BIND_IP i1.extdns.example</span><br><span class="line">dig @$DESIGNATE_BIND_IP -x $fip</span><br><span class="line"></span><br><span class="line">$ dig @$DESIGNATE_BIND_IP i1.extdns.example</span><br><span class="line">...</span><br><span class="line">i1.extdns.example.	3600	IN	A	10.5.150.2</span><br><span class="line">extdns.example.		3600	IN	NS	ns1.extdns.example.</span><br><span class="line">ns1.extdns.example.	3600	IN	A	10.5.0.16</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"># We can also see the external DNS record sets in Designate</span><br><span class="line">openstack recordset list extdns.example.</span><br><span class="line"></span><br><span class="line">$ openstack recordset list extdns.example.</span><br><span class="line">+--------------------------------------+---------------------+------+--------------------------------------------------------------------+--------+--------+</span><br><span class="line">| id                                   | name                | type | records                                                            | status | action |</span><br><span class="line">+--------------------------------------+---------------------+------+--------------------------------------------------------------------+--------+--------+</span><br><span class="line">| 92c8f5d6-eeca-4b0d-968b-deed4697b787 | extdns.example.     | NS   | ns1.extdns.example.                                                | ACTIVE | NONE   |</span><br><span class="line">| a0167123-714d-4c34-8542-ad8b5019c318 | extdns.example.     | SOA  | ns1.extdns.example. extdns.example. 1548816241 3505 600 86400 3600 | ACTIVE | NONE   |</span><br><span class="line">| 99f97832-edea-4727-be68-73536d9145d3 | ns1.extdns.example. | A    | 10.5.0.16                                                          | ACTIVE | NONE   |</span><br><span class="line">| 728808e5-e6dd-4b9d-b7fa-ad260a855ac4 | i1.extdns.example.  | A    | 10.5.150.2                                                         | ACTIVE | NONE   |</span><br><span class="line">+--------------------------------------+---------------------+------+--------------------------------------------------------------------+--------+--------+</span><br></pre></td></tr></table></figure></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://github.com/openstack/neutron/blob/stable/pike/neutron/plugins/ml2/extensions/dns_integration.py#L285" target="_blank" rel="external">https://github.com/openstack/neutron/blob/stable/pike/neutron/plugins/ml2/extensions/dns_integration.py#L285</a><br>[2] <a href="https://docs.openstack.org/mitaka/networking-guide/config-dns-int.html" target="_blank" rel="external">https://docs.openstack.org/mitaka/networking-guide/config-dns-int.html</a><br>[3] <a href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/8/html-single/dns-as-a-service_guide/index" target="_blank" rel="external">https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/8/html-single/dns-as-a-service_guide/index</a><br>[4] <a href="https://openstackdevops.wordpress.com/2018/01/27/designate-and-neutron-dns-integration/" target="_blank" rel="external">https://openstackdevops.wordpress.com/2018/01/27/designate-and-neutron-dns-integration/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/09/Win-10-UEFI-Ubuntu-18-04-UEFI-双系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/09/Win-10-UEFI-Ubuntu-18-04-UEFI-双系统/" itemprop="url">Win 10 UEFI + Ubuntu 18.04 UEFI 双系统</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-09T01:28:15+08:00">
                2018-09-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本人昨天买了一块SSD, 结果后来发现原来这块SSD存在硬件质量问题, 造成了软件上的种种诡异问题, 如U盘时而识别时而不识别, 如触摸屏左键时而抽风, 如ghost安装win10时几乎到100%的进度时忽然来一个无响应, 重启系统后出现了”To interrupt normal start up, press the blue ThinkVantage button.”, 此时键盘无反应, 既进不了系统, 也进不了BIOS. 拨CMOS电源也无效. 最后发现是这块SSD有质量问题. 估计是SSD有控制器主要是软件吧, 控制器软件有bug导致运行ghost这种软件时也能导致硬件挂住.<br>也正是因为这个问题吧, 七搞八搞, 一不小心在重试的过程中将之前的一块linux分区误删了, 于是之前打算的迁移双系统的想法泡汤(当然, 那些通过分区助手或者ghost来迁移分区的网上文章照着做没一个是成功的).<br>这样, 有机会事隔多年再一次重装双系统的机会, 但是发现世道变了, 之前百试不爽的方法现在行不通了. 后经查证, 主要原因是ubuntu 18.04开始默认采用UEFI, 而win10默认仍然是MBR. 这样会导致一系列的问题, 如报错: grub-efi-amd64-signed failed to install 18.04, 统一采用UEFI安装.</p>
<h2 id="BIOS设置"><a href="#BIOS设置" class="headerlink" title="BIOS设置"></a>BIOS设置</h2><p>在BIOS中将Boot Mode设置为UEFI Only, 如果有Secure Boot选项还要disable它(不做这一步可能会造成按F12键之后无法找到U盘)<br>注: 改成UEFI only之后, 运行双系统, 四系统都没问题, 但后来进不了U盘的livecd, 报: couldn’t get UEFI db list, 所以只得改回Both, 但UEFI优先.</p>
<h2 id="安装win10"><a href="#安装win10" class="headerlink" title="安装win10"></a>安装win10</h2><ul>
<li>下载大白菜UEFI专版 - <a href="http://www.bigbaicai.com/download.html?down2" target="_blank" rel="external">http://www.bigbaicai.com/download.html?down2</a></li>
<li>下载win10 ghost - axel -n 10 <a href="http://xz.win10cjb.com/18.5/win10_64/DEEP_Win10x64_201805.rar" target="_blank" rel="external">http://xz.win10cjb.com/18.5/win10_64/DEEP_Win10x64_201805.rar</a></li>
<li>制作大白菜启动U盘, 如果界面上有UEFI字眼就点上(不记得了, 有就点上), 还要注意一点, 记得点里面的格式转换, 将FAT32格式(HDD-FAT32)转换成NTFS(HDD-NTFS)转换, 否则HDD-FAT32格式不能拷贝大于4G的ghost文件哦,</li>
<li>按F12选U盘启动进入大白菜后, 用DiskGenius工具重新分区, 必须将BIOS+MBR格式转UEFI+GPT格式. 分区表格式为GUID而不是MBR, window上管EFI分区叫ESP/MSR分区</li>
<li><p>注意, 不要修改推荐的卷标, 这个卷就是指向的ESP/MSR分区.</p>
<h2 id="安装win10后"><a href="#安装win10后" class="headerlink" title="安装win10后"></a>安装win10后</h2><p>安装win10后需要将禁用掉快速启动, 否则会造成按F12无法选择U盘启动. 菜单路径为: “设置 -&gt; 系统 -&gt; 电源与睡眠 -&gt; 其他电源设置 -&gt; 选择电源按钮的功能 -&gt; 更改当前不可用的设置 -&gt; 启动快速启动”</p>
<h2 id="安装ubuntu-18-04"><a href="#安装ubuntu-18-04" class="headerlink" title="安装ubuntu 18.04"></a>安装ubuntu 18.04</h2><p>像安装win10一样, 一样要注意重要一点, 需创建大概300M左右的UEF分区, 另外, 还可以创建一个根分区和一个备份文件用的bak分区.<br>注意, windows非常霸道, 它是总修改bios里的启动顺序, 将它的”Windows boot Manager”放在”ubuntu grub”的前面, 可以在bios里锁定启动顺序</p>
<h2 id="安装win7"><a href="#安装win7" class="headerlink" title="安装win7"></a>安装win7</h2><p>win7若没有sata的驱动, 所以得先改回IDE, 装完win7之后再改回AHCI, 否则也容易挂在启动界面不动了.<br>注: 我未遇到以上问题, 可能因为我装的win7并不是原版的, 已经带了sata驱动</p>
<h2 id="加装SSD"><a href="#加装SSD" class="headerlink" title="加装SSD"></a>加装SSD</h2><p>如果加装了SSD之后呢? 那得注意:</p>
</li>
<li><p>装win10时同样需要进大白菜或老毛桃后用DiskGenius在SSD上划分ESP/MSR分区</p>
</li>
<li>装ubuntu时, 分区处也要创建EFI分区, 同时grub设置安装在SSD上, 相当于: grub-install /dev/sdX.</li>
<li>bios里选择哪块硬盘启动. 其实在SSD上安装grub后, 这个grub会连HDD上原先的win10与ubuntu一起放在启动列表里. 注意, windows非常霸道, 它是总修改bios里的启动顺序, 将它的”Windows boot Manager”放在”ubuntu grub”的前面, 可以在bios里锁定启动顺序</li>
<li><p>有时候需要对ssd优化, 例如不要将swap分区放在ssd以延长寿命, 如更改i/o调度策略为noop, 如使用bcache</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>装完之后进入win10发现thinkpad小红点左键失灵, 再切换进ubuntu发现小红点左键正常(实际上, 5次大概有一次有问题, 只是登录界面左键与右键似乎混乱了, 登录之后就正常了. 再换PE进系统发现小红点左键依然有问题. 所以基本断定和硬件没有关系, 应该是win10上的小红点驱动有问题.<br>但搜索了很多帖子, 没一个能解决问题的, 联想的小红点win10驱动做得太烂了. 所以决定回到win7, 回到win7之后该问题解决. 另外, PE回到win7的过程中不会伤害之前SSD上安装的ubuntu系统, 也不会伤害原HDD里的双系统.</p>
<h2 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h2><p>现在在笔记本x220t上装了win10, 也装了ubuntu 18.04, 但是如何将工作机t440p的根分区迁移到x220t的根分区呢? 因为我们已经在x220t上安装了ubuntu 18.04, 这样省去了采用命令划分EFI分区, 以及最后填充EFI分区的步骤. 现在将精力集中在如何快速迁移根分区上.</p>
</li>
<li><p>目的机x220t因为有写操作, 故要以livecd启动, 启动ssh server, 并将根分区加载到/mnt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo -i</span><br><span class="line">apt install openssh-server</span><br><span class="line">passwd</span><br><span class="line">echo &apos;PermitRootLogin yes&apos; &gt;&gt; /etc/ssh/sshd_config</span><br><span class="line">service ssh restart</span><br><span class="line">fdisk -l</span><br><span class="line">mount /dev/sdb8 /mnt</span><br></pre></td></tr></table></figure>
</li>
<li><p>源机t440p最好也以livecd启动, 注意: 例如源机上有一个软链指向了/bak分区, 但因为此时没有挂载/bak分区, 所以在rsync命令迁移时会报错退出. 人工删除该软链重新运行即可.  且需要注意 rsync命令中的/mnt/后应该有/, 否则会将mnt目录迁移到根分区的mnt目录下.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo -i</span><br><span class="line">fdisk -l</span><br><span class="line">mount /dev/sda9 /mnt</span><br><span class="line"></span><br><span class="line"># rsync will now copy all files, directories, permissions and owners over to the destination machine.</span><br><span class="line"># It also skips all files and directories that are not on the root filesystem, like /dev/, /sys/, /proc/.</span><br><span class="line"># If there are filesystems that are mounted separately on the source machine and your want those copied too, use rsync again on those mountpoints too.</span><br><span class="line">rsync -xavP --numeric-ids --exclude=&apos;tmp&apos; /mnt root@192.168.99.128:/</span><br><span class="line">#rsync -xavP --numeric-ids --exclude=&apos;tmp&apos; --exclude=&apos;/nas&apos; /mnt/ root@192.168.99.128:/mnt/</span><br></pre></td></tr></table></figure>
</li>
<li><p>更新grub, 此时会报”canot find EFI directory”, 这样会导致这时生成grub时无法找到原HDD中的双系统, 不要紧, 只要找到目前SSD中的双系统即可. 呆会下一步再运行一下grub命令即可解决</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/sdb8 /mnts</span><br><span class="line">for d in dev sys proc; do mount --bind /$d /mnt/$d; done</span><br><span class="line">chroot /mnt/ grub-install /dev/sdb   # canot find EFI directory</span><br><span class="line">chroot /mnt/ update-grub</span><br></pre></td></tr></table></figure>
</li>
<li><p>修复fstab, 之前运行上述迁移命令前忘了备份x220t上的fstab系统, 导致它被覆盖, OK, 我们修复它.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">blkid</span><br><span class="line">e2label /dev/sdb8 &quot;ROOT_SSD&quot;</span><br><span class="line">tee &quot;/mnt/etc/fstab&quot; &lt;&lt;EOF</span><br><span class="line">#UUID can be found via blkid command</span><br><span class="line">#LABEL=boot /boot ext2 sync 0 2</span><br><span class="line">#UUID=735b3be3-779c-4d21-a944-b033225f3ab4 none   swap    sw      0       0</span><br><span class="line">#LABEL=SWAP none swap sw 0 0</span><br><span class="line">UUID=9401-D2EA /boot/efi vfat defaults 0 2</span><br><span class="line">LABEL=ROOT_SSD / ext4 errors=remount-ro 0 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
<li><p>这时重启系统, 就可以以grub选择启动SSD上的双系统了, 如果还想把HDD的原有的双系统也加到grub的话, 那进ubuntu系统后再执行一次update-grub命令即可.</p>
</li>
<li>这种迁移方式效果非常好, 各种工作软件不需要再重装了. 呵呵<h2 id="调整分区"><a href="#调整分区" class="headerlink" title="调整分区"></a>调整分区</h2>一个分区不够用时, 可以使用gpartd合并相邻的空闲分区.注意一点, 要合并的分区必须是umount状态时才能合并.<h2 id="SSD优化"><a href="#SSD优化" class="headerlink" title="SSD优化"></a>SSD优化</h2></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"># disable scanning for btrfs filesystems when boot</span><br><span class="line">sudo apt-get purge btrfs-tools</span><br><span class="line">sudo update-initramfs -ukall</span><br><span class="line"></span><br><span class="line"># enable TRIM feature by adding discard option</span><br><span class="line"># what&apos;s TRIM - https://blog.csdn.net/quqi99/article/details/50963308</span><br><span class="line"># the option noatime is used to disable access time for a file</span><br><span class="line">sudo hdparm -I /dev/sdb |grep TRIM</span><br><span class="line">vi /etc/fstab</span><br><span class="line">LABEL=ROOT_SSD /               ext4    noatime,discard,errors=remount-ro 0       1</span><br><span class="line">sudo mount -o remount /dev/sdb8</span><br><span class="line">sudo mount |grep sdb8 |grep discard</span><br><span class="line"></span><br><span class="line"># Try not to use swap space unless it&apos;s running out of memory.</span><br><span class="line">echo 1 &gt; /proc/sys/vm/swappiness</span><br><span class="line"></span><br><span class="line"># avoid visiting ssd by using ramdisk for /tmp instead of tmpfs</span><br><span class="line">vim /etc/fstab</span><br><span class="line">tmpfs /tmp tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">tmpfs /var/tmp tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">tmpfs /var/log tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">sudo mount -o remount /</span><br><span class="line"></span><br><span class="line"># Set chrome to use ramdisk cache</span><br><span class="line">cd ~/.cache/google-chrome/Default</span><br><span class="line">rm -rf Cache</span><br><span class="line">sudo ln -s /tmp Cache</span><br><span class="line">rm -rf Media\ Cache/</span><br><span class="line">sudo ln -s /tmp Media\ Cache</span><br><span class="line"></span><br><span class="line"># Use noop for I/O elevator</span><br><span class="line">cat /sys/block/sda/queue/scheduler</span><br><span class="line">sudo vi /etc/default/grub</span><br><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=&quot;elevator=noop&quot;</span><br><span class="line">sudo update-grub</span><br><span class="line"></span><br><span class="line"># Test SSD speed</span><br><span class="line">$ sudo hdparm -Tt /dev/sdb</span><br><span class="line">/dev/sdb:</span><br><span class="line"> Timing cached reads:   9128 MB in  2.00 seconds = 4569.28 MB/sec</span><br><span class="line"> Timing buffered disk reads: 818 MB in  3.01 seconds = 272.07 MB/sec</span><br><span class="line"></span><br><span class="line"># Make sure 4K align</span><br><span class="line">$ sudo fdisk -lu |grep sdb |grep sectors</span><br><span class="line">Disk /dev/sdb: 232.9 GiB, 250059350016 bytes, 488397168 sectors</span><br><span class="line"></span><br><span class="line"># Health check</span><br><span class="line">$ sudo smartctl -s on -a /dev/sdb |grep PASSED</span><br><span class="line">SMART overall-health self-assessment test result: PASSED</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/03/也谈wifi断流问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/03/也谈wifi断流问题/" itemprop="url">也谈wifi断流问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-03T12:02:42+08:00">
                2018-09-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-09-03)</strong></p>
<h2 id="导言"><a href="#导言" class="headerlink" title="导言"></a>导言</h2><p>现实生活中的悖论真多, 本来pmtud是设计用来在mtu不一致的情况下协商mss值的, 结果很多服务端或者中间路由器会错误地禁用掉icmp-type=3或者icmp=type=4, 于是ptmud不可用, 于是很多路由器中的clamp-mss-to-pmtu设置(iptables -t mangle -A POSTROUTING -p tcp –tcp-flags SYN,RST SYN -j TCPMSS –clamp-mss-to-pmtu)也失效, 这样tcp访问某些特定mtu值不一致的网站时就会出现各种莫名其妙的问题.<br>另一方面, 对于udp, 因为无连接, 所以无法协商mss, 这样有些网络设备(eg: Nokia7)会设置禁止pmtud协商(disable DF bit in the IP header of the sender, ip_no_pmtu_disc=1), 从而也会反过来造成路由器中的clamp-mss-to-pmtu失效.</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>笔者最近应该是遇到了常听大家说起的wifi断流问题, 新入一款安卓原生系统手机, 但是在使用wifi上网时会感觉到某些APP上网不流畅, 尤其是使用京东APP搜索商品时会总说找不着网络, 但此时显然是有网络的. 为此, 笔者先做了一系统排除性实验:</p>
<ul>
<li>排除法测试, 使用京东APP搜索商品时说找不着网络, 但使用京东APP的其他功能没有问题, 并且使用京东以外的其他APP也没问题</li>
<li>排除法测试, 切换为4G网络使用京东APP搜索商品正常, 仅仅只是使用WIFI网络时才会出问题.</li>
<li>排除法测试, 去麦当劳使用WIFI确认无问题, 但速度也不快, 但能打开页面.</li>
<li>排除法测试, 难道是家里的WIFI有问题吗? 但换个手机型号使用京东APP搜索商品却又正常.</li>
<li>排除法测试, 难道是VPN的问题? 关掉VPN, 恢复DNS国内设置依然有问题.</li>
<li>排除法测试, 继续换一个没有VPN的干净的OpenWRT路由器依然有问题, 可惜家里没有Non-OpenWRT路由器可供测试.</li>
<li>排除法测试, 路由器上修改802.11g, 802.11n, 802.11ac等设置后问题依旧.</li>
<li>排除法测试, 检查了路由器上的MAC地址是否与其他机器重复, 未发现异常</li>
<li>排除法测试, 使用114.114.114.114作为DNS, 问题依旧</li>
<li>排除法测试, OpenWRT路由器使用tcpdump抓包, 干扰条目过多, 未深入</li>
<li>排除法测试, 现在问题看起来只是发生在这款特定手机型号与特定的OpenWRT路由器与特定的某些APP如京东, 手机刷机到android 8.1与7.1两个版本问题依旧.</li>
<li>排除法测试, google搜索大量京东或别的某些应用在各种手机型号上出问题的帖子, 试着更改帖子中的各种切换手机配置的操作, 如不对京东使用电源优化,问题依旧.</li>
<li><p>排除法测试, 绝大多数时候打不开京东的这个搜索商品的功能, 但极少数情况又能打开, 但非常慢, 使用别家的wifi网络时也是非常慢, 很难说清楚现象.</p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>上述一系列排除性测试让我相信该问题仅和我使用特定的手机型号, 使用特定的OpenWRT路由器, 使用特定的某些APP如京东有关.<br>京东APP, 一个上层应用而已, 理论上只有下列几个因素会影响到上层应用:</p>
</li>
<li><p>DNS</p>
</li>
<li>IPv6/IPv4 fallback</li>
<li>MTU<br>理论让我将目光回到MTU, 修改OpenWRT路由器WAN口的MTU=1492后问题依旧.继续深挖:</li>
<li>路由器背后的手机操作系统应该有/proc/sys/net/ipv4/ip_no_pmtu_disc=0让手机可以根据pmtu来确实应用所需的mss值. 遗憾地是, 手机没有root, 无法检查此项值. 参考: Note7 WiFi问题技术分析及给三星的解决方案 <a href="http://tieba.baidu.com/p/4793087714" target="_blank" rel="external">http://tieba.baidu.com/p/4793087714</a> , 参考: <a href="https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt" target="_blank" rel="external">https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt</a> , 参考: <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=5d424d5a674f782d0659a3b66d951f412901faee" target="_blank" rel="external">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=5d424d5a674f782d0659a3b66d951f412901faee</a></li>
<li>OpenWRT路由器tcpdump抓包, 看到的mss值确实不小. 既然无root权限无法修改手机的ip_no_pmtu_disc参数, 那有没有方法直接修改OpenWRT路由器强迫修改mss值呢?<br>OK, 在路由器上添加如下两个命令, 问题就这么解决了:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#iptables -A FORWARD -j ACCEPT</span><br><span class="line">iptables -t mangle -A FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# iptables-save |grep mss</span><br><span class="line">:mssfix - [0:0]</span><br><span class="line">-A FORWARD -j mssfix</span><br><span class="line">-A FORWARD -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">-A mssfix -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -m comment --comment &quot;wan (mtu_fix)&quot; -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# tcpdump -ni br-lan src host 192.168.99.194 and dst host 111.13.24.129 and dst port 443</span><br><span class="line">06:37:42.085674 IP 192.168.99.194.39494 &gt; 111.13.24.129.443: Flags [S], seq 140081180, win 65535, options [mss 1460,sackOK,TS val 8629819 ecr 0,nop,wscale 8], length 0</span><br><span class="line">06:37:42.092397 IP 192.168.99.194.39494 &gt; 111.13.24.129.443: Flags [.], ack 2370816066, win 343, length 0</span><br><span class="line">06:37:42.095245 IP 192.168.99.194.39494 &gt; 111.13.24.129.443: Flags [P.], seq 0:173, ack 1, win 343, length 173</span><br><span class="line">06:37:42.141194 IP 192.168.99.194.39494 &gt; 111.13.24.129.443: Flags [.], ack 1453, win 354, length 0</span><br><span class="line">06:37:42.141396 IP 192.168.99.194.39494 &gt; 111.13.24.129.443: Flags [.], ack 2905, win 365, length 0</span><br><span class="line">06:37:42.141536 IP 192.168.99.194.39494 &gt; 111.13.24.129.443: Flags [.], ack 3472, win 377, length 0</span><br><span class="line">06:37:42.147373 IP 192.168.99.194.39494 &gt; 111.13.24.129.443: Flags [P.], seq 173:491, ack 3472, win 377, length 318</span><br><span class="line">06:37:42.185607 IP 192.168.99.194.39494 &gt; 111.13.24.129.443: Flags [P.], seq 491:1736, ack 3714, win 388, length 1245</span><br><span class="line">06:37:42.194932 IP 192.168.99.194.39494 &gt; 111.13.24.129.443: Flags [P.], seq 1736:1767, ack 4065, win 388, length 31</span><br><span class="line">06:37:42.195258 IP 192.168.99.194.39494 &gt; 111.13.24.129.443: Flags [R.], seq 1767, ack 4065, win 388, length 0</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这款手机的操作系统没有设置ip_no_pmtu_disc参数去协商mss值, 而OpenWRT路由器刚好缺一条iptables rule (iptables -t mangle -A FORWARD -p tcp –tcp-flags SYN,RST SYN -j TCPMSS –clamp-mss-to-pmtu), 这样遭遇了pppoe的1492 MTU问题.<br>换句话说, 当我外出时, 如果所连的路由器没有加这条设置, 那么这个问题仍然又遇到. 手机操作系统ip_no_pmtu_disc设置才能彻底解决某些应用wifi网络不能上网的问题.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">iptables -t mangle -I POSTROUTING -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">iptables -t mangle -I OUTPUT -o pppoe-wan -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">iptables -t mangle -I FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">ip6tables -t mangle -I POSTROUTING -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">ip6tables -t mangle -I OUTPUT -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">ip6tables -t mangle -I FORWARD -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br></pre></td></tr></table></figure></p>
<p>另外, 要想clamp-mss-to-pmtu生效, 需要设置充许设计DF=1来禁用分片从而启用pmtud协议.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 0 &gt;/proc/sys/net/ipv4/ip_no_pmtu_disc</span><br></pre></td></tr></table></figure></p>
<p>但设置”echo 0 &gt;/proc/sys/net/ipv4/ip_no_pmtu_disc”后之后, 对于无连接的udp包, 由于无法协商mss值, 当大分片的udp包到达路由器后, 路由器会简单地丢弃它.</p>
<h2 id="另一个案例"><a href="#另一个案例" class="headerlink" title="另一个案例"></a>另一个案例</h2><p>openstack虚机上再创建docker容器, 因为是vxlan网络虚机的mtu=1450, docker0的mtu如果为1500时将导致docker container无法通信.<br>当mtu配置不正确时此时需要依赖mss, 此时计算节点充当的是路由器它发现此情况(不能将docker container发出的mtu=1500的包发出时)应该发ICMP error到docker container, 或者openstack vrouter应当做这件事情.</p>
<p>docker container错误的具体表现是无法下载, 此时, 最可能的情况时, 最大的包到达openstack vrouter后, 它从external interface收到mtu=1500的包并尝试分片发给虚机, 失败后将发ICMP error到外部下载服务器. 此时:</p>
<p>1, 当non-DVR时, l3-agent上的snat-xxx确实向外部下载服务器发出了ICMP error:</p>
<p>11:45:04.873959 fa:16:3e:c5:b3:ed &gt; fe:54:00:36:ab:b4, ethertype IPv4 (0x0800), length 590: 100.64.1.1 &gt; 120.146.233.220: ICMP 103.245.215.9 unreachable - need to frag (mtu 1450), length 556</p>
<p>2, 当DVR时, FIP移到了计算节点上, 此时是qrouter-xxx, 但是这个ns没有default route,<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@maas-node02:~# ip -n qrouter-1752c73a-be9f-4326-97cc-99dbe0988b3c rule show</span><br><span class="line">0:	from all lookup local</span><br><span class="line">32766:	from all lookup main</span><br><span class="line">32767:	from all lookup default</span><br><span class="line">57481:	from 103.245.215.14 lookup 16</span><br><span class="line">80000:	from 103.245.215.0/28 lookup 16</span><br><span class="line"></span><br><span class="line">root@maas-node02:~# ip -n qrouter-1752c73a-be9f-4326-97cc-99dbe0988b3c route show table 16</span><br><span class="line">default via 169.254.106.115 dev rfp-1752c73a-b</span><br><span class="line"></span><br><span class="line">root@maas-node02:~# ip -n qrouter-1752c73a-be9f-4326-97cc-99dbe0988b3c route show</span><br><span class="line">103.245.215.0/28 dev qr-ec03268e-fb proto kernel scope link src 103.245.215.1</span><br><span class="line">169.254.106.114/31 dev rfp-1752c73a-b proto kernel scope link src 169.254.106.114</span><br></pre></td></tr></table></figure></p>
<p>只有再添加下列默认路由之后, DVR qrouter-xxx’s才能将ICMP error发出去, 这样才可能去使用mss,</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@maas-node02:~# ip -n qrouter-1752c73a-be9f-4326-97cc-99dbe0988b3c route add default via 169.254.106.115 dev rfp-1752c73a-b</span><br></pre></td></tr></table></figure>
<p>所以这样造成的问题就是, non-DVR虚机上运行docker container没问题, 而DVR虚机上运行docker container有问题. 解决办法有三个:</p>
<p>1, 修改docker0的mtu=1450, 我们不能修改bridge的mtu, 但可以往docker0里再添加一个tap, 这样bridge的mtu将取决于tap mtu的最小值.<br>2, 计算节点上运行:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t mangle -A FORWARD -o ens3 -p tcp -m tcp --tcp-flags SYN,RST SYN -m tcpmss --mss 1400:65495 -j TCPMSS --clamp-mss-to-pmtu</span><br></pre></td></tr></table></figure></p>
<p>3, to increase the global-physnet-mtu to 1550 to allow the real tenant network MTU to be 1500.<br>注: 沿路的交换机也要配置相应的MTU, 特别是如果交换机配置的MTU过小, 那么ICMP error直接就没有提示就被drop( 千万注意: 过来的包的MTU如果大于设备的MTU值才会分片分段, 如果是小于的话直接就DROP掉了, 这个参数net.ipv4.tcp_mtu_probing也可以探测这种情况)了这样导致MTU没配对之后也无法利用MSS, 这种问题更不好查. 另外, 也发现IPv6情况下的ICMPv6没有被ip6table rule允许的情况.</p>
<h2 id="另一个问题-ssh连接时不时中断"><a href="#另一个问题-ssh连接时不时中断" class="headerlink" title="另一个问题 - ssh连接时不时中断"></a>另一个问题 - ssh连接时不时中断</h2><p>我的mtu是1484=1456+28(IP header is 20 byptes, ICMP header is 8 bytes), gavin的mtu是1492. 这个网页(<a href="https://ubuntuforums.org/showthread.php?t=2341699)说" target="_blank" rel="external">https://ubuntuforums.org/showthread.php?t=2341699)说</a>:<br>we are using a PPPoE connection the highest MTU we can get is 1492. And your ISP might not even go that high. The highest I could get mine was 1484. 这个网页(<a href="https://www.gargoyle-router.com/phpbb/viewtopic.php?t=8787)也提到了pppoe-wan口的mtu有时总比设置的要少8" target="_blank" rel="external">https://www.gargoyle-router.com/phpbb/viewtopic.php?t=8787)也提到了pppoe-wan口的mtu有时总比设置的要少8</a> byptes.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# ip addr show pppoe-wan | grep mtu</span><br><span class="line">608: pppoe-wan: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1484 qdisc fq_codel state UNKNOWN group default qlen 3</span><br><span class="line"></span><br><span class="line">hua@t440p:~$ ping -M do -i 1 -c 2 -s 1456 vps</span><br><span class="line">1464 bytes from vps (xx.xx.xx.xx.xx): icmp_seq=1 ttl=57 time=209 ms</span><br><span class="line">hua@t440p:~$ ping -M do -i 1 -c 2 -s 1457 vps</span><br><span class="line">ping: local error: Message too long, mtu=1484</span><br><span class="line"></span><br><span class="line">ubuntu@gavin-P70:~$ ping -M do -i 1 -c 2 -s 1464 vps</span><br><span class="line">1472 bytes from xx.xx.xx.xx.xx: icmp_seq=1 ttl=58 time=48.5 ms</span><br><span class="line">ubuntu@gavin-P70:~$ ping -M do -i 1 -c 2 -s 1465 vps</span><br><span class="line">ping: local error: Message too long, mtu=1492</span><br></pre></td></tr></table></figure></p>
<p>抓包看到的gavin的mss值是1452(1492-40), 我的mss值却是1460.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hua@t440p:~$ sudo tcpdump -s0 -p -ni eth0 src host 192.168.99.135 and dst host xx.xx.xx.xx and dst port 22 and &apos;(ip and ip[20+13] &amp; tcp-syn != 0)&apos;</span><br><span class="line">08:00:45.771287 IP 192.168.99.135.35172 &gt; xx.xx.xx.xx.22: Flags [S], seq 1056384328, win 29200, options [mss 1460,sackOK,TS val 92453102 ecr 0,nop,wscale 7], length 0</span><br><span class="line"></span><br><span class="line">hua@t440p:~$ sudo tcpdump -s0 -p -ni eth0 src host xx.xx.xx.xx and &apos;(ip and ip[20+13] &amp; tcp-syn != 0)&apos;</span><br><span class="line">08:01:31.252313 IP xx.xx.xx.xx.22 &gt; 192.168.99.135.35182: Flags [S.], seq 1913298511, ack 4239124226, win 28960, options [mss 1452,sackOK,TS val 3432015413 ecr 92498502,nop,wscale 7], length 0</span><br></pre></td></tr></table></figure></p>
<p>为什么我的mss值却是1460呢? 可能是根据t440p client上的mtu 1500来设置的, 却没有参考路由器上的1484. 查看了路由器的设置是使用了”–clamp-mss-to-pmtu”, 如果对端如gavin家不支持pmtu协商呢(如他家的tplink路由器什么的没有设置ip_no_pmtu_disc=0).</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# iptables-save |grep mss</span><br><span class="line">:mssfix - [0:0]</span><br><span class="line">-A FORWARD -j mssfix</span><br><span class="line">-A mssfix -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -m comment --comment &quot;wan (mtu_fix)&quot; -j TCPMSS --clamp-mss-to-pmtu</span><br></pre></td></tr></table></figure>
<p>只有继续添加了下列针对POSTROUTING的clamp-mss-to-pmtu才变回1444<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# iptables -t mangle -A POSTROUTING -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line"></span><br><span class="line">hua@t440p:~$ sudo tcpdump -s0 -p -ni eth0 src host xx.xx.xx.xx and &apos;(ip and ip[20+13] &amp; tcp-syn != 0)&apos;</span><br><span class="line">08:51:53.831560 IP xx.xx.xx.xx.22 &gt; 192.168.99.135.36554: Flags [S.], seq 3638522412, ack 307088327, win 28960, options [mss 1444,sackOK,TS val 3432771057 ecr 95521097,nop,wscale 7], length 0</span><br></pre></td></tr></table></figure></p>
<p>所以在路由器上设置最终为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">iptables -t mangle -A FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">iptables -t mangle -A OUTPUT -o pppoe-wan -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">iptables -t mangle -A POSTROUTING -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">ip6tables -t mangle -A FORWARD -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">ip6tables -t mangle -A OUTPUT -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">ip6tables -t mangle -A POSTROUTING -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br></pre></td></tr></table></figure></p>
<p>改了之后, 从路由器的<strong>pppoe-wan口(出是1444, 进是1452)</strong>和t440p的<strong>eth0口(出是1444, 进是1460)</strong>看到的mss值是不一样的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# tcpdump -s0 -p -ni pppoe-wan src host xx.xx.xx.xx and &apos;(ip and ip[20+13] &amp; tcp-syn != 0)&apos;</span><br><span class="line">01:45:59.915458 IP xx.xx.xx.xx.22 &gt; 10.2.156.119.37466: Flags [S.], seq 2070487858, ack 2656232535, win 28960, options [mss 1452,sackOK,TS val 3433582582 ecr 98767213,nop,wscale 7], length 0</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# tcpdump -s0 -p -ni eth0 src host 192.168.99.135 and dst host xx.xx.xx.xx and dst port 22 and &apos;(ip and ip[20+13] &amp; tcp-syn != 0)&apos;</span><br><span class="line">01:45:59.835236 IP 10.2.156.119.37466 &gt; xx.xx.xx.xx.22: Flags [S], seq 2656232534, win 29200, options [mss 1444,sackOK,TS val 98767213 ecr 0,nop,wscale 7], length 0</span><br><span class="line"></span><br><span class="line">hua@t440p:~$ sudo tcpdump -s0 -p -ni eth0 src host xx.xx.xx.xx and &apos;(ip and ip[20+13] &amp; tcp-syn != 0)&apos;</span><br><span class="line">09:45:59.925637 IP xx.xx.xx.xx.22 &gt; 192.168.99.135.37466: Flags [S.], seq 2070487858, ack 2656232535, win 28960, options [mss 1444,sackOK,TS val 3433582582 ecr 98767213,nop,wscale 7], length 0</span><br><span class="line"></span><br><span class="line">hua@t440p:~$ sudo tcpdump -s0 -p -ni eth0 dst host xx.xx.xx.xx and dst port 22 and &apos;(ip and ip[20+13] &amp; tcp-syn != 0)&apos;</span><br><span class="line">09:45:59.842593 IP 192.168.99.135.37466 &gt; xx.xx.xx.xx.22: Flags [S], seq 2656232534, win 29200, options [mss 1460,sackOK,TS val 98767213 ecr 0,nop,wscale 7], length 0</span><br></pre></td></tr></table></figure></p>
<p>如果不在路由器, 改在t440p上单为ssh设置的话可以:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># https://blog.cloudflare.com/path-mtu-discovery-in-practice/</span><br><span class="line"># sudo ip route change default via &lt;&gt; advmss 1444</span><br><span class="line">sudo iptables -t mangle -A OUTPUT -p tcp --dport 22 -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --set-mss 1444</span><br></pre></td></tr></table></figure></p>
<p>另外, 也可以将t440p上的mtu设置为1484, 这样路由器和t440p上进和出的mss值全统一到1444了.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ifconfig eth0 mtu 1484</span><br></pre></td></tr></table></figure></p>
<p>只有两端的话可以通过mss协商解决, 但两端之间还有一系统路由器交换机什么的就需要pmtud来协商mss值了. pmtud的原理就是设置df=1禁止分片但又传大分片给路由器, 路由器根据df=1应该丢弃掉包并返回 icmp unreachable messages, 但有些路由器的icmp规则设置的过于严格(<strong>远端机器无法ping, “sudo mtr xxx -r –no-dns -P 22”的输出的最后一跳丢包率是100%, 100%的丢包率不一定是真的丢包, 而是icmp限速了或者禁用了</strong>) 可以会丢弃icmp unreachable messages. 至少应该设置:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># https://www.iana.org/assignments/icmp-parameters/icmp-parameters.xhtml</span><br><span class="line">iptables -A INPUT -p icmp -m icmp --icmp-type 3 -j ACCEPT</span><br><span class="line">iptables -A INPUT -p icmp -m icmp --icmp-type 4 -j ACCEPT</span><br><span class="line">iptables -A INPUT -p icmp -m icmp --icmp-type 11 -j ACCEPT</span><br></pre></td></tr></table></figure></p>
<h2 id="20190426更新"><a href="#20190426更新" class="headerlink" title="20190426更新"></a>20190426更新</h2><p>如此好的一篇文章 (<a href="https://www.zeitgeist.se/2013/11/26/mtu-woes-in-ipsec-tunnels-how-to-fix/" target="_blank" rel="external">https://www.zeitgeist.se/2013/11/26/mtu-woes-in-ipsec-tunnels-how-to-fix/</a> ), 相见恨晚. 这篇文章中提到了两点和我之前长时间痛苦摸索的基本一致:</p>
<ul>
<li>文章说pmtud理论很饱满, 但现实很残酷, 很多网站或路由器很粗鲁地将icmp-type 3 and 4禁用掉了, 从而导致ptmud失效.</li>
<li>在ptmud失效的情况下, 对于tcp, 在server端运行” iptables -t mangle -A FORWARD -o eth0 -p tcp -m tcp –tcp-flags SYN,RST SYN -s 172.16.16.0/24 -m tcpmss –mss 1361:1536 -j TCPMSS –set-mss 1360”  或者 “sudo iptables -t mangle -A FORWARD -p tcp –dport 22 -m tcp –tcp-flags SYN,RST SYN -j TCPMSS –set-mss 1444” 来动态设置mss是一个好办法.</li>
<li>在ptmud失效的情况下, 对于udp, udp是无连接的, 无法协商mss值, 在server端运行 “echo 1 &gt;/proc/sys/net/ipv4/ip_no_pmtu_disc” (The only solution to guarantee that UDP works is to disable the Don’t Fragment (DF) bit in the IP header of the sender. This will allow our VPN server to fragment any UDP packet). 注意: <strong>ip_no_pmtu_disc=1也意味着禁止pmtud协商了哦</strong>.</li>
</ul>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>减少client端的mss值, 并查看mss值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># https://blog.cloudflare.com/path-mtu-discovery-in-practice/</span><br><span class="line"># sudo ip route change default via &lt;&gt; advmss 1400</span><br><span class="line"># sudo iptables -t mangle -A OUTPUT -p tcp --dport 22 -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --set-mss 1444</span><br><span class="line">hua@t440p:~$ sudo iptables-save |grep mss</span><br><span class="line">-A OUTPUT -p tcp -m tcp --dport 22 -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --set-mss 1444</span><br><span class="line"></span><br><span class="line">hua@t440p:~$ sudo tcpdump -s0 -p -ni eth0 src host 192.168.99.135 and dst host xxx and dst port 22 and &apos;(ip and ip[20+13] &amp; tcp-syn != 0)&apos;</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">22:05:34.295036 IP 192.168.99.135.55502 &gt; xxx.22: Flags [S], seq 2332107979, win 29200, options [mss 1444,sackOK,TS val 56741396 ecr 0,nop,wscale 7], length 0</span><br></pre></td></tr></table></figure>
<p>Enable smart MTU black hole detection. RFC4821 proposes a mechanism to detect ICMP black holes and tries to adjust the path MTU in a smart way. To enable this on Linux type:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt; /proc/sys/net/ipv4/tcp_mtu_probing</span><br><span class="line">echo 1024 &gt; /proc/sys/net/ipv4/tcp_base_mss</span><br></pre></td></tr></table></figure></p>
<p>检测丢包(使用ping不准的):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hua@t440p:~$ netstat -s -p|grep -i segments</span><br><span class="line">    11519400 segments received</span><br><span class="line">    11624725 segments sent out</span><br><span class="line">    84339 segments retransmitted</span><br><span class="line">    980 bad segments received</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/03/IPv6来啦/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/03/IPv6来啦/" itemprop="url">IPv6来啦</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-03T16:01:05+08:00">
                2018-08-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="基础-ND协议的三个位"><a href="#基础-ND协议的三个位" class="headerlink" title="基础 - ND协议的三个位"></a>基础 - ND协议的三个位</h2><p>ND协议包中有三个位(Auto, Managed, Other)：</p>
<ul>
<li>M bit (Managed Address Configuration), M bit如果是1,表示Clients要另外再去跟DHCPv6要IPv6 Prefix</li>
<li>O bit (Other Configuration), O bit如果是1,表示Clients要去跟DHCPv6要DNS(RDNSS)等其他信息<br>这样：</li>
<li>slaas, Stateless autoconfiguration, A=1, M=0, O=0, 主机將只得到Router給的 Prefix, 无法取得DNS等资讯, 其他必须自己填写.</li>
<li>dhcpv6-stateful, A=0, M=1, O=1, 所有信息（IPv6 prefix, DNS等)都通过DHCPv6获得,客戶端主要使用UDP port 546, 而服務器端使用 UDP port 547</li>
<li>dhcpv6-stateless,A=1, M=0, O=1, 除了使用RA裡面的Prefix,其他如DNS等等信息会由DHCPv6 取得.<h2 id="基础-Neutron-IPv6"><a href="#基础-Neutron-IPv6" class="headerlink" title="基础 - Neutron IPv6"></a>基础 - Neutron IPv6</h2>Neutron中有两个重要属性来支持IPv6 (ipv6_address_mode 与 ipv6_ra_mode):</li>
<li>ipv6_ra_mode, 如果设置表示由Neutron来使用radvd来模拟软件IPv6路由器, 如果不设置表示使用外部IPv6路由器</li>
<li>ipv6_address_mode, 对应上述ND协议中的三个位(Auto, Managed, Other), 例如: 对于dhcpv6-stateless, 3比特应该是: A=1, M=0, O=1.</li>
</ul>
<p>下面是创建一个使用外部IPv6路由器并使用dhcpv6-stateless的例子:<br>neutron net-create –provider:network_type flat –provider:physical_network physnet1 –router:external=True ext_net<br>neutron subnet-create ext_net –name external-subnet-v6 –ip_version 6 –ipv6_address_mode dhcpv6-stateless –allocation-pool start=2001:db8:0:1::2,end=2001:db8:0:1:ffff:ffff:ffff:ffff 2001:db8:0:1::/64</p>
<h2 id="基础-Ubuntu中手工配置IPv6的注意点"><a href="#基础-Ubuntu中手工配置IPv6的注意点" class="headerlink" title="基础 - Ubuntu中手工配置IPv6的注意点"></a>基础 - Ubuntu中手工配置IPv6的注意点</h2><p>Ubuntu中配置IPv6可以采用network-manager, 也可采用在/etc/network/interface中手工配置, 也可以使用最新的netplan. 这里描述的是采用手工配置的方法.<br>先看一个遇到的实际问题:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">下面配置不work</span><br><span class="line">iface eth0 inet6 auto</span><br><span class="line">   # use SLAAC to get global IPv6 address from the router</span><br><span class="line">   # we may not enable ipv6 forwarding, otherwise SLAAC gets disabled</span><br><span class="line">   up sleep 5</span><br><span class="line">   dhcp 1</span><br><span class="line">   autoconf 1</span><br><span class="line">   accept_ra 2</span><br><span class="line"></span><br><span class="line">下列配置work</span><br><span class="line">iface eth0 inet6 static</span><br><span class="line">address 2001:192:168:99::135</span><br><span class="line">   gateway 2001:192:168:99::1</span><br><span class="line">   netmask 64</span><br><span class="line">且改成network-manager也work, 这是为什么呢?</span><br><span class="line"></span><br><span class="line">测试方法是:</span><br><span class="line">#it will flush link-local address as well</span><br><span class="line">#ip addr flush br-eth0</span><br><span class="line"># avoid the error: can&apos;t get a link-local address</span><br><span class="line">sudo ip link set dev eth0 down</span><br><span class="line">sudo ip link set dev eth0 up</span><br><span class="line">ifdown br-eth0</span><br><span class="line">ifup --force --verbose br-eth0</span><br></pre></td></tr></table></figure></p>
<p>采用”ifup –force –verbose br-eth0”命令看到的错误是”can’t get a link-local address”.<br>为什么static模式与network-manager模式没有这个错误呢? 原来是这两者默认执行了:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br></pre></td></tr></table></figure></p>
<p>并且之前Linux网桥br-eth0上一直没有IPv6地址的原因也是这个, 且上面”sudo ip link set dev eth0 up”这句也会自动设置disable_ipv6=0, 但不会对br-eth0作同样的设置.<br>所以添加”up echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6”后问题解决, 完整配置如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">root@node1:~# cat /etc/network/interfaces</span><br><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line">auto eth0</span><br><span class="line">iface eth0 inet manual</span><br><span class="line">auto br-eth0</span><br><span class="line">iface br-eth0 inet static</span><br><span class="line">    address 192.168.99.124/24</span><br><span class="line">    gateway 192.168.99.1</span><br><span class="line">    bridge_ports eth0</span><br><span class="line">    dns-nameservers 192.168.99.1</span><br><span class="line">    bridge_stp on</span><br><span class="line">    bridge_fd 0</span><br><span class="line">    bridge_maxwait 0</span><br><span class="line">    up echo -n 0 &gt; /sys/devices/virtual/net/$IFACE/bridge/multicast_snooping</span><br><span class="line"># for stateless it&apos;s &apos;inet6 auto&apos;, for stateful it&apos;s &apos;inet6 dhcp&apos;</span><br><span class="line">iface br-eth0 inet6 auto</span><br><span class="line">    #iface eth0 inet6 static</span><br><span class="line">    #address 2001:192:168:99::135</span><br><span class="line">    #gateway 2001:192:168:99::1</span><br><span class="line">    #netmask 64</span><br><span class="line">    # use SLAAC to get global IPv6 address from the router</span><br><span class="line">    # we may not enable ipv6 forwarding, otherwise SLAAC gets disabled</span><br><span class="line">    # sleep 5 is due a bug and &apos;dhcp 1&apos; indicates that info should be obtained from dhcpv6 server for stateless</span><br><span class="line">    up echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br><span class="line">    up sleep 5</span><br><span class="line">    autoconf 1</span><br><span class="line">    accept_ra 2</span><br><span class="line">    dhcp 1</span><br></pre></td></tr></table></figure></p>
<p>此外, 最好设置accept_ra=2, 因为经常会遇到自动配置的IPv6地址丢失或者不能获取的问题。一般情况是都是启用了IPv6转发功能(sudo sysctl -w net.ipv6.conf.all.forwarding=1)引起的。<br>为了配置IPv6 address和default gateway, client/host都会默认去listen或者solicit RA广播, 并且host作为router时会忽略RA, 这由accept_ra设置:</p>
<ul>
<li>0 Do not accept RouterAdvertisements.</li>
<li>1 Accept Router Advertisements if forwarding is disabled.</li>
<li>2 Overrule forwarding behavior. Accept Router Advertisements  even if forwarding is enabled.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv6.conf.all.forwarding=1</span><br><span class="line">sudo sysctl -w net.ipv6.conf.all.accept_ra=2</span><br><span class="line">sudo sysctl -w net.ipv6.conf.br-lan.disable_ipv6=0</span><br><span class="line">#echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="IPv6中的防火墙"><a href="#IPv6中的防火墙" class="headerlink" title="IPv6中的防火墙"></a>IPv6中的防火墙</h2><p>IPv6 Router端:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># Clear all ip6tables rules</span><br><span class="line">ip6tables -t nat -X</span><br><span class="line">ip6tables -t nat -P PREROUTING ACCEPT</span><br><span class="line">ip6tables -t nat -P POSTROUTING ACCEPT</span><br><span class="line">ip6tables -t nat -P OUTPUT ACCEPT</span><br><span class="line">ip6tables -t mangle -F</span><br><span class="line">ip6tables -t mangle -X</span><br><span class="line">ip6tables -t mangle -P PREROUTING ACCEPT</span><br><span class="line">ip6tables -t mangle -P INPUT ACCEPT</span><br><span class="line">ip6tables -t mangle -P FORWARD ACCEPT</span><br><span class="line">ip6tables -t mangle -P OUTPUT ACCEPT</span><br><span class="line">ip6tables -t mangle -P POSTROUTING ACCEPT</span><br><span class="line">ip6tables -F</span><br><span class="line">ip6tables -X</span><br><span class="line">ip6tables -P FORWARD ACCEPT</span><br><span class="line">ip6tables -P INPUT ACCEPT</span><br><span class="line">ip6tables -P OUTPUT ACCEPT</span><br><span class="line">ip6tables -t raw -F</span><br><span class="line">ip6tables -t raw -X</span><br><span class="line">ip6tables -t raw -P PREROUTING ACCEPT</span><br><span class="line">ip6tables -t raw -P OUTPUT ACCEPT</span><br><span class="line"></span><br><span class="line"># Default DROP rules</span><br><span class="line">ip6tables -P INPUT   DROP</span><br><span class="line">ip6tables -P OUTPUT  ACCEPT</span><br><span class="line">ip6tables -P FORWARD DROP</span><br><span class="line"></span><br><span class="line"># Allow established connections</span><br><span class="line">ip6tables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br><span class="line">ip6tables -A FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br><span class="line"></span><br><span class="line"># For IPv6</span><br><span class="line"># it&apos;s not required due to ipv6-icmp</span><br><span class="line"># sudo ip6tables -A INPUT -p udp --dport 547 -j ACCEPT</span><br><span class="line">#ip6tables -A INPUT -p icmpv6 --icmpv6-type echo-request -j ACCEPT</span><br><span class="line">ip6tables -A INPUT -p ipv6-icmp -j ACCEPT</span><br><span class="line">ip6tables -A FORWARD -p ipv6-icmp -j ACCEPT</span><br><span class="line"></span><br><span class="line"># Ajust MTU</span><br><span class="line">ip6tables -t mangle -A POSTROUTING -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br></pre></td></tr></table></figure></p>
<p>IPv6 Client端:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ip6tables -t filter -A INPUT -p udp -m udp --sport 547 --dport 546 -j ACCEPT</span><br><span class="line">ip6tables -t filter -A INPUT -p ipv6-icmp -j ACCEPT</span><br><span class="line"></span><br><span class="line"># or security group</span><br><span class="line">https://bugs.launchpad.net/neutron/+bug/1335984</span><br><span class="line">openstack security group rule create $secgroup --protocol udp --dst-port 546 --ethertype IPv6</span><br><span class="line">openstack security group rule create $secgroup --protocol icmpv6 --ethertype IPv6</span><br><span class="line"></span><br><span class="line"># Flow based firewall</span><br><span class="line">hard_timeout=0,idle_timeout=0,priority=4,udp,tp_dst=546/0xffff,table=32,tp_src=547/0xffff,nw_src=fe80::f816:3eff:fea3:ec40,actions=learn(table=33,priority=5,hard_timeout=120,eth_type=0x800,nw_proto=17,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],NXM_OF_IP_SRC[]=NXM_OF_IP_DST[],NXM_OF_UDP_SRC[]=NXM_OF_UDP_DST[], NXM_OF_UDP_DST[]=NXM_OF_UDP_SRC[],output:NXM_OF_IN_PORT[]),normal</span><br></pre></td></tr></table></figure></p>
<p>另外, 别忘了禁用掉ufw或者SELinux之类的.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ufw disable</span><br></pre></td></tr></table></figure></p>
<h2 id="Statefull-DHCPv6"><a href="#Statefull-DHCPv6" class="headerlink" title="Statefull DHCPv6"></a>Statefull DHCPv6</h2><p>采用isc-dhcp-server搭建DHCPv6 Server:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">https://jochen.kirstaetter.name/dhcpv6-ipv6-in-your-local-network/</span><br><span class="line">hua@t440p:~$ ip addr show eth0 |grep inet6 |grep global</span><br><span class="line">    inet6 2001:192:168:99::430/128 scope global</span><br><span class="line">echo &apos;Acquire::ForceIPv4 &quot;true&quot;;&apos; | sudo tee /etc/apt/apt.conf.d/99force-ipv4</span><br><span class="line">sudo apt install isc-dhcp-server</span><br><span class="line">grep -v ^# /etc/dhcp/dhcpd6.conf</span><br><span class="line">sudo cp /etc/dhcp/dhcpd6.conf /etc/dhcp/dhcpd6.conf_bak</span><br><span class="line">sudo bash -c &apos;cat &gt;/etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">authoritative;</span><br><span class="line">default-lease-time 14400;</span><br><span class="line">max-lease-time 86400;</span><br><span class="line">log-facility local7;</span><br><span class="line">subnet6 2001:192:168:99::/64 &#123;</span><br><span class="line">    option dhcp6.name-servers 2001:4860:4860::8888, 2001:4860:4860::8844;</span><br><span class="line">    option dhcp6.domain-search &quot;quqi.com&quot;;</span><br><span class="line">    range6 2001:192:168:99::100 2001:192:168:99::199;</span><br><span class="line">    range6 2001:192:168:99::/64 temporary;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo touch /var/lib/dhcp/dhcpd6.leases</span><br><span class="line">sudo /usr/sbin/dhcpd -6 -d -cf /etc/dhcp/dhcpd6.conf eth0</span><br><span class="line">sudo chown dhcpd:dhcpd /var/lib/dhcp/dhcpd6.leases</span><br><span class="line">sudo service isc-dhcp-server6 restart</span><br></pre></td></tr></table></figure></p>
<p>然后记得照上节说的设置DHCPv6 Server与Client上的防火墙规则. 接着在另一台机器上作client测试:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># need to use &apos;inet6 dhcp&apos; in client side for statefull DHCPv6</span><br><span class="line">iface br-eth0 inet6 dhcp</span><br><span class="line">    #iface eth0 inet6 static</span><br><span class="line">    #address 2001:192:168:99::135</span><br><span class="line">    #gateway 2001:192:168:99::1</span><br><span class="line">    #netmask 64</span><br><span class="line">    # use SLAAC to get global IPv6 address from the router</span><br><span class="line">    # we may not enable ipv6 forwarding, otherwise SLAAC gets disabled</span><br><span class="line">    # sleep 5 is due a bug and &apos;dhcp 1&apos; indicates that info should be obtained from dhcpv6 server for stateless</span><br><span class="line">    up echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br><span class="line">    up sleep 5</span><br><span class="line">    autoconf 1</span><br><span class="line">    accept_ra 2</span><br><span class="line">    dhcp 1</span><br><span class="line"></span><br><span class="line"># test command</span><br><span class="line">dhclient -6 -d br-eth0</span><br><span class="line"></span><br><span class="line"># verity</span><br><span class="line">hua@node1:~$ sudo tcpdump -ni eth0 ip6 host fe80::d5a3:10a3:6161:5b2e</span><br><span class="line">12:44:00.868609 IP6 fe80::d5a3:10a3:6161:5b2e.547 &gt; fe80::fa32:e4ff:febe:87cd.546: dhcp6 advertise</span><br><span class="line">12:44:01.946548 IP6 fe80::d5a3:10a3:6161:5b2e.547 &gt; fe80::fa32:e4ff:febe:87cd.546: dhcp6 reply</span><br><span class="line">root@node1:~# cat /etc/resolv.conf</span><br><span class="line"># Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)</span><br><span class="line">#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN</span><br><span class="line">nameserver 192.168.99.1</span><br><span class="line">#nameserver 211.136.17.107</span><br><span class="line">#nameserver 114.114.114.114</span><br><span class="line">#nameserver 223.5.5.5</span><br><span class="line">nameserver 2001:4860:4860::8888</span><br><span class="line">nameserver 2001:4860:4860::8844</span><br><span class="line">nameserver 2001:db8::1:6a1:51ff:fe8a:2ca7</span><br><span class="line">search quqi.com lan</span><br></pre></td></tr></table></figure>
<p>另外, 使用BIND9的例子可参见 - <a href="https://jochen.kirstaetter.name/enabling-dns-for-ipv6-infrastructure/" target="_blank" rel="external">https://jochen.kirstaetter.name/enabling-dns-for-ipv6-infrastructure/</a></p>
<h2 id="SLAAC-Stateless-Address-Auto-Configuration"><a href="#SLAAC-Stateless-Address-Auto-Configuration" class="headerlink" title="SLAAC (Stateless Address Auto Configuration)"></a>SLAAC (Stateless Address Auto Configuration)</h2><p>radvd来提供RA部分, SLAAC只有RA部分. RA只能设置IPv6 prefix与DNS (RDNSS).<br>Historically the software package radvd was commonly used for just the RA-part of this. But dnsmasq offers a more complete setup.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv6.conf.all.forwarding=1</span><br><span class="line">sudo ip addr add 2001:db8:0:1::1/64 dev eth0</span><br><span class="line">sudo apt-get install radvd</span><br><span class="line">$ cat /etc/radvd.conf</span><br><span class="line">    interface eth0</span><br><span class="line">    &#123;</span><br><span class="line">       AdvSendAdvert on;</span><br><span class="line">       prefix 2001:db8:0:1::/64</span><br><span class="line">       &#123;</span><br><span class="line">            AdvOnLink on;</span><br><span class="line">            AdvAutonomous on;</span><br><span class="line">       &#125;;</span><br><span class="line">       #Send DNS Server setting</span><br><span class="line">       #RDNSS fd5d:12c9:2201:1::2&#123;</span><br><span class="line">    &#125;;</span><br><span class="line">sudo /etc/init.d/radvd restart</span><br><span class="line">sudo ip6tables -F</span><br><span class="line"></span><br><span class="line">neutron subnet-create --ip-version=6 --name=ext-v6-subnet --gateway 2001:db8:0:1::1 --allocation-pool start=2001:db8:0:1::5,end=2001:db8:0:1:ffff:ffff:ffff:fffe --disable-dhcp ext_net 2001:db8:0:1::/64</span><br><span class="line">neutron net-create private</span><br><span class="line">neutron subnet-create --ip-version=6 --name=private_v6_subnet --ipv6-address-mode=slaac --ipv6-ra-mode=slaac private 2001:db8:0:2::/64</span><br><span class="line">neutron router-interface-add provider-router private_v6_subnet</span><br></pre></td></tr></table></figure></p>
<h2 id="SLAAS-with-Stateless-DHCPv6"><a href="#SLAAS-with-Stateless-DHCPv6" class="headerlink" title="SLAAS with Stateless DHCPv6"></a>SLAAS with Stateless DHCPv6</h2><p>Stateless意味着:</p>
<ul>
<li>radvd提供RA (AdvManagedFlag=off)</li>
<li>client使用radvd RA提供的IPv6 prefix配置IPv6 address</li>
<li>client的其他信息如DNS等从DHCPv6获得<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">sudo bash -c &apos;cat &gt; /etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">interface eth0</span><br><span class="line">&#123;</span><br><span class="line">    AdvSendAdvert on;</span><br><span class="line">    MinRtrAdvInterval 30;</span><br><span class="line">    MaxRtrAdvInterval 100;</span><br><span class="line">    AdvManagedFlag off;</span><br><span class="line">    AdvOtherConfigFlag on;</span><br><span class="line">    prefix 2001:192:168:99::/64</span><br><span class="line">    &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">        AdvRouterAddr off;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; /etc/radvd.conf&apos; &lt;&lt;EOF</span><br><span class="line">default-lease-time 600;</span><br><span class="line">max-lease-time 7200;</span><br><span class="line">log-facility local7;</span><br><span class="line">option dhcp6.name-servers 2001:4860:4860::8888;</span><br><span class="line">option dhcp6.domain-search &quot;&quot;;</span><br><span class="line">subnet6 2001:192:168:99::/64 &#123;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="SLAAS-with-Statefull-DHCPv6"><a href="#SLAAS-with-Statefull-DHCPv6" class="headerlink" title="SLAAS with Statefull DHCPv6"></a>SLAAS with Statefull DHCPv6</h2><p>Statefull意味着:</p>
<ul>
<li>radvd不提供RA (AdvManagedFlag=on)</li>
<li>client使用DHCPv6去配置IPv6 address</li>
<li>client的其他信息如DNS等也从DHCPv6获得<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">sudo bash -c &apos;cat &gt; /etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">interface eth0</span><br><span class="line">&#123;</span><br><span class="line">    AdvSendAdvert on;</span><br><span class="line">    MinRtrAdvInterval 30;</span><br><span class="line">    MaxRtrAdvInterval 100;</span><br><span class="line">    AdvManagedFlag on;</span><br><span class="line">    AdvOtherConfigFlag on;</span><br><span class="line">    prefix 2001:192:168:99::/64</span><br><span class="line">    &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">        AdvRouterAddr off;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt;/etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">authoritative;</span><br><span class="line">default-lease-time 14400;</span><br><span class="line">max-lease-time 86400;</span><br><span class="line">log-facility local7;</span><br><span class="line">subnet6 2001:192:168:99::/64 &#123;</span><br><span class="line">    option dhcp6.name-servers 2001:4860:4860::8888, 2001:4860:4860::8844;</span><br><span class="line">    option dhcp6.domain-search &quot;quqi.com&quot;;</span><br><span class="line">    range6 2001:192:168:99::100 2001:192:168:99::199;</span><br><span class="line">    range6 2001:192:168:99::/64 temporary;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="bastion上安装radvd产生的后果"><a href="#bastion上安装radvd产生的后果" class="headerlink" title="bastion上安装radvd产生的后果"></a>bastion上安装radvd产生的后果</h2><p>bastion是openstack over openstack测试环境中underlying openstack提供的一台虚机, 用于安装juju继续部署上层openstack.<br>忽然在bastion上运行juju add-model或者juju deploy偶尔(不是次次)将会出现下列问题:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ERROR failed to create environ: authentication failed.: authentication failed</span><br><span class="line">caused by: requesting token: failed executing the request http://10.230.19.53:5000/v3/auth/tokens</span><br><span class="line">caused by: Post http://10.230.19.53:5000/v3/auth/tokens: dial tcp 10.230.19.53:5000: i/o timeout</span><br></pre></td></tr></table></figure></p>
<p>刚开始怀疑snap会自动升级juju版本到最新版本的原因, 其实不是. 接着发现从bastion连controller (juju ssh 0 -m controller)时偶尔会断线, 接着使用下列命令发现偶尔有timeout出现确认了这个假设.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">while true; do nc -w 1 -vz 10.230.19.53 5000; sleep 1; done</span><br></pre></td></tr></table></figure></p>
<p>接着在underlying openstack中看到了下列日志:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1000s of [484018.924930] IPv6: qr-0166579a-c8: IPv6 duplicate address 2001:192:168:99:f816:3eff:fec9:783 used by fa:16:3e:c9:07:83 detected!</span><br></pre></td></tr></table></figure></p>
<p>才得知是在bastion上运行了radvd的原因, 一种原因是tenant network (zhhuabj_admin_net)做了HA的, 各vrrp节点上的keepalived由于没有配置这个未被管理的IPv6网段, 所以各vrrp节点上都被分配了相同的IPv6地址(2001:192:168:99:f816:3eff:fec9:783), 这样会引起keepalived不快会发生迁移导致tenant网络不稳定. 解决办法设想的是再创建一个non-HA的tenant network, 然后在这个network上开一台虚机上跑radvd, 上层的openstack环境也使用这个network.<br>但这里似乎不是这原因, 就是bastion上分配了ipv6地址导致连juju时ipv4/ipv6 fallback似乎有点问题导致网络时而中断.</p>
<p>另外, security group会禁止在虚机上提供DHCPv6服务(禁止从547到546的traffic),也有MAC/IP匹配防欺骗的rules等. 所以如果想使用这个openstack-over-openstack环境上做openstack使用外部stateless router的实验的话, 最好通过底层juju的use-default-secgroup=false (<a href="https://github.com/juju/juju/blob/2.5/provider/openstack/config.go#L20)禁用底层的security" target="_blank" rel="external">https://github.com/juju/juju/blob/2.5/provider/openstack/config.go#L20)禁用底层的security</a> group.</p>
<p>之前还遇到了一个在bastion上安装radvd造成无法登录bastion的问题, 那是因为在l3-agent上分配了两个网卡, 并且将这两个网卡都plug进了一个网桥中, 结果这个网卡从radvd处发生广播风暴导致无法登录bastion.</p>
<h2 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h2><p>用户想根据外部物理IPv6 stateless router定义的IPv6网络, 虚机分配了IP, 但是网卡上去没配置.<br>下面我们在一个openstack over openstack环境上模拟这种测试.<br>首先, 我们不能直接在bastion上安装radvd, 因为这会导致basion上也分配到IPv6后造成bastion和juju通信有问题. 所以想要在openstack over openstack环境上继续安装radvd模拟外部路由器的话需要做特殊处理. 那就是创建一个单独的ipv6 tenant router, 在这个router里创建一个虚机安装radvd, 并且在上层openstack环境里使用flat定义IPv6网络(这样它就和radvd在同一个IPv6网络了).<br>1, 第一步, 需要创建一个单独的router, 并且要确保定义network时禁用underlying的security group.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">source ~/novarc</span><br><span class="line">#openstack router create --centralized --no-ha --description &quot;for radvd&quot; zhhuabj_router_radvd</span><br><span class="line">openstack router create zhhuabj_router_radvd</span><br><span class="line"># remember to disable security group for underlying openstack network</span><br><span class="line">openstack network create --disable-port-security radvd-net</span><br><span class="line">openstack subnet create --subnet-range 10.10.0.0/24 --network radvd-net --allocation-pool start=10.10.0.50,end=10.10.0.100 --gateway 10.10.0.1 radvd-subnet</span><br><span class="line">openstack router add subnet zhhuabj_router_radvd radvd-subnet</span><br><span class="line">openstack router set --external-gateway ext_net zhhuabj_router_radvd</span><br></pre></td></tr></table></figure></p>
<p>2, 第二步, 创建一个虚机安装radvd来模拟外部路由器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">source ~/novarc</span><br><span class="line">openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">openstack server create --image auto-sync/ubuntu-bionic-18.04-amd64-server-20190122-disk1.img --flavor m1.small --key-name mykey --network=radvd-net ip6router</span><br><span class="line">openstack floating ip create ext_net</span><br><span class="line">openstack server add floating ip ip6router 10.230.65.104</span><br></pre></td></tr></table></figure></p>
<p>注意, 这里虽然做的是stateless IPv6的实验, 但这里并不需要安装DHCPv6服务器, 因为openstack已经帮我们创建好了:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nobody   22883     1  0 06:45 ?        00:00:00 dnsmasq --no-hosts --no-resolv --strict-order --except-interface=lo --pid-file=/var/lib/neutron/dhcp/0aed25cf-b578-460d-9f4c-10d2fbe40179/pid --dhcp-hostsfile=/var/lib/neutron/dhcp/0aed25cf-b578-460d-9f4c-10d2fbe40179/host --addn-hosts=/var/lib/neutron/dhcp/0aed25cf-b578-460d-9f4c-10d2fbe40179/addn_hosts --dhcp-optsfile=/var/lib/neutron/dhcp/0aed25cf-b578-460d-9f4c-10d2fbe40179/opts --dhcp-leasefile=/var/lib/neutron/dhcp/0aed25cf-b578-460d-9f4c-10d2fbe40179/leases --dhcp-match=set:ipxe,175 --bind-interfaces --interface=ns-9b88221a-86 --dhcp-range=set:tag0,2001:192:168:99::,static,64,86400s --dhcp-option-force=option:mtu,1500 --dhcp-lease-max=16777216 --conf-file=/etc/neutron/dnsmasq.conf --domain=openstacklocal</span><br><span class="line">ubuntu@juju-a09725-xenial-mitaka-5:~$ sudo cat /var/lib/neutron/dhcp/0aed25cf-b578-460d-9f4c-10d2fbe40179/opts</span><br><span class="line">tag:tag0,option6:domain-search,openstacklocalubuntu@juju-a09725-xenial-mitaka-5:~$ sudo cat /var/lib/neutron/dhcp/0aed25cf-b578-460d-9f4c-10d2fbe40179/addn_hosts</span><br><span class="line">2001:192:168:99:f816:3eff:fe1f:95ba	host-2001-192-168-99-f816-3eff-fe1f-95ba.openstacklocal host-2001-192-168-99-f816-3eff-fe1f-95ba</span><br><span class="line">2001:192:168:99:f816:3eff:fe6f:121f	host-2001-192-168-99-f816-3eff-fe6f-121f.openstacklocal host-2001-192-168-99-f816-3eff-fe6f-121f</span><br></pre></td></tr></table></figure></p>
<p>下面为了知识完备性, 如果一定要自己去创建外部Stateless DHCPv6的话, 可以这样:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y isc-dhcp-server</span><br><span class="line">sudo bash -c &apos;cat &gt; /etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">default-lease-time 600;</span><br><span class="line">max-lease-time 7200;</span><br><span class="line">log-facility local7;</span><br><span class="line">option dhcp6.name-servers 2001:4860:4860::8888;</span><br><span class="line">option dhcp6.domain-search &quot;&quot;;</span><br><span class="line">subnet6 2001:192:168:99::/64 &#123;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo service isc-dhcp-server6 restart</span><br></pre></td></tr></table></figure></p>
<p>第三步, 创建上层openstack<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./generate-bundle.sh --series xenial --release mitaka</span><br><span class="line">juju add-model xenial-mitaka</span><br><span class="line">juju deploy ./b/openstack.yaml</span><br><span class="line">~/stsstack-bundles/openstack/novarc</span><br></pre></td></tr></table></figure></p>
<p>第四步, 因为上层openstack环境需要定义flat network, 所以它实际使用了br-data, 那么需要为计算节点与网络节点的br-data添加一个外部网络.<br>ens3(VM) tap55f99960-ba(compute) -&gt; qbr55f99960-ba -&gt; qvb55f99960-ba(qbr) -&gt; qvo55f99960-ba(br-int) -&gt; br-data -&gt; ens7 - &gt; external<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">source ~/novarc</span><br><span class="line">nova interface-attach $(nova list |grep $(juju ssh neutron-gateway/0 -- hostname) |awk &apos;&#123;print $2&#125;&apos;) --net-id=$(neutron net-show radvd-net -c id -f value)</span><br><span class="line">juju ssh neutron-gateway/0 -- sudo ovs-vsctl add-port br-data ens7</span><br><span class="line">juju ssh neutron-gateway/0 -- sudo ifconfig ens7 up</span><br><span class="line">nova interface-attach $(nova list |grep $(juju ssh nova-compute/0 -- hostname) |awk &apos;&#123;print $2&#125;&apos;) --net-id=$(neutron net-show radvd-net -c id -f value)</span><br><span class="line">juju ssh nova-compute/0 -- sudo ovs-vsctl add-port br-data ens7</span><br><span class="line">juju ssh nova-compute/0 -- sudo ifconfig ens7 up</span><br><span class="line"></span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">neutron net-create --provider:network_type flat --provider:physical_network physnet1 --router:external=True ipv6_net</span><br><span class="line">neutron subnet-create ipv6_net --name ipv6_subnet --ip_version 6 --ipv6_address_mode dhcpv6-stateless --allocation-pool start=2001:192:168:99::2,end=2001:192:168:99:ffff:ffff:ffff:ffff 2001:192:168:99::/64</span><br><span class="line">openstack router create myrouter</span><br><span class="line">openstack router add subnet myrouter ipv6_subnet</span><br><span class="line">#openstack router set --external-gateway ext_net myrouter</span><br></pre></td></tr></table></figure></p>
<p>第五步,创建一个虚机用以充当IPv6 client, 这里注意一定要为Ipv6定义flat的网络, 另外, 额外定义了一个ipv4网络目的是为了让虚机完成metadata功能我们容易ssh进去调试.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">neutron net-create --provider:network_type flat --provider:physical_network physnet1 --router:external=True ipv6_net</span><br><span class="line">neutron subnet-create ipv6_net --name ipv6_subnet --ip_version 6 --ipv6_address_mode dhcpv6-stateless --allocation-pool start=2001:192:168:99::2,end=2001:192:168:99:ffff:ffff:ffff:ffff 2001:192:168:99::/64</span><br><span class="line">openstack router create myrouter</span><br><span class="line">openstack router add subnet myrouter ipv6_subnet</span><br><span class="line">#openstack router set --external-gateway ext_net myrouter</span><br><span class="line"></span><br><span class="line"># create another ipv4 network to make metadata feature pass</span><br><span class="line">openstack network create ipv4-net</span><br><span class="line">openstack subnet create --subnet-range 10.11.0.0/24 --network ipv4-net --allocation-pool start=10.11.0.50,end=10.11.0.100 --gateway 10.11.0.1 ipv4-subnet</span><br><span class="line">openstack router add subnet myrouter ipv4-subnet</span><br><span class="line"></span><br><span class="line">openstack image create --disk-format=raw --container-format=bare xenial --file /home/ubuntu/images/xenial-server-cloudimg-amd64-disk1.img</span><br><span class="line">openstack security group rule create default --protocol tcp --remote-ip 0.0.0.0/0 --dst-port 22</span><br><span class="line">openstack security group rule create default --protocol icmp --remote-ip 0.0.0.0/0</span><br><span class="line">openstack security group rule list default</span><br><span class="line">openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">openstack server create --image xenial --flavor m1.small --key-name mykey --network=ipv4-net --network=ipv6_net ip6client</span><br></pre></td></tr></table></figure></p>
<p>第六步, 虚机内部配置调试<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">juju scp ~/.ssh/id_rsa* neutron-gateway/0:/home/ubuntu/.ssh/</span><br><span class="line">juju ssh neutron-gateway/0</span><br><span class="line">sudo ip netns exec qrouter-f6d50237-add3-4bda-b848-861bfa68c7a3 ssh -i ~/.ssh/id_rsa ubuntu@10.11.0.51 -v</span><br><span class="line"></span><br><span class="line">sudo vim /etc/network/interfaces.d/50-cloud-init.cfg</span><br><span class="line">iface ens3 inet6 auto</span><br><span class="line">    up echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br><span class="line">    up sleep 5</span><br><span class="line">    autoconf 1</span><br><span class="line">    accept_ra 2</span><br><span class="line">    dhcp 1</span><br><span class="line"></span><br><span class="line">sudo dhclient -6 -d ens3</span><br><span class="line">#sudo ifup --force --verbose ens3</span><br><span class="line"></span><br><span class="line"># debug, the fe80 address of ipv6 client is fe80::f816:3eff:fe6f:121f</span><br><span class="line">sudo tcpdump -ni ens3 ip6 host fe80::f816:3eff:fe6f:121f</span><br></pre></td></tr></table></figure></p>
<p>注意, 在给br-data添加外部网卡及停用外部DHCPv6(这样使用openstack dnsmasq提供的IPv6)后, 所以除ovs网桥以外的网卡(ens3(VM) tap55f99960-ba(compute) -&gt; qbr55f99960-ba -&gt; qvb55f99960-ba(qbr) -&gt; qvo55f99960-ba(br-int) -&gt; br-data -&gt; ens7 - &gt; external)均可以成功抓到下列包(注: 在ovs bridge上抓到的包没有dhcp6 advertise, 但这似乎没有影响到整体功能, 可能就是对ovs bridge使用tcpdump看不到dhcp6 advertise吧):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">07:44:01.209860 IP6 fe80::f816:3eff:fe6f:121f.546 &gt; ff02::1:2.547: dhcp6 solicit</span><br><span class="line">07:44:01.213087 IP6 fe80::f816:3eff:fe1f:95ba.547 &gt; fe80::f816:3eff:fe6f:121f.546: dhcp6 advertise</span><br><span class="line">07:44:02.294432 IP6 fe80::f816:3eff:fe6f:121f.546 &gt; ff02::1:2.547: dhcp6 solicit</span><br><span class="line">07:44:02.296687 IP6 fe80::f816:3eff:fe1f:95ba.547 &gt; fe80::f816:3eff:fe6f:121f.546: dhcp6 advertise</span><br><span class="line">07:44:04.399586 IP6 fe80::f816:3eff:fe6f:121f.546 &gt; ff02::1:2.547: dhcp6 solicit</span><br><span class="line">07:44:04.401203 IP6 fe80::f816:3eff:fe1f:95ba.547 &gt; fe80::f816:3eff:fe6f:121f.546: dhcp6 advertise</span><br><span class="line">07:44:05.035467 IP6 :: &gt; ff02::1:ffe0:75b0: ICMP6, neighbor solicitation, who has 2001:192:168:99:f816:3eff:fee0:75b0, length 32</span><br><span class="line">07:44:05.036112 IP6 2001:192:168:99:f816:3eff:fee0:75b0 &gt; ff02::1: ICMP6, neighbor advertisement, tgt is 2001:192:168:99:f816:3eff:fee0:75b0, length 32</span><br><span class="line">07:44:08.665018 IP6 fe80::f816:3eff:fe6f:121f.546 &gt; ff02::1:2.547: dhcp6 solicit</span><br><span class="line">07:44:08.666282 IP6 fe80::f816:3eff:fe1f:95ba.547 &gt; fe80::f816:3eff:fe6f:121f.546: dhcp6 advertise</span><br><span class="line">07:44:13.668128 IP6 fe80::f816:3eff:fe1f:95ba &gt; fe80::f816:3eff:fe6f:121f: ICMP6, neighbor solicitation, who has fe80::f816:3eff:fe6f:121f, length 32</span><br><span class="line">07:44:13.668187 IP6 fe80::f816:3eff:fe6f:121f &gt; fe80::f816:3eff:fe1f:95ba: ICMP6, neighbor advertisement, tgt is fe80::f816:3eff:fe6f:121f, length 24</span><br></pre></td></tr></table></figure></p>
<p>测试结果:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@ip6client:~$ ip addr show ens3 |grep inet6</span><br><span class="line">    inet6 2001:192:168:99:f816:3eff:fe6f:121f/64 scope global mngtmpaddr dynamic</span><br><span class="line">    inet6 fe80::f816:3eff:fe6f:121f/64 scope link</span><br><span class="line">ubuntu@ip6client:~$ ping6 2001:192:168:99:f816:3eff:fe1f:95ba</span><br><span class="line">PING 2001:192:168:99:f816:3eff:fe1f:95ba(2001:192:168:99:f816:3eff:fe1f:95ba) 56 data bytes</span><br><span class="line">64 bytes from 2001:192:168:99:f816:3eff:fe1f:95ba: icmp_seq=1 ttl=64 time=3.80 ms</span><br><span class="line">ubuntu@juju-a09725-xenial-mitaka-5:~$ sudo ip netns exec qdhcp-0aed25cf-b578-460d-9f4c-10d2fbe40179 ping6 2001:192:168:99:f816:3eff:fe6f:121f</span><br><span class="line">PING 2001:192:168:99:f816:3eff:fe6f:121f(2001:192:168:99:f816:3eff:fe6f:121f) 56 data bytes</span><br><span class="line">64 bytes from 2001:192:168:99:f816:3eff:fe6f:121f: icmp_seq=1 ttl=64 time=2.97 ms</span><br></pre></td></tr></table></figure></p>
<h2 id="附件-防火墙及流表"><a href="#附件-防火墙及流表" class="headerlink" title="附件 - 防火墙及流表"></a>附件 - 防火墙及流表</h2><p>实际上, security group的默认规则是不影响虚机使用外部IPv6路由器获取RA的.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br></pre></td><td class="code"><pre><span class="line">root@juju-a09725-xenial-mitaka-7:~# sudo ovs-ofctl dump-flows br-data</span><br><span class="line">NXST_FLOW reply (xid=0x4):</span><br><span class="line"> cookie=0xa53ad21731e554e6, duration=10484.383s, table=0, n_packets=247, n_bytes=25966, idle_age=2619, priority=4,in_port=1,dl_vlan=2 actions=strip_vlan,NORMAL</span><br><span class="line"> cookie=0xa53ad21731e554e6, duration=168851.241s, table=0, n_packets=39, n_bytes=4126, idle_age=7795, hard_age=65534, priority=2,in_port=1 actions=drop</span><br><span class="line"> cookie=0xa53ad21731e554e6, duration=168852.108s, table=0, n_packets=1803, n_bytes=173620, idle_age=18, hard_age=65534, priority=0 actions=NORMAL</span><br><span class="line"></span><br><span class="line">root@juju-a09725-xenial-mitaka-7:~# sudo ovs-ofctl dump-flows br-int</span><br><span class="line">NXST_FLOW reply (xid=0x4):</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10493.212s, table=0, n_packets=0, n_bytes=0, idle_age=10493, priority=10,icmp6,in_port=3,icmp_type=136 actions=resubmit(,24)</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10487.634s, table=0, n_packets=39, n_bytes=3058, idle_age=2630, priority=10,icmp6,in_port=4,icmp_type=136 actions=resubmit(,24)</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10492.928s, table=0, n_packets=384, n_bytes=16128, idle_age=26, priority=10,arp,in_port=3 actions=resubmit(,24)</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10487.502s, table=0, n_packets=0, n_bytes=0, idle_age=10491, priority=10,arp,in_port=4 actions=resubmit(,24)</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=168862.878s, table=0, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=2,in_port=1 actions=drop</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10493.495s, table=0, n_packets=31789, n_bytes=2827279, idle_age=0, priority=9,in_port=3 actions=resubmit(,25)</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10488.022s, table=0, n_packets=208, n_bytes=22908, idle_age=2632, priority=9,in_port=4 actions=resubmit(,25)</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10495.768s, table=0, n_packets=1803, n_bytes=173620, idle_age=30, priority=3,in_port=1,vlan_tci=0x0000 actions=mod_vlan_vid:2,NORMAL</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=168864.656s, table=0, n_packets=32596, n_bytes=2637470, idle_age=0, hard_age=65534, priority=0 actions=NORMAL</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=168864.535s, table=23, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=0 actions=drop</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10493.351s, table=24, n_packets=0, n_bytes=0, idle_age=10493, priority=2,icmp6,in_port=3,icmp_type=136,nd_target=fe80::f816:3eff:feb9:b96a actions=NORMAL</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10487.892s, table=24, n_packets=3, n_bytes=234, idle_age=2778, priority=2,icmp6,in_port=4,icmp_type=136,nd_target=2001:192:168:99:f816:3eff:fe6f:121f actions=NORMAL</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10487.762s, table=24, n_packets=36, n_bytes=2824, idle_age=2630, priority=2,icmp6,in_port=4,icmp_type=136,nd_target=fe80::f816:3eff:fe6f:121f actions=NORMAL</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10493.068s, table=24, n_packets=384, n_bytes=16128, idle_age=26, priority=2,arp,in_port=3,arp_spa=10.11.0.51 actions=resubmit(,25)</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=168864.420s, table=24, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=0 actions=drop</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10493.780s, table=25, n_packets=32173, n_bytes=2843407, idle_age=0, priority=2,in_port=3,dl_src=fa:16:3e:b9:b9:6a actions=NORMAL</span><br><span class="line"> cookie=0x8a5790f2d6b535e6, duration=10488.305s, table=25, n_packets=208, n_bytes=22908, idle_age=2632, priority=2,in_port=4,dl_src=fa:16:3e:6f:12:1f actions=NORMAL</span><br><span class="line"></span><br><span class="line">root@juju-a09725-xenial-mitaka-7:~# ip6tables-save</span><br><span class="line"># Generated by ip6tables-save v1.6.0 on Fri Jan 25 09:47:42 2019</span><br><span class="line">*raw</span><br><span class="line">:PREROUTING ACCEPT [3823:312730]</span><br><span class="line">:OUTPUT ACCEPT [47:3376]</span><br><span class="line">:neutron-openvswi-OUTPUT - [0:0]</span><br><span class="line">:neutron-openvswi-PREROUTING - [0:0]</span><br><span class="line">-A PREROUTING -j neutron-openvswi-PREROUTING</span><br><span class="line">-A OUTPUT -j neutron-openvswi-OUTPUT</span><br><span class="line">-A neutron-openvswi-PREROUTING -m physdev --physdev-in qvb55f99960-ba -j CT --zone 2</span><br><span class="line">-A neutron-openvswi-PREROUTING -m physdev --physdev-in tap55f99960-ba -j CT --zone 2</span><br><span class="line">-A neutron-openvswi-PREROUTING -m physdev --physdev-in qvbb2d4fa47-0e -j CT --zone 1</span><br><span class="line">-A neutron-openvswi-PREROUTING -m physdev --physdev-in tapb2d4fa47-0e -j CT --zone 1</span><br><span class="line">COMMIT</span><br><span class="line"># Completed on Fri Jan 25 09:47:42 2019</span><br><span class="line"># Generated by ip6tables-save v1.6.0 on Fri Jan 25 09:47:42 2019</span><br><span class="line">*mangle</span><br><span class="line">:PREROUTING ACCEPT [3852:314932]</span><br><span class="line">:INPUT ACCEPT [288:24080]</span><br><span class="line">:FORWARD ACCEPT [2054:171782]</span><br><span class="line">:OUTPUT ACCEPT [93:6580]</span><br><span class="line">:POSTROUTING ACCEPT [1588:128442]</span><br><span class="line">:neutron-openvswi-FORWARD - [0:0]</span><br><span class="line">:neutron-openvswi-INPUT - [0:0]</span><br><span class="line">:neutron-openvswi-OUTPUT - [0:0]</span><br><span class="line">:neutron-openvswi-POSTROUTING - [0:0]</span><br><span class="line">:neutron-openvswi-PREROUTING - [0:0]</span><br><span class="line">:neutron-openvswi-scope - [0:0]</span><br><span class="line">-A PREROUTING -j neutron-openvswi-PREROUTING</span><br><span class="line">-A INPUT -j neutron-openvswi-INPUT</span><br><span class="line">-A FORWARD -j neutron-openvswi-FORWARD</span><br><span class="line">-A OUTPUT -j neutron-openvswi-OUTPUT</span><br><span class="line">-A POSTROUTING -j neutron-openvswi-POSTROUTING</span><br><span class="line">-A neutron-openvswi-PREROUTING -j neutron-openvswi-scope</span><br><span class="line">-A neutron-openvswi-PREROUTING -m connmark ! --mark 0x0/0xffff0000 -j CONNMARK --restore-mark --nfmask 0xffff0000 --ctmask 0xffff0000</span><br><span class="line">COMMIT</span><br><span class="line"># Completed on Fri Jan 25 09:47:42 2019</span><br><span class="line"># Generated by ip6tables-save v1.6.0 on Fri Jan 25 09:47:42 2019</span><br><span class="line">*filter</span><br><span class="line">:INPUT ACCEPT [186:15512]</span><br><span class="line">:FORWARD ACCEPT [0:0]</span><br><span class="line">:OUTPUT ACCEPT [7:776]</span><br><span class="line">:neutron-filter-top - [0:0]</span><br><span class="line">:neutron-openvswi-FORWARD - [0:0]</span><br><span class="line">:neutron-openvswi-INPUT - [0:0]</span><br><span class="line">:neutron-openvswi-OUTPUT - [0:0]</span><br><span class="line">:neutron-openvswi-i55f99960-b - [0:0]</span><br><span class="line">:neutron-openvswi-ib2d4fa47-0 - [0:0]</span><br><span class="line">:neutron-openvswi-local - [0:0]</span><br><span class="line">:neutron-openvswi-o55f99960-b - [0:0]</span><br><span class="line">:neutron-openvswi-ob2d4fa47-0 - [0:0]</span><br><span class="line">:neutron-openvswi-s55f99960-b - [0:0]</span><br><span class="line">:neutron-openvswi-scope - [0:0]</span><br><span class="line">:neutron-openvswi-sg-chain - [0:0]</span><br><span class="line">:neutron-openvswi-sg-fallback - [0:0]</span><br><span class="line">-A INPUT -j neutron-openvswi-INPUT</span><br><span class="line">-A FORWARD -j neutron-filter-top</span><br><span class="line">-A FORWARD -j neutron-openvswi-FORWARD</span><br><span class="line">-A OUTPUT -j neutron-filter-top</span><br><span class="line">-A OUTPUT -j neutron-openvswi-OUTPUT</span><br><span class="line">-A neutron-filter-top -j neutron-openvswi-local</span><br><span class="line">-A neutron-openvswi-FORWARD -j neutron-openvswi-scope</span><br><span class="line">-A neutron-openvswi-FORWARD -m physdev --physdev-out tap55f99960-ba --physdev-is-bridged -m comment --comment &quot;Direct traffic from the VM interface to the security group chain.&quot; -j neutron-openvswi-sg-chain</span><br><span class="line">-A neutron-openvswi-FORWARD -m physdev --physdev-in tap55f99960-ba --physdev-is-bridged -m comment --comment &quot;Direct traffic from the VM interface to the security group chain.&quot; -j neutron-openvswi-sg-chain</span><br><span class="line">-A neutron-openvswi-FORWARD -m physdev --physdev-out tapb2d4fa47-0e --physdev-is-bridged -m comment --comment &quot;Direct traffic from the VM interface to the security group chain.&quot; -j neutron-openvswi-sg-chain</span><br><span class="line">-A neutron-openvswi-FORWARD -m physdev --physdev-in tapb2d4fa47-0e --physdev-is-bridged -m comment --comment &quot;Direct traffic from the VM interface to the security group chain.&quot; -j neutron-openvswi-sg-chain</span><br><span class="line">-A neutron-openvswi-INPUT -m physdev --physdev-in tap55f99960-ba --physdev-is-bridged -m comment --comment &quot;Direct incoming traffic from VM to the security group chain.&quot; -j neutron-openvswi-o55f99960-b</span><br><span class="line">-A neutron-openvswi-INPUT -m physdev --physdev-in tapb2d4fa47-0e --physdev-is-bridged -m comment --comment &quot;Direct incoming traffic from VM to the security group chain.&quot; -j neutron-openvswi-ob2d4fa47-0</span><br><span class="line">-A neutron-openvswi-i55f99960-b -p ipv6-icmp -m icmp6 --icmpv6-type 130 -j RETURN</span><br><span class="line">-A neutron-openvswi-i55f99960-b -p ipv6-icmp -m icmp6 --icmpv6-type 131 -j RETURN</span><br><span class="line">-A neutron-openvswi-i55f99960-b -p ipv6-icmp -m icmp6 --icmpv6-type 132 -j RETURN</span><br><span class="line">-A neutron-openvswi-i55f99960-b -p ipv6-icmp -m icmp6 --icmpv6-type 135 -j RETURN</span><br><span class="line">-A neutron-openvswi-i55f99960-b -p ipv6-icmp -m icmp6 --icmpv6-type 136 -j RETURN</span><br><span class="line">-A neutron-openvswi-i55f99960-b -m state --state RELATED,ESTABLISHED -m comment --comment &quot;Direct packets associated with a known session to the RETURN chain.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-i55f99960-b -s fe80::f816:3eff:fe1f:95ba/128 -p udp -m udp --sport 547 -m udp --dport 546 -j RETURN</span><br><span class="line">-A neutron-openvswi-i55f99960-b -m set --match-set NIPv6e50abcfd-5bdb-462d-aa21- src -j RETURN</span><br><span class="line">-A neutron-openvswi-i55f99960-b -p ipv6-icmp -j RETURN</span><br><span class="line">-A neutron-openvswi-i55f99960-b -m state --state INVALID -m comment --comment &quot;Drop packets that appear related to an existing connection (e.g. TCP ACK/FIN) but do not have an entry in conntrack.&quot; -j DROP</span><br><span class="line">-A neutron-openvswi-i55f99960-b -m comment --comment &quot;Send unmatched traffic to the fallback chain.&quot; -j neutron-openvswi-sg-fallback</span><br><span class="line">-A neutron-openvswi-ib2d4fa47-0 -p ipv6-icmp -m icmp6 --icmpv6-type 130 -j RETURN</span><br><span class="line">-A neutron-openvswi-ib2d4fa47-0 -p ipv6-icmp -m icmp6 --icmpv6-type 131 -j RETURN</span><br><span class="line">-A neutron-openvswi-ib2d4fa47-0 -p ipv6-icmp -m icmp6 --icmpv6-type 132 -j RETURN</span><br><span class="line">-A neutron-openvswi-ib2d4fa47-0 -p ipv6-icmp -m icmp6 --icmpv6-type 135 -j RETURN</span><br><span class="line">-A neutron-openvswi-ib2d4fa47-0 -p ipv6-icmp -m icmp6 --icmpv6-type 136 -j RETURN</span><br><span class="line">-A neutron-openvswi-ib2d4fa47-0 -m state --state RELATED,ESTABLISHED -m comment --comment &quot;Direct packets associated with a known session to the RETURN chain.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-ib2d4fa47-0 -m set --match-set NIPv6e50abcfd-5bdb-462d-aa21- src -j RETURN</span><br><span class="line">-A neutron-openvswi-ib2d4fa47-0 -p ipv6-icmp -j RETURN</span><br><span class="line">-A neutron-openvswi-ib2d4fa47-0 -m state --state INVALID -m comment --comment &quot;Drop packets that appear related to an existing connection (e.g. TCP ACK/FIN) but do not have an entry in conntrack.&quot; -j DROP</span><br><span class="line">-A neutron-openvswi-ib2d4fa47-0 -m comment --comment &quot;Send unmatched traffic to the fallback chain.&quot; -j neutron-openvswi-sg-fallback</span><br><span class="line">-A neutron-openvswi-o55f99960-b -s ::/128 -d ff02::/16 -p ipv6-icmp -m icmp6 --icmpv6-type 131 -m comment --comment &quot;Allow IPv6 ICMP traffic.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-o55f99960-b -s ::/128 -d ff02::/16 -p ipv6-icmp -m icmp6 --icmpv6-type 135 -m comment --comment &quot;Allow IPv6 ICMP traffic.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-o55f99960-b -s ::/128 -d ff02::/16 -p ipv6-icmp -m icmp6 --icmpv6-type 143 -m comment --comment &quot;Allow IPv6 ICMP traffic.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-o55f99960-b -j neutron-openvswi-s55f99960-b</span><br><span class="line">-A neutron-openvswi-o55f99960-b -p ipv6-icmp -m icmp6 --icmpv6-type 134 -m comment --comment &quot;Drop IPv6 Router Advts from VM Instance.&quot; -j DROP</span><br><span class="line">-A neutron-openvswi-o55f99960-b -p ipv6-icmp -m comment --comment &quot;Allow IPv6 ICMP traffic.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-o55f99960-b -p udp -m udp --sport 546 -m udp --dport 547 -m comment --comment &quot;Allow DHCP client traffic.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-o55f99960-b -p udp -m udp --sport 547 -m udp --dport 546 -m comment --comment &quot;Prevent DHCP Spoofing by VM.&quot; -j DROP</span><br><span class="line">-A neutron-openvswi-o55f99960-b -m state --state RELATED,ESTABLISHED -m comment --comment &quot;Direct packets associated with a known session to the RETURN chain.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-o55f99960-b -j RETURN</span><br><span class="line">-A neutron-openvswi-o55f99960-b -m state --state INVALID -m comment --comment &quot;Drop packets that appear related to an existing connection (e.g. TCP ACK/FIN) but do not have an entry in conntrack.&quot; -j DROP</span><br><span class="line">-A neutron-openvswi-o55f99960-b -m comment --comment &quot;Send unmatched traffic to the fallback chain.&quot; -j neutron-openvswi-sg-fallback</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -s ::/128 -d ff02::/16 -p ipv6-icmp -m icmp6 --icmpv6-type 131 -m comment --comment &quot;Allow IPv6 ICMP traffic.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -s ::/128 -d ff02::/16 -p ipv6-icmp -m icmp6 --icmpv6-type 135 -m comment --comment &quot;Allow IPv6 ICMP traffic.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -s ::/128 -d ff02::/16 -p ipv6-icmp -m icmp6 --icmpv6-type 143 -m comment --comment &quot;Allow IPv6 ICMP traffic.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -p ipv6-icmp -m icmp6 --icmpv6-type 134 -m comment --comment &quot;Drop IPv6 Router Advts from VM Instance.&quot; -j DROP</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -p ipv6-icmp -m comment --comment &quot;Allow IPv6 ICMP traffic.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -p udp -m udp --sport 546 -m udp --dport 547 -m comment --comment &quot;Allow DHCP client traffic.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -p udp -m udp --sport 547 -m udp --dport 546 -m comment --comment &quot;Prevent DHCP Spoofing by VM.&quot; -j DROP</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -m state --state RELATED,ESTABLISHED -m comment --comment &quot;Direct packets associated with a known session to the RETURN chain.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -j RETURN</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -m state --state INVALID -m comment --comment &quot;Drop packets that appear related to an existing connection (e.g. TCP ACK/FIN) but do not have an entry in conntrack.&quot; -j DROP</span><br><span class="line">-A neutron-openvswi-ob2d4fa47-0 -m comment --comment &quot;Send unmatched traffic to the fallback chain.&quot; -j neutron-openvswi-sg-fallback</span><br><span class="line">-A neutron-openvswi-s55f99960-b -s 2001:192:168:99:f816:3eff:fe6f:121f/128 -m mac --mac-source FA:16:3E:6F:12:1F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-s55f99960-b -s fe80::f816:3eff:fe6f:121f/128 -m mac --mac-source FA:16:3E:6F:12:1F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-s55f99960-b -m comment --comment &quot;Drop traffic without an IP/MAC allow rule.&quot; -j DROP</span><br><span class="line">-A neutron-openvswi-sg-chain -m physdev --physdev-out tap55f99960-ba --physdev-is-bridged -m comment --comment &quot;Jump to the VM specific chain.&quot; -j neutron-openvswi-i55f99960-b</span><br><span class="line">-A neutron-openvswi-sg-chain -m physdev --physdev-in tap55f99960-ba --physdev-is-bridged -m comment --comment &quot;Jump to the VM specific chain.&quot; -j neutron-openvswi-o55f99960-b</span><br><span class="line">-A neutron-openvswi-sg-chain -m physdev --physdev-out tapb2d4fa47-0e --physdev-is-bridged -m comment --comment &quot;Jump to the VM specific chain.&quot; -j neutron-openvswi-ib2d4fa47-0</span><br><span class="line">-A neutron-openvswi-sg-chain -m physdev --physdev-in tapb2d4fa47-0e --physdev-is-bridged -m comment --comment &quot;Jump to the VM specific chain.&quot; -j neutron-openvswi-ob2d4fa47-0</span><br><span class="line">-A neutron-openvswi-sg-chain -j ACCEPT</span><br><span class="line">-A neutron-openvswi-sg-fallback -m comment --comment &quot;Default drop rule for unmatched traffic.&quot; -j DROP</span><br><span class="line">COMMIT</span><br><span class="line"># Completed on Fri Jan 25 09:47:42 2019</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@juju-a09725-xenial-mitaka-7:~# ovs-vsctl show</span><br><span class="line">4c7ed97c-a113-48c5-840c-252bb0027f19</span><br><span class="line">    Bridge br-ex</span><br><span class="line">        Port br-ex</span><br><span class="line">            Interface br-ex</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-int</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;qvob2d4fa47-0e&quot;</span><br><span class="line">            tag: 1</span><br><span class="line">            Interface &quot;qvob2d4fa47-0e&quot;</span><br><span class="line">        Port &quot;qvo55f99960-ba&quot;</span><br><span class="line">            tag: 2</span><br><span class="line">            Interface &quot;qvo55f99960-ba&quot;</span><br><span class="line">        Port patch-tun</span><br><span class="line">            Interface patch-tun</span><br><span class="line"></span><br><span class="line">root@juju-a09725-xenial-mitaka-7:~# ip addr show</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8958 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:d5:28:84 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.5.0.4/16 brd 10.5.255.255 scope global ens3</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::f816:3eff:fed5:2884/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: fan-252: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8908 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 62:59:80:9b:95:91 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 252.0.4.1/8 scope global fan-252</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::6059:80ff:fe9b:9591/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: ftun0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8908 qdisc noqueue master fan-252 state UNKNOWN group default qlen 1000</span><br><span class="line">    link/ether 62:59:80:9b:95:91 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::6059:80ff:fe9b:9591/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">7: ovs-system: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/ether 32:5b:19:f0:ed:6d brd ff:ff:ff:ff:ff:ff</span><br><span class="line">8: br-int: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1458 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/ether 62:64:d4:23:dd:43 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::6064:d4ff:fe23:dd43/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">9: br-ex: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/ether 66:87:20:0d:38:4e brd ff:ff:ff:ff:ff:ff</span><br><span class="line">10: br-data: &lt;BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/ether a2:e0:9f:bb:06:46 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 2001:192:168:99:a0e0:9fff:febb:646/64 scope global mngtmpaddr dynamic</span><br><span class="line">       valid_lft 82152sec preferred_lft 10152sec</span><br><span class="line">    inet6 fe80::a0e0:9fff:febb:646/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">11: br-tun: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/ether 1e:29:d4:32:d7:43 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::1c29:d4ff:fe32:d743/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">12: gre0@NONE: &lt;NOARP&gt; mtu 1476 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/gre 0.0.0.0 brd 0.0.0.0</span><br><span class="line">13: gretap0@NONE: &lt;BROADCAST,MULTICAST&gt; mtu 1462 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">14: gre_sys@NONE: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 65490 qdisc pfifo_fast master ovs-system state UNKNOWN group default qlen 1000</span><br><span class="line">    link/ether ae:90:21:f5:b5:8c brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::ac90:21ff:fef5:b58c/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">15: qbrb2d4fa47-0e: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1458 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether ae:48:8e:e0:62:fc brd ff:ff:ff:ff:ff:ff</span><br><span class="line">16: qvob2d4fa47-0e@qvbb2d4fa47-0e: &lt;BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP&gt; mtu 1458 qdisc noqueue master ovs-system state UP group default qlen 1000</span><br><span class="line">    link/ether 0a:4c:b6:39:72:ed brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::84c:b6ff:fe39:72ed/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">17: qvbb2d4fa47-0e@qvob2d4fa47-0e: &lt;BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP&gt; mtu 1458 qdisc noqueue master qbrb2d4fa47-0e state UP group default qlen 1000</span><br><span class="line">    link/ether ae:48:8e:e0:62:fc brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::ac48:8eff:fee0:62fc/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">18: qbr55f99960-ba: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether ce:fb:c8:4f:5f:cc brd ff:ff:ff:ff:ff:ff</span><br><span class="line">19: qvo55f99960-ba@qvb55f99960-ba: &lt;BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master ovs-system state UP group default qlen 1000</span><br><span class="line">    link/ether 1a:a0:dc:19:6c:e2 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::18a0:dcff:fe19:6ce2/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">20: qvb55f99960-ba@qvo55f99960-ba: &lt;BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master qbr55f99960-ba state UP group default qlen 1000</span><br><span class="line">    link/ether ce:fb:c8:4f:5f:cc brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::ccfb:c8ff:fe4f:5fcc/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">21: tapb2d4fa47-0e: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1458 qdisc pfifo_fast master qbrb2d4fa47-0e state UNKNOWN group default qlen 1000</span><br><span class="line">    link/ether fe:16:3e:b9:b9:6a brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::fc16:3eff:feb9:b96a/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">22: tap55f99960-ba: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master qbr55f99960-ba state UNKNOWN group default qlen 1000</span><br><span class="line">    link/ether fe:16:3e:6f:12:1f brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::fc16:3eff:fe6f:121f/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">23: ens7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master ovs-system state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:41:29:bf brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::f816:3eff:fe41:29bf/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-int&#125;</span><br><span class="line">        Port br-int</span><br><span class="line">            Interface br-int</span><br><span class="line">                type: internal</span><br><span class="line">        Port int-br-data</span><br><span class="line">            Interface int-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=phy-br-data&#125;</span><br><span class="line">    Bridge br-tun</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port patch-int</span><br><span class="line">            Interface patch-int</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-tun&#125;</span><br><span class="line">        Port &quot;gre-0a05000b&quot;</span><br><span class="line">            Interface &quot;gre-0a05000b&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.4&quot;, out_key=flow, remote_ip=&quot;10.5.0.11&quot;&#125;</span><br><span class="line">        Port br-tun</span><br><span class="line">            Interface br-tun</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-data</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;ens7&quot;</span><br><span class="line">            Interface &quot;ens7&quot;</span><br><span class="line">        Port phy-br-data</span><br><span class="line">            Interface phy-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=int-br-data&#125;</span><br><span class="line">        Port br-data</span><br><span class="line">            Interface br-data</span><br><span class="line">                type: internal</span><br><span class="line">    ovs_version: &quot;2.5.5&quot;</span><br></pre></td></tr></table></figure></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="http://asdkda.github.io/2016/02/05/ipv6/" target="_blank" rel="external">http://asdkda.github.io/2016/02/05/ipv6/</a><br>[2] <a href="http://tldp.org/HOWTO/html_single/Linux+IPv6-HOWTO/#idp57787920" target="_blank" rel="external">http://tldp.org/HOWTO/html_single/Linux+IPv6-HOWTO/#idp57787920</a><br>[3] <a href="https://jochen.kirstaetter.name/dhcpv6-ipv6-in-your-local-network/" target="_blank" rel="external">https://jochen.kirstaetter.name/dhcpv6-ipv6-in-your-local-network/</a><br>[4] <a href="https://www.slideshare.net/shixiongshang1/ipv6-case-study-v26" target="_blank" rel="external">https://www.slideshare.net/shixiongshang1/ipv6-case-study-v26</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">张华</p>
              <p class="site-description motion-element" itemprop="description">blog.csdn.net/quqi99</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">59</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张华</span>

  
</div>


  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
