<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="blog.csdn.net/quqi99">
<meta property="og:type" content="website">
<meta property="og:title" content="技术并艺术着">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="blog.csdn.net/quqi99">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="技术并艺术着">
<meta name="twitter:description" content="blog.csdn.net/quqi99">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/"/>





  <title>技术并艺术着</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">技术并艺术着</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">张华的技术博客 - blog.csdn.net/quqi99</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/09/在KVM中运行win10虚机/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/09/在KVM中运行win10虚机/" itemprop="url">在KVM中运行win10虚机</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-09T09:55:35+08:00">
                2020-11-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2015-12-22<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )<br>KVM默认不支持windows 10，需要做一些设置：<br>1, sudo usermod -a -G vboxusers hua<br>2, 修改下列配置使KVM支持windows 10所需的PAE、NX、SSE2特性。PAE支持32位处理器可以访问4GB以上物理内存功能版本的Windows，并且它是NX的先决条件。NX可让处理器帮助保护电脑免受恶意软件的攻击。SSE2（一项使用已久的关于处理器的标准）是一套由越来越多的第三方应用和驱动程序使用的指令集。<br>   cpu model: core2duo<br>   cpu features: nx=require<br>   nic: rtl8139 to e1000</p>
<p>在ubuntu上制作win 10 usb启动盘的工具：</p>
<p>sudo add-apt-repository ppa:gezakovacs/ppa<br>sudo apt-get update<br>sudo apt-get install unetbootin</p>
<p>后续的工作是采用SR-IOV与USB直通，待续。</p>
<p>20200603更新　－　virtualbox中安装win10</p>
<p>立刻仅支持windows所以需要一个windows虚机，ubuntu 20.04上的kvm安装win10报错一时半会解不了，换成virtualbox</p>
<p>安装　－　<a href="https://www.oracle.com/virtualization/technologies/vm/downloads/virtualbox-downloads.html#extpack" target="_blank" rel="external">https://www.oracle.com/virtualization/technologies/vm/downloads/virtualbox-downloads.html#extpack</a></p>
<p>在虚机中若想使用host上的摄像头，还得安装上面链接中的ExtPack, 这样在启动虚机之后在devices -&gt; webcams菜单就能使用host的摄像头了．</p>
<p>在虚机中若想使用host上的麦克风和音箱怎么办？　在’devices -&gt; audio”菜单中将’audio output’与’audio input’都选上即可．</p>
<p>鼠标在虚机与host机上无缝切换，　在’devices -&gt; insert guest cd’然后在虚机里打开cd安装驱动即可．</p>
<p>全屏切换　host + F,  host是指right ctrl键，进入全屏退出全屏都是它．</p>
<p>20201109更新 - kvm安装win10<br>之前virtualbox安装的win10在开关多次之后，会造成这样一个问题，在chrome上使用fast.com测速时会降到几十K到12M之间，</p>
<p>而同时在firefox上测速能达到69M左右，在重启机器之后chrome上的测速又能恢复到92M。</p>
<p>所以不敢再继续使用virtualbox了，改用KVM吧。</p>
<p>1, 直接将之前的virtualbox镜像转成kvm的 -　qemu-img convert -p -f vdi -O raw win10.vdi win10.img</p>
<p>2, 导入镜像创建虚机时注意一点，在”Choose the operating system you are installing”处输入win搜索windows时没有win10的版本，需勾选”Include end of life operating systems“才出来。</p>
<p>3, 第一次默认安装对硬盘和网卡均使用默认驱动。</p>
<ol>
<li>安装完启动win10后在里面下载安装virtualbox驱动 - <a href="https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/stable-virtio/virtio-win.iso" target="_blank" rel="external">https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/stable-virtio/virtio-win.iso</a></li>
</ol>
<p>5, 此时只能将网卡驱动改为virtio(也可以改成mapvtap + virtio)重启机器可以进win10</p>
<p>6, 但此时若将硬盘也改为virtio驱动会报错的。因为硬盘里还根本没有iscsi-virtio驱动啊。解决办法是在硬盘默认驱动进入win10后，</p>
<p>   再添加第二块virtio驱动这样iscsi-virtio就装在硬盘了。这时再重启就可以了。见：　<a href="https://superuser.com/questions/1057959/windows-10-in-kvm-change-boot-disk-to-virtio" target="_blank" rel="external">https://superuser.com/questions/1057959/windows-10-in-kvm-change-boot-disk-to-virtio</a></p>
<p>7, 使用spice这样声音和麦克就都用了。注：如果不将网络与硬盘改为virtio驱动，在likeshuo使用音频会有延时听不清楚。</p>
<p>8, 可使用spice redirect usb特性将集成视频卡加到虚机，注意：选错usb可能造成蓝牙键盘失去连接。</p>
<p>９，”rsync -avztur –progress /bak/* /mnt/share/“, /mnt/share是一块iscis盘，bak缺空间，第１步转换后的win10硬盘在iscsi盘上，但之前加了–delete参数导制被删除转了两遍。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/08/使用iSCSI挂载QNAP存储/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/08/使用iSCSI挂载QNAP存储/" itemprop="url">使用iSCSI挂载QNAP存储</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-08T15:16:38+08:00">
                2020-11-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2015-12-28<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</p>
<p>QNAP服务端<br>系统设置 -&gt; 存储空间总管 -&gt; iSCSI选项卡<br>入口管理: 启动iSCSI目标服务<br>iSCSI目标管理：创建一个iSCSI目标并挂载一个iSCSI LUN<br>  iqn.2004-04.com.qnap:ts-212p:iscsi.quqiSCSI.d5ad13<br>  目标名称：quqiSCSI<br>  目标别名：quqiSCSI<br>  启用CHAP认证：username/password<br>  动态配置：quqiSCSI, 800G</p>
<p>在qnap中文件将存储于：/share/HDA_DATA/.@iscsi.img/iSCSI-quqiSCSI-56809a35.000</p>
<p>OpenWRT服务端<br>opkg install tgt<br>dd if=/dev/zero of=/mnt/sda1/images/sdb_for_t440p.raw bs=1M count=80000</p>
<p>vi /etc/config/tgt<br>config target 1<br>       option name ‘iqn.2018-05.com.quqi99:sdb_for_t440p’<br>       option allow 192.168.99.0/24<br>config lun 1_1</p>
<h1 id="option-readonly-0"><a href="#option-readonly-0" class="headerlink" title="option readonly 0"></a>option readonly 0</h1><pre><code>option device /mnt/sda1/images/sdb_for_t440p.raw
</code></pre><p>/etc/init.d/tgt enable<br>/etc/init.d/tgt restart<br>20201105更新 - 但现在报这个错误：　tgt: Failed to create target，　运行’tgtd  -f -d -D’显示Segmentation fault</p>
<p>iSCSI Initiator客户端<br>hua@node1:~$ sudo /etc/init.d/open-iscsi start</p>
<p>hua@node1:~$ sudo update-rc.d -f open-iscsi remove<br> Removing any system startup links for /etc/init.d/open-iscsi …<br>   /etc/rc0.d/K81open-iscsi<br>   /etc/rc0.d/S45open-iscsi<br>   /etc/rc1.d/K81open-iscsi<br>   /etc/rc6.d/K81open-iscsi<br>hua@node1:~$ sudo update-rc.d open-iscsi start 20 2 3 4 5 . stop 20 0 1 6 .<br>update-rc.d: warning:  start runlevel arguments (2 3 4 5) do not match open-iscsi Default-Start values (S)<br> Adding system startup for /etc/init.d/open-iscsi …<br>   /etc/rc0.d/K20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc1.d/K20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc6.d/K20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc2.d/S20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc3.d/S20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc4.d/S20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc5.d/S20open-iscsi -&gt; ../init.d/open-iscsi<br>hua@node1:~$ sudo update-rc.d open-iscsi enable<br>update-rc.d: warning:  start runlevel arguments (none) do not match open-iscsi Default-Start values (S)<br>update-rc.d: warning:  stop runlevel arguments (none) do not match open-iscsi Default-Stop values (0 1 6)<br> Enabling system startup links for /etc/init.d/open-iscsi …<br> Removing any system startup links for /etc/init.d/open-iscsi …<br>   /etc/rc0.d/K20open-iscsi<br>   /etc/rc1.d/K20open-iscsi<br>   /etc/rc2.d/S20open-iscsi<br>   /etc/rc3.d/S20open-iscsi<br>   /etc/rc4.d/S20open-iscsi<br>   /etc/rc5.d/S20open-iscsi<br>   /etc/rc6.d/K20open-iscsi<br> Adding system startup for /etc/init.d/open-iscsi …<br>   /etc/rc0.d/K20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc1.d/K20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc6.d/K20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc2.d/S20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc3.d/S20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc4.d/S20open-iscsi -&gt; ../init.d/open-iscsi<br>   /etc/rc5.d/S20open-iscsi -&gt; ../init.d/open-iscsi<br>hua@node1:~$ sudo sysv-rc-conf –list open-iscsi<br>open-iscsi   0:off    1:off    2:on    3:on    4:on    5:on    6:off</p>
<p>vi /etc/iscsi/iscsid.conf<br>node.startup = automatic<br>node.session.auth.authmethod = CHAP<br>node.session.auth.username = username<br>node.session.auth.password = password</p>
<p>hua@node1:~$ sudo iscsiadm -m discovery -t st -p 192.168.99.122<br>192.168.99.122:3260,1 iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13<br>10.8.0.1:3260,1 iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13</p>
<p>hua@node1:~$ sudo cat /etc/iscsi/initiatorname.iscsi<br>InitiatorName=iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13</p>
<p>hua@node1:~$ sudo iscsiadm -m node -T iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13 -p 192.168.99.122 –op new<br>New iSCSI node [tcp:[hw=,ip=,net_if=,iscsi_if=default] 192.168.99.122,3260,-1 iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13] added</p>
<p>hua@node1:~$ sudo iscsiadm -m node -T iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13 -p 192.168.99.122 –login<br>Logging in to [iface: default, target: iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13, portal: 192.168.99.122,3260] (multiple)<br>Login to [iface: default, target: iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13, portal: 192.168.99.122,3260] successful.<br>hua@node1:~$ sudo iscsiadm -m node -T iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13 -p 192.168.99.122 –op update -n node.startup -v automatic</p>
<p>hua@node1:~$ ls -l /dev/disk/by-path/ip-192.168.99.122\:3260-iscsi-iqn.2004-04.com.qnap\:ts-212p\:iscsi.quqiscsi.d5ad13-lun-0<br>lrwxrwxrwx 1 root root 9 Dec 28 10:22 /dev/disk/by-path/ip-192.168.99.122:3260-iscsi-iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13-lun-0 -&gt; ../../sdb</p>
<p>hua@node1:~$ cat /sys/class/iscsi_host/host16/device/session11/iscsi_session/session11/targetname<br>iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13</p>
<p>hua@node1:~$ sudo cat /etc/udev/rules.d/55-openiscsi.rules<br>KERNEL==”sd*”, BUS==”scsi”, PROGRAM=”/etc/udev/scripts/iscsidev.sh %b”,SYMLINK+=”iscsi/%c”</p>
<p>hua@node1:~$ sudo cat /etc/udev/scripts/iscsidev.sh</p>
<p>#!/bin/sh</p>
<h1 id="FILE-etc-udev-scripts-iscsidev-sh"><a href="#FILE-etc-udev-scripts-iscsidev-sh" class="headerlink" title="FILE: /etc/udev/scripts/iscsidev.sh"></a>FILE: /etc/udev/scripts/iscsidev.sh</h1><p>BUS=${1}<br>HOST=${BUS%%:<em>}<br>[ -e /sys/class/iscsi_host ] || exit 1<br>file=”/sys/class/iscsi_host/host${HOST}/device/session</em>/iscsi_session*/targetname”<br>target_name=$(cat ${file})</p>
<h1 id="This-is-not-an-open-scsi-drive"><a href="#This-is-not-an-open-scsi-drive" class="headerlink" title="This is not an open-scsi drive"></a>This is not an open-scsi drive</h1><p>if [ -z “${target_name}” ]; then<br>  exit 1<br>fi<br>echo “${target_name##*.}”</p>
<p>hua@node1:~$ sudo fdisk -l<br>…<br>Disk /dev/sdb: 859.0 GB, 858993459200 bytes<br>255 heads, 63 sectors/track, 104433 cylinders, total 1677721600 sectors<br>Units = sectors of 1 * 512 = 512 bytes<br>Sector size (logical/physical): 512 bytes / 512 bytes<br>I/O size (minimum/optimal): 1048576 bytes / 1048576 bytes<br>Disk identifier: 0x00000000</p>
<p>Disk /dev/sdb doesn’t contain a valid partition table</p>
<p>hua@node1:~$ sudo mkfs.ext4 /dev/sdb<br>mke2fs 1.42.9 (4-Feb-2014)<br>/dev/sdb is entire device, not just one partition!<br>Proceed anyway? (y,n) y<br>Discarding device blocks: done<br>Filesystem label=<br>OS type: Linux<br>Block size=4096 (log=2)<br>Fragment size=4096 (log=2)<br>Stride=256 blocks, Stripe width=256 blocks<br>52428800 inodes, 209715200 blocks<br>10485760 blocks (5.00%) reserved for the super user<br>First data block=0<br>Maximum filesystem blocks=4294967296<br>6400 block groups<br>32768 blocks per group, 32768 fragments per group<br>8192 inodes per group<br>Superblock backups stored on blocks:<br>    32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,<br>    4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968,<br>    102400000</p>
<p>Allocating group tables: done<br>Writing inode tables: done<br>Creating journal (32768 blocks): done<br>Writing superblocks and filesystem accounting information: done</p>
<p>hua@node1:~$ sudo mkdir /qnap<br>hua@node1:~$ sudo mount -t ext4 /dev/sdb /qnap<br>hua@node1:~$ df -h |grep sdb<br>/dev/sdb        788G   69M  748G   1% /qnap</p>
<p>hua@node1:~$ sudo tune2fs -l /dev/sdb |grep UUID<br>Filesystem UUID:          30aa3ef9-698b-41c2-9637-dc79be91eb79</p>
<p>hua@node1:~$ sudo cat /etc/fstab |grep sdb<br>/dev/sdb    /qnap    ext4    defaults,auto,_netdev    0    0</p>
<p>hua@hua-ThinkPad-T440p:/bak$ sudo mount -t ext4 /dev/sdb /qnap<br>mount: /dev/sdb is already mounted or /qnap busy<br>hua@hua-ThinkPad-T440p:/bak$ sudo multipath -ll<br>36001405abdafa5bd00cbd4d1ad9498d1 dm-0 QNAP,iSCSI Storage<br>size=800G features=’0’ hwhandler=’0’ wp=rw<br><code>-+- policy=&#39;round-robin 0&#39; prio=1 status=active</code>- 6:0:0:0 sdb 8:16 active ready running<br>hua@hua-ThinkPad-T440p:/bak$ sudo multipath -F<br>hua@hua-ThinkPad-T440p:/bak$ sudo multipath -ll<br>hua@hua-ThinkPad-T440p:/bak$ sudo mount -t ext4 /dev/sdb /qnap<br>自动挂载<br>可参考： <a href="https://blog.csdn.net/bing_g/article/details/51279427" target="_blank" rel="external">https://blog.csdn.net/bing_g/article/details/51279427</a></p>
<p>写了个脚本如下：</p>
<p>cat /etc/auto.iscsi</p>
<p>#!/bin/bash</p>
<p>IQN=”iqn.2018-05.com.quqi99:sdb_for_t440p”<br>IP=”192.168.99.1”<br>PORT=”3260”<br>LUN=”1”<br>OPTS=”-nocheck,ro,fstype=ext4”</p>
<p>if iscsiadm -m session | grep “$IQN”; then<br>  echo node exists<br>else<br>  iscsiadm -m node -T “$IQN” -p “$IP” –login 1&gt;&amp;2<br>fi</p>
<h1 id="Let-udev-settle-before-we-try-to-look-up-the-block-device"><a href="#Let-udev-settle-before-we-try-to-look-up-the-block-device" class="headerlink" title="Let udev settle before we try to look up the block device."></a>Let udev settle before we try to look up the block device.</h1><p>sleep 1</p>
<h1 id="Figure-out-the-block-device-using-the-udev-symlink"><a href="#Figure-out-the-block-device-using-the-udev-symlink" class="headerlink" title="Figure out the block device using the udev symlink."></a>Figure out the block device using the udev symlink.</h1><p>DEV_LINK=<code>readlink /dev/disk/by-path/ip-${IP}:${PORT}-iscsi-${IQN}-lun-${LUN}</code><br>DEV_NODE=<code>basename $DEV_LINK</code><br>DEV_FULL=”/dev/$DEV_NODE”</p>
<h1 id="Return-the-magic-to-automount"><a href="#Return-the-magic-to-automount" class="headerlink" title="Return the magic to automount"></a>Return the magic to automount</h1><p>echo “${OPTS} :${DEV_FULL}${LUN}”<br>sudo mount -t ext4 ${DEV_FULL} /bak_openwrt/</p>
<p>遇到的问题<br>1, 多出来的10.8.0.1:3260这个Portal连不上会导致开机时超时非常慢，得删除它。</p>
<p>hua@node2:~$ sudo iscsiadm -m discoverydb -P1<br>SENDTARGETS:<br>DiscoveryAddress: 192.168.99.122,3260<br>Target: iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13<br>Portal: 192.168.99.122:3260,1<br>Iface Name: default<br>Portal: 10.8.0.1:3260,1<br>Iface Name: default<br>DiscoveryAddress: aa.quqi.com,3260<br>iSNS:<br>No targets found.<br>STATIC:<br>Target: iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13<br>Portal: aa.quqi.com:3260,-1<br>Iface Name: default<br>FIRMWARE:<br>No targets found.</p>
<p>hua@node2:~$ sudo iscsiadm -m discoverydb -t st -p 10.8.0.1,3260 -o delete<br>iscsiadm: Discovery record [10.8.0.1,3260] not found.<br>hua@node2:~$ sudo iscsiadm -m discoverydb -t st -p 10.8.0.1:3260 -o delete<br>iscsiadm: Discovery record [10.8.0.1,3260] not found</p>
<p>hua@node2:~$ sudo iscsiadm -m discoverydb -P1<br>SENDTARGETS:<br>DiscoveryAddress: 192.168.99.122,3260<br>Target: iqn.2004-04.com.qnap:ts-212p:iscsi.quqiscsi.d5ad13<br>Portal: 192.168.99.122:3260,1<br>Iface Name: default<br>DiscoveryAddress: veryhua2006.myqnapcloud.com,3260<br>iSNS:<br>No targets found.<br>STATIC:<br>No targets found.<br>FIRMWARE:<br>No targets found.</p>
<p>2, 遇到这个类似的问题（<a href="http://forum.open-e.com/showthread.php?1262-Problem-synchronize-data-using-2-initiator-1-target），即多个iscsi" target="_blank" rel="external">http://forum.open-e.com/showthread.php?1262-Problem-synchronize-data-using-2-initiator-1-target），即多个iscsi</a> client连向同一个iscsi server时，在共享存储上写入新内容了，iscsi client需要先umount再mount才能更新。似乎没有自动地sync</p>
<p>20200413更新<br>遇到一个问题，ssh与nfs都可以用，但是访问portal登录时输入用户名和密码后无反应无跳转也不报错。下载固件( <a href="https://www.qnap.com.cn/zh-cn/download?model=ts-212p&amp;category=firmware" target="_blank" rel="external">https://www.qnap.com.cn/zh-cn/download?model=ts-212p&amp;category=firmware</a> ) 使用qfinder pro重刷即可。多等一会，不会损坏nfs数据。</p>
<p>20201108更新 - 群晖上使用iscsi<br>sudo apt install open-iscsi -y<br>sudo iscsiadm -m discoverydb -P1</p>
<h1 id="etc-iscsi-iscsid-conf-for-CHAP-username-password"><a href="#etc-iscsi-iscsid-conf-for-CHAP-username-password" class="headerlink" title="/etc/iscsi/iscsid.conf for CHAP username/password"></a>/etc/iscsi/iscsid.conf for CHAP username/password</h1><p>#sudo bash -c ‘cat &gt; /etc/iscsi/initiatorname.iscsi’ &lt;&lt; EOF<br>cat &lt;&lt; EOF | sudo tee /etc/iscsi/initiatorname.iscsi<br>InitiatorName=iqn.2020-11.com.quqi:catdisk.share<br>EOF</p>
<h1 id="discover-target"><a href="#discover-target" class="headerlink" title="discover target"></a>discover target</h1><p>sudo iscsiadm -m discovery -t sendtargets -p 192.168.2.108</p>
<h1 id="confirm-status-after-discovery"><a href="#confirm-status-after-discovery" class="headerlink" title="confirm status after discovery"></a>confirm status after discovery</h1><p>sudo iscsiadm -m node -o show</p>
<h1 id="login-to-the-target"><a href="#login-to-the-target" class="headerlink" title="login to the target"></a>login to the target</h1><h1 id="sudo-iscsiadm-m-node-–login"><a href="#sudo-iscsiadm-m-node-–login" class="headerlink" title="sudo iscsiadm -m node –login"></a>sudo iscsiadm -m node –login</h1><p>sudo iscsiadm -m node -T iqn.2020-11.com.quqi:catdisk.share -p 192.168.2.108 –login</p>
<h1 id="confirm-the-established-session"><a href="#confirm-the-established-session" class="headerlink" title="confirm the established session"></a>confirm the established session</h1><p>sudo iscsiadm -m session -o show<br>cat /proc/partitions  #or fdisk -l<br>sudo gdisk /dev/sdc  #n,[enter],[enter],[enter],[enter],t,8300,p,w,Y<br>sudo parted /dev/sdc print<br>sudo mkfs.ext4 /dev/sdc1<br>sudo mount /dev/sdc1 /mnt/share/<br>sudo lsblk<br>sudo blkid</p>
<h1 id="use-autofs"><a href="#use-autofs" class="headerlink" title="use autofs"></a>use autofs</h1><p>cat &lt;&lt; EOF | sudo tee -a /etc/auto.master<br>/-      auto.direct<br>EOF<br>cat &lt;&lt; EOF | sudo tee -a /etc/auto.direct</p>
<p>#/cat    -fstype=nfs,rw,rsize=32768,wsize=32768,vers=3,username=admin,password=xxx     192.168.2.108:/volume1/bak</p>
<p>#/nas    -fstype=nfs4,rsize=32768,wsize=32768     192.168.2.103:/Publicj</p>
<h1 id="DEV-NAME-readlink-dev-disk-by-path-ip-192-168-2-108-3260-iscsi-iqn-2020-11-com-quqi-catdisk-share-lun-1-xargs-basename"><a href="#DEV-NAME-readlink-dev-disk-by-path-ip-192-168-2-108-3260-iscsi-iqn-2020-11-com-quqi-catdisk-share-lun-1-xargs-basename" class="headerlink" title="DEV_NAME=$(readlink /dev/disk/by-path/ip-192.168.2.108\:3260-iscsi-iqn.2020-11.com.quqi\:catdisk.share-lun-1 |xargs basename)"></a>DEV_NAME=$(readlink /dev/disk/by-path/ip-192.168.2.108\:3260-iscsi-iqn.2020-11.com.quqi\:catdisk.share-lun-1 |xargs basename)</h1><p>/mnt/share    -fstype=ext4,rw,nosuid,nodev    :/dev/sdc1<br>EOF</p>
<h1 id="or-use-fstab"><a href="#or-use-fstab" class="headerlink" title="or use fstab"></a>or use fstab</h1><p>sudo bash -c ‘cat &gt;&gt;/etc/fstab’ &lt;&lt;EOF<br>/dev/sdc1     /mnt/share   ext4  defaults,auto,_netdev  0  0<br>EOF<br>sudo mount -a</p>
<p>sudo iscsiadm -m node -T iqn.2020-11.com.quqi:catdisk.share -p 192.168.2.108 –op update -n node.startup -v automatic<br>sudo systemctl enable open-iscsi</p>
<p>20201109更新　- 使用samba<br>openwrt上的samba server<br>1, set samba share - <a href="http://192.168.99.1/cgi-bin/luci/admin/nas/samba" target="_blank" rel="external">http://192.168.99.1/cgi-bin/luci/admin/nas/samba</a><br>2, smbpasswd -a root  #root/password<br>3, cat /etc/samba/smb.conf  &amp;&amp; cat /etc/samba/smbpasswd &amp;&amp; ps |grep -E ‘smbd|nmbd’<br>4, root@OpenWrt:~# cat /etc/samba/smb.conf<br>[global]<br>    netbios name = OpenWrt<br>    display charset = UTF-8</p>
<pre><code>#interfaces = lo br-lan
server string = OpenWrt
unix charset = UTF-8
workgroup = WORKGROUP
bind interfaces only = yes
deadtime = 30
enable core files = no
local master = yes
map to guest = Bad User
max protocol = SMB2
min receivefile size = 16384
null passwords = yes
passdb backend = smbpasswd
    # run &apos;smbpasswd root&apos; to set pass for &apos;root&apos;, we also need to comment &apos;invalid users=root&apos;
    #invalid users = root
security = user
    smb passwd file = /etc/samba/smbpasswd
socket options = TCP_NODELAY IPTOS_LOWDELAY
use sendfile = yes
</code></pre><p>[share]<br>    path = /mnt/sdc2<br>    read only = no<br>    guest ok = yes<br>    create mask = 0666<br>    directory mask = 0777<br>    browseable = yes</p>
<p>5, windows client: \192.168.2.47\share, 开机自动挂载可: 计算机-&gt;映射网络驱动器<br>6, Linux client<br>smbclient -L //192.168.2.47 -U root%password<br>smbclient //192.168.2.47/share -U root%password -c “ls”<br>sudo apt install cifs-utils -y<br>dmesg  #To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount<br>sudo mount -t cifs -o username=root,password=password,vers=1.0 //192.168.2.47/share /mnt/smb<br>autofs: /mnt/smb    -fstype=cifs,rw,username=root,password=password,vers=1.0,file_mode=0777,dir_mode=0777 ://192.168.2.47/share</p>
<p>目前规划<br>QNAP NAS(2T)的nfs仍通过autofs作工作之用，且做为照片主备分入口<br>OpenWrt上的4T硬盘，划分出/dev/sdc1(2T)定期通过crontab用rsync从QNAP同步备份数据.<br>OpenWrt上的/dev/sdc2(1T)做SMB在win与android电视之间共享孩子要看的视频<br>OpenWRT上的tgt iscsi server不work, 其余sdc3(500G)与sdc4(226G)备用<br>CATDISK(1T)上刷了群晖，做了两块iSCSI, iqn.2020-11.com.quqi:catdisk.share(500G)给Linux用，iqn.2020-10.com.quqi:catdisk.win(200G)给win10用<br>CATDIST(100G)上还有一个windisk nfs (\192.168.2.108\volume1\windisk)<br>CATDIST也通过ssh备份一些极其重要的小数据如毕业证</p>
<p>/nas    -fstype=nfs4,rsize=32768,wsize=32768     192.168.2.103:/Public</p>
<h1 id="DEV-NAME-readlink-dev-disk-by-path-ip-192-168-2-108-3260-iscsi-iqn-2020-11-com-quqi-catdisk-share-lun-1-xargs-basename-1"><a href="#DEV-NAME-readlink-dev-disk-by-path-ip-192-168-2-108-3260-iscsi-iqn-2020-11-com-quqi-catdisk-share-lun-1-xargs-basename-1" class="headerlink" title="DEV_NAME=$(readlink /dev/disk/by-path/ip-192.168.2.108\:3260-iscsi-iqn.2020-11.com.quqi\:catdisk.share-lun-1 |xargs basename)"></a>DEV_NAME=$(readlink /dev/disk/by-path/ip-192.168.2.108\:3260-iscsi-iqn.2020-11.com.quqi\:catdisk.share-lun-1 |xargs basename)</h1><p>/mnt/nasbak    -fstype=ext4,rw,nosuid,nodev    :/dev/sdc1<br>/mnt/smbwin    -fstype=cifs,rw,username=root,password=password,vers=1.0,file_mode=0777,dir_mode=0777 ://192.168.2.47/share<br>/nfswin    -fstype=nfs,rw,rsize=32768,wsize=32768,vers=3,username=quqi99,password=xxx     192.168.2.108:/volume1/windisk</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/04/使用rsync同步数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/04/使用rsync同步数据/" itemprop="url">使用rsync同步数据</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-04T21:15:27+08:00">
                2020-11-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2015-12-28<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )<br>急需使用rsync在家里的多台机器上同步相片。</p>
<p>sudo apt-get  install  rsync<br>sudo update-rc.d -f rsync remove<br>sudo update-rc.d rsync start 20 2 3 4 5 . stop 20 0 1 6 .<br>sudo update-rc.d rsync enable<br>hua@node1:~$ sudo sysv-rc-conf –list rsync<br>rsync        0:off    1:off    2:on    3:on    4:on    5:on    6:off</p>
<p>这时候就可以在一台机器上同步目录了(rsync server运行在qnap上，统一在qnap上修改，rsync client定时运行下列命令即可让客户端的文件夹与服务端同步，以服务端为准）:</p>
<p>rsync -avzur –progress –delete /bak/tmp/qnap/ /qnap/<br>rsync -avzur –progress –delete –password-file=/etc/rsync.secret  /bak/tmp/qnap/ /qnap/</p>
<p>在多台机器上同步目录：</p>
<p>rsync -rave “ssh -p 22 -l hua” -avzur –progress –delete 192.168.99.124:/qnap/ /qnap/<br>等价于：rsync -avzur –progress –delete hua@192.168.99.124:/qnap/ /qnap/</p>
<p>也可以配置使用::qnap使用下列配置文件/etc/rsyncd.conf中的[qnap]模块：</p>
<p>sudo rsync -avrzP hua@192.168.99.124::qnap qnap</p>
<p>hua@node1:~$ sudo rsync –list-only hua@192.168.99.124::<br>++++++++++++++++++++++++++++++++++++++++++++++<br>Welcome to use quqi rsync services!<br>++++++++++++++++++++++++++++++++++++++++++++++</p>
<p>qnap               This is qnap backup data</p>
<p>配置[qnap]模块的步骤如下：</p>
<p>sudo touch /etc/rsyncd.conf<br>sudo touch /etc/rsyncd.motd<br>hua@node1:~$ sudo cat /etc/rsyncd.motd<br>++++++++++++++++++++++++++++++++++++++++++++++<br>Welcome to use quqi rsync services!<br>++++++++++++++++++++++++++++++++++++++++++++++<br>sudo touch /etc/rsyncd.secrets<br>hua@node1:~$ sudo cat /etc/rsyncd.secrets<br>hua:Passw0rd<br>sudo chmod 600 /etc/rsyncd.secrets<br>sudo chown root:root /etc/rsyncd.secrets<br>hua@node1:~$ sudo cat /etc/default/rsync |grep ‘RSYNC_ENABLE’<br>RSYNC_ENABLE=true</p>
<p>sudo /etc/init.d/rsync restart<br>sudo iptables -A INPUT -p tcp -m state –state NEW  -m tcp –dport 873 -j ACCEPT<br>vi /etc/rsyncd.conf<br>pid file = /var/run/rsyncd.pid<br>port = 873<br>address = 192.168.99.124</p>
<p>#usermod -g root hua<br>uid = hua<br>gid = root<br>use chroot = yes<br>read only = yes<br>hosts allow=192.168.99.0/255.255.255.0 10.0.1.0/255.255.255.0<br>hosts deny=*<br>max connections = 5<br>motd file = /etc/rsyncd.motd<br>log file = /var/log/rsync.log</p>
<p>#transfer logging = yes<br>log format = %t %a %m %f %b<br>syslog facility = local3<br>timeout = 300</p>
<p>[qnap]<br>path = /qnap<br>list=yes             # 可以使用rsync –list-only hua@192.168.99.124::命令列出目录<br>ignore errors<br>auth users = hua,root<br>secrets file = /etc/rsyncd.secrets<br>comment = This is qnap backup data<br>exclude = tmp/  test/</p>
<p>最后，我实际上是这样处理的，我有一个qnap，一个台式机，一个笔记本，对于一些相片啥的想多存储几份别一个机器哪天坏了丢了。</p>
<p>1, 由于iscsi上一个bug，一个client对qnap上的iscsi server写了之后，没法实时更新在另一个client上（必须先umount再mount一下才行）， 并且qnap的iscsi采用一个大的虚拟文件存储的，这都不是我想要的。所以最后只使用了qnap上的nfs将相片存储了一份。</p>
<p>2, 台式机因为IP固定开机自动mount (sudo mount -t nfs -o vers=3 192.168.99.122:/Public /bak/qnap), 另外直接复制了一份到/bak/qnap_local目录防止rsync操作失误毁坏数据。</p>
<p>3, 笔记本因为经常外出IP不固定，外出时使用/bak/qnap_local目录的内容，在家需要同步时手工同步：</p>
<p>   sudo mount -t nfs -o vers=3 192.168.99.122:/Public /bak/qnap<br>   cd ~ &amp;&amp; rsync -avzurP –exclude ‘doc’ –exclude ‘photo’ –exclude ‘media’  –progress –delete /bak/qnap/ /bak/qnap_local</p>
<p>4, 平时在家办公统一从台式机上写/bak/qnap目录将数据直接写到qnap上。手机等移动设备通过qnap ftp访问数据。</p>
<p>20171031更新：</p>
<p>最后的方案是：</p>
<p>1， 使用autos先将nas上的nfs共享目录共享到台式机（注： nfs共离目录无法使用inotify)：</p>
<p>hua@node1:~$ grep -r ‘auto.direct’ /etc/auto.master<br>/-      auto.direct        –timeout 60<br>hua@node1:~$ cat /etc/auto.direct<br>/nas    -fstype=nfs4,rsize=32768,wsize=32768     192.168.99.122:/Public</p>
<p>2, 然后直接手动运行下列两个命令：</p>
<p>rsync -avztur –progress –delete  /nas/doc/  /bak/doc<br>rsync -avztur –progress –delete  /nas/photo/  /bak/photo</p>
<p>20201104更新 - nas往openwrt同步数据</p>
<p>rsync can work in two different mode, rsync over rsync (873, rsyncd) and rsync over ssh, see <a href="https://serverfault.com/questions/827633/confused-about-rsync-port-873-and-nas" target="_blank" rel="external">https://serverfault.com/questions/827633/confused-about-rsync-port-873-and-nas</a><br>we use rsync over ssh mode here.</p>
<h1 id="openwrt-192-168-2-47-192-168-99-1"><a href="#openwrt-192-168-2-47-192-168-99-1" class="headerlink" title="openwrt (192.168.2.47, 192.168.99.1)"></a>openwrt (192.168.2.47, 192.168.99.1)</h1><p>opkg install rsync</p>
<h1 id="nas-192-168-2-103-push-data-into-openwrt-192-168-2-47"><a href="#nas-192-168-2-103-push-data-into-openwrt-192-168-2-47" class="headerlink" title="nas (192.168.2.103) push data into openwrt(192.168.2.47)"></a>nas (192.168.2.103) push data into openwrt(192.168.2.47)</h1><h1 id="don’t-use-rsync"><a href="#don’t-use-rsync" class="headerlink" title="don’t use rsync"></a>don’t use rsync</h1><p>cd /share/HDA_DATA/Public/test &amp;&amp; touch test1 &amp;&amp; touch test2 &amp;&amp; touch test3<br>ssh root@192.168.2.47 “tee -a /etc/dropbear/authorized_keys” &lt; ~/.ssh/id_rsa.pub<br>rsync -avztur –progress –delete –exclude ‘test/test1’ –exclude ‘test/test2’ /share/HDA_DATA/Public/test root@192.168.2.47:/mnt/sdb1/<br>rsync -avztur –progress –delete –exclude ‘test1’ –exclude ‘test2’ /share/HDA_DATA/Public/test/ root@192.168.2.47:/mnt/sdb1/<br>rsync -avztur –progress –delete –exclude ‘windisk’ –exclude ‘media’ /share/HDA_DATA/Public/ root@192.168.2.47:/mnt/sdb1/<br>contab -e<br>0 1 <em> </em> * /usr/bin/rsync -avztur –progress –delete –exclude ‘windisk’ –exclude ‘media’ /share/HDA_DATA/Public/ root@192.168.2.47:/mnt/sdb1/</p>
<p>或者在openwrt端做:</p>
<p>mkdir ~/.ssh<br>dropbearkey -t rsa -f ~/.ssh/id_rsa<br>dropbearkey -y -f ~/.ssh/id_rsa |sed -n 2p &gt; ~/.ssh/id_rsa.pub</p>
<h1 id="https-community-onion-io-topic-2538-resolved-ssh-from-omega-to-linux-server-without-password-9"><a href="#https-community-onion-io-topic-2538-resolved-ssh-from-omega-to-linux-server-without-password-9" class="headerlink" title="https://community.onion.io/topic/2538/resolved-ssh-from-omega-to-linux-server-without-password/9"></a><a href="https://community.onion.io/topic/2538/resolved-ssh-from-omega-to-linux-server-without-password/9" target="_blank" rel="external">https://community.onion.io/topic/2538/resolved-ssh-from-omega-to-linux-server-without-password/9</a></h1><p>ln -s ~/.ssh/id_rsa ~/.ssh/id_dropbear<br>chmod 700 ~/.ssh<br>touch ~/.ssh/authorized_keys &amp;&amp; chmod 644 ~/.ssh/authorized_keys<br>ssh admin@192.168.2.103 “tee -a /root/.ssh/authorized_keys” &lt; ~/.ssh/id_rsa.pub<br>/usr/bin/rsync -avztur –progress –delete –exclude ‘windisk’ –exclude ‘media’ admin@192.168.2.103:/share/HDA_DATA/Public/ /mnt/sdb1/</p>
<p>但这无论从nas还是从openwrt运行rsync都由于nas太慢大概只有4M左右，可能提升速度最好的办法是先将nas通过nfs映射到openwrt然后再拷．这样速度能达到30M</p>
<p>opkg install nfs-utils<br>showmount -e 192.168.2.103<br>/usr/bin/mount -t nfs 192.168.2.103:Public /mnt/nas -o proto=tcp -o nolock -o vers=4<br>/usr/bin/rsync -avztur –progress –delete –exclude ‘windisk’ –exclude ‘media’ /mnt/nas/ /mnt/sdc1/<br>但是我担心将mount放到fstab时当nas有问题时也影响openwrt的启动，所以我将上面命令放在rc.local中.<br>root@OpenWrt:~# cat /etc/init.d/done</p>
<p>#!/bin/sh /etc/rc.common</p>
<h1 id="Copyright-C-2006-OpenWrt-org"><a href="#Copyright-C-2006-OpenWrt-org" class="headerlink" title="Copyright (C) 2006 OpenWrt.org"></a>Copyright (C) 2006 OpenWrt.org</h1><p>START=95<br>boot() {<br>    mount_root done<br>    rm -f /sysupgrade.tgz &amp;&amp; sync</p>
<pre><code># process user commands
[ -f /etc/rc.local ] &amp;&amp; {
    sh /etc/rc.local
}

# set leds to normal state
. /etc/diag.sh
set_state done
</code></pre><p>}<br>并且crontab也在openwrt这边做．这样速度达到了30M</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/04/Install-OpenStack-on-MAAS-Nodes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/04/Install-OpenStack-on-MAAS-Nodes/" itemprop="url">Install OpenStack on MAAS Nodes</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-04T16:23:01+08:00">
                2020-11-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>作者：张华 发表于：2016-11-09<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</em></p>
<p>1, Prepare MAAS Nodes</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y maas-cli</span><br><span class="line">echo &apos;&lt;key-in-&lt;MAASIP&gt;/MAAS/r/account/prefs/api-keys&gt;&apos; &gt; ~/maas-apikey</span><br><span class="line">maas login admin http://10.230.56.2/MAAS `cat ~/maas-apikey`</span><br><span class="line">maas admin tags read</span><br><span class="line"></span><br><span class="line"># https://juju.is/docs/maas-cloud</span><br><span class="line">sudo bash -c &apos;cat &gt; /tmp/mymmas.yaml&apos; &lt;&lt; EOF</span><br><span class="line">clouds:</span><br><span class="line">   mymmas:</span><br><span class="line">      type: maas</span><br><span class="line">      auth-types: [oauth1]</span><br><span class="line">      endpoint: http://&lt;MAASIP&gt;/MAAS</span><br><span class="line">EOF</span><br><span class="line">juju remove-cloud --local mymmas</span><br><span class="line">juju add-cloud --local mymmas /tmp/mymmas.yaml</span><br><span class="line">juju list-clouds</span><br><span class="line">juju show-cloud mymmas --local</span><br><span class="line">sudo bash -c &apos;cat &gt; /tmp/credential.yaml&apos; &lt;&lt; EOF</span><br><span class="line">credentials:</span><br><span class="line">  mymmas:</span><br><span class="line">    zhhuabj:</span><br><span class="line">      auth-type: oauth1</span><br><span class="line">      maas-oauth: &lt;key-in-&lt;MAASIP&gt;/MAAS/r/account/prefs/api-keys&gt;</span><br><span class="line">EOF</span><br><span class="line">juju remove-credential --local mymmas zhhuabj</span><br><span class="line">juju add-credential --local mymmas -f /tmp/credential.yaml</span><br><span class="line">juju credentials --local</span><br><span class="line">juju show-credential --local mymmas zhhuabj</span><br><span class="line">cat ~/.local/share/juju/credentials.yaml</span><br><span class="line"></span><br><span class="line">juju bootstrap --debug segmaas --no-gui --config image-stream=daily --config default-series=focal --constraints=&quot;tags=virtual&quot;</span><br><span class="line"># hit this error https://discourse.maas.io/t/bootstrap-instance-started-but-did-not-change-to-deployed-state-instance-8epqeq-failed-to-deploy/2237/3</span><br><span class="line"># workaround for above issue,</span><br><span class="line"># first change rootfs to use lvm for the virutal host z-rotomvm14, then add a tag &apos;z-rotomvm14&apos; for it as well</span><br><span class="line"># finnally use the following two tags to try this host again.</span><br><span class="line">juju bootstrap --debug segmaas --no-gui --config image-stream=daily --config default-series=focal --constraints=&quot;tags=virtual,z-rotomvm14&quot;</span><br><span class="line">this is the bug - https://bugs.launchpad.net/curtin/+bug/1876258</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line">series:                     &amp;series                    bionic</span><br><span class="line">debug:                      &amp;debug                     True</span><br><span class="line">verbose:                    &amp;verbose                   True</span><br><span class="line">openstack_origin:           &amp;openstack_origin          cloud:bionic-ussuri</span><br><span class="line">source:                     &amp;source                    cloud:bionic-ussuri</span><br><span class="line"></span><br><span class="line">machines:</span><br><span class="line">  &apos;0&apos;:</span><br><span class="line">    constraints: &quot;tags=shuckle&quot;</span><br><span class="line">    series: *series</span><br><span class="line">  &apos;1&apos;:</span><br><span class="line">    constraints: &quot;tags=virtual&quot;</span><br><span class="line">    series: *series</span><br><span class="line"></span><br><span class="line">series: *series</span><br><span class="line">applications:</span><br><span class="line">  ntp:</span><br><span class="line">    charm: cs:ntp</span><br><span class="line">    num_units: 0</span><br><span class="line">  mysql:</span><br><span class="line">    charm: cs:~openstack-charmers-next/percona-cluster</span><br><span class="line">    num_units: 1</span><br><span class="line">    bindings:</span><br><span class="line">        &quot;&quot;: oam</span><br><span class="line">    options:</span><br><span class="line">      source: *source</span><br><span class="line">      root-password: ChangeMe123</span><br><span class="line">      sst-password: ChangeMe123</span><br><span class="line">      innodb-buffer-pool-size: 2G</span><br><span class="line">      max-connections: 2000</span><br><span class="line">    to:</span><br><span class="line">      - lxd:0</span><br><span class="line">  rabbitmq-server:</span><br><span class="line">    charm: cs:~openstack-charmers-next/rabbitmq-server</span><br><span class="line">    num_units: 1</span><br><span class="line">    bindings:</span><br><span class="line">        &quot;&quot;: oam</span><br><span class="line">    options:</span><br><span class="line">      source: *source</span><br><span class="line">    to:</span><br><span class="line">      - lxd:0</span><br><span class="line">  cinder:</span><br><span class="line">    num_units: 1</span><br><span class="line">    charm: cs:~openstack-charmers-next/cinder-428</span><br><span class="line">    bindings:</span><br><span class="line">        &quot;&quot;: oam</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      block-device: /dev/sdb</span><br><span class="line">      overwrite: &quot;true&quot;</span><br><span class="line">      glance-api-version: 2</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">    to:</span><br><span class="line">      - lxd:0</span><br><span class="line">  glance:</span><br><span class="line">    charm: cs:~openstack-charmers-next/glance</span><br><span class="line">    num_units: 1</span><br><span class="line">    bindings:</span><br><span class="line">        &quot;&quot;: oam</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">    to:</span><br><span class="line">      - lxd:0</span><br><span class="line">  keystone:</span><br><span class="line">    charm: cs:~openstack-charmers-next/keystone</span><br><span class="line">    num_units: 1</span><br><span class="line">    bindings:</span><br><span class="line">        &quot;&quot;: oam</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">      admin-password: openstack</span><br><span class="line">    to:</span><br><span class="line">      - lxd:0</span><br><span class="line">  nova-cloud-controller:</span><br><span class="line">    charm: cs:~openstack-charmers-next/nova-cloud-controller</span><br><span class="line">    num_units: 1</span><br><span class="line">    bindings:</span><br><span class="line">        &quot;&quot;: oam</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">      network-manager: Neutron</span><br><span class="line">    to:</span><br><span class="line">      - lxd:0</span><br><span class="line">  nova-compute:</span><br><span class="line">    charm: cs:~openstack-charmers-next/nova-compute</span><br><span class="line">    num_units: 1</span><br><span class="line">    bindings:</span><br><span class="line">        &quot;&quot;: oam</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">      enable-resize: True</span><br><span class="line">      enable-live-migration: True</span><br><span class="line">      migration-auth-type: ssh</span><br><span class="line">    to:</span><br><span class="line">      - 0</span><br><span class="line">  neutron-openvswitch:</span><br><span class="line">    charm: cs:~openstack-charmers-next/neutron-openvswitch</span><br><span class="line">    num_units: 0</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      prevent-arp-spoofing: false</span><br><span class="line">      flat-network-providers: physnet1</span><br><span class="line">  neutron-api:</span><br><span class="line">    charm: cs:~openstack-charmers-next/neutron-api</span><br><span class="line">    num_units: 1</span><br><span class="line">    bindings:</span><br><span class="line">        &quot;&quot;: oam</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">      vlan-ranges: &apos;&apos;  # prevent creating defaults since we don&apos;t need them</span><br><span class="line">      neutron-security-groups: True</span><br><span class="line">      enable-ml2-port-security: False</span><br><span class="line">      flat-network-providers: &apos;physnet1&apos;</span><br><span class="line">    to:</span><br><span class="line">      - lxd:0</span><br><span class="line">  neutron-gateway:</span><br><span class="line">    charm: cs:~openstack-charmers-next/neutron-gateway</span><br><span class="line">    num_units: 1</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">      bridge-mappings: physnet1:br-data</span><br><span class="line">      worker-multiplier: 0.5</span><br><span class="line">      dns-servers: 10.230.56.2</span><br><span class="line">    to:</span><br><span class="line">      - 1</span><br><span class="line">  placement:</span><br><span class="line">    charm: cs:~openstack-charmers-next/placement-36</span><br><span class="line">    num_units: 1</span><br><span class="line">    bindings:</span><br><span class="line">        &quot;&quot;: oam</span><br><span class="line">    options:</span><br><span class="line">      worker-multiplier: 0.5</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">    to:</span><br><span class="line">    - lxd:0</span><br><span class="line">relations:</span><br><span class="line">  - [ keystone, mysql ]</span><br><span class="line">  - [ &quot;nova-cloud-controller:shared-db&quot;, &quot;mysql:shared-db&quot; ]</span><br><span class="line">  - [ &quot;nova-cloud-controller:amqp&quot;, &quot;rabbitmq-server:amqp&quot; ]</span><br><span class="line">  - [ nova-cloud-controller, glance ]</span><br><span class="line">  - [ nova-cloud-controller, keystone ]</span><br><span class="line">  - [ nova-compute, nova-cloud-controller ]</span><br><span class="line">  - [ nova-compute, &apos;rabbitmq-server:amqp&apos; ]</span><br><span class="line">  - [ nova-compute, glance ]</span><br><span class="line">  - [ glance, mysql ]</span><br><span class="line">  - [ glance, keystone ]</span><br><span class="line">  - [ glance, &quot;cinder:image-service&quot; ]</span><br><span class="line">  - [ glance, rabbitmq-server ]</span><br><span class="line">  - [ cinder, mysql ]</span><br><span class="line">  - [ cinder, rabbitmq-server ]</span><br><span class="line">  - [ cinder, nova-cloud-controller ]</span><br><span class="line">  - [ cinder, keystone ]</span><br><span class="line">  - [ ntp, nova-compute ]</span><br><span class="line">  - [ neutron-api, mysql ]</span><br><span class="line">  - [ neutron-api, rabbitmq-server ]</span><br><span class="line">  - [ neutron-api, nova-cloud-controller ]</span><br><span class="line">  - [ neutron-api, neutron-openvswitch ]</span><br><span class="line">  - [ neutron-api, keystone ]</span><br><span class="line">  - [ neutron-openvswitch, nova-compute ]</span><br><span class="line">  - [ neutron-openvswitch, rabbitmq-server ]</span><br><span class="line">  - [ neutron-gateway, neutron-api ]</span><br><span class="line">  - [ neutron-gateway, nova-cloud-controller ]</span><br><span class="line">  - [ &quot;rabbitmq-server:amqp&quot;, &quot;neutron-gateway:amqp&quot; ]</span><br><span class="line">  - [ placement, mysql ]</span><br><span class="line">  - [ placement, keystone ]</span><br><span class="line">  - [ placement, nova-cloud-controller ]</span><br></pre></td></tr></table></figure>
<p>2, Upload the image</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://api.jujucharms.com/charmstore/v5/openstack-base/archive</span><br><span class="line">source novarc</span><br><span class="line">wget http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud-1511.qcow2</span><br><span class="line">glance image-create --name centos --disk-format qcow2 --container-format bare --file ./CentOS-7-x86_64-GenericCloud-1511.qcow2 --progress</span><br></pre></td></tr></table></figure>
<p>3, Create the network<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># NOTE: can use seg-bundles instead</span><br><span class="line">neutron net-create private --provider:network_type gre --provider:segmentation_id 1012</span><br><span class="line">neutron subnet-create --allocation-pool start=192.168.21.22,end=192.168.21.122 --gateway 192.168.21.1 private 192.168.21.0/24 --enable_dhcp=True --name private_subnet</span><br><span class="line"></span><br><span class="line">neutron net-create ext_net -- --router:external=True --provider:network_type flat --provider:physical_network physnet1</span><br><span class="line">neutron subnet-create --allocation-pool start=10.230.56.100,end=10.230.56.104 --gateway 10.230.56.1 ext_net 10.230.56.100/21 --enable_dhcp=False --name ext_net_subnet</span><br><span class="line"></span><br><span class="line">neutron router-create provider-router</span><br><span class="line">EXT_NET_ID=$(neutron net-list |grep &apos; ext_net &apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">ROUTER_ID=$(neutron router-list |grep &apos; provider-router &apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">SUBNET_ID=$(neutron subnet-list |grep &apos;192.168.21.0/24&apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">neutron router-interface-add $ROUTER_ID $SUBNET_ID</span><br><span class="line">neutron router-gateway-set $ROUTER_ID $EXT_NET_ID</span><br><span class="line">#neutron router-gateway-clear provider-router</span><br><span class="line">#neutron router-interface-delete provider-router private_subnet</span><br><span class="line">#nova floating-ip-delete 10.230.56.101</span><br><span class="line">#neutron subnet-delete ext_net_subnet</span><br><span class="line">#neutron subnet-delete private_subnet</span><br><span class="line">#neutron net-delete ext_net</span><br><span class="line">#neutron net-delete private</span><br><span class="line">#neutron router-delete provider-router</span><br></pre></td></tr></table></figure></p>
<p>4, Boot the VM<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">neutron security-group-rule-create --protocol icmp --direction ingress default</span><br><span class="line">neutron security-group-rule-create --protocol tcp --port-range-min 22 --port-range-max 22 --direction ingress default</span><br><span class="line">nova keypair-add --pub-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">nova service-list</span><br><span class="line">nova hypervisor-list</span><br><span class="line">nova boot --poll --key-name mykey --image centos --flavor 2 --nic net-id=$(neutron net-list |grep &apos;private&apos; |awk &apos;&#123;print $2&#125;&apos;) --availability-zone nova:node2 i2</span><br><span class="line">nova floating-ip-create</span><br><span class="line">nova floating-ip-associate i2 10.230.56.104</span><br><span class="line">ssh -i mykey centos@10.230.56.104 -v #dd if=/dev/urandom of=/var/tmp/live_mig_test bs=4M count=1000  #~/.local/share/juju/ssh/juju_id_rsa</span><br><span class="line">nova live-migration --block-migrate i2 voltorb</span><br><span class="line">#sudo virsh --connect qemu+ssh://node2/system list</span><br><span class="line">#LIBVIRT_DEBUG=1 virsh migrate --verbose --live --copy-storage-all instance-0000000d qemu+ssh://voltorb/system 2&gt;&amp;1 &gt; debug.log</span><br></pre></td></tr></table></figure></p>
<h2 id="Appendix-sriov-yaml"><a href="#Appendix-sriov-yaml" class="headerlink" title="Appendix - sriov yaml"></a>Appendix - sriov yaml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line">juju export-bundle --filename /tmp/sriov.yaml   #seg-bundles</span><br><span class="line">series: bionic</span><br><span class="line">applications:</span><br><span class="line">  glance:</span><br><span class="line">    charm: cs:~openstack-charmers-next/glance-423</span><br><span class="line">    num_units: 1</span><br><span class="line">    to:</span><br><span class="line">    - lxd:0</span><br><span class="line">    options:</span><br><span class="line">      debug: true</span><br><span class="line">      verbose: true</span><br><span class="line">      worker-multiplier: 0.25</span><br><span class="line">  keystone:</span><br><span class="line">    charm: cs:~openstack-charmers-next/keystone-508</span><br><span class="line">    num_units: 1</span><br><span class="line">    to:</span><br><span class="line">    - lxd:0</span><br><span class="line">    options:</span><br><span class="line">      admin-password: openstack</span><br><span class="line">      debug: true</span><br><span class="line">      verbose: true</span><br><span class="line">      worker-multiplier: 0.25</span><br><span class="line">  mysql:</span><br><span class="line">    charm: cs:~openstack-charmers-next/percona-cluster-376</span><br><span class="line">    num_units: 1</span><br><span class="line">    to:</span><br><span class="line">    - lxd:0</span><br><span class="line">    options:</span><br><span class="line">      innodb-buffer-pool-size: 512M</span><br><span class="line">      max-connections: 1000</span><br><span class="line">      root-password: admin</span><br><span class="line">      sst-password: admin</span><br><span class="line">  neutron-api:</span><br><span class="line">    charm: local:bionic/neutron-api-0</span><br><span class="line">    num_units: 1</span><br><span class="line">    to:</span><br><span class="line">    - lxd:0</span><br><span class="line">    options:</span><br><span class="line">      debug: true</span><br><span class="line">      enable-sriov: true</span><br><span class="line">      flat-network-providers: physnet1</span><br><span class="line">      neutron-security-groups: true</span><br><span class="line">      supported-pci-vendor-devs: 14e4:16af 8086:1515 8086:1528</span><br><span class="line">      verbose: true</span><br><span class="line">      vlan-ranges: &quot;&quot;</span><br><span class="line">      worker-multiplier: 0.25</span><br><span class="line">  neutron-openvswitch:</span><br><span class="line">    charm: local:bionic/neutron-openvswitch-0</span><br><span class="line">    options:</span><br><span class="line">      debug: true</span><br><span class="line">      enable-local-dhcp-and-metadata: true</span><br><span class="line">      enable-sriov: true</span><br><span class="line">      sriov-device-mappings: physnet1:eno50</span><br><span class="line">      verbose: true</span><br><span class="line">      vlan-ranges: &quot;&quot;</span><br><span class="line">  nova-cloud-controller:</span><br><span class="line">    charm: local:bionic/nova-cloud-controller-501</span><br><span class="line">    num_units: 1</span><br><span class="line">    to:</span><br><span class="line">    - lxd:0</span><br><span class="line">    options:</span><br><span class="line">      debug: true</span><br><span class="line">      network-manager: Neutron</span><br><span class="line">      verbose: true</span><br><span class="line">      worker-multiplier: 0.25</span><br><span class="line">  nova-compute:</span><br><span class="line">    charm: local:bionic/nova-compute-133</span><br><span class="line">    num_units: 1</span><br><span class="line">    to:</span><br><span class="line">    - &quot;1&quot;</span><br><span class="line">    options:</span><br><span class="line">      debug: true</span><br><span class="line">      pci-passthrough-whitelist: &apos;[&#123;&quot;devname&quot;:&quot;eno50&quot;, &quot;physical_network&quot;:&quot;physnet1&quot;&#125;]&apos;</span><br><span class="line">      verbose: true</span><br><span class="line">  ntp:</span><br><span class="line">    charm: cs:ntp-41</span><br><span class="line">  rabbitmq-server:</span><br><span class="line">    charm: cs:~openstack-charmers-next/rabbitmq-server-379</span><br><span class="line">    num_units: 1</span><br><span class="line">    to:</span><br><span class="line">    - lxd:0</span><br><span class="line">machines:</span><br><span class="line">  &quot;0&quot;:</span><br><span class="line">    constraints: tags=buneary</span><br><span class="line">  &quot;1&quot;:</span><br><span class="line">    constraints: tags=duduo</span><br><span class="line">  &quot;2&quot;:</span><br><span class="line">    constraints: tags=virtual</span><br><span class="line">    series: bionic</span><br><span class="line">relations:</span><br><span class="line">- - keystone:shared-db</span><br><span class="line">  - mysql:shared-db</span><br><span class="line">- - nova-cloud-controller:identity-service</span><br><span class="line">  - keystone:identity-service</span><br><span class="line">- - glance:identity-service</span><br><span class="line">  - keystone:identity-service</span><br><span class="line">- - neutron-api:identity-service</span><br><span class="line">  - keystone:identity-service</span><br><span class="line">- - neutron-openvswitch:neutron-plugin-api</span><br><span class="line">  - neutron-api:neutron-plugin-api</span><br><span class="line">- - neutron-api:shared-db</span><br><span class="line">  - mysql:shared-db</span><br><span class="line">- - neutron-api:amqp</span><br><span class="line">  - rabbitmq-server:amqp</span><br><span class="line">- - glance:shared-db</span><br><span class="line">  - mysql:shared-db</span><br><span class="line">- - glance:amqp</span><br><span class="line">  - rabbitmq-server:amqp</span><br><span class="line">- - nova-cloud-controller:image-service</span><br><span class="line">  - glance:image-service</span><br><span class="line">- - nova-cloud-controller:amqp</span><br><span class="line">  - rabbitmq-server:amqp</span><br><span class="line">- - neutron-openvswitch:amqp</span><br><span class="line">  - rabbitmq-server:amqp</span><br><span class="line">- - nova-cloud-controller:shared-db</span><br><span class="line">  - mysql:shared-db</span><br><span class="line">- - nova-cloud-controller:neutron-api</span><br><span class="line">  - neutron-api:neutron-api</span><br><span class="line">- - nova-compute:amqp</span><br><span class="line">  - rabbitmq-server:amqp</span><br><span class="line">- - nova-compute:image-service</span><br><span class="line">  - glance:image-service</span><br><span class="line">- - nova-cloud-controller:cloud-compute</span><br><span class="line">  - nova-compute:cloud-compute</span><br><span class="line">- - nova-compute:neutron-plugin</span><br><span class="line">  - neutron-openvswitch:neutron-plugin</span><br><span class="line">- - ntp:juju-info</span><br><span class="line">  - nova-compute:juju-info</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/30/Play-with-OVN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/30/Play-with-OVN/" itemprop="url">Play with OVN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-10-30T16:06:55+08:00">
                2020-10-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华  发表于：2019-11-22<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</strong></p>
<p>OVN is the replacement of Neutron, so we need to have a look at OVN.</p>
<p>Refer - <a href="https://zhhuabj.blog.csdn.net/article/details/42773417" target="_blank" rel="external">https://zhhuabj.blog.csdn.net/article/details/42773417</a></p>
<h2 id="Basic-ovn-L2-test"><a href="#Basic-ovn-L2-test" class="headerlink" title="Basic ovn L2 test"></a>Basic ovn L2 test</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">#controller node has ovn-central(northbound and southbound db), but compute node (local ovn-controller) doesn&apos;t have it</span><br><span class="line">sudo apt install -y openvswitch-switch ovn-common ovn-controller-vtep ovn-docker ovn-host ovn-central</span><br><span class="line"></span><br><span class="line">#In controller, enable remote access, tell OVN southbound db to accept TCP connections from ovn-controllers</span><br><span class="line">sudo ovn-sbctl set-connection ptcp:6642</span><br><span class="line">#In controller, for the time being don&apos;t need to tell OVN northbound db to accept TCP connections from ovn-controllers</span><br><span class="line">sudo ovn-nbctl set-connection ptcp:6641</span><br><span class="line">$ netstat -lntp | grep  664</span><br><span class="line">(Not all processes could be identified, non-owned process info</span><br><span class="line"> will not be shown, you would have to be root to see it all.)</span><br><span class="line">tcp        0      0 0.0.0.0:6642            0.0.0.0:*               LISTEN      -</span><br><span class="line">tcp        0      0 127.0.0.1:6640          0.0.0.0:*               LISTEN      -</span><br><span class="line">tcp        0      0 0.0.0.0:6641            0.0.0.0:*               LISTEN      -</span><br><span class="line"></span><br><span class="line">#In controller, create logical switch and ports:</span><br><span class="line">sudo ovn-nbctl ls-add sw</span><br><span class="line">sudo ovn-nbctl lsp-add sw sp1</span><br><span class="line">sudo ovn-nbctl lsp-set-addresses sp1 &quot;00:00:00:00:00:01 10.0.0.1&quot;</span><br><span class="line">sudo ovn-nbctl lsp-add sw sp2</span><br><span class="line">sudo ovn-nbctl lsp-set-addresses sp2 &quot;00:00:00:00:00:02 10.0.0.2&quot;</span><br><span class="line">sudo ovn-nbctl show</span><br><span class="line"></span><br><span class="line">#In compute node, make ovn-controller connect to southbound db, and create test</span><br><span class="line">#external_ids:ovn-remote=&quot;tcp:&lt;remote-controller-ip&gt;:6642&quot; external_ids:ovn-encap-ip=&lt;my-ip-used-for-endpoint&gt;</span><br><span class="line">sudo ovs-vsctl set open_vswitch . external_ids:ovn-remote=&quot;tcp:localhost:6642&quot; external_ids:ovn-encap-ip=localhost \</span><br><span class="line">external_ids:ovn-encap-type=&quot;geneve&quot; external_ids:system-id=&quot;vm1&quot;</span><br><span class="line">sudo ip link add sp1_l type veth peer name sp1_r</span><br><span class="line">sudo ovs-vsctl add-port br-int sp1_l  #sudo ovs-vsctl add-br br-int -- set Bridge br-int fail-mode=secure</span><br><span class="line">sudo ovs-vsctl set interface sp1_l external_ids:iface-id=sp1</span><br><span class="line">sudo ip link set sp1_l up</span><br><span class="line">sudo ip netns add sp1</span><br><span class="line">sudo ip link set sp1_r netns sp1</span><br><span class="line">sudo ip netns exec sp1 ip link set sp1_r up</span><br><span class="line">sudo ip netns exec sp1 ip addr add 10.0.0.1/24 dev sp1_r</span><br><span class="line">sudo ip netns exec sp1 ip link set dev sp1_r address 00:00:00:00:00:01</span><br><span class="line"></span><br><span class="line">#or run the following command on another machine instead</span><br><span class="line">sudo ovs-vsctl set open_vswitch . external_ids:ovn-remote=&quot;tcp:localhost:6642&quot; external_ids:ovn-encap-ip=localhost \</span><br><span class="line">external_ids:ovn-encap-type=&quot;geneve&quot; external_ids:system-id=&quot;vm2&quot;</span><br><span class="line">sudo ip link add sp2_l type veth peer name sp2_r</span><br><span class="line">sudo ovs-vsctl add-port br-int sp2_l</span><br><span class="line">sudo ovs-vsctl set interface sp2_l external_ids:iface-id=sp2</span><br><span class="line">sudo ip link set sp2_l up</span><br><span class="line">sudo ip netns add sp2</span><br><span class="line">sudo ip link set sp2_r netns sp2</span><br><span class="line">sudo ip netns exec sp2 ip link set sp2_r up</span><br><span class="line">sudo ip netns exec sp2 ip addr add 10.0.0.2/24 dev sp2_r</span><br><span class="line">sudo ip netns exec sp2 ip link set dev sp2_r address 00:00:00:00:00:02</span><br><span class="line"></span><br><span class="line">#test</span><br><span class="line">$ sudo ip netns exec sp1 ping 10.0.0.2 -c 1</span><br><span class="line">PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.318 ms</span><br><span class="line"></span><br><span class="line">hua@node1:~$ sudo ovn-nbctl show</span><br><span class="line">switch a28291a4-bea9-445f-af0f-cae65c04e9f7 (sw)</span><br><span class="line">    port sp2</span><br><span class="line">        addresses: [&quot;00:00:00:00:00:02 10.0.0.2&quot;]</span><br><span class="line">    port sp1</span><br><span class="line">        addresses: [&quot;00:00:00:00:00:01 10.0.0.1&quot;]</span><br><span class="line">hua@node1:~$ sudo ovn-sbctl show</span><br><span class="line">Chassis vm2</span><br><span class="line">    hostname: node1</span><br><span class="line">    Encap geneve</span><br><span class="line">        ip: localhost</span><br><span class="line">        options: &#123;csum=&quot;true&quot;&#125;</span><br><span class="line">    Port_Binding sp2</span><br><span class="line">    Port_Binding sp1</span><br><span class="line"></span><br><span class="line"># reset</span><br><span class="line">sudo ovn-nbctl lsp-del sp1</span><br><span class="line">sudo ovn-nbctl lsp-del sp2</span><br><span class="line">sudo ovn-nbctl ls-del sw</span><br><span class="line">sudo ip netns del sp1</span><br><span class="line">sudo ip netns del sp2</span><br><span class="line">sudo ovs-vsctl del-port br-int sp1_l</span><br><span class="line">sudo ovs-vsctl del-port br-int sp2_l</span><br></pre></td></tr></table></figure>
<h2 id="Basic-ovs-flow-test"><a href="#Basic-ovs-flow-test" class="headerlink" title="Basic ovs flow test"></a>Basic ovs flow test</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -itd --name i1 --net=none ubuntu:20.04 /bin/bash</span><br><span class="line">sudo docker run -itd --name i2 --net=none ubuntu:20.04 /bin/bash</span><br><span class="line">sudo ovs-vsctl add-br br-int</span><br><span class="line">sudo ovs-docker add-port br-int eth0 i1 --ipaddress=192.168.1.2/24</span><br><span class="line">sudo ovs-docker add-port br-int eth0 i2 --ipaddress=192.168.1.3/24</span><br><span class="line">sudo docker exec -it i1 bash</span><br><span class="line">sudo docker exec -it i1 ping 192.168.1.3</span><br><span class="line">sudo ovs-vsctl list interface d15c80f8359d4_l</span><br><span class="line">#when doing test in the two machines</span><br><span class="line">#sudo ovs-vsctl add-port br-int vxlan1 -- set interface vxlan1 type=vxlan options:remote_ip=192.168.99.122 options:key=flow</span><br><span class="line">#sudo ovs-vsctl add-port br-int vxlan1 -- set interface vxlan1 type=vxlan options:remote_ip=192.168.99.123 options:key=flow</span><br><span class="line"></span><br><span class="line">#test 1 - delete flow</span><br><span class="line">$ sudo ovs-ofctl dump-flows br-int</span><br><span class="line"> cookie=0x0, duration=563.338s, table=0, n_packets=6, n_bytes=364, priority=0 actions=NORMAL</span><br><span class="line">sudo ovs-ofctl del-flows br-int</span><br><span class="line">sudo docker exec -it i1 ping 192.168.1.3</span><br><span class="line"></span><br><span class="line">#test 2 - add flow</span><br><span class="line">$ sudo ovs-vsctl list interface d15c80f8359d4_l |grep ofport</span><br><span class="line">ofport              : 3</span><br><span class="line">$ sudo ovs-vsctl list interface 85023af15d0c4_l |grep ofport</span><br><span class="line">ofport              : 4</span><br><span class="line">sudo ovs-ofctl add-flow br-int &quot;priority=1,in_port=3,actions=output:4&quot;</span><br><span class="line">sudo ovs-ofctl add-flow br-int &quot;priority=2,in_port=4,actions=output:3&quot;</span><br><span class="line">sudo ovs-ofctl dump-flows br-int</span><br><span class="line">sudo docker exec -it i1 ping 192.168.1.3</span><br></pre></td></tr></table></figure>
<h2 id="ovn-L3-test"><a href="#ovn-L3-test" class="headerlink" title="ovn L3 test"></a>ovn L3 test</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">#create two vSwitches</span><br><span class="line">sudo ovn-nbctl ls-add sw0</span><br><span class="line">sudo ovn-nbctl lsp-add sw0 sw0-port1</span><br><span class="line">sudo ovn-nbctl lsp-set-addresses sw0-port1 &quot;50:54:00:00:00:01 192.168.0.2&quot;</span><br><span class="line"></span><br><span class="line">sudo ovn-nbctl ls-add sw1</span><br><span class="line">sudo ovn-nbctl lsp-add sw1 sw1-port1</span><br><span class="line">sudo ovn-nbctl lsp-set-addresses sw1-port1 &quot;50:54:00:00:00:03 11.0.0.2&quot;</span><br><span class="line"></span><br><span class="line">#create a vRouter, and connect two vSwitches to it</span><br><span class="line">sudo ovn-nbctl lr-add lr0</span><br><span class="line"></span><br><span class="line">sudo ovn-nbctl lrp-add lr0 lrp0 00:00:00:00:ff:01 192.168.0.1/24</span><br><span class="line">sudo ovn-nbctl lsp-add sw0 lrp0-attachment</span><br><span class="line">sudo ovn-nbctl lsp-set-type lrp0-attachment router</span><br><span class="line">sudo ovn-nbctl lsp-set-addresses lrp0-attachment 00:00:00:00:ff:01</span><br><span class="line">sudo ovn-nbctl lsp-set-options lrp0-attachment router-port=lrp0</span><br><span class="line"></span><br><span class="line">sudo ovn-nbctl lrp-add lr0 lrp1 00:00:00:00:ff:02 11.0.0.1/24</span><br><span class="line">sudo ovn-nbctl lsp-add sw1 lrp1-attachment</span><br><span class="line">sudo ovn-nbctl lsp-set-type lrp1-attachment router</span><br><span class="line">sudo ovn-nbctl lsp-set-addresses lrp1-attachment 00:00:00:00:ff:02</span><br><span class="line">sudo ovn-nbctl lsp-set-options lrp1-attachment router-port=lrp1</span><br><span class="line"></span><br><span class="line">hua@node1:~$ sudo ovn-nbctl show</span><br><span class="line">switch 25c77c44-9be4-434b-8b38-e325d4c2b044 (sw0)</span><br><span class="line">    port lrp0-attachment</span><br><span class="line">        type: router</span><br><span class="line">        addresses: [&quot;00:00:00:00:ff:01&quot;]</span><br><span class="line">        router-port: lrp0</span><br><span class="line">    port sw0-port1</span><br><span class="line">        addresses: [&quot;50:54:00:00:00:01 192.168.0.2&quot;]</span><br><span class="line">switch 0b33e823-577b-4c76-a661-c3bd358624cc (sw1)</span><br><span class="line">    port lrp1-attachment</span><br><span class="line">        type: router</span><br><span class="line">        addresses: [&quot;00:00:00:00:ff:02&quot;]</span><br><span class="line">        router-port: lrp1</span><br><span class="line">    port sw1-port1</span><br><span class="line">        addresses: [&quot;50:54:00:00:00:03 11.0.0.2&quot;]</span><br><span class="line">router cd8095b3-287f-4e0c-af3d-a10a089f977c (lr0)</span><br><span class="line">    port lrp1</span><br><span class="line">        mac: &quot;00:00:00:00:ff:02&quot;</span><br><span class="line">        networks: [&quot;11.0.0.1/24&quot;]</span><br><span class="line">    port lrp0</span><br><span class="line">        mac: &quot;00:00:00:00:ff:01&quot;</span><br><span class="line">        networks: [&quot;192.168.0.1/24&quot;]</span><br><span class="line">hua@node1:~$ sudo ovn-trace --minimal sw0 &apos;inport == &quot;sw0-port1&quot; &amp;&amp; eth.src == 50:54:00:00:00:01 &amp;&amp; ip4.src == 192.168.0.2 &amp;&amp; eth.dst == 00:00:00:00:ff:01 &amp;&amp; ip4.dst == 11.0.0.2 &amp;&amp; ip.ttl == 64&apos;</span><br><span class="line"># ip,reg14=0x1,vlan_tci=0x0000,dl_src=50:54:00:00:00:01,dl_dst=00:00:00:00:ff:01,nw_src=192.168.0.2,nw_dst=11.0.0.2,nw_proto=0,nw_tos=0,nw_ecn=0,nw_ttl=64</span><br><span class="line">ip.ttl--;</span><br><span class="line">eth.src = 00:00:00:00:ff:02;</span><br><span class="line">eth.dst = 50:54:00:00:00:03;</span><br><span class="line">output(&quot;sw1-port1&quot;);</span><br><span class="line"></span><br><span class="line"># reset</span><br><span class="line">sudo ovn-nbctl ls-del sw0</span><br><span class="line">sudo ovn-nbctl ls-del sw1</span><br><span class="line">sudo ovn-nbctl lr-del lr0</span><br></pre></td></tr></table></figure>
<p>其他见文档　OVN Routing and ovn-trace　－　<a href="http://dani.foroselectronica.es/ovn-routing-and-ovn-trace-550/" target="_blank" rel="external">http://dani.foroselectronica.es/ovn-routing-and-ovn-trace-550/</a></p>
<h2 id="ovn-dhcp"><a href="#ovn-dhcp" class="headerlink" title="ovn dhcp"></a>ovn dhcp</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#create dhcp port</span><br><span class="line">sudo ovn-nbctl lsp-add sw0 sw0-dhcpport</span><br><span class="line">sudo ovn-nbctl lsp-set-addresses sw0-dhcpport &quot;02:ac:10:ff:01:30 192.168.0.3&quot;</span><br><span class="line">#sudo ovn-nbctl lsp-set-port-security sw0-dhcpport &quot;02:ac:10:ff:01:30 192.168.0.3&quot;</span><br><span class="line">options=&quot;$(sudo ovn-nbctl create DHCP_Options cidr=192.168.0.0/24 \</span><br><span class="line">options=&quot;\&quot;server_id\&quot;=\&quot;192.168.0.10\&quot; \&quot;server_mac\&quot;=\&quot;02:ac:10:ff:01:29\&quot; \</span><br><span class="line">\&quot;lease_time\&quot;=\&quot;3600\&quot; \&quot;router\&quot;=\&quot;192.168.0.10\&quot;&quot;)&quot;</span><br><span class="line">echo &quot;DHCP options is: &quot; $options</span><br><span class="line">sudo ovn-nbctl lsp-set-dhcpv4-options sw0-dhcpport $options</span><br><span class="line">sudo ovn-nbctl dhcp-options-list</span><br><span class="line">sudo ovn-nbctl lsp-get-dhcpv4-options sw0-dhcpport</span><br><span class="line"></span><br><span class="line">#create test vm</span><br><span class="line">sudo ip netns add nsi3</span><br><span class="line">sudo ovs-vsctl add-port br-int i3 -- set interface i3 type=internal</span><br><span class="line">sudo ip link set i3 address 02:ac:10:ff:01:30</span><br><span class="line">sudo ip link set i3 netns nsi3</span><br><span class="line">sudo ovs-vsctl set Interface i3 external_ids:iface-id=sw0-i3</span><br><span class="line"></span><br><span class="line">#get ip address via dhcp</span><br><span class="line">sudo ip netns exec nsi3 dhclient i3</span><br><span class="line">sudo ip netns exec nsi3 ip addr show i3</span><br><span class="line">sudo ip netns exec nsi3 ip route show</span><br></pre></td></tr></table></figure>
<h2 id="OVN-vRouter"><a href="#OVN-vRouter" class="headerlink" title="OVN vRouter"></a>OVN vRouter</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sudo ovn-nbctl ls-add sw0</span><br><span class="line">sudo ovn-nbctl lsp-add sw0 outs-wan</span><br><span class="line">sudo ovn-nbctl lsp-set-addresses outs-wan unknown</span><br><span class="line">sudo ovn-nbctl lsp-set-type outs-wan localnet</span><br><span class="line">sudo ovn-nbctl lsp-set-options outs-wan network_name=wanNet</span><br><span class="line"></span><br><span class="line">sudo ovs-vsctl add-br br-eth</span><br><span class="line">sudo ovs-vsctl set Open_vSwitch . external-ids:ovn-bridge-mappings=wanNet:br-eth</span><br><span class="line">sudo ovs-vsctl add-port br-eth eth0</span><br><span class="line">sudo ip link set br-eth up</span><br><span class="line">sudo ip addr add 192.168.66.111/23 dev br-eth</span><br><span class="line"></span><br><span class="line">#associated VM&apos;s port to bridge</span><br><span class="line">sudo ovs-vsctl set Interface i3 external_ids:iface-id=i3</span><br></pre></td></tr></table></figure>
<h2 id="OVN-SNAT-DNAT"><a href="#OVN-SNAT-DNAT" class="headerlink" title="OVN SNAT/DNAT"></a>OVN SNAT/DNAT</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#fixed-ip: 10.0.1.103  FIP: 192.168.99.122</span><br><span class="line">ovn-nbctl -- --id=@nat create nat type=&quot;snat&quot; logical_ip=10.0.1.0/24 external_ip=192.168.99.122 -- add logical_router gateway_route nat @nat</span><br><span class="line">ovn-nbctl -- --id=@nat create nat type=&quot;dnat_and_snat&quot; logical_ip=10.0.1.103 external_ip=192.168.99.122 -- add logical_router gateway_route nat @nat</span><br></pre></td></tr></table></figure>
<h2 id="一个问题，如何从ovn网关ping其他机器"><a href="#一个问题，如何从ovn网关ping其他机器" class="headerlink" title="一个问题，如何从ovn网关ping其他机器"></a>一个问题，如何从ovn网关ping其他机器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">如下，以前non-ovn环境下，可以从l3-agent上的qrouter-xxx上通过GW(192.168.21.1)来ping servic vm IP (192.168.21.39), 但现在ovn情况下无namespace了，该如何来做这件事呢？</span><br><span class="line">router ca47f4c3-3379-475a-ab80-fac4062e0a3e (neutron-ab4310a3-09b9-4638-8f7c-3873bc9b4c47) (aka provider-router)</span><br><span class="line">    port lrp-c6ffc24d-9213-4e31-80e2-f68107f9aad1</span><br><span class="line">        mac: &quot;fa:16:3e:0e:f8:f5&quot;</span><br><span class="line">        networks: [&quot;192.168.21.1/24&quot;]</span><br><span class="line">    ...</span><br><span class="line">switch a14b3c9a-b5f8-43f2-9ac8-18e58d9f1887 (neutron-0f409568-561e-4e33-89ea-2814faa44add) (aka private)</span><br><span class="line">    port 3f382ff5-7601-4bec-a687-e964adadefc2</span><br><span class="line">        addresses: [&quot;fa:16:3e:f1:fa:a5 192.168.21.237&quot;]</span><br><span class="line">    port 38d6c6f7-8a64-406d-94bb-c550eb50427d</span><br><span class="line">        type: localport</span><br><span class="line">        addresses: [&quot;fa:16:3e:8d:0b:5b 192.168.21.2&quot;]</span><br><span class="line">    port c6ffc24d-9213-4e31-80e2-f68107f9aad1</span><br><span class="line">        type: router</span><br><span class="line">        router-port: lrp-c6ffc24d-9213-4e31-80e2-f68107f9aad1</span><br><span class="line">    port 18ce4590-453a-4152-97b9-eafb3523047d (aka octavia-lb-6058a336-3922-468f-9f70-8e34bd14e195)</span><br><span class="line">        type: virtual</span><br><span class="line">        addresses: [&quot;fa:16:3e:ce:84:fd 192.168.21.39&quot;]</span><br><span class="line"></span><br><span class="line">这样，来做一个pingvm</span><br><span class="line">sudo ovn-nbctl lsp-add a14b3c9a-b5f8-43f2-9ac8-18e58d9f1887 pingvm</span><br><span class="line">sudo ovn-nbctl lsp-set-addresses pingvm &quot;40:44:00:00:00:01 192.168.21.122&quot;</span><br><span class="line"></span><br><span class="line">在计算节点中继续：</span><br><span class="line">sudo ovs-vsctl add-port br-int pingvm -- set Interface pingvm type=internal -- set Interface pingvm external_ids:iface-id=pingvm</span><br><span class="line">sudo ip netns add pingvm</span><br><span class="line">sudo ip link set pingvm netns pingvm</span><br><span class="line">sudo ip netns exec pingvm ip link set pingvm address 40:44:00:00:00:01</span><br><span class="line">sudo ip netns exec pingvm ip addr add 192.168.21.122/24 dev pingvm</span><br><span class="line">sudo ip netns exec pingvm ip link set pingvm up</span><br><span class="line">sudo ip netns exec pingvm ip route add default via 192.168.21.1</span><br><span class="line"></span><br><span class="line">测试, 上面实验可能ping不了，因为应该用octavia的管理IP，但这不妨碍，思路如此．</span><br><span class="line">sudo ip netns exec pingvm ping 192.168.21.39</span><br><span class="line">sudo ip netns exec pingvm ssh 192.168.21.39</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/28/ssh总断/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/28/ssh总断/" itemprop="url">ssh总断</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-10-28T19:43:30+08:00">
                2020-10-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华 发表于：2020-10-28<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</strong></p>
<p>公司服务器今天升级了，结果遇到了一个问题，登录在该服务器上的bastion虚机在运行 一个名为configure的脚本的下列代码时总是中断．<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">set_img_properties ()</span><br><span class="line">&#123;</span><br><span class="line">    img_name=$1</span><br><span class="line">    img_version=$2</span><br><span class="line">    img_file=$3</span><br><span class="line"></span><br><span class="line">    ts=`stat ~/images/$img_file| sed -rn &apos;s/Modify:\s+([[:digit:]-]+)\s+.+/\1/p&apos;| tr -d &apos;-&apos;`</span><br><span class="line">    declare -A props=( [architecture]=x86_64</span><br><span class="line">                       [os_distro]=&apos;ubuntu&apos;</span><br><span class="line">                       [os_version]=$img_version</span><br><span class="line">                       [version_name]=&quot;$ts&quot;</span><br><span class="line">                       [product_name]=&quot;com.ubuntu.cloud:server:$&#123;img_version&#125;:amd64&quot;</span><br><span class="line">    )</span><br><span class="line">    for p in $&#123;!props[@]&#125;; do</span><br><span class="line">      openstack image set --property $p=$&#123;props[$p]&#125; $img_name &amp;</span><br><span class="line">    done</span><br><span class="line">    wait</span><br><span class="line">&#125;</span><br><span class="line">set_img_properties bionic 18.04 bionic-server-cloudimg-amd64.img &amp;</span><br></pre></td></tr></table></figure></p>
<p>ssh中断之后，只能重启bastion才能解决．<br>因为一直没有问题，只是今天服务器升级才遇到问题，所以没想别的，只是要求同事也测了一下，他没遇到问题．<br>接着，以为是mtu问题，将mtu从8930改为1450依旧有问题．<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip netns exec qrouter-1c6f53cf-9b6d-4794-ae8e-61ad1b8e4042 ping -O -M do -s 8930 10.5.0.8</span><br><span class="line">ip netns exec qrouter-1c6f53cf-9b6d-4794-ae8e-61ad1b8e4042 nc -vz 10.5.0.8 22</span><br></pre></td></tr></table></figure></p>
<p>所以就以为是底层openstack有问题，但我没有底层openstack的管理权限，所以只好找有权限的同事帮忙，最后确定没有这方面的问题．<br>最后，就是怀疑bastion这台虚机有问题了．发现里面什么时候安装了devstack，删除devstack后，正常了．<br>但为什么之前一又没问题呢？在有devstack的情况下，代码作下列更改问题也消失．<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#set_img_properties bionic 18.04 bionic-server-cloudimg-amd64.img &amp;</span><br><span class="line">set_img_properties bionic 18.04 bionic-server-cloudimg-amd64.img</span><br></pre></td></tr></table></figure></p>
<p>devstack这些东西不要乱在机器上装啊，习惯要好．上了一大课．</p>
<p>另外，如果ssh连接慢的话，可以尝试在sshd.conf中添加：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">UseDNS no</span><br><span class="line">GSSAPIAuthentication no</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/22/如何将国外的ftp气象大数据下载回来/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/22/如何将国外的ftp气象大数据下载回来/" itemprop="url">如何将国外的ftp气象大数据下载回来</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-10-22T20:49:19+08:00">
                2020-10-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华 发表于：2020-10-22<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</strong></p>
<p>由于运营商对non-http流量限速，从国外ftp下载大数据将变得异常艰难．目前采用的方法如下：</p>
<p>1, 国外虚机上安装curlftpfs将ftp站点镜像到/mnt/ftp<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install curlftpfs -y</span><br><span class="line">#sudo fusermount -zu /mnt/ftp</span><br><span class="line">sudo mkdir -p /mnt/ftp &amp;&amp; sudo chown -R $USER /mnt/ftp</span><br><span class="line">sudo bash -c &apos;cat &gt;&gt;/etc/fstab&apos; &lt;&lt;EOF</span><br><span class="line">curlftpfs#@ftp.hycom.org/datasets/global/GLBa0.08_rect/data /mnt/ftp fuse defaults,rw,allow_other,uid=1000,gid=1000,_netdev 0 0</span><br><span class="line">EOF</span><br><span class="line">sudo mount -a</span><br></pre></td></tr></table></figure></p>
<p>2, 安装nginx指向/mnt/ftp将ftp变http<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install nginx -y</span><br><span class="line">sudo vim /etc/nginx/sites-available/default</span><br><span class="line">        #root /var/www/html;</span><br><span class="line">        root /mnt/ftp;</span><br><span class="line">        location / &#123;</span><br><span class="line">                try_files $uri $uri/ =404;</span><br><span class="line">                autoindex on;</span><br><span class="line">                autoindex_exact_size off;</span><br><span class="line">                autoindex_localtime on;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></p>
<p>3, 国内采用下列命令下载．<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget -c -m http://3.18.xx.xx</span><br><span class="line">#rsync -avztur -e &quot;ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i ~/.aws/xxx.pem&quot; --progress ubuntu@3.18.xx.xx:/mnt/ftp .</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/14/Lost-connection-to-MySQL-server-during-query/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/14/Lost-connection-to-MySQL-server-during-query/" itemprop="url">Lost connection to MySQL server during query</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-10-14T13:37:44+08:00">
                2020-10-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-11-06)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>neutron designate日志中发现错误”Got lower serial for”, 并且创建zone时永远停留在PENDING状态.</p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>minidns中看到下列日志:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var/log/designate/designate-mdns.log.2.gz:2018-10-23 23:27:36.016 94713 INFO designate.mdns.handler [req-26d8910d-61d5-4fd6-bc6b-df7acaf36c12 - - - - -] NotFound, refusing. Question was xxx.openstack-au-east-2.oc.xxx.com. IN SOA</span><br><span class="line">var/log/designate/designate-mdns.log.2.gz:2018-10-23 23:27:36.024 94713 WARNING designate.mdns.handler [req-fa5518dd-9506-44f8-a2ee-ee7d79ffaa3c - - - - -] ZoneNotFound while handling axfr request. Question was xxx.openstack-au-east-2.oc.xxx.com. IN AXFR: ZoneNotFound: Could not find Zone</span><br></pre></td></tr></table></figure></p>
<p>根据代码[1], 查询DB时报ZoneNotFound从而导致无法构建SOA无法构建axfr response, 从而导致minidns master与bind9 slave无法做zone transfer, 这样导致bind9 slave的serial number也无法更新, 最终在minidns notify时看到”Got lower serial for”</p>
<p>在发生ZoneNotFound的附近有下列日志:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[req-b48612b0-ed3e-46d9-8510-6634282ef0a2 - - - - -] Database connection was found disconnected; reconnecting: DBConnectionError: (pymysql.err.OperationalError) (2013, &apos;Lost connection to MySQL server during query&apos;) [SQL: u&apos;SELECT 1&apos;]</span><br></pre></td></tr></table></figure>
<p>于是, 用下列测试程序重现了上述DB error,</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">from sqlalchemy.engine import create_engine</span><br><span class="line">url = &apos;mysql+pymysql://root@127.0.0.1:3306/mysql&apos;</span><br><span class="line">engine = create_engine(url, pool_recycle=4).connect()</span><br><span class="line">query = &apos;SELECT NOW();&apos;</span><br><span class="line">while True:</span><br><span class="line">    print(&apos;Q1&apos;, engine.execute(query).fetchall())</span><br><span class="line">    engine.execute(&apos;SET wait_timeout=2&apos;)</span><br><span class="line">    time.sleep(3)</span><br><span class="line">    print(&apos;Q2&apos;, engine.execute(query).fetchall())</span><br></pre></td></tr></table></figure>
<p>或者使用oslo.db测试程序:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p -e &quot;SET GLOBAL wait_timeout=5, slow_query_log=on, long_query_time=0.0;&quot;</span><br><span class="line"></span><br><span class="line">$ cat test.py</span><br><span class="line">import sys</span><br><span class="line">import time</span><br><span class="line">from oslo_config import cfg</span><br><span class="line">from oslo_db import options as db_options</span><br><span class="line">from oslo_db.sqlalchemy import session as db_session</span><br><span class="line">from sqlalchemy.sql.expression import select</span><br><span class="line">_facade = db_session.EngineFacade(&quot;mysql://root@localhost/test&quot;)</span><br><span class="line">x = _facade.get_session()</span><br><span class="line">print(x.scalar(select([23])))</span><br><span class="line">time.sleep(5)</span><br><span class="line">print(x.scalar(select([23])))</span><br></pre></td></tr></table></figure></p>
<p>连接线的过期时间(pool_recycle, 连接池里的连接空闲一段时间后自动释放, oslo中默认是3600)不能大于服务器端的wait_timeout时间(这里是2, 默认是8小时). 所以应该设置wait_timeout大于3600, 或者haproxy中的配置大于3600.<br>wait_timeout是mysql的一个设置，主要是用来断开不使用的数据库连接。当连接空闲的时间达到wait_timeout设置的最大值时，mysql会主动切断这个连接，以供别的客户端连接数据库。这个值一般是28800，也就是8小时。在mysql中可以通过： show variables like “%timeout%”;获取。<br>另外，当数据库主动切断连接的时候，mysql客户端并不知道这个连接已经被切断，所以程序并不知道其已经无效了，如果mysql客户端再不支持ReConnect，双重的问题叠加在一起就会导致连接池返回无效连接的可能.</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p> mysqldump –single-transaction -u root -p designate –skip-extended-insert &gt; /tmp/designate-$(date +%s).sql</p>
<p>For the error ‘Lost connection to MySQL server during query’,</p>
<p>wait_timeout is a setting of mysql, which is used for server side to disconnect unused client connections proactively. The default is 8 hours(28800), we can check it by ‘show variables like “%timeout%”;’ or ‘juju config mysql wait-timeout’</p>
<p>All the rest of the timeout below should be less than wait_timeout, if they are greater than wait_timeout, the error ‘Lost connection to MySQL server during query’ will happen.<br>1, the default value of olso’s connection_recycle_time is 3600<br>2, the timeout in haproxy.cfg</p>
<p>So we need to collect the following info for further analyses.</p>
<p>1, juju config mysql wait-timeout<br>2, mysql -unova -p -h<mysql_ip> -e ‘show variables like “%timeout%”‘  #eg: run it in nova-cloud-controller/0<br>3, juju ssh neutron-api/0 – sudo grep -r ‘connection_recycle_time’ /etc/neutron/<br>4, juju ssh neutron-api/0 – sudo grep -r ‘timeout’ /etc/haproxy/</mysql_ip></p>
<h2 id="一些命令"><a href="#一些命令" class="headerlink" title="一些命令"></a>一些命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#This will show which openstack service is using the most mysql connections</span><br><span class="line">select user, count(*) from information_schema.processlist group by user;</span><br><span class="line"></span><br><span class="line">juju run --application mysql leader-get</span><br><span class="line">juju run --application mysql &quot;mysql -uroot -pChangeMe123 -e \&quot;SELECT IFNULL(usr,&apos;All Users&apos;) user,IFNULL(hst,&apos;All Hosts&apos;) host,COUNT(1) Connections FROM (SELECT user usr,LEFT(host,LOCATE(&apos;:&apos;,host) - 1) hst FROM information_schema.processlist WHERE user NOT IN (&apos;system user&apos;,&apos;root&apos;)) A GROUP BY usr,hst WITH ROLLUP;\&quot;&quot;</span><br></pre></td></tr></table></figure>
<h2 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h2><p>openstack的各服务都有大量的这种错误：<br>var/log/mysql/error.log:2019-08-29T16:07:45.335406Z 420821 [Note] Aborted connection 420821 to db: ‘keystone’ user: ‘keystone’ host: ‘10.191.5.49’ (Got timeout reading communication packets)</p>
<p>要求客户增大了connect_timeout, net_read_timeout, net_write_timeout, interactive_timeout后使用‘show global status like ‘aborted%’;’看到Aborted_clients的数目仍在增大<br>show global variables like ‘max_conn%’;<br>show global variables like ‘%timeout%’;<br>show global status like ‘aborted%’;<br>show processlist;</p>
<p>这时发现在21:55:48， 所有的designate serveres都收到了mysql错误， 通过mysql的查询日志找到21:04到21:16之间mysql收到了40个gnocchi查询，一个查询就要返回500MB的大小, 然后看到了警告：InnoDB: Warning: difficult to find free blocks in the buffer pool (338 search iterations)!”<br>所以看起来像是IO swamp的问题进而造成查询超时。解决方法：<br>1， 增加innodb_buffer_pool_size (juju中通过dataset-size控制）<br>2, 删除gnocchi中的相关数据<br>3, 调查designate中当遇到mysql超时时是不是会反复retry造成对DB的flood</p>
<h2 id="20201014更新"><a href="#20201014更新" class="headerlink" title="20201014更新"></a>20201014更新</h2><p>amphora-agent writes heatbeat to udp, then octavia-health-manager gets heatbeat from udp and writes them to DB, finally health_manager gets heartbeat from DB via get_stale_amphora to decide if failover process will be started</p>
<p>当health-manager线程的数目(pgrep -af /usr/bin/octavia-health-manager | wc -l, 160)大于mysql的连接数时(ss -tp | grep -c :mysql, 90)时上面的get_stale_amphora就会报”Lost connection to MySQL server during query”错误(排除wait-timeout!=3600这个因素之后),<br>sqlalchemy看到这个错误后就会reconnect, 从而产生下面提到的”QueuePool limit of size 10 overflow 20 reached, connection timed out, timeout 10”这个错误(<a href="http://sqlalche.me/e/3o7r" target="_blank" rel="external">http://sqlalche.me/e/3o7r</a>). sqlalchemy’s reconnect可能不是replace, 而是删除老连接然后建立新连接, 这次当达到max_pool_size+max_overflow=20个连接后永远无新连接供它reconnect(sqlalchemy使用max_pool_size=10, 当一次使用多于5时, 会用到默认的max_overflow=10这样可以达到15个连接, 但多于20个后不再允许溢出.), 这可能是一个bug - <a href="https://github.com/sqlalchemy/sqlalchemy/issues/5308" target="_blank" rel="external">https://github.com/sqlalchemy/sqlalchemy/issues/5308</a></p>
<p>可能在mysql在做failover时会出现这种情况, 因为new VIP owner没有old TCP connections从而导致之后的old TCP connections to go stale从而导致reconnect.</p>
<p>可能的解决方法:<br>1, 如果mysql不再failover的话可能这个问题也不再重启了, 这个可以等下列fix<br>2, as a base leve request a stable backport for the following patch<br>health-manager的eventlet/greenlet的数目由health_update_threads参数决定, 默认与CPU核数同, 大多数情况下都是短连接会多路复用还没问题, 但有时候也会各种因素让有的变成长连接. charm中一般对于worker threads有0.25x的乘数(LXD容器中最大是4), octavia-charm也应该用这个乘数来减小worker threads的数目 - <a href="https://bugs.launchpad.net/charm-octavia/+bug/1889731" target="_blank" rel="external">https://bugs.launchpad.net/charm-octavia/+bug/1889731</a><br>3, We could additionally reconfigure the oslo.db [database] section to include a pool overflow limit at least as large as the number of expected threads by worker-multiplier<br>4, We could additionally open a bug against sqlalchemy that it should allow for connection replacement even when the pool limit is reached</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://github.com/openstack/designate/blob/stable/queens/designate/mdns/handler.py#L233" target="_blank" rel="external">https://github.com/openstack/designate/blob/stable/queens/designate/mdns/handler.py#L233</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/29/UEFI-Secure-Boot学习草稿/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/29/UEFI-Secure-Boot学习草稿/" itemprop="url">UEFI Secure Boot学习草稿</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-29T19:17:27+08:00">
                2020-09-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华 发表于：2020-09-29<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</strong></p>
<h2 id="什么是secure-boot"><a href="#什么是secure-boot" class="headerlink" title="什么是secure boot"></a>什么是secure boot</h2><p>secureboot is designed to present non-Windows OS from booting(Secure Boot works by placing the root of trust in firmware), you can still boot Grub2 with secureboot using shim and MOK manager. And from grub2, you can boot into other operating systems.也就是说:<br>secureboot将根证书放在固件firmware中, 然后可以验证signed bootloader, signed bootloader然后再验证signed kernel和signed 2nd stage boot loader.这样系统允许你修改secureboot keys.</p>
<ul>
<li>db, 允许bootloaders的公钥集合</li>
<li>dbx, 不允许bootloaders的公钥集合</li>
<li>KEK, 允许操作db的公钥集合</li>
<li>PK, 允许操作KEK的私钥.</li>
</ul>
<p>默认地, 系统有硬件制造商的PK, microsoft和硬件制造商的公钥在db与KEK里. 这样就可以使用microsoft-certified bootloaders, 再通过它签名的shim来使用其他linuxers. 有的UEFI BIOS setup允许adding and delteing所有的secureboot keys, 而有些却允许你要么删除所有要么用默认(删除之前记得备份哦). 如果PK被删除的话, secure boot这时叫so-called setup mode. 你可能想有这个密钥:<br>the db set should contain:</p>
<ul>
<li>your own public key certificate, for booting things you’ve explicitly signed</li>
<li>maybe your favorite Linux distribution’s kernel signing certificate, if you want to use pre-packaged kernels without manually re-signing them</li>
<li>maybe hardware vendor’s certificate, to allow installing firmware updates if necessary maybe Microsoft’s third-party UEFI certificate, to allow the use of pre-packaged Linux bootloaders and live Linux boot media without explicitly re-signing them or disabling Secure Boot</li>
<li>maybe Microsoft’s OS signing certificate, if you dual-boot with Windows</li>
</ul>
<p>the KEK set should contain:</p>
<ul>
<li>your own certificate, for updating db and dbx</li>
<li>if your system includes UEFI-aware Microsoft OSs, you may want to include Microsoft’s KEK certificate, as Microsoft’s updates sometimes include updates to db and/or dbx and those updates won’t install successfully if access to Secure Boot is denied</li>
<li>and finally, once all the rest is set up as you want, you should place your own certificate into PK to make Secure Boot effective again.</li>
</ul>
<h2 id="有无shim"><a href="#有无shim" class="headerlink" title="有无shim"></a>有无shim</h2><p>bootloader有两种, shim与grub2都叫bootloader, 所以理论上是可以不需要shim的, 但为什么需要shim呢? 这个网页(<a href="https://unix.stackexchange.com/questions/423666/secureboot-with-uefi-bootloader-and-grub2-only)说:grub" target="_blank" rel="external">https://unix.stackexchange.com/questions/423666/secureboot-with-uefi-bootloader-and-grub2-only)说:grub</a> uses firmware API to validate binary signatures; you might prefer shim instead of signing the binaries with the “precious” key each time.</p>
<p>非secureboot模式下, 没有shim组件, efi直接启动grub2.<br>在secureboot模式下, 有shim组件, 且shim需要使用efi中的证书签名(grub2和kernel的签名不一定非要用efi中的证书, 可以自己随意定制后再使用shim相关工具导入nvram中). 即使在secureboot模式下也可以有shim和无shim:</p>
<ul>
<li>无shim, 在centos中可以跳过shim, 直接让efi启动grub2也是没问题的, 但grub2与kernel都需要使用efi中的证书签名, 由efi进行grub2与kernel的校验.</li>
<li>有shim, grub2中用户选择kernel后, grub2回调shim组件校验kernel(grub2, kernel使用相同的私钥签名)</li>
</ul>
<h2 id="可信问题"><a href="#可信问题" class="headerlink" title="可信问题"></a>可信问题</h2><ul>
<li>initrd和intrd加载的模式都是不可信的, 这部分都没有经过签名;</li>
<li>systemtap, kexec, kdump也都是没有签名的;</li>
<li>第三方KO模式没有签名(正常情况下, 模块需要使用mok签名, shim来验证)</li>
</ul>
<h2 id="secureboot启动流程"><a href="#secureboot启动流程" class="headerlink" title="secureboot启动流程"></a>secureboot启动流程</h2><p>1, 打开电源, 先运行Secure Boot-capable UEFI firmware (对于qemu虚机, 这个secureboot capable UEFI OVMF firmware叫UEFI x86_64 : usr/share/OVMF/OVMF_CODE.fd,  (sudo apt install ovmf &amp;&amp; sudo systemctl restart libvirtd)</p>
<p>2, firware验证bootloader的签名. UEFI firmware中预先在NVRAM系统中(或者compiled-in defaults)集成了一些公钥集合(secure boot key sets) , 它可以给bootloader验证签名(shim or grub2), 不使用shim的话, grub2得每次调用firware api去验证签名.</p>
<p>UEFI firmware uses /boot/efi/EFI/BOOT/BOOTX64.EFI (从md5sum看它和/boot/efi/EFI/centos/shimx64.efi是同一个文件,  对于shim就是将shimx64.efi拷贝到BOOTX64.EFI, 对于grub2可能就是将grubx64.efi拷贝到BOOTX64.EFI了) to boot at the first stage.</p>
<p>[root@test2 ~]# md5sum /boot/efi/EFI/BOOT/BOOTX64.EFI<br>25d9ccc49c419d76324a29615e8371c2  /boot/efi/EFI/BOOT/BOOTX64.EFI<br>[root@test2 ~]# md5sum /boot/efi/EFI/centos/shimx64.efi<br>25d9ccc49c419d76324a29615e8371c2  /boot/efi/EFI/centos/shimx64.efi<br>[root@test2 ~]# md5sum /boot/efi/EFI/centos/shimx64-centos.efi<br>d435494a957479acac3aca09915c21d1  /boot/efi/EFI/centos/shimx64-centos.efi<br>[root@test2 ~]# md5sum /boot/efi/EFI/centos/grubx64.efi<br>031b972f3ab267f37e01ada73f4b480d  /boot/efi/EFI/centos/grubx64.efi</p>
<p>3, bootloader再去验证kernel的签名.</p>
<p>then shim will load grub2 (/boot/efi/EFI/centos/grubx64.efi) in the second stage</p>
<p>4, kernel再去验证module的签名.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://wiki.ubuntu.com/UEFI/SecureBoot/Testing?action=show&amp;redirect=SecurityTeam%2FSecureBoot" target="_blank" rel="external">https://wiki.ubuntu.com/UEFI/SecureBoot/Testing?action=show&amp;redirect=SecurityTeam%2FSecureBoot</a><br>[2] <a href="https://www.aioboot.com/en/secure-boot/" target="_blank" rel="external">https://www.aioboot.com/en/secure-boot/</a><br>[3] <a href="https://specs.openstack.org/openstack/nova-specs/specs/train/approved/allow-secure-boot-for-qemu-kvm-guests.html" target="_blank" rel="external">https://specs.openstack.org/openstack/nova-specs/specs/train/approved/allow-secure-boot-for-qemu-kvm-guests.html</a><br>[4] Grub 2：拯救你的 bootloader, <a href="https://linux.cn/article-6892-1.html?pr" target="_blank" rel="external">https://linux.cn/article-6892-1.html?pr</a><br>[5] <a href="https://unix.stackexchange.com/questions/423666/secureboot-with-uefi-bootloader-and-grub2-only" target="_blank" rel="external">https://unix.stackexchange.com/questions/423666/secureboot-with-uefi-bootloader-and-grub2-only</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/18/引入nova-placement之后对调度的影响/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/18/引入nova-placement之后对调度的影响/" itemprop="url">引入nova placement之后对调度的影响</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-18T15:33:22+08:00">
                2020-09-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华 发表于：2020-09-17<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</strong></p>
<h2 id="nova-cell-v2"><a href="#nova-cell-v2" class="headerlink" title="nova cell v2"></a>nova cell v2</h2><p>nova cell v2将nova db分成了3个(nova, nova_api, nova_cell0，虚机信息只存储在所在的cell中，公共数据存储在nova_api库中), nova_api中的3个表(nova_api.host_mappings, nova_api.instance_mappings, nova_api.cell_mappings可以直接从instance找到cell_id进而找到DB与MQ的信息，这样nova-api直接就可以操作该cell之类的DB与MQ从而可以让nova-compute可以水平扩展到更多的物理节点，另一方面，nova-api节点也不再需要nova-cell服务，要有nova-api与nova-scheduler两个服务即可．</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; pager less -S</span><br><span class="line">PAGER set to &apos;less -S&apos;</span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">mysql&gt; select instance_uuid,cell_id from instance_mappings;</span><br><span class="line">+--------------------------------------+---------+</span><br><span class="line">| instance_uuid                        | cell_id |</span><br><span class="line">+--------------------------------------+---------+</span><br><span class="line">| 4039ed4e-d0a1-46ba-99a5-68bc84421b42 |       2 |</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from host_mappings;</span><br><span class="line">+---------------------+------------+----+---------+-------------------------------------+</span><br><span class="line">| created_at          | updated_at | id | cell_id | host                                |</span><br><span class="line">+---------------------+------------+----+---------+-------------------------------------+</span><br><span class="line">| 2020-09-16 06:18:26 | NULL       |  1 |       2 | juju-3ba760-ceilometer-15.cloud.sts |</span><br><span class="line"></span><br><span class="line">mysql&gt; select transport_url,name,database_connection from cell_mappings;</span><br><span class="line">+----------------------------------------------------------------------------------------------------------+-------+-----------------------------------------------------------------------------+</span><br><span class="line">| transport_url                                                                                            | name  | database_connection                                                         |</span><br><span class="line">+----------------------------------------------------------------------------------------------------------+-------+-----------------------------------------------------------------------------+</span><br><span class="line">| none:///                                                                                                 | cell0 | mysql+pymysql://nova:4Hjrdj5yMTkG6V9nxNpqrfVdhtJ5Tnww@10.5.0.103/nova_cell0 |</span><br><span class="line">| rabbit://nova:wSz5LjscfBqKnhVWKBZnrXdwS5Kz6TByz9jKfm2xKHbCRYPPSbcnqFwPTnCp8VpP@10.5.0.199:5672/openstack | cell1 | mysql+pymysql://nova:4Hjrdj5yMTkG6V9nxNpqrfVdhtJ5Tnww@10.5.0.103/nova       |</span><br></pre></td></tr></table></figure>
<p>所以当遇到这种错误时:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openstack server delete 2ebf1b2d-f679-4265-9c4b-71420dace71a</span><br><span class="line">No server with a name or ID of 2ebf1b2d-f679-4265-9c4b-71420dace71a</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo nova-manage cell_v2 list_cells</span><br><span class="line">sudo nova-manage cell_v2 map_instances --cell_uuid &lt;cell-id-from-above&gt;</span><br><span class="line">openstack server delete 2ebf1b2d-f679-4265-9c4b-71420dace71a</span><br></pre></td></tr></table></figure>
<h2 id="nova-placement-API"><a href="#nova-placement-API" class="headerlink" title="nova placement API"></a>nova placement API</h2><p>nova placement API在Newton被引入, nova-scheduler调用placement-api用于调度. 主要用于跟踪记录Resource Provider(compute-node, external storage-pool, external ip-allocation-pool etc)的Inventory和Usage.自Pike版本, 必须启用Placement API来辅助nova-scheduler service进行compute node调度，并以此替代之前的RAMFilter、CoreFilter和DiskFilter。概念对象如下:</p>
<ul>
<li>Resource Class, 资源种类, placement api默认实现了DISK_GB, MEMORY_MB,VCPU三种标准resource classes, 也提供了custom resource classes的接口.</li>
<li>Resource Providers：资源提供者，实际提供资源的对象，例如：compute node、storage pool</li>
<li>Inventory：资源清单，资源提供者所拥有的资源清单，例如：compute node 拥有的vCPU、Disk、RAM 等 inventories</li>
<li>Resource Allocations：资源分配状况，包含了Resource Class、Resource Provider以及Consumer 的映射关系。记录消费者使用了多少该类型的资源数量</li>
<li>Provider Aggregate：资源聚合，类似 HostAggregate 的概念</li>
<li>Traits：资源特征，不同资源提供者可能会具有不同的资源特征。Traits 作为资源提供者特征的描述，它不能够被消费，但在某些Workflow 或者会需要这些信息。例如：标识可用的Disk是一个SSD，可以帮助Scheduler更好的匹配 instance boot请求。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from resource_providers;</span><br><span class="line">+---------------------+---------------------+----+--------------------------------------+-------------------------------------+------------+----------+------------------+--------------------+</span><br><span class="line">| created_at          | updated_at          | id | uuid                                 | name                                | generation | can_host | root_provider_id | parent_provider_id |</span><br><span class="line">+---------------------+---------------------+----+--------------------------------------+-------------------------------------+------------+----------+------------------+--------------------+</span><br><span class="line">| 2020-09-16 06:18:15 | 2020-09-16 10:19:33 |  1 | a7081054-ee03-44b8-ae21-f20e0535cfc1 | juju-3ba760-ceilometer-15.cloud.sts |         19 |     NULL |                1 |               NULL |</span><br><span class="line"></span><br><span class="line"># for the field resource_class_id, 0 means VCPU, 1 means MEMORY_MB, 2 means DISK_GB</span><br><span class="line">mysql&gt; select * from inventories;</span><br><span class="line">+---------------------+------------+----+----------------------+-------------------+-------+----------+----------+----------+-----------+------------------+</span><br><span class="line">| created_at          | updated_at | id | resource_provider_id | resource_class_id | total | reserved | min_unit | max_unit | step_size | allocation_ratio |</span><br><span class="line">+---------------------+------------+----+----------------------+-------------------+-------+----------+----------+----------+-----------+------------------+</span><br><span class="line">| 2020-09-16 06:18:15 | NULL       |  1 |                    1 |                 0 |     2 |        0 |        1 |        2 |         1 |               16 |</span><br><span class="line">| 2020-09-16 06:18:15 | NULL       |  2 |                    1 |                 1 |  3944 |      512 |        1 |     3944 |         1 |              1.5 |</span><br><span class="line">| 2020-09-16 06:18:15 | NULL       |  3 |                    1 |                 2 |    38 |        0 |        1 |       38 |         1 |                1 |</span><br><span class="line">mysql&gt; select * from allocations;</span><br><span class="line">+---------------------+------------+----+----------------------+--------------------------------------+-------------------+------+</span><br><span class="line">| created_at          | updated_at | id | resource_provider_id | consumer_id                          | resource_class_id | used |</span><br><span class="line">+---------------------+------------+----+----------------------+--------------------------------------+-------------------+------+</span><br><span class="line">| 2020-09-16 08:45:44 | NULL       | 16 |                    1 | 64cb10fd-246f-4864-b06d-687d59c47c2c |                 2 |    1 |</span><br><span class="line">| 2020-09-16 08:45:44 | NULL       | 17 |                    1 | 64cb10fd-246f-4864-b06d-687d59c47c2c |                 1 |   64 |</span><br><span class="line">| 2020-09-16 08:45:44 | NULL       | 18 |                    1 | 64cb10fd-246f-4864-b06d-687d59c47c2c |                 0 |    1 |</span><br></pre></td></tr></table></figure>
<h2 id="Placement-CLI"><a href="#Placement-CLI" class="headerlink" title="Placement CLI"></a>Placement CLI</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python3-osc-placement -y</span><br><span class="line"></span><br><span class="line">$ openstack resource provider list</span><br><span class="line">+--------------------------------------+-------------------------------------+------------+</span><br><span class="line">| uuid                                 | name                                | generation |</span><br><span class="line">+--------------------------------------+-------------------------------------+------------+</span><br><span class="line">| a7081054-ee03-44b8-ae21-f20e0535cfc1 | juju-3ba760-ceilometer-15.cloud.sts |         19 |</span><br><span class="line">+--------------------------------------+-------------------------------------+------------+</span><br><span class="line"></span><br><span class="line">$  openstack resource provider inventory list a7081054-ee03-44b8-ae21-f20e0535cfc1</span><br><span class="line">+----------------+------------------+----------+----------+----------+-----------+-------+</span><br><span class="line">| resource_class | allocation_ratio | min_unit | max_unit | reserved | step_size | total |</span><br><span class="line">+----------------+------------------+----------+----------+----------+-----------+-------+</span><br><span class="line">| VCPU           |             16.0 |        1 |        2 |        0 |         1 |     2 |</span><br><span class="line">| MEMORY_MB      |              1.5 |        1 |     3944 |      512 |         1 |  3944 |</span><br><span class="line">| DISK_GB        |              1.0 |        1 |       38 |        0 |         1 |    38 |</span><br><span class="line">+----------------+------------------+----------+----------+----------+-----------+-------+</span><br><span class="line"></span><br><span class="line">$ openstack resource provider usage show a7081054-ee03-44b8-ae21-f20e0535cfc1</span><br><span class="line">+----------------+-------+</span><br><span class="line">| resource_class | usage |</span><br><span class="line">+----------------+-------+</span><br><span class="line">| VCPU           |     3 |</span><br><span class="line">| MEMORY_MB      |   192 |</span><br><span class="line">| DISK_GB        |     3 |</span><br><span class="line">+----------------+-------+</span><br></pre></td></tr></table></figure>
<h2 id="one-bug"><a href="#one-bug" class="headerlink" title="one bug"></a>one bug</h2><p>例如, 如<a href="https://bugs.launchpad.net/nova/+bug/1679750描述的场景" target="_blank" rel="external">https://bugs.launchpad.net/nova/+bug/1679750描述的场景</a>, 在hostA上创建一虚机,hostA死掉了, 这时删除虚机时无法删除实例(因为nova-compute这时死掉了啊), 这样会导致allocations表中的记录没有被删除. 如果hostA又起来了, nova-compute的init_host-&gt;_complete_partial_deletion<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pre_start_hook -&gt; update_available_resource -&gt; nova/compute/manager.py#update_available_resource_for_node -&gt; update_available_resource -&gt; _update_available_resource -&gt; _remove_deleted_instances_allocations</span><br></pre></td></tr></table></figure></p>
<p>当把一个nova-compute删除时，删了service和compute_node表记录后,却没有删除placement resource provider和host mapping records.<br>nova-compute自己都死了它是没法自己删自己的,所以改由nova-api在启动时在删除instances时也删除allocations表中的记录 -<br><a href="https://review.opendev.org/#/c/580498/" target="_blank" rel="external">https://review.opendev.org/#/c/580498/</a></p>
<h2 id="debug"><a href="#debug" class="headerlink" title="debug"></a>debug</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">select * nova_api.from host_mappings;</span><br><span class="line">select * from nova_api.cell_mappings;</span><br><span class="line">select * from nova_api.resource_providers where name like &apos;%xxx%&apos;;   xx.bos01.xxx (9)</span><br><span class="line">select * from nova.compute_nodes where host like &apos;%bagon%&apos; or hypervisor_hostname like &apos;%xxx%&apos;;</span><br><span class="line">select * from nova_api.inventories where resource_provider_id in (select id from nova_api.resource_providers where name like &apos;%xxx%&apos;);</span><br><span class="line">select * from nova_api.allocations where resource_provider_id in (select id from nova_api.resource_providers where name like &apos;%xxx%&apos;) order by consumer_id,resource_provider_id,resource_class_id;</span><br><span class="line">select uuid, host, node, vcpus, memory_mb, vm_state, power_state, task_state, root_gb, ephemeral_gb, cell_name,deleted from nova.instances where uuid in (select consumer_id from nova_api.allocations where resource_provider_id in (select id from nova_api.resource_providers where name like &apos;%xxx%&apos;)) order by uuid;</span><br></pre></td></tr></table></figure>
<h2 id="20201230更新-another-bug"><a href="#20201230更新-another-bug" class="headerlink" title="20201230更新 - another bug"></a>20201230更新 - another bug</h2><p>“select numa_topology from nova.compute_nodes where hypervisor_hostname=’cloud3.xxx.com’\G”显示cell0上的pinned_cpus将所有CPU全用完了导致nova-schedule无法继续调度报“Filter NUMATopologyFilter returned 0 hosts”这种错。<br>下面代码分析显示周期性的update_available_resource本来是可以自动修改数据库记录的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pre_start_hook -&gt; update_available_resource -&gt; _update_available_resource -&gt; _update_usage_from_instances -&gt; _update_usage_from_instance -&gt; _update_usage -&gt; numa_usage_from_instance_numa</span><br></pre></td></tr></table></figure></p>
<p>从数据库拿出host_cell.pinned_cpus作为pinned_cpus的初始值，特别要注意：host_cell.pinned_cpus并不是直接从数据库取的，它通过运行下列的self._copy_resources(cn, resources)方法实际上让host_cell.pinned_cpus永远为empty<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">693 def _init_compute_node(self, context, resources):</span><br><span class="line">...</span><br><span class="line">713 if nodename in self.compute_nodes:</span><br><span class="line">714 cn = self.compute_nodes[nodename]</span><br><span class="line">715 self._copy_resources(cn, resources)</span><br><span class="line">716 self._setup_pci_tracker(context, cn, resources)</span><br><span class="line">717 return False</span><br></pre></td></tr></table></figure></p>
<p>它根据free变量来决定是往pinned_cpus上加还是减。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">./nova/virt/hardware.py#numa_usage_from_instance_numa</span><br><span class="line">def numa_usage_from_instance_numa(host_topology, instance_topology,free=False):</span><br><span class="line">...</span><br><span class="line">for host_cell in host_topology.cells:</span><br><span class="line">new_cell = objects.NUMACell(</span><br><span class="line">id=host_cell.id,</span><br><span class="line">cpuset=shared_cpus,</span><br><span class="line">pcpuset=dedicated_cpus,</span><br><span class="line">memory=host_cell.memory,</span><br><span class="line">cpu_usage=0,</span><br><span class="line">memory_usage=0,</span><br><span class="line">mempages=host_cell.mempages,</span><br><span class="line">pinned_cpus=host_cell.pinned_cpus,</span><br><span class="line">siblings=host_cell.siblings)</span><br><span class="line">...</span><br><span class="line">if free:</span><br><span class="line">if (instance_cell.cpu_thread_policy ==</span><br><span class="line">fields.CPUThreadAllocationPolicy.ISOLATE):</span><br><span class="line">new_cell.unpin_cpus_with_siblings(pinned_cpus)</span><br><span class="line">else:</span><br><span class="line">new_cell.unpin_cpus(pinned_cpus)</span><br></pre></td></tr></table></figure></p>
<p>free是由”free = sign == -1“决定的（看仔细，右边的是两个等号，左边的是一个等号）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def _update_usage(self, usage, nodename, sign=1):</span><br><span class="line">...</span><br><span class="line">free = sign == -1</span><br><span class="line">cn.numa_topology = hardware.numa_usage_from_instance_numa(</span><br><span class="line">host_numa_topology, instance_numa_topology, free)._to_json()</span><br><span class="line"></span><br><span class="line">def _update_usage_from_instance():</span><br><span class="line">is_new_instance = uuid not in self.tracked_instances</span><br><span class="line">is_removed_instance = not is_new_instance and (is_removed or</span><br><span class="line">instance[&apos;vm_state&apos;] in vm_states.ALLOW_RESOURCE_REMOVAL)</span><br><span class="line">if is_new_instance:</span><br><span class="line">self.tracked_instances.add(uuid)</span><br><span class="line">sign = 1</span><br><span class="line">if is_removed_instance:</span><br><span class="line">self.tracked_instances.remove(uuid)</span><br><span class="line">sign = -1</span><br><span class="line">...</span><br><span class="line">self._update_usage(self._get_usage_dict(instance, instance),nodename, sign=sign)</span><br></pre></td></tr></table></figure></p>
<p>所以只要update_available_resource运行那脏记录必须得到修改，那现在没修改说明update_available_resource一直没运行，日志里发现这种错误placement正在使用http而非https打头的endpoint从而导致placement api不可用，这样导致update_available_resource在调用update_placement时出错，从而导致update_available_resource自2020-10-26后再未运行。详见－<a href="https://bugs.launchpad.net/charm-nova-compute/+bug/1826382" target="_blank" rel="external">https://bugs.launchpad.net/charm-nova-compute/+bug/1826382</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2020-10-26 15:43:34.459 1393 WARNING keystoneauth.discover [req-5dcdc394-2784-40d2-984c-54fe261f36f0 - - - - -] Failed to contact the endpoint at http://placement-int.xxx.com:8778 for discovery. Fallback to using that endpoint as the base url.</span><br><span class="line">2020-10-26 15:43:34.463 1393 ERROR nova.compute.manager [req-5dcdc394-2784-40d2-984c-54fe261f36f0 - - - - -] Could not retrieve compute node resource provider 8bd4062b-84c7-4aab-ade7-31dc01695878 and therefore unable to error out any instances stuck in BUILDING state. Error: Failed to retrieve allocations for resource provider 8bd4062b-84c7-4aab-ade7-31dc01695878:</span><br></pre></td></tr></table></figure>
<p>关于numa测试环境的搭建可以见－<a href="https://blog.csdn.net/quqi99/article/details/51993512" target="_blank" rel="external">https://blog.csdn.net/quqi99/article/details/51993512</a>, 注意一点，grub里定义isolcpus并不会让nova不使用这些cpu, nova里专门有vcpu_pin_set来做这件事。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://blog.csdn.net/jmilk/article/details/81264240" target="_blank" rel="external">https://blog.csdn.net/jmilk/article/details/81264240</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">张华</p>
              <p class="site-description motion-element" itemprop="description">blog.csdn.net/quqi99</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">94</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张华</span>

  
</div>


  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
