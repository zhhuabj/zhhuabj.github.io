<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="blog.csdn.net/quqi99">
<meta property="og:type" content="website">
<meta property="og:title" content="技术并艺术着">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="blog.csdn.net/quqi99">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="技术并艺术着">
<meta name="twitter:description" content="blog.csdn.net/quqi99">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title>技术并艺术着</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">技术并艺术着</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">张华的技术博客 - blog.csdn.net/quqi99</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/16/分析Ubuntu-Kernel-Kdump文件/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/16/分析Ubuntu-Kernel-Kdump文件/" itemprop="url">分析Ubuntu Kernel Kdump文件</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-01-16T18:54:49+08:00">
                2021-01-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2014-07-23<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>(<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )<br>      Linux内核在发生kernel panic时会打印出Oops信息，把目前的寄存器状态、堆栈内容、以及完整的Call trace都使用内核转储工具kdump dump到一个文件里，之后我们再用gdb来分析.<br>      kexec是一个快速启动的机制，允许通过已经运行的内核的上下文不经过BIOS启动一个linux内核，它是实现kdump的关键。首先用户空间的工具kexec-tools将捕获内核的地址传递给生产内核，从而在系统崩溃时能找到捕获内核的地址并运行。</p>
<p>1, 安装linux-crashdump (sudo apt-get install linux-crashdump)将安装crash, kexec-tools, makedumpfile三个工具，安装后会产生如下grub2选项。</p>
<p>hua@node1:~$ cat /etc/default/grub.d/kexec-tools.cfg<br>GRUB_CMDLINE_LINUX_DEFAULT=”$GRUB_CMDLINE_LINUX_DEFAULT crashkernel=384M-:128M”</p>
<p>2,  修改kdump配置文件(/etc/default/kdump-tools): USE_KDUMP=1</p>
<p>3, 启动kdump, sudo /etc/init.d/kdump-tools start ，或重启机器会看到如下信息代表成功。</p>
<p>hua@node1:~$ cat /var/crash/kexec_cmd   #捕获镜像与生产镜像用的是同一个<br>/sbin/kexec -p –command-line=”BOOT_IMAGE=/boot/vmlinuz-4.4.0-9-generic root=UUID=e9127b13-568c-4a69-9bbd-0b00e44f0ad9 ro quiet splash intel_iommu=on pci=assign-busses vt.handoff=7 irqpoll maxcpus=1 nousb” –initrd=/boot/initrd.img-4.4.0-9-generic /boot/vmlinuz-4.4.0-9-generic</p>
<p>hua@node1:~$ cat /proc/cmdline<br>BOOT_IMAGE=/boot/vmlinuz-4.4.0-9-generic root=UUID=e9127b13-568c-4a69-9bbd-0b00e44f0ad9 ro quiet splash intel_iommu=on pci=assign-busses crashkernel=384M-:128M vt.handoff=7</p>
<p>hua@node1:~$ sudo dmesg | grep crash<br>[    0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-4.4.0-9-generic root=UUID=e9127b13-568c-4a69-9bbd-0b00e44f0ad9 ro quiet splash intel_iommu=on pci=assign-busses crashkernel=384M-:128M vt.handoff=7<br>[    0.000000] Reserving 128MB of memory at 704MB for crashkernel (System RAM: 32640MB)</p>
<p>cat /etc/sysctl.conf</p>
<h1 id="VMCORE-setup"><a href="#VMCORE-setup" class="headerlink" title="VMCORE setup"></a>VMCORE setup</h1><p>kernel.hung_task_panic = 0<br>kernel.panic = 0<br>kernel.panic_on_io_nmi = 0<br>kernel.panic_on_oops = 0<br>kernel.panic_on_unrecovered_nmi = 0<br>kernel.softlockup_panic = 0<br>kernel.unknown_nmi_panic = 0</p>
<p> kernel.sysrq=1</p>
<p>kernel.hung_task_timeout_secs = 0</p>
<p>sysctl -w vm.dirty_ratio=5                  #写缓存频率</p>
<p>fs.pipe-user-pages-soft = 16384<br>fs.xfs.panic_mask = 0<br>kernel.hardlockup_panic = 0<br>kernel.hung_task_check_count = 4194304<br>kernel.hung_task_panic = 0<br>kernel.hung_task_timeout_secs = 120<br>kernel.hung_task_warnings = 8<br>kernel.panic = 0<br>kernel.panic_on_io_nmi = 0<br>kernel.panic_on_oops = 0<br>kernel.panic_on_unrecovered_nmi = 0<br>kernel.panic_on_warn = 0<br>kernel.soft_watchdog = 1<br>kernel.softlockup_all_cpu_backtrace = 0<br>kernel.softlockup_panic = 0<br>kernel.unknown_nmi_panic = 0</p>
<p>4,  按组合键Alt+SysRq+c就可以产生一个panic（或 echo c &gt; /proc/sysrq-trigger）, 然后在/var/crash/目录可以找到crash日志</p>
<pre><code>ubuntu里也有一个命令如sudo apport-cli -f -P `pidof firefox`用于收集panic时的kernel日志的
</code></pre><p>5, 一般拿过来的crash log是通过base64加密过，可解密:apport-unpack 00069866-linux-image-3.2.0-23-generic.0.txt ./tmp/</p>
<p>6, crash工具需要内核调试信息dbgsym才可以工作，先看看有没有/user/lib/debug/boot这个目录，没有的话从这里下载<a href="http://ddebs.ubuntu.com/pool/main/l/linux/，" target="_blank" rel="external">http://ddebs.ubuntu.com/pool/main/l/linux/，</a> 或者：<br>echo “deb <a href="http://ddebs.ubuntu.com" target="_blank" rel="external">http://ddebs.ubuntu.com</a> $(lsb_release -cs) main restricted universe multiverse” | sudo tee -a /etc/apt/sources.list.d/ddebs.list</p>
<p>deb <a href="http://ddebs.ubuntu.com" target="_blank" rel="external">http://ddebs.ubuntu.com</a> trusty main restricted universe multiverse<br>deb <a href="http://ddebs.ubuntu.com" target="_blank" rel="external">http://ddebs.ubuntu.com</a> trusty-updates main restricted universe multiverse<br>deb <a href="http://ddebs.ubuntu.com" target="_blank" rel="external">http://ddebs.ubuntu.com</a> trusty-proposed main restricted universe multiverse</p>
<p>   sudo apt-key adv –keyserver keyserver.ubuntu.com –recv-keys ECDCAD72428D7C01<br>   sudo apt-get update<br>   sudo apt-get install systemtap<br>   sudo apt-get install linux-image-$(uname -r)-dbgsym</p>
<p>   sudo apt-get source linux-image-$(uname -r)</p>
<p>或者使用“axel -n 64”命令高速下载后安装‘sudo dpkg -i *.ddeb’</p>
<p>没有时再：</p>
<p><a href="https://wiki.ubuntu.com/Kernel/Systemtap" target="_blank" rel="external">https://wiki.ubuntu.com/Kernel/Systemtap</a><br><a href="http://chrisarges.net/2015/10/02/building-ubuntu-kernels-with-debug-symbols.html" target="_blank" rel="external">http://chrisarges.net/2015/10/02/building-ubuntu-kernels-with-debug-symbols.html</a></p>
<p>6, crash /usr/lib/debug/boot/vmlinux-3.5.0-17-generic VmDump</p>
<p>注意：使用4.4内核调试实时内核时（ sudo crash /usr/lib/debug/boot/vmlinux-4.4.0-9-generic）报错“invalid structure member offset: module_core_size”， 见这个bug (<a href="https://www.redhat.com/archives/crash-utility/2016-January/msg00030.html" target="_blank" rel="external">https://www.redhat.com/archives/crash-utility/2016-January/msg00030.html</a> ), 我采用(sudo crash –no_modules /usr/lib/debug/boot/vmlinux-4.4.0-9-generic)避免模块的初始化错误中断crash</p>
<p>自己调试机运行的什么版本的kernel和客户运行的没有关系，只需要使用–mod参数指定和客户运行的debug symbol的版本一致即可。</p>
<p>wget <a href="http://ddebs.ubuntu.com/pool/main/l/linux/linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42_amd64.ddeb" target="_blank" rel="external">http://ddebs.ubuntu.com/pool/main/l/linux/linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42_amd64.ddeb</a> -O /home/zhhuabj/debs/4.13.0-37.42/linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42_amd64.ddeb</p>
<p>strings vmcore.201803282124 |less  #NOTE: vmcore may first need to unzip<br>dpkg -x linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42_amd64.ddeb /home/zhhuabj/debs/4.13.0-37.42/<br>cat run_crash.sh</p>
<p>exec crash –mod /home/zhhuabj/debs/4.13.0-37.42/usr/lib/debug/lib/modules/4.13.0-37-generic /home/zhhuabj/debs/4.13.0-37.42/usr/lib/debug/boot/vmlinux-4.13.0-37-generic vmcore.201803282124</p>
<p>NOTE: 上面的方法可能不成功，例如，4.13.0-37是artful的GA Kernel，但对于xenial来说是HWE Kernel。sosreport中的uname显示版本号（上面是通过strings命令查看的版本号，似乎不能显示更详细的版本号)是“4.13.0-37-generic #42~16.04.1”，这种版本号就是在xenial中使用4.13.0-37 hwe kernel。所以正确的debug symbol应该是：<a href="https://launchpad.net/~canonical-kernel-team/+archive/ubuntu/ppa/+build/14432003/+files/linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42~16.04.1_amd64.ddeb" target="_blank" rel="external">https://launchpad.net/~canonical-kernel-team/+archive/ubuntu/ppa/+build/14432003/+files/linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42~16.04.1_amd64.ddeb</a></p>
<p>附录一， 如何利用dump文件找到源码中出错误的地方</p>
<p>因为编译优化会产生代码行号不一致，所以一般是理解汇编，再看源码作为参考：</p>
<p>1, 查看backtrace列表，exception RIP是kmem_cache_alloc_trace+0x7c (或者查看RIP寄存器)</p>
<p>crash&gt; bt -l<br>PID: 47656  TASK: ffff880115fa3000  CPU: 14  COMMAND: “make”<br> …</p>
<p> #5 [ffff881f136edb30] general_protection at ffffffff817650c8<br>    /build/buildd/linux-lts-trusty-3.13.0/arch/x86/kernel/entry_64.S: 1514<br>    [exception RIP: kmem_cache_alloc_trace+0x7c]</p>
<p>2, 将标识符 kmem_cache_alloc_trace+0x7c 转换为其所对应的物理地址 0xffffffff811af2fc<br>crash&gt; dis kmem_cache_alloc_trace+0x7c<br>0xffffffff811af2fc <kmem_cache_alloc_trace+0x7c>:       mov    0x0(%r13,%rax,1),%rbx</kmem_cache_alloc_trace+0x7c></p>
<p>查看汇编也可以使用x/100gi命令：</p>
<p>故对于动态链接库采用gdb查看CoreDump时可以采用x/100gi $rip代替</p>
<p>(gdb) p $rip<br>$2 = (void (*)()) 0x7fa84c275470 <malloc_consolidate+336><br>(gdb) x/2gi $rip<br>=&gt; 0x7fa84c275470 <malloc_consolidate+336>: mov    0x8(%rbx),%rax<br>   0x7fa84c275474 <malloc_consolidate+340>: and    $0xfffffffffffffff8,%rax</malloc_consolidate+340></malloc_consolidate+336></malloc_consolidate+336></p>
<p>readelf命令也可以查看物理地址:<br>readelf -wL vmlinux<br>Decoded dump of debug contents of section .debug_line:<br>[… search for %rip value …]<br>skbuff.c                                    2918  0xffffffff81614495<br>skbuff.c                                    2911  0xffffffff816144b8<br>skbuff.c                                    2904  0xffffffff816144ba<br>skbuff.c                                    2825  0xffffffff816144bc</p>
<p>3, 用addr2line命令来找出其对应的源代码<br>   -e, 标明需要对其进行地址转换的程序的名称。<br>   -f, 显示函数名称，以及它们的所在文件和行数信息。<br>   -i, 如果要转换的地址属于一个内联函数, 那么，所有作用域内从第一个非内联函数起的信息都会被列出。<br>addr2line 0xffffffff811af2fc -e /mnt/ddeb-3.13.0-34.60/usr/lib/debug/boot/vmlinux-3.13.0-45-generic -f -i<br>get_freepointer<br>/build/buildd/linux-lts-trusty-3.13.0/mm/slub.c:260<br>get_freepointer_safe<br>/build/buildd/linux-lts-trusty-3.13.0/mm/slub.c:275<br>slab_alloc_node<br>/build/buildd/linux-lts-trusty-3.13.0/mm/slub.c:2416<br>slab_alloc<br>/build/buildd/linux-lts-trusty-3.13.0/mm/slub.c:2455<br>kmem_cache_alloc_trace<br>/build/buildd/linux-lts-trusty-3.13.0/mm/slub.c:2472</p>
<p>或者如果已经安装了源码的话可以直接使用crash的list命令查看相关代码。<br>crash&gt; list *0xffffffff816144ba<br>0xffffffff816144ba is in skb_segment (/build/buildd/linux-3.13.0/net/core/skbuff.c:2904).<br>2899                    skb_shinfo(nskb)-&gt;tx_flags = skb_shinfo(head_skb)-&gt;tx_flags &amp;<br>2900                            SKBTX_SHARED_FRAG;<br>2901<br>2902                    while (pos &lt; offset + len) {<br>2903                            if (i &gt;= nfrags) {<br>2904                                    BUG_ON(skb_headlen(list_skb));<br>[…]</p>
<p>注意，对应用态的动态链接库使用addr2line却显示了下列的问号（因为动态链接库要重定位），对动态链接库如何使用addr2line待查。<br>$ addr2line 0x7fa84c275470 -f -i -e /usr/lib/x86_64-linux-gnu/debug/libstdc++.so.6<br>??<br>??:0</p>
<p>4, 确认源代码, 直接看源码，或者若是结构体直接采用下列命令显示行号后和汇编里的代码对行号。</p>
<p>crash&gt; struct -o transction_s.t_locaked_list</p>
<p>附录二，从soft lookup的例子熟悉kernel开发流程</p>
<p>1, 使用’crash&gt; log &gt; log.txt’可以看到很多有用的信息</p>
<p>2, 说明systemd进程是在等锁(_raw_spin_lock_irq)，其他类似很多日志表明其他一些进程也是类似在等锁，所以systemd等进程不会是凶手<br>[ 1043.679592] NMI watchdog: Watchdog detected hard LOCKUP on cpu 17<br>…<br>[ 1043.679646] CPU: 17 PID: 86236 Comm: systemd Not tainted 4.13.0-37-generic #42~16.04.1-Ubuntu<br>…<br>[ 1043.679664] Call Trace:<br>[ 1043.679671]  _raw_spin_lock_irq+0x28/0x30<br>…</p>
<p>3, 真正造成死锁的是40号CPU的sgdisk（sgdisk -&gt; block_ioctl -&gt; blkdev_ioctl -&gt; blkdev_reread_part -&gt; <strong>blkdev_reread_part -&gt; rescan_partitions -&gt; drop_partitions -&gt; invalidate_partition -&gt; </strong>invalidate_device -&gt; invalidate_bdev -&gt; invalidate_bh_lrus -&gt; on_each_cpu_cond -&gt; on_each_cpu_mask -&gt; smp_call_function_many）</p>
<p>其smp_call_function_many用于要求其他CPU执行相关函数， 所以原因可能是：</p>
<p>1) 其他CPU也stuck了，这需要一个个检查其他CPU的情况。但crash显示其他CPU都在等待spin lock而无法访问状态.</p>
<p>PID: 384217 TASK: ffff8fa582ed9e40 CPU: 47 COMMAND: “ceph-osd”<br>bt: read error: kernel virtual address: fffffe000081b000 type: “stack contents”</p>
<p>bt: read of stack at fffffe000081b000 failed</p>
<p>需禁用KASLR后(nokaslr)并设置一旦watchdog捕获到panic后立即抓crash(nmi_watchdog=panic)后重新生成fresh crash</p>
<p>2）40号CPU自己在执行长任务。</p>
<p>[ 1062.041799] Kernel panic - not syncing: softlockup: hung tasks<br>[ 1062.042657] CPU: 40 PID: 383965 Comm: sgdisk Tainted: G             L  4.13.0-37-generic #42~16.04.1-Ubuntu<br>[ 1062.043524] Hardware name: Lenovo ThinkSystem SR650 -[7X06CTO1WW]-/-[7X06CTO1WW]-, BIOS -[IVE116S-1.20]- 02/08/2018<br>[ 1062.044396] Call Trace:<br>[ 1062.045251]  <irq><br>[ 1062.046093]  dump_stack+0x63/0x8b<br>[ 1062.046931]  panic+0xe4/0x24d<br>[ 1062.047752]  watchdog_timer_fn+0x219/0x220<br>[ 1062.048557]  ? watchdog_park_threads+0x70/0x70<br>[ 1062.049358]  <strong>hrtimer_run_queues+0xe7/0x230<br>[ 1062.050149]  hrtimer_interrupt+0xb1/0x200<br>[ 1062.050941]  smp_trace_apic_timer_interrupt+0x6f/0xa0<br>[ 1062.051720]  ? </strong>brelse+0x30/0x30<br>[ 1062.052486]  smp_apic_timer_interrupt+0xe/0x10<br>[ 1062.053244]  apic_timer_interrupt+0x1af/0x1c0<br>[ 1062.053984]  </irq><br>[ 1062.054707] RIP: 0010:smp_call_function_many+0x20b/0x270<br>[ 1062.055433] RSP: 0018:ffffbaae766efc40 EFLAGS: 00000202 ORIG_RAX: ffffffffffffff10<br>[ 1062.056159] RAX: 0000000000000003 RBX: 0000000000000130 RCX: 000000000000000b<br>[ 1062.056877] RDX: ffff8f487dee7b18 RSI: 0000000000000130 RDI: ffff8f486e974280<br>[ 1062.057588] RBP: ffffbaae766efc78 R08: 0000000000000000 R09: c4ff7effffddea38<br>[ 1062.058295] R10: fffff1c6f324aac0 R11: ffff8f486e974280 R12: ffffffffb88915b0<br>[ 1062.058998] R13: 0000000000000000 R14: ffff8f487e123a00 R15: 0000000000000130<br>[ 1062.059696]  ? <strong>brelse+0x30/0x30<br>[ 1062.060387]  ? </strong>brelse+0x30/0x30<br>[ 1062.061067]  on_each_cpu_mask+0x28/0x70<br>[ 1062.061733]  ? mark_buffer_async_write+0x20/0x20<br>[ 1062.062398]  on_each_cpu_cond+0xb6/0x160<br>[ 1062.063053]  ? <strong>brelse+0x30/0x30<br>[ 1062.063686]  invalidate_bh_lrus+0x29/0x30<br>[ 1062.064303]  invalidate_bdev+0x3a/0x60<br>[ 1062.064906]  </strong>invalidate_device+0x4d/0x60<br>[ 1062.065489]  invalidate_partition+0x31/0x50<br>[ 1062.066054]  rescan_partitions+0x50/0x330<br>[ 1062.066602]  ? security_capable+0x4e/0x70<br>[ 1062.067130]  __blkdev_reread_part+0x65/0x70<br>[ 1062.067659]  blkdev_reread_part+0x23/0x40<br>[ 1062.068168]  blkdev_ioctl+0x38f/0x930<br>[ 1062.068657]  ? mempool_free_slab+0x17/0x20<br>[ 1062.069130]  ? mempool_free+0x2f/0x90<br>[ 1062.069579]  block_ioctl+0x3d/0x50<br>[ 1062.070012]  do_vfs_ioctl+0xa4/0x600<br>[ 1062.070430]  ? blkdev_fsync+0x35/0x50<br>[ 1062.070854]  ? vfs_fsync_range+0x4e/0xb0<br>[ 1062.071281]  SyS_ioctl+0x79/0x90<br>[ 1062.071712]  entry_SYSCALL_64_fastpath+0x24/0xab<br>[ 1062.072150] RIP: 0033:0x7f3b43fe0f47<br>[ 1062.072579] RSP: 002b:00007ffe7affbc58 EFLAGS: 00000246 ORIG_RAX: 0000000000000010<br>[ 1062.073021] RAX: ffffffffffffffda RBX: 00007ffe7afffaa8 RCX: 00007f3b43fe0f47<br>[ 1062.073455] RDX: 00007ffe7affbb90 RSI: 000000000000125f RDI: 0000000000000004<br>[ 1062.073876] RBP: 00007ffe7affba20 R08: 0000555ea8d45a80 R09: 0000000000000001<br>[ 1062.074281] R10: 0000555ea8d45a80 R11: 0000000000000246 R12: 0000000000000001<br>[ 1062.074691] R13: 00007ffe7afffaa8 R14: 0000000000000000 R15: 00007ffe7affe8d2</p>
<p>4, upstream kernel中搜索invalidate_bh_lrus，及使用google搜索相应的信息<br>git log –grep=invalidate_bh_lrus<br>git grep invalidate_bh_lrus<br>git blame fs/block_dev.c</p>
<p>5, 向Ubuntu贡献patch, 订阅邮件列表(<a href="https://lists.ubuntu.com/mailman/listinfo/kernel-team" target="_blank" rel="external">https://lists.ubuntu.com/mailman/listinfo/kernel-team</a>), 该页面上有”kernel-team Archives”的链接,里面对SRU的相关的内容类似如下(<a href="https://lists.ubuntu.com/archives/kernel-team/2018-March/thread.html" target="_blank" rel="external">https://lists.ubuntu.com/archives/kernel-team/2018-March/thread.html</a>), PATCH0是patch的说明，之后有PATH1等，被接受是ACK，已经合并到branch是APPLIED。机器人会解析这些邮件标题然后自动往lp bug中更新。所以SRU时并不在lp bug提交的并不是debdiff，而是在邮件里提交的patch，patch是由git-send-email生成的(最初先发到自己邮箱测试)，测试通过后发到邮件列表kernel-team@lists.ubuntu.com：<br>[SRU] [A/B] [PATCH 0/2] Fix wrong battery status on Asus laptops   Kai-Heng Feng<br>[SRU] [A/B] [PATCH 1/2] ACPI / battery: Add quirk for Asus GL502VSK and UX305LA   Kai-Heng Feng<br>[SRU] [A/B] [PATCH 2/2] ACPI / battery: Add quirk for Asus UX360UA and UX410UAK   Kai-Heng Feng<br>ACK / APPLIED[B]: [SRU] [A/B] [PATCH 0/2] Fix wrong battery status on Asus laptops   Seth Forshee<br>ACK: [SRU] [A/B] [PATCH 0/2] Fix wrong battery status on Asus laptops   Colin Ian King<br>APPLIED[Artful/backlog]: [SRU] [A/B] [PATCH 0/2] Fix wrong battery status on Asus laptops   Kleber Souza</p>
<p>Reference<br>1, <a href="http://my.oschina.net/guol/blog/128030" target="_blank" rel="external">http://my.oschina.net/guol/blog/128030</a></p>
<p>2, <a href="http://www.inaddy.org/mini-howtos/dumps/using-ubuntu-crash-dump-with-kdum" target="_blank" rel="external">http://www.inaddy.org/mini-howtos/dumps/using-ubuntu-crash-dump-with-kdum</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/16/Building-Ubuntu-Kernels-with-Debug-Symbols/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/16/Building-Ubuntu-Kernels-with-Debug-Symbols/" itemprop="url">Building Ubuntu Kernels with Debug Symbols</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-01-16T18:45:24+08:00">
                2021-01-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2016-02-25<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )<br>使用gdb或者crash时需要debug symbols, 可以从<a href="http://ddebs.ubuntu.com/pool/main/l/linux/（NOTE" target="_blank" rel="external">http://ddebs.ubuntu.com/pool/main/l/linux/（NOTE</a>: 此链接只是GA Kernel的debug symbols, 如果是HWE Kernel的符号表一般通过google查找，见本文最下方说明）下载，如果这个网址没有，版本不一样crash就打不起来，所以得自己build一个(<a href="https://wiki.ubuntu.com/Kernel/BuildYourOwnKernel" target="_blank" rel="external">https://wiki.ubuntu.com/Kernel/BuildYourOwnKernel</a>,  <a href="https://wiki.ubuntu.com/Kernel/Dev/KernelGitGuide" target="_blank" rel="external">https://wiki.ubuntu.com/Kernel/Dev/KernelGitGuide</a>, <a href="https://wiki.edubuntu.org/Kernel/Dev/KernelBugFixing)。" target="_blank" rel="external">https://wiki.edubuntu.org/Kernel/Dev/KernelBugFixing)。</a></p>
<p>注意：即使自己build也不能保证每次compile的時候symbol address都一样, GCC的版本也有不同。实际上，如果从<a href="http://ddebs.ubuntu.com/pool/main/l/linux/找不着对应的GA" target="_blank" rel="external">http://ddebs.ubuntu.com/pool/main/l/linux/找不着对应的GA</a> Kernel的符号表，也找不着HWE Kernel的符号表的话。我们只能自己编译，但是自己编译也是没用的。自己编译的目的只是为了让crash运行起来，里面的symbols是无法相信的，只能用二进制知识直接看memory。</p>
<p>但有时候里面没有需要自己生成，下需方法使用了debian/rules脚本来为Ubuntu Kernel生成debug symbols, 所以它不需要注释的那些make命令， 这个脚本会自动生成.config文件，如果要修改可以使用fakeroot debian/rules editconfigs命令。如果使用的是社区的Kernel, 默认的.config文件应该未包括了生成debug symbols的配置(CONFIG_KALLSYMS=y &amp; CONFIG_KALLSYMS_ALL=y, 路径为：Kernel hacking -&gt; Compile-time checks and compiler options -&gt; Compile the kernel with debug info )。</p>
<p>注：在xenial中也可以可以build trusty的，kernel与上层应用不同，kernel依赖的包很少，这样只要在xenial将相应的依赖安装了就可以build trusty。所以编译kennel不需要像上层应用的编译那样搞什么pbuilder等。</p>
<p><a href="http://kernel.ubuntu.com/~kernel-ppa/mainline/" target="_blank" rel="external">http://kernel.ubuntu.com/~kernel-ppa/mainline/</a></p>
<p>git config –add core.compression -1   #For the error ‘git index-pack failed’</p>
<p>git clone git://kernel.ubuntu.com/ubuntu/linux.git ubuntu-linux</p>
<p>#git clone –reference ubuntu-linux git://kernel.ubuntu.com/ubuntu/ubuntu-vivid.git<br>git clone –reference ubuntu-linux git://kernel.ubuntu.com/ubuntu/ubuntu-xenial.git</p>
<p>git clone git://kernel.ubuntu.com/ubuntu/linux.git</p>
<p>#git clone –reference linux git://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/bionic</p>
<p>#git checkout -b sfxxxx origin/master</p>
<p>#git cherry-pick -s -x commit_id</p>
<p>#git remote add linus git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git</p>
<p>#git remote -v</p>
<p>#git fetch –tags linus</p>
<p>#git remote add rotom_xenial zhhuabj@10.230.56.3:/home/zhhuabj/ubuntu-xenial</p>
<p>#git push rotom_xenial sfxxxx<br>cd ubuntu-xenial<br>git tag -l Ubuntu-*<br>git checkout -b Ubuntu-4.4.0-0.10 Ubuntu-4.4.0-0.10</p>
<p>sudo apt-get install libncurses5-dev qt4-dev-tools kernel-package fakeroot build-essential crash kexec-tools makedumpfile kernel-wedge libelf-dev asciidoc binutils-dev</p>
<p>sudo apt-get build-dep linux-image-$(uname -r)   #需要添加附录中的deb-src源</p>
<p>sudo apt-get install pkg-config-dbgsym  #xenial</p>
<p>#make xconfig             #or make menuconfig</p>
<p>#make localmodconfig      #speed compliling time for test</p>
<p>#make-kpkg                #a script which automates and replaces the sequence “make dep; make clean; make bzImage; make modules”</p>
<p>#make mrproper</p>
<p>#git reset –hard HEAD<br>fakeroot debian/rules clean</p>
<p>#fakeroot debian/rules editconfigs</p>
<p>#fakeroot debian/rules prepare-generic</p>
<p>#debian/rules build-generic   #build kernel</p>
<p>fakeroot debian/rules DEB_BUILD_OPTIONS=parallel=4 clean binary-generic binary-headers skipdbg=false</p>
<p>自己调试机运行的什么版本的kernel和客户运行的没有关系，只需要使用–mod参数指定和客户运行的debug symbol的版本一致即可。</p>
<p>wget <a href="http://ddebs.ubuntu.com/pool/main/l/linux/linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42_amd64.ddeb" target="_blank" rel="external">http://ddebs.ubuntu.com/pool/main/l/linux/linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42_amd64.ddeb</a> -O /home/zhhuabj/debs/4.13.0-37.42/linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42_amd64.ddeb<br>strings vmcore.201803282124 |less  #NOTE: vmcore may first need to unzip<br>dpkg -x linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42_amd64.ddeb /home/zhhuabj/debs/4.13.0-37.42/<br>cat run_crash.sh</p>
<p>exec crash –mod /home/zhhuabj/debs/4.13.0-37.42/usr/lib/debug/lib/modules/4.13.0-37-generic /home/zhhuabj/debs/4.13.0-37.42/usr/lib/debug/boot/vmlinux-4.13.0-37-generic vmcore.201803282124</p>
<p>注意：上面的方法可能不成功，例如，4.13.0-37是artful的GA Kernel，但对于xenial来说是HWE Kernel。sosreport中的uname显示版本号（上面是通过strings命令查看的版本号，似乎不能显示更详细的版本号)是“4.13.0-37-generic #42~16.04.1”，这种版本号就是在xenial中使用4.13.0-37 hwe kernel。所以正确的debug symbol应该是：<a href="https://launchpad.net/~canonical-kernel-team/+archive/ubuntu/ppa/+build/14432003/+files/linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42~16.04.1_amd64.ddeb" target="_blank" rel="external">https://launchpad.net/~canonical-kernel-team/+archive/ubuntu/ppa/+build/14432003/+files/linux-image-4.13.0-37-generic-dbgsym_4.13.0-37.42~16.04.1_amd64.ddeb</a></p>
<p>继续遇到此问题“crash: cannot resolve “init_level4_pgt” “ - <a href="https://bugs.launchpad.net/ubuntu/+source/crash/+bug/1736425，在xenial中添加&#39;deb" target="_blank" rel="external">https://bugs.launchpad.net/ubuntu/+source/crash/+bug/1736425，在xenial中添加&#39;deb</a> <a href="http://archive.ubuntu.com/ubuntu/" target="_blank" rel="external">http://archive.ubuntu.com/ubuntu/</a> bionic main’升级crash后解决。</p>
<p>附录：为UCA包编译近似的符号表</p>
<p>UCA缺乏debug symbol，例如为trusty上的mitaka uca的qemu包构建debug symbol，因为都是ppa编译的其编译器版本及设置都差不多这样编译出的debug symbol还可以近似地去用。<br>1, PPA中有”Build debug symbols”的选项（<a href="https://launchpad.net/~zhhuabj/+archive/ubuntu/trusty-mitaka-sru/+edit），再在" target="_blank" rel="external">https://launchpad.net/~zhhuabj/+archive/ubuntu/trusty-mitaka-sru/+edit），再在</a> “Add PPA dependency”里添加”~ubuntu-cloud-archive/+archive/ubuntu/mitaka-staging”<br>2, 进这个页面(<a href="https://launchpad.net/~ubuntu-cloud-archive/+archive/ubuntu/mitaka-staging），点击&quot;View" target="_blank" rel="external">https://launchpad.net/~ubuntu-cloud-archive/+archive/ubuntu/mitaka-staging），点击&quot;View</a> package details” -&gt; “copy packages”，在搜索框输入qemu并同时将其后的下拉列表从Published改为Superseded这样就可以选择客户所用的qemu版本。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/15/OpenStack对NUMA的支持情况/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/15/OpenStack对NUMA的支持情况/" itemprop="url">OpenStack对NUMA的支持情况</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-01-15T19:11:40+08:00">
                2021-01-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2016-03-24<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</p>
<p>理论<br>vCPU topology, libvirt将第一个vCPU在虚机中视为: 1 socket with 1 core and no hyper-threads. 但有的操作系统的license会限制socket的数目，另外一般地在不同的core上的2个threads的性能会比2个在同相core上的threads的性能要好。<br>NUMA topology, NUMA节点有自己独立的RAM、Bus、PCI和pCPU sockets, 为一个VM分配cpu及PCI设备时应该尽量分配同一个NUMA节点上的pCPU。<br>Guest NUMA, 如果一个VM要求的vCPU/RAM/PCIe大于一个NUMA节点所具有的物理pCPU/RAM/PCIe呢？<br>可划分为多个NUMA节点（hw:numa_nodes=N).<br>Large pages, CPU支持4k, 2M/4M, 1G的Hugepage模式(page_sizes=(any|small|large)，这时cpu的页表数目会减少提升TLB页表的命中率，但操作系统默认为4k，运行时间长了很难找到连续的大页空间分配。当前Kernel不允许为NUMA节点预留大页，NUMA节点有特定的RAM，也就是说，NUMA节点也有特定的大页。在的NUMA节点有足够的大页空间，有的可能刚好没有了。<br>Dedicated resource, overcommit_ram=0,overcommit_vcpus=0<br>KSM(kernel shared memory), 将相同的内存分页进行合并，合并之后若再遇到写就再用CoW打开一份，要能阻止宿主机将特定的内存分页合并。<br>例如：我的t440p是一个cpu(socket), 双核，开了超线程，4个core id, 所以siblings也是4(一个物理封装中的逻辑cpu个数，只有一个cpu所以是一个物理，然后双核，超线程).</p>
<p>1, cpu个数(socket)： cat /proc/cpuinfo | grep “physical id” | sort | uniq | wc -l<br>2, cpu核数： cat /proc/cpuinfo | grep “cpu cores” | uniq<br>3, Logic CPU ID: cat /proc/cpuinfo | grep “core id”<br>4, 每颗cpu的逻辑核数： cat /proc/cpuinfo | grep “siblings”<br>5, 所有cpu的逻辑核数： cat /proc/cpuinfo | grep “processor” | wc -l<br>6, 是否启用超线程(相同则没启用：cat /proc/cpuinfo | grep -e “cpu cores”  -e “siblings” | sort | uniq)</p>
<p>实际操作<br>Image方式, glance image-update –property hw_numa_nodes=2 hw_numa_cpus.0=0 hw_numa_mem.0=512 hw_numa_cpus.1=0 hw_numa_mem.1=512 image_name<br>Flavor方式, nova flavor-key flv_name set hw:numa_nodes=2 hw:numa_cpus.0=0 hw:numa_mem.0=512 hw:numa_cpus.1=0 hw:numa_mem.1=512<br>hw:numa_nodes=NN                     #guest NUMA node数量<br>hw:numa_mempolicy=preferred|strict   #RAM占用方式<br>hw:numa_cpus.N=<cpu-list>            #guest NUMA node N中的vcpu列表<br>hw:numa_mem.1=<ram-size>             #guest NUMA node N中的RAM大小<br>hw:cpu_thread_policy=prefer|isolate|require<br>hw:cpu_policy=shared|dedicated<br>libvirt.xml</ram-size></cpu-list></p>
<p><cputune><br>  /<strong> pin vCPU to pCPU set in cputune </strong>/<br>  <vcpupin vcpu="0" cpuset="4-7,12-15"><br></vcpupin></cputune><br>/<strong> expoert guest numa in cpu/numa </strong>/ </p>
<cpu><br>   <topology sockets="2" cores="2" threads="1"><br>   <numa><br>      <cell id="0" cpus="0-1" memory="1048576"><br>   </cell></numa><br></topology></cpu> 


<p>nova-scheduler<br>NUMATopologyFilter<br>一些命令<br>hua@node1:~$ sudo virsh nodeinfo<br>CPU model:           x86_64<br>CPU(s):              4<br>CPU frequency:       3348 MHz<br>CPU socket(s):       1<br>Core(s) per socket:  4<br>Thread(s) per core:  1<br>NUMA cell(s):        1<br>Memory size:         32753068 KiB</p>
<p>hua@node1:~$ sudo virsh freecell 0<br>0: 9974312 KiB</p>
<p>附件 - Power SMT</p>
<p>Power 8有一个SMT特性，即多线程的并发改为一个核内多个指令的并发从而提升性能， 但是KVM Power版本却不支持SMT， 所以需要将SMT关闭，这样造成性能下降，这样pacemaker将会报这种错”Sep 22 06:52:35 juju-b209b8-4-lxd-2 crmd[122100]: notice: High CPU load detected“，从而造成如glance service的vip不work了也就无法ping了。其实，即使SMT=off (echo off &gt; /sys/devices/system/cpu/smt/control)也是可以利offline的核的， 即采用这个网页（<a href="https://www.ibm.com/developerworks/community/blogs/fe313521-2e95-46f2-817d-44a4f27eba32/entry/enabling_smt_on_powerkvm_guests?lang=en）的方法：" target="_blank" rel="external">https://www.ibm.com/developerworks/community/blogs/fe313521-2e95-46f2-817d-44a4f27eba32/entry/enabling_smt_on_powerkvm_guests?lang=en）的方法：</a></p>
<p>nova针对一个虚机使用8个vcpu有下列三种配置方法：</p>
<p>1) By default in nova</p>
<p><vcpu placement="static">8</vcpu></p>
<cpu><br><topology sockets="8" cores="1" threads="1"><br>…<br></topology></cpu>

<p>2) 4 threads</p>
<p><vcpu>8</vcpu></p>
<cpu><br><topology sockets="1" cores="2" threads="4"><br>…<br></topology></cpu> 

<p>3) 8 threads</p>
<p><vcpu>8</vcpu></p>
<cpu><br><topology sockets="1" cores="1" threads="8"><br>…<br></topology></cpu>

<p>如想要配置成上面的2）的话，可以：</p>
<p>openstack flavor set <flavor_uuid> \<br>–vcpus 8 \<br>–property hw:cpu_sockets=1 \<br>–property hw:cpu_cores=2 \<br>–property hw:cpu_threads=4<br>配置成上面的3）的话，可以：</flavor_uuid></p>
<p>openstack flavor set <flavor_uuid> \<br>–vcpus 8 \<br>–property hw:cpu_sockets=1 \<br>–property hw:cpu_cores=1 \<br>–property hw:cpu_threads=8</flavor_uuid></p>
<p>Power8在设计上是有缺陷的, 它需要先关闭SMT, 然后在KVM里又可以使用offline CPU, Power9则修复了这个问题, 见: <a href="https://www.linux-kvm.org/images/7/77/01x09a-KVMPower.pdf" target="_blank" rel="external">https://www.linux-kvm.org/images/7/77/01x09a-KVMPower.pdf</a></p>
<p>另外, 因为SMT关闭了, 当Power8上的KVM未使用上面拓扑时一个使用8个vcpu的虚机占了8个核而不是一个核上的8线程, 这样无形中CPU数少了8倍. 这个机器如果不光是KVM还有mysql的话mysql也存在这种情况, 这样使用perf查看时会看到mysql与kvm并没有哪个特别宽, 都差不多分布比较均匀, 这样反而证明了整体性能需要提升. mysql因为是openstack的底层服务无法使用上面的拓扑使用多线程, 所以最好不要将mysql和kvm安装在一块.</p>
<p>再说说sbiblings<br>siblings指一个物理cpu上的cpu, 下面的设置是两个cell两个物理cpu，一个物理cpu是32个core超线程是2故共32个thread</p>
<p>NUMA node0 CPU(s):   0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62<br>NUMA node1 CPU(s):   1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63<br>CPU(s):              64<br>On-line CPU(s) list: 0-63<br>Thread(s) per core:  2<br>Core(s) per socket:  16<br>Socket(s):           2<br>NUMA node(s):        2</p>
<p>nova中看到的pcpuset与siblings如下：</p>
<p>pcpuset=set([8,10,12,14,16,18,20,22,24,26,28,30,40,42,44,46,48,50,52,54,56,58,60,62])<br>siblings=[set([16,48]),set([10,42]),set([54,22]),set([46,14]),set([12,44]),set([20,52]),set([26,58]),set([28,60]),set([62,30]),set([18,50]),set([8,40]),set([24,56])]</p>
<p>当设置cpu_thread_policy=’isolate’时，意味着不用thread只用真正的core.<br>因为siblings对象的引入的目的就是为了无论服务器是否开启了超线程，Nova 同样能够支持物理CPU绑定的功能。<br>这样，当一个虚机使用了[8, 10, 12, 16, 18, 20, 24, 26, 28, 46, 54, 62]这些cpu的话，pinned_cpus会如下：</p>
<p>pinned_cpus=set([8,10,12,14,16,18,20,22,24,26,28,30,40,42,44,46,48,50,52,54,56,58,60,62])</p>
<p>所以用thread的话就配置hw:cpu_thread_policy=require, 用core的话就用cpu_thread_policy=’isolate’.<br>而且如果emulator也用了isolate的话（hw:emulator_threads_policy=’isolate’）, not only will it not allow a sibling but it will also require all pcpu to be<br>available on the same numa node.</p>
<p>参考<br><a href="https://wiki.openstack.org/wiki/VirtDriverGuestCPUMemoryPlacement" target="_blank" rel="external">https://wiki.openstack.org/wiki/VirtDriverGuestCPUMemoryPlacement</a><br><a href="https://specs.openstack.org/openstack/nova-specs/specs/liberty/approved/virt-driver-cpu-pinning.html" target="_blank" rel="external">https://specs.openstack.org/openstack/nova-specs/specs/liberty/approved/virt-driver-cpu-pinning.html</a><br><a href="http://blog.csdn.net/canxinghen/article/details/41810241" target="_blank" rel="external">http://blog.csdn.net/canxinghen/article/details/41810241</a><br><a href="https://specs.openstack.org/openstack/nova-specs/specs/mitaka/approved/virt-driver-cpu-thread-pinning.html" target="_blank" rel="external">https://specs.openstack.org/openstack/nova-specs/specs/mitaka/approved/virt-driver-cpu-thread-pinning.html</a><br><a href="http://docs.openstack.org/developer/nova/testing/libvirt-numa.html" target="_blank" rel="external">http://docs.openstack.org/developer/nova/testing/libvirt-numa.html</a><br><a href="https://www.berrange.com/posts/2010/02/12/controlling-guest-cpu-numa-affinity-in-libvirt-with-qemu-kvm-xen/" target="_blank" rel="external">https://www.berrange.com/posts/2010/02/12/controlling-guest-cpu-numa-affinity-in-libvirt-with-qemu-kvm-xen/</a><br><a href="https://review.openstack.org/#/c/140290/" target="_blank" rel="external">https://review.openstack.org/#/c/140290/</a><br><a href="http://slideplayer.com/slide/4868412/" target="_blank" rel="external">http://slideplayer.com/slide/4868412/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/14/Using-BPF-USDT-to-trace-OpenStack/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/14/Using-BPF-USDT-to-trace-OpenStack/" itemprop="url">Using BPF USDT to trace OpenStack</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-01-14T20:22:20+08:00">
                2021-01-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华 发表于：2021-01-14<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>./nova/compute/resource_tracker.py#_update_available_resource中的_update_usage_from_instances函数没有DEBUG LEVEL日志，有办法通过probe则不是通过改代码写日志的方法来调试该函数吗？<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def _update_available_resource(self, context, resources, startup=False):</span><br><span class="line">...</span><br><span class="line">cn = self.compute_nodes[nodename]</span><br></pre></td></tr></table></figure></p>
<h2 id="确认python版本是否支持USDT探针"><a href="#确认python版本是否支持USDT探针" class="headerlink" title="确认python版本是否支持USDT探针"></a>确认python版本是否支持USDT探针</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python3-bpfcc libbpfcc bpfcc-tools -y</span><br><span class="line"># if the output is empty, it means we need to compile python with dtrace</span><br><span class="line"># for &gt;&gt;python3.7 supports &apos;--with-dtrace&apos;</span><br><span class="line"># https://bugs.launchpad.net/ubuntu/+source/python3.8/+bug/1818778</span><br><span class="line">tplist-bpfcc -l $(which python3)</span><br></pre></td></tr></table></figure>
<h2 id="探针种类"><a href="#探针种类" class="headerlink" title="探针种类"></a>探针种类</h2><p><a href="https://www.collabora.com/news-and-blog/blog/2019/05/14/an-ebpf-overview-part-5-tracing-user-processes/" target="_blank" rel="external">https://www.collabora.com/news-and-blog/blog/2019/05/14/an-ebpf-overview-part-5-tracing-user-processes/</a><br>有三种探针:<br>1, USDT静态探针, 主要是针对所依赖的二进制模块(eg: libc.so, libpthread.so, libvirt.so etc)的预定义探针。python是解释型语言，看来函数./nova/compute/resource_tracker.py#_update_available_resource只能通过下列function<strong>entry与function</strong>return两种探针来做。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># https://github.com/iovisor/bcc/blob/master/tools/tplist.py</span><br><span class="line"># tplist-bpfcc -p $(ps -ef |grep nova-compute |grep -v grep |awk &apos;&#123;print $2&#125;&apos;) |grep python |grep function</span><br><span class="line">b&apos;/proc/1551047/root/usr/bin/python3.8&apos; b&apos;python&apos;:b&apos;function__entry&apos;</span><br><span class="line">b&apos;/proc/1551047/root/usr/bin/python3.8&apos; b&apos;python&apos;:b&apos;function__return&apos;</span><br></pre></td></tr></table></figure></p>
<p>2, 自定义探针(tracepints), 需要在你的python代码中通过provider.add_probe添加探针，这种和打日志没啥区别啊。略。<br>3, uprobes动态探针，不需要改运行代码，可以通过下列类似b.attach_uprobe来添加探针，但这种探针显示也是针对模块的，对解释型的python不适用。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b.attach_uprobe(name=&quot;c&quot;, sym=&quot;getaddrinfo&quot;, fn_name=&quot;do_entry&quot;, pid=args.pid)</span><br><span class="line">b.attach_uretprobe(name=&quot;c&quot;, sym=&quot;getaddrinfo&quot;, fn_name=&quot;do_return&quot;, pid=args.pid)</span><br></pre></td></tr></table></figure></p>
<h2 id="一个例子"><a href="#一个例子" class="headerlink" title="一个例子"></a>一个例子</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">root@demo:~# ./test.py $(ps -ef |grep nova-compute |grep -v grep |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">207625.396728000   b&apos;_update_available_resource here here!&apos;</span><br><span class="line"></span><br><span class="line">root@demo:~# cat test.py</span><br><span class="line">#!/usr/bin/env python3</span><br><span class="line">from bcc import BPF, USDT</span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">bpf = &quot;&quot;&quot;</span><br><span class="line">#include &lt;uapi/linux/ptrace.h&gt;</span><br><span class="line"></span><br><span class="line">static int strncmp(char *s1, char *s2, int size) &#123;</span><br><span class="line">    for (int i = 0; i &lt; size; ++i)</span><br><span class="line">        if (s1[i] != s2[i])</span><br><span class="line">            return 1;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int trace_file_transfers(struct pt_regs *ctx) &#123;</span><br><span class="line">    uint64_t fnameptr;</span><br><span class="line">    char fname[128]=&#123;0&#125;, searchname[30]=&quot;_update_available_resource&quot;;</span><br><span class="line"></span><br><span class="line">    bpf_usdt_readarg(2, ctx, &amp;fnameptr);</span><br><span class="line">    bpf_probe_read(&amp;fname, sizeof(fname), (void *)fnameptr);</span><br><span class="line"></span><br><span class="line">    if (!strncmp(fname, searchname, sizeof(searchname)))</span><br><span class="line">        bpf_trace_printk(&quot;_update_available_resource here here!\\n&quot;);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">u = USDT(pid=int(sys.argv[1]))</span><br><span class="line">u.enable_probe(probe=&quot;function__entry&quot;, fn_name=&quot;trace_file_transfers&quot;)</span><br><span class="line">b = BPF(text=bpf, usdt_contexts=[u])</span><br><span class="line">while 1:</span><br><span class="line">    try:</span><br><span class="line">        (_, _, _, _, ts, msg) = b.trace_fields()</span><br><span class="line">    except ValueError:</span><br><span class="line">        continue</span><br><span class="line">    print(&quot;%-18.9f %s&quot; % (ts, msg))</span><br></pre></td></tr></table></figure>
<h2 id="打印变量"><a href="#打印变量" class="headerlink" title="打印变量"></a>打印变量</h2><p><a href="https://zhuanlan.zhihu.com/p/138887361" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/138887361</a><br>bcc自带的脚本已经能够满足一般的需求, 但是也不能满足所有需求. 这里以uprobe例, 看一下在bcc里面怎么访问变量, 很大程度上取决于probe的位置:</p>
<ul>
<li>如果在函数的入口, 那么可以通过PT_REGS_PARM很方便读取到入参</li>
<li>如果在函数中间, 上面的方式就不在工作了, PT_REGS_PARM这些宏其实就是一些寄存器, 在函数中间入参所对应的寄存器可能已经被修改. 如果想要访问函数的入参或者局部变量,需要反汇编并找到对应的寄存器或者地址</li>
<li>如果是return probe, 这个时候的sp/bp已经是caller的栈了, 需要小心计算在栈上的偏移 bcc目前还不支持读取dwarf信息<br><img src="https://img-blog.csdnimg.cn/20210114201720154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">$sudo ./write_local.py</span><br><span class="line">a: 1, b: 2, uninit_c: 0, c: 80</span><br><span class="line">$./foo</span><br><span class="line">83</span><br><span class="line">#!/usr/bin/python</span><br><span class="line"></span><br><span class="line">from __future__ import print_function</span><br><span class="line">import bcc</span><br><span class="line">import ctypes as ct</span><br><span class="line"></span><br><span class="line">text = &quot;&quot;&quot;</span><br><span class="line">#include &lt;uapi/linux/ptrace.h&gt;</span><br><span class="line"></span><br><span class="line">struct data_t &#123;</span><br><span class="line">    int a;</span><br><span class="line">    int b;</span><br><span class="line">    int uninit_c;</span><br><span class="line">    int c;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">BPF_PERF_OUTPUT(events);</span><br><span class="line"></span><br><span class="line">int foo(struct pt_regs *ctx) &#123;</span><br><span class="line">    struct data_t data = &#123;&#125;;</span><br><span class="line">    int c = 80;</span><br><span class="line">    void *bp = (void *)ctx-&gt;bp;</span><br><span class="line"></span><br><span class="line">    data.a = PT_REGS_PARM1(ctx);</span><br><span class="line">    data.b = PT_REGS_PARM2(ctx);</span><br><span class="line">    bpf_probe_read(&amp;data.uninit_c, sizeof(data.uninit_c), bp - 4);</span><br><span class="line">    bpf_probe_write_user(bp - 4, &amp;c, 4);</span><br><span class="line">    bpf_probe_read(&amp;data.c, sizeof(data.c), bp - 4);</span><br><span class="line"></span><br><span class="line">    events.perf_submit(ctx, &amp;data, sizeof(struct data_t));</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">b = bcc.BPF(text=text)</span><br><span class="line">b.attach_uprobe(name=&quot;/home/wufei/work/test/foo&quot;, addr=0x40053a, fn_name=&quot;foo&quot;)</span><br><span class="line"></span><br><span class="line">class Data(ct.Structure):</span><br><span class="line">    _fields_ = [</span><br><span class="line">        (&quot;a&quot;, ct.c_int),</span><br><span class="line">        (&quot;b&quot;, ct.c_int),</span><br><span class="line">        (&quot;uninit_c&quot;, ct.c_int),</span><br><span class="line">        (&quot;c&quot;, ct.c_int),</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">def print_event(cpu, data, size):</span><br><span class="line">    event = ct.cast(data, ct.POINTER(Data)).contents</span><br><span class="line">    print(&quot;a: %d, b: %d, uninit_c: %d, c: %d&quot; % (event.a, event.b, event.uninit_c, event.c))</span><br><span class="line"></span><br><span class="line"># loop with callback to print_event</span><br><span class="line">b[&quot;events&quot;].open_perf_buffer(print_event)</span><br><span class="line">while 1:</span><br><span class="line">    b.kprobe_poll()</span><br></pre></td></tr></table></figure>
<p>似乎trace变量并不容易：</p>
<ul>
<li>一是python代码怎么反编译找到cn变量的位置呢？这种方法（python3 -m dis ./nova/compute/resource_tracker.py |grep ‘Disassembly of &lt;code object _update_available_resource’ -A 10）似乎是伪码。tracing变量只对cython有效(是cython，不是cpython, cython是python的C扩展用于在python解释器中运行编译后的C代码, apt install cython3 cython3-dbg)</li>
<li>cn变量不是基本变量，而是一个结构体，这样类似于应用态的systemtap一样结构体所依赖的结构体层层定义在bpf中，这样非常麻烦的。</li>
<li>传入参数似乎很容易打印，但也只是涉及基本变量，若是结构体也蛮麻烦的。</li>
<li>本例中的cn变量是一个全局变量，而且依赖于位置，更麻烦。</li>
</ul>
<h2 id="Appendix-py-spy-python-tool"><a href="#Appendix-py-spy-python-tool" class="headerlink" title="Appendix - py-spy (python tool)"></a>Appendix - py-spy (python tool)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip3 install py-spy</span><br><span class="line">py-spy record -o profile.svg --pid $PID</span><br><span class="line">py-spy top --pid $PID</span><br><span class="line">py-spy dump --pid $PID</span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://blog.csdn.net/hehuyi_in/article/details/108910781" target="_blank" rel="external">https://blog.csdn.net/hehuyi_in/article/details/108910781</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/30/Testing-OpenStack-NUMA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/30/Testing-OpenStack-NUMA/" itemprop="url">Testing OpenStack NUMA</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-12-30T12:13:20+08:00">
                2020-12-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2016-07-22<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</p>
<p>虚机模拟NUMA硬件<br>我们可能没有NUMA硬件，但可以采用VM模拟。</p>
<p>1,  参考链接[1]打开KVM的嵌套虚拟化功能，Ubuntu KVM默认应该是开启的。</p>
<p>2, [可选] host机的网络如下，将仅有一块网卡eth0插到了br-phy中。</p>
<p>auto br-phy<br>allow-ovs br-phy<br>iface br-phy inet static<br>pre-up /usr/bin/ovs-vsctl – –may-exist add-br br-phy<br>pre-up /usr/bin/ovs-vsctl – –may-exist add-port br-phy eth0<br>  address 192.168.99.125<br>  gateway 192.168.99.1<br>  network 192.168.99.0<br>  netmask 255.255.255.0<br>  broadcast 192.168.99.255<br>ovs_type OVSBridge<br>ovs_ports eth0</p>
<p>#sudo ip -6 addr add 2001:2:3:4500:fa32:e4ff:febe:87cd/64 dev br-phy<br>iface br-phy inet6 static<br>pre-up modprobe ipv6<br>address 2001:2:3:4500:fa32:e4ff:febe:87cd<br>netmask 64<br>gateway 2001:2:3:4500::1</p>
<p>auto eth0<br>allow-br-phy eth0<br>iface eth0 inet manual<br>ovs_bridge br-phy<br>ovs_type OVSPort</p>
<p>然后让KVM支持Openvswitch网桥：</p>
<p>sudo ovs-vsctl add-br br-phy<br>sudo virsh net-destroy default<br>sudo virsh net-edit default</p>
<p><network><br>  <name>default</name><br>  <forward mode="bridge"><br>  <bridge name="br-phy"><br>  <virtualport type="openvswitch"><br></virtualport></bridge></forward></network><br>sudo virsh net-undefine default<br>sudo virsh net-autostart br-phy<br>3, 结合virt-manger安装一VM.</p>
<p>sudo apt-get install virt-viewer openvswitch-switch qemu-kvm libvirt-bin virt-manager virtinst virt-top  python-libvirt<br>sudo virt-install \<br>   –name openstack_demo \<br>   –ram 8096 \<br>   –vcpus 8 \<br>   –file /images/kvm/openstack_demo.img \<br>   –file-size 20 \<br>   –cdrom /images/iso/ubuntu-20.04-legacy-server-amd64.iso<br>4, 一定要在VM关闭的情况下修改VM的拓扑为NUMA拓扑。</p>
<p>sudo virsh destroy openstack_demo<br>sudo virsh edit openstack_demo</p>
<cpu mode="host-passthrough"><br>  <numa><br>    <cell id="0" cpus="0-3" memory="4096000"><br>    <cell id="1" cpus="4-5" memory="2048000"><br>    <cell id="2" cpus="6-7" memory="2048000"><br>  </cell></cell></cell></numa><br></cpu>

<p>sudo virsh start openstack_demo<br>5, VM内打开大页支持，因为openstack numa需要大页支持。</p>
<p>hua@demo:~$ cat  /etc/default/grub |grep GRUB_CMDLINE_LINUX<br>GRUB_CMDLINE_LINUX_DEFAULT=””<br>GRUB_CMDLINE_LINUX=”transparent_hugepage=never hugepagesz=2M hugepages=512 default_hugepagesz=2M”</p>
<h1 id="add-also-add-isolcpus-0-1-2-3"><a href="#add-also-add-isolcpus-0-1-2-3" class="headerlink" title="add also add isolcpus=0,1,2,3"></a>add also add isolcpus=0,1,2,3</h1><p>cat &lt;&lt; EOF | sudo tee -a /etc/fstab<br>nodev /mnt/huge hugetlbfs pagesize=2MB 0 0<br>EOF</p>
<p>sudo update-grub<br>sudo mkdir -p /mnt/huge<br>sudo reboot</p>
<p>#hua@demo:~$ sudo sysctl -w vm.nr_hugepages=512</p>
<p>#vm.nr_hugepages = 512<br>6, 这时我们看到：</p>
<p>ubuntu@demo:~$ numactl –hardware<br>available: 3 nodes (0-2)<br>node 0 cpus: 0 1 2 3<br>node 0 size: 3846 MB<br>node 0 free: 3115 MB<br>node 1 cpus: 4 5<br>node 1 size: 1969 MB<br>node 1 free: 1542 MB<br>node 2 cpus: 6 7<br>node 2 size: 1966 MB<br>node 2 free: 1466 MB<br>node distances:<br>node   0   1   2<br>  0:  10  20  20<br>  1:  20  10  20<br>  2:  20  20  10<br>ubuntu@demo:~$ grep Hugepagesize /proc/meminfo<br>Hugepagesize:       2048 kB<br>ubuntu@demo:~$ cat /proc/meminfo | grep Huge<br>AnonHugePages:         0 kB<br>ShmemHugePages:        0 kB<br>FileHugePages:         0 kB<br>HugePages_Total:     512<br>HugePages_Free:      512<br>HugePages_Rsvd:        0<br>HugePages_Surp:        0<br>Hugepagesize:       2048 kB<br>Hugetlb:         1048576 kB<br>ubuntu@demo:~$ sudo cat /sys/devices/system/node/node*/meminfo | grep -i huge<br>Node 0 AnonHugePages:         0 kB<br>Node 0 ShmemHugePages:        0 kB<br>Node 0 FileHugePages:        0 kB<br>Node 0 HugePages_Total:   171<br>Node 0 HugePages_Free:    171<br>Node 0 HugePages_Surp:      0<br>Node 1 AnonHugePages:         0 kB<br>Node 1 ShmemHugePages:        0 kB<br>Node 1 FileHugePages:        0 kB<br>Node 1 HugePages_Total:   171<br>Node 1 HugePages_Free:    171<br>Node 1 HugePages_Surp:      0<br>Node 2 AnonHugePages:         0 kB<br>Node 2 ShmemHugePages:        0 kB<br>Node 2 FileHugePages:        0 kB<br>Node 2 HugePages_Total:   170<br>Node 2 HugePages_Free:    170<br>Node 2 HugePages_Surp:      0<br>安装OpenStack<br>还需要配置pypi，详见：<a href="https://blog.csdn.net/quqi99/article/details/97622336" target="_blank" rel="external">https://blog.csdn.net/quqi99/article/details/97622336</a></p>
<p>git clone git://github.com/openstack-dev/devstack.git<br>cd devstack<br>cat &lt;&lt; EOF | sudo tee local.conf<br>[[local|localrc]]</p>
<p>#OFFLINE=True<br>GIT_BASE=<a href="http://git.trystack.cn" target="_blank" rel="external">http://git.trystack.cn</a><br>NOVNC_REPO=<a href="http://git.trystack.cn/kanaka/noVNC.git" target="_blank" rel="external">http://git.trystack.cn/kanaka/noVNC.git</a><br>SPICE_REPO=<a href="http://git.trystack.cn/git/spice/sice-html5.git" target="_blank" rel="external">http://git.trystack.cn/git/spice/sice-html5.git</a><br>DEST=/home/ubuntu/openstack<br>DATA_DIR=\$DEST/data<br>SERVICE_DIR=\$DEST/status</p>
<p>DOWNLOAD_DEFAULT_IMAGES=False<br>IMAGE_URLS=”<a href="http://download.cirros-cloud.net/0.5.1/cirros-0.5.1-x86_64-disk.img" target="_blank" rel="external">http://download.cirros-cloud.net/0.5.1/cirros-0.5.1-x86_64-disk.img</a>“</p>
<p>LOGFILE=\$DATA_DIR/logs/stack.log<br>VERBOSE=True</p>
<p>disable_service n-net<br>enable_service neutron q-svc q-dhcp q-l3 q-meta q-agt</p>
<p>MYSQL_PASSWORD=password<br>DATABASE_PASSWORD=password<br>SERVICE_TOKEN=password<br>SERVICE_PASSWORD=password<br>ADMIN_PASSWORD=password<br>RABBIT_PASSWORD=password</p>
<p>[[post-config|$NOVA_CONF]]<br>[DEFAULT]<br>firewall_driver=nova.virt.firewall.NoopFirewallDriver</p>
<p>[filter_scheduler]<br>enabled_filters=RamFilter,ComputeFilter,AvailabilityZoneFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,PciPassthroughFilter,NUMATopologyFilter<br>EOF</p>
<p>FORCE=yes ./stack.sh</p>
<p>sudo systemctl enable mysql.service<br>sudo systemctl enable rabbitmq-server.service<br>sudo systemctl enable apache2.service</p>
<p>. openrc admin</p>
<p>VM内安装配置OpenStack<br>1, VM内使用devstack安装OpenStack，略。但记得添加AggregateInstanceExtraSpecsFilter, NUMATopologyFilter到scheduler_default_filters （/etc/nova/nova.conf)中并重启nova-schedule进程。</p>
<p>2, 配置aggregate</p>
<p>nova aggregate-create hpgs-aggr<br>nova aggregate-set-metadata hpgs-aggr hpgs=true<br>nova aggregate-create normal-aggr<br>nova aggregate-set-metadata normal-aggr hpgs=false</p>
<p>#Add one or more hosts to them:<br>nova aggregate-add-host hpgs-aggr demo<br>hua@demo:~$ nova aggregate-show hpgs-aggr<br>+—-+———–+——————-+——–+————-+<br>| Id | Name      | Availability Zone | Hosts  | Metadata    |<br>+—-+———–+——————-+——–+————-+<br>| 1  | hpgs-aggr | -                 | ‘demo’ | ‘hpgs=true’ |<br>+—-+———–+——————-+——–+————-+<br>3, 配置flavor</p>
<p>nova flavor-create –ephemeral 0 –swap 0 –rxtx-factor 1.0 –is-public True m1.numa2nodes b8c065ce-90c2-41f9-8d50-1d47a040b494 256 1 2<br>nova flavor-key m1.numa2nodes set aggregate_instance_extra_specs:hpgs=true      #使用aggregate<br>nova flavor-key m1.numa2nodes set hw:mem_page_size=2048                         #配置大页支持</p>
<p>#nova flavor-key m1.numa2nodes set hw:cpu_policy=’dedicated’ hw:cpu_thread_policy=’isolate’</p>
<p>#nova flavor-key m1.numa2nodes set hw:emulator_threads_policy=’isolate’ hypervisor_type=’QEMU’</p>
<p>nova flavor-key m1.numa2nodes set hw:numa_nodes=2                               #配置numa_nodes，若不配置下列两行就是自动模型，配置下面两行为手动模式<br>nova flavor-key m1.numa2nodes set hw:numa_mem.0=128 hw:numa_mem.1=128 hw:numa_mempolicy=strict<br>nova flavor-key m1.numa2nodes set hw:numa_cpus.0=0  hw:numa_cpus.1=1 hw:cpu_policy=dedicated</p>
<p>hua@demo:/bak/openstack/nova$ nova flavor-show m1.numa2nodes |grep extra_specs<br>| extra_specs                | {“hw:cpu_policy”: “dedicated”, “hw:mem_page_size”: “2048”, “hw:numa_mempolicy”: “strict”, “hw:numa_mem.1”: “128”, “hw:numa_mem.0”: “128”, “hw:numa_nodes”: “2”, “aggregate_instance_extra_specs:hpgs”: “true”, “hw:numa_cpus.0”: “0”, “hw:numa_cpus.1”: “1”} |<br>4, 创建虚机</p>
<p>NET_ID=$(neutron net-list |grep ‘private’ |awk ‘{print $2}’)<br>nova boot –image cirros-0.5.1-x86_64-disk –flavor m1.numa2nodes –nic net-id=$NET_ID i1<br>5, 创建虚机后的大页情况，可以看到在node0与node1上已经各用了171-107=64块大页</p>
<p>hua@demo:/bak/openstack/nova$ sudo cat /sys/devices/system/node/node*/meminfo | grep -i huge<br>Node 0 AnonHugePages:         0 kB<br>Node 0 HugePages_Total:   171<br>Node 0 HugePages_Free:    107<br>Node 0 HugePages_Surp:      0<br>Node 1 AnonHugePages:         0 kB<br>Node 1 HugePages_Total:   171<br>Node 1 HugePages_Free:    107<br>Node 1 HugePages_Surp:      0<br>Node 2 AnonHugePages:         0 kB<br>Node 2 HugePages_Total:   170<br>Node 2 HugePages_Free:    170<br>Node 2 HugePages_Surp:      0<br>6, DB情况</p>
<p>mysql&gt; select numa_topology from instance_extra;<br>{<br>  “nova_object.version”: “1.2”,<br>  “nova_object.changes”: [<br>    “cells”<br>  ],<br>  “nova_object.name”: “InstanceNUMATopology”,<br>  “nova_object.data”: {<br>    “cells”: [<br>      {<br>        “nova_object.version”: “1.3”,<br>        “nova_object.changes”: [<br>          “cpu_topology”,<br>          “pagesize”,<br>          “cpuset”,<br>          “cpu_policy”,<br>          “memory”,<br>          “cpu_pinning_raw”,<br>          “id”,<br>          “cpu_thread_policy”<br>        ],<br>        “nova_object.name”: “InstanceNUMACell”,<br>        “nova_object.data”: {<br>          “pagesize”: 2048,<br>          “cpu_topology”: {<br>            “nova_object.version”: “1.0”,<br>            “nova_object.changes”: [<br>              “cores”,<br>              “threads”,<br>              “sockets”<br>            ],<br>            “nova_object.name”: “VirtCPUTopology”,<br>            “nova_object.data”: {<br>              “cores”: 1,<br>              “threads”: 1,<br>              “sockets”: 1<br>            },<br>            “nova_object.namespace”: “nova”<br>          },<br>          “cpuset”: [<br>            0<br>          ],<br>          “cpu_policy”: “dedicated”,<br>          “memory”: 128,<br>          “cpu_pinning_raw”: {<br>            “0”: 0<br>          },<br>          “id”: 0,<br>          “cpu_thread_policy”: null<br>        },<br>        “nova_object.namespace”: “nova”<br>      },<br>      {<br>        “nova_object.version”: “1.3”,<br>        “nova_object.changes”: [<br>          “cpu_topology”,<br>          “pagesize”,<br>          “cpuset”,<br>          “cpu_policy”,<br>          “memory”,<br>          “cpu_pinning_raw”,<br>          “id”,<br>          “cpu_thread_policy”<br>        ],<br>        “nova_object.name”: “InstanceNUMACell”,<br>        “nova_object.data”: {<br>          “pagesize”: 2048,<br>          “cpu_topology”: {<br>            “nova_object.version”: “1.0”,<br>            “nova_object.changes”: [<br>              “cores”,<br>              “threads”,<br>              “sockets”<br>            ],<br>            “nova_object.name”: “VirtCPUTopology”,<br>            “nova_object.data”: {<br>              “cores”: 1,<br>              “threads”: 1,<br>              “sockets”: 1<br>            },<br>            “nova_object.namespace”: “nova”<br>          },<br>          “cpuset”: [<br>            1<br>          ],<br>          “cpu_policy”: “dedicated”,<br>          “memory”: 128,<br>          “cpu_pinning_raw”: {<br>            “1”: 4<br>          },<br>          “id”: 1,<br>          “cpu_thread_policy”: null<br>        },<br>        “nova_object.namespace”: “nova”<br>      }<br>    ]<br>  },<br>  “nova_object.namespace”: “nova”<br>}<br>其他有用信息：</p>
<p>export MYSQL_PASSWORD=ChangeMe123<br>juju run –application mysql “mysql -u root -p$MYSQL_PASSWORD -e \”select <em> from nova.instances where host=’juju-38b529-ovn-6.cloud.sts’\G\””<br>juju run –application mysql “mysql -u root -p$MYSQL_PASSWORD -e \”select </em> from nova.instance_extra where instance_uuid=’0761d1de-7acd-4781-ae8b-f5ba864ab6ec’\G\””<br>juju run –application mysql “mysql -u root -p$MYSQL_PASSWORD -e \”select <em> from nova.compute_nodes where hypervisor_hostname=’p2-bits-cloud-xxx.maas’ or hypervisor_hostname=’p2-bits-cloud-xxx.maas’\G\””<br>juju run –application mysql “mysql -u root -p$MYSQL_PASSWORD -e \”select </em> from nova_api.request_specs where instance_uuid=’0761d1de-7acd-4781-ae8b-f5ba864ab6ec’\G\””<br>生成的虚机配置文件</p>
<p><domain type="kvm" id="1"><br>  <name>instance-00000001</name><br>  <uuid>3bddd8f6-ee18-4b44-a9e3-86ba2c6c25cc</uuid><br>  <metadata><br>    <nova:instance xmlns:nova="http://openstack.org/xmlns/libvirt/nova/1.0"><br>      <nova:package version="14.0.0"><br>      <nova:name>i1</nova:name><br>      <nova:creationtime>2016-07-22 03:46:03</nova:creationtime><br>      <nova:flavor name="m1.numa2nodes"><br>        <nova:memory>256</nova:memory><br>        <nova:disk>1</nova:disk><br>        <nova:swap>0</nova:swap><br>        <nova:ephemeral>0</nova:ephemeral><br>        <nova:vcpus>2</nova:vcpus><br>      </nova:flavor><br>      <nova:owner><br>        <nova:user uuid="e6001bf33a174ffb9d3ad3e9ff47d059">admin</nova:user><br>        <nova:project uuid="f5a578104510494da0ecae0fb514a6f1">demo</nova:project><br>      </nova:owner><br>      <nova:root type="image" uuid="d8184047-f7b3-4622-83e1-fb9d7ede807f"><br>    </nova:root></nova:package></nova:instance><br>  </metadata><br>  <memory unit="KiB">262144</memory><br>  <currentmemory unit="KiB">262144</currentmemory><br>  <memorybacking><br>    <hugepages><br>      <page size="2048" unit="KiB" nodeset="0"><br>      <page size="2048" unit="KiB" nodeset="1"><br>    </page></page></hugepages><br>  </memorybacking><br>  <vcpu placement="static">2</vcpu><br>  <cputune><br>    <shares>2048</shares><br>    <vcpupin vcpu="0" cpuset="0"><br>    <vcpupin vcpu="1" cpuset="4"><br>    <emulatorpin cpuset="0,4"><br>  </emulatorpin></vcpupin></vcpupin></cputune><br>  <numatune><br>    <memory mode="strict" nodeset="0-1"><br>    <memnode cellid="0" mode="strict" nodeset="0"><br>    <memnode cellid="1" mode="strict" nodeset="1"><br>  </memnode></memnode></memory></numatune><br>  <resource><br>    <partition>/machine</partition><br>  </resource><br>  <sysinfo type="smbios"><br>    <system><br>      <entry name="manufacturer">OpenStack Foundation</entry><br>      <entry name="product">OpenStack Nova</entry><br>      <entry name="version">14.0.0</entry><br>      <entry name="serial">4d63962c-1942-0164-e7a7-fa97578f4e3a</entry><br>      <entry name="uuid">3bddd8f6-ee18-4b44-a9e3-86ba2c6c25cc</entry><br>      <entry name="family">Virtual Machine</entry><br>    </system><br>  </sysinfo><br>  <os><br>    <type arch="x86_64" machine="pc-i440fx-wily">hvm</type><br>    <kernel>/opt/stack/data/nova/instances/3bddd8f6-ee18-4b44-a9e3-86ba2c6c25cc/kernel</kernel><br>    <initrd>/opt/stack/data/nova/instances/3bddd8f6-ee18-4b44-a9e3-86ba2c6c25cc/ramdisk</initrd><br>    <cmdline>root=/dev/vda console=tty0 console=ttyS0</cmdline><br>    <boot dev="hd"><br>    <smbios mode="sysinfo"><br>  </smbios></boot></os><br>  <features><br>    <acpi><br>    <apic><br>  </apic></acpi></features><br>  <cpu><br>    <topology sockets="2" cores="1" threads="1"><br>    <numa><br>      <cell id="0" cpus="0" memory="131072" unit="KiB" memaccess="shared"><br>      <cell id="1" cpus="1" memory="131072" unit="KiB" memaccess="shared"><br>    </cell></cell></numa><br>  </topology></cpu><br>  <clock offset="utc"><br>    <timer name="pit" tickpolicy="delay"><br>    <timer name="rtc" tickpolicy="catchup"><br>    <timer name="hpet" present="no"><br>  </timer></timer></timer></clock><br>  <on_poweroff>destroy</on_poweroff><br>  <on_reboot>restart</on_reboot><br>  <on_crash>destroy</on_crash><br>  <devices><br>    <emulator>/usr/bin/kvm-spice</emulator><br>    <disk type="file" device="disk"><br>      <driver name="qemu" type="qcow2" cache="none"><br>      <source file="/opt/stack/data/nova/instances/3bddd8f6-ee18-4b44-a9e3-86ba2c6c25cc/disk"><br>      <backingstore type="file" index="1"><br>        <format type="raw"><br>        <source file="/opt/stack/data/nova/instances/_base/5b06ec6b6abd700935b24a454e8ce3461d050a9f"><br>        <backingstore><br>      </backingstore><br>      <target dev="vda" bus="virtio"><br>      <alias name="virtio-disk0"><br>      <address type="pci" domain="0x0000" bus="0x00" slot="0x03" function="0x0"><br>    </address></alias></target></format></backingstore></driver></disk><br>    <disk type="file" device="cdrom"><br>      <driver name="qemu" type="raw" cache="none"><br>      <source file="/opt/stack/data/nova/instances/3bddd8f6-ee18-4b44-a9e3-86ba2c6c25cc/disk.config"><br>      <backingstore><br>      <target dev="hdd" bus="ide"><br>      <readonly><br>      <alias name="ide0-1-1"><br>      <address type="drive" controller="0" bus="1" target="0" unit="1"><br>    </address></alias></readonly></target></backingstore></driver></disk><br>    <controller type="usb" index="0"><br>      <alias name="usb"><br>      <address type="pci" domain="0x0000" bus="0x00" slot="0x01" function="0x2"><br>    </address></alias></controller><br>    <controller type="pci" index="0" model="pci-root"><br>      <alias name="pci.0"><br>    </alias></controller><br>    <controller type="ide" index="0"><br>      <alias name="ide"><br>      <address type="pci" domain="0x0000" bus="0x00" slot="0x01" function="0x1"><br>    </address></alias></controller><br>    <interface type="bridge"><br>      <mac address="fa:16:3e:0b:52:0b"><br>      <source bridge="qbref7fef26-3e"><br>      <target dev="tapef7fef26-3e"><br>      <model type="virtio"><br>      <alias name="net0"><br>      <address type="pci" domain="0x0000" bus="0x00" slot="0x02" function="0x0"><br>    </address></alias></model></target></mac></interface><br>    <serial type="file"><br>      <source path="/opt/stack/data/nova/instances/3bddd8f6-ee18-4b44-a9e3-86ba2c6c25cc/console.log"><br>      <target port="0"><br>      <alias name="serial0"><br>    </alias></target></serial><br>    <serial type="pty"><br>      <source path="/dev/pts/20"><br>      <target port="1"><br>      <alias name="serial1"><br>    </alias></target></serial><br>    <console type="file"><br>      <source path="/opt/stack/data/nova/instances/3bddd8f6-ee18-4b44-a9e3-86ba2c6c25cc/console.log"><br>      <target type="serial" port="0"><br>      <alias name="serial0"><br>    </alias></target></console><br>    <memballoon model="virtio"><br>      <stats period="10"><br>      <alias name="balloon0"><br>      <address type="pci" domain="0x0000" bus="0x00" slot="0x04" function="0x0"><br>    </address></alias></stats></memballoon><br>  </devices><br>  <seclabel type="dynamic" model="apparmor" relabel="yes"><br>    <label>libvirt-3bddd8f6-ee18-4b44-a9e3-86ba2c6c25cc</label><br>    <imagelabel>libvirt-3bddd8f6-ee18-4b44-a9e3-86ba2c6c25cc</imagelabel><br>  </seclabel><br></domain><br>20201208更新<br>1, create a VM with 3 numa nodes according to the doc [1]</p>
<cpu mode="host-passthrough"><br>  <numa><br>    <cell id="0" cpus="0-3" memory="4096000"><br>    <cell id="1" cpus="4-5" memory="2048000"><br>    <cell id="2" cpus="6-7" memory="2048000"><br>  </cell></cell></cell></numa><br></cpu>

<p>2, enable huge page, and use ‘isolcpus=0,1,2,3’ to just use cpu in numa0<br>注意：grub里定义isolcpus并不会让nova不使用这些cpu, nova里专门有vcpu_pin_set来做这件事。</p>
<p>$ cat /proc/cmdline |grep isolcpu<br>BOOT_IMAGE=/boot/vmlinuz-5.4.0-26-generic root=/dev/mapper/vgdemo-root ro transparent_hugepage=never hugepagesz=2M hugepages=512 default_hugepagesz=2M isolcpus=0,1,2,3</p>
<p>3, set up openstack test env.</p>
<p>4, create test aggreate and flavor and test vm</p>
<p>nova aggregate-create hpgs-aggr<br>nova aggregate-set-metadata hpgs-aggr hpgs=true<br>nova aggregate-create normal-aggr<br>nova aggregate-set-metadata normal-aggr hpgs=false<br>nova aggregate-add-host hpgs-aggr demo<br>nova aggregate-show hpgs-aggr</p>
<p>nova flavor-create –ephemeral 0 –swap 0 –rxtx-factor 1.0 –is-public True m1.numa2nodes b8c065ce-90c2-41f9-8d50-1d47a040b494 256 1 2<br>nova flavor-key m1.numa2nodes set aggregate_instance_extra_specs:hpgs=true<br>nova flavor-key m1.numa2nodes set hw:mem_page_size=2048<br>nova flavor-key m1.numa2nodes set hw:cpu_policy=’dedicated’ hw:cpu_thread_policy=’isolate’<br>nova flavor-key m1.numa2nodes set hw:emulator_threads_policy=’isolate’ hypervisor_type=’QEMU’</p>
<p>nova boot –image cirros-0.5.1-x86_64-disk –flavor m1.numa2nodes –nic net-id=$NET_ID i1</p>
<p>3, This instance i1 uses cpu 0 and 1, and use cpu 2 as emulatorpin</p>
<p>$ ps -eLo psr,args |grep qemu- |grep -v ‘grep’ |awk ‘{print $1}’ |sort -n |uniq<br>0<br>1<br>2</p>
<p>$ sudo virsh emulatorpin instance-00000001</p>
<h2 id="emulator-CPU-Affinity"><a href="#emulator-CPU-Affinity" class="headerlink" title="emulator: CPU Affinity"></a>emulator: CPU Affinity</h2><pre><code>*: 2
</code></pre><p>$ sudo virsh vcpuinfo instance-00000001<br>VCPU:           0<br>CPU:            0<br>State:          running<br>CPU time:       21.2s<br>CPU Affinity:   y——-</p>
<p>VCPU:           1<br>CPU:            1<br>State:          running<br>CPU time:       14.9s<br>CPU Affinity:   -y——</p>
<p>$ taskset -apc <code>pidof qemu-system-x86_64</code><br>pid 15014’s current affinity list: 2<br>pid 15016’s current affinity list: 2<br>pid 15022’s current affinity list: 2<br>pid 15023’s current affinity list: 0<br>pid 15025’s current affinity list: 1<br>pid 15039’s current affinity list: 2</p>
<p>sudo virsh dumpxml instance-00000001<br>  …<br>  <vcpu placement="static">2</vcpu><br>  <cputune><br>    <shares>2048</shares><br>    <vcpupin vcpu="0" cpuset="0"><br>    <vcpupin vcpu="1" cpuset="1"><br>    <emulatorpin cpuset="2"><br>  </emulatorpin></vcpupin></vcpupin></cputune><br>  <cpu mode="custom" match="exact" check="full"><br>    <model fallback="forbid">qemu64</model><br>    <topology sockets="2" cores="1" threads="1"><br>    <feature policy="require" name="x2apic"><br>    <feature policy="require" name="hypervisor"><br>    <feature policy="require" name="lahf_lm"><br>    <feature policy="disable" name="svm"><br>    <numa><br>      <cell id="0" cpus="0-1" memory="262144" unit="KiB" memaccess="shared"><br>    </cell></numa><br>  </feature></feature></feature></feature></topology></cpu></p>
<p>4, host’s numa_toplogy</p>
<p>select numa_topology from nova_cell1.compute_nodes where host=’demo’ \G;</p>
<p>see <a href="https://paste.ubuntu.com/p/MjmMHZxS6s/" target="_blank" rel="external">https://paste.ubuntu.com/p/MjmMHZxS6s/</a></p>
<p>5, instance’s numa_toplogy</p>
<p>select numa_topology from instance_extra where instance_uuid in (select uuid from instances where host=’demo’) \G;</p>
<p>see <a href="https://paste.ubuntu.com/p/CP2t2ghCfH/" target="_blank" rel="external">https://paste.ubuntu.com/p/CP2t2ghCfH/</a></p>
<p>参考<br>[1] <a href="http://docs.openstack.org/developer/devstack/guides/devstack-with-nested-kvm.html" target="_blank" rel="external">http://docs.openstack.org/developer/devstack/guides/devstack-with-nested-kvm.html</a></p>
<p>[2] <a href="https://docs.openstack.org/nova/rocky/contributor/testing/libvirt-numa.html" target="_blank" rel="external">https://docs.openstack.org/nova/rocky/contributor/testing/libvirt-numa.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/28/回忆pdb基础/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/28/回忆pdb基础/" itemprop="url">回忆pdb基础</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-12-28T10:06:02+08:00">
                2020-12-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2015-05-05<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )<br>人啊，总要不断地与记忆作斗争。</p>
<p>1, 加-g参数编译可执行性文件, 如果没有-g，你将看不见程序的函数名、变量名，所代替的全是运行时的内存地址。<br>   cc -g test.c -o test<br>   静态检查程序错误，splint test.c<br>   单元测试可使用CUnit, gcc -o test.o -I /usr/local/include/CUnit -L /usr/local/lib/ -g testcase.c -l cunit ./test.o</p>
<p>   若是要调试master可以下载源码用./configure前加上CFLAGS=”-Wall -O2 -g”即可编译。若是ubuntu repo里已经有的package，则直接安装dbg即可编译(没有dbg包时可次优选择dbgsym包）。<br>2, 启动gdb, gdb test<br>   启动GDB的方法有以下几种：<br>    a、gdb <program><br>       program也就是你的执行文件，一般在当然目录下。<br>    b、gdb <program> core<br>       用gdb同时调试一个运行程序和core文件，core是程序非法执行后core dump后产生的文件。<br>       如果产生coredump呢？ 需要执ulimit -c unlimited才可以(缺省是coredump文件大小是0字节所以它不生成）。<br>       并不是所有的异常都会生成coredump文件，附录1是一个运行异常时会产生coredump文件的例子。<br>       运行后coredump文件产生在当前文件夹的core文件中。分析它： gdb ./test ./core, 如下显示了是哪一句出了错误：<br>       (gdb) bt</program></program></p>
<pre><code>   #0  0x000000000040054d in core_dump () at test.c:5
   #1  0x0000000000400585 in main () at test.c:10
c、gdb &lt;program&gt; &lt;PID&gt;
   通过sudo gdb启动gdb后直接attach &lt;PID&gt;可以attach到正在运行的程序，当然程序得加-g参数编译的。
</code></pre><p>3, 一些常用gdb命令<br>   l, 列出源代码</p>
<p>   break 16, 第16行设置断点<br>   b fn1 if a&gt;b, 条件设置断点<br>   break func, 在函数的入口处设置断点<br>   delete/disable/enable/clear 16, 删除第16个断点<br>   delete breakpoints，清除所有断点<br>   info break, 查看断点<br>   r, 运行程序，到断点处处时会停止运行等待用户输入（run), 在gdb中正常结束的程序也可以用此命令重新运行<br>   n, 单步执行(next)<br>   s, 进入函数(step)<br>   c, 继续运行(continue), 到下一个断点处<br>   p <variable>, 打印变量的值<br>   set var i=1, 修改变量的值<br>   info registers, 查看寄存器<br>   bt, 查看函数堆栈<br>   call 函数(参数),调用程序中可见的函数，并传递“参数”，如：call gdb_test(55)<br>   display 表达式：在单步运行时将非常有用，它将在每次单步进行指令后，紧接着输出被设置的表达式及值。如： display a<br>   watch 表达式：设置一个监视点，一旦被监视的“表达式”的值改变，gdb将强行终止正在被调试的程序。如：watch a<br>   q, 退出<br>4, 使用GDB调试多进程程序, <a href="https://www.ibm.com/developerworks/cn/linux/l-cn-gdbmp/" target="_blank" rel="external">https://www.ibm.com/developerworks/cn/linux/l-cn-gdbmp/</a></variable></p>
<p>5, 使用cgdb可以很方便的查看代码。<br>6, 性能分析, 比如哪个函数调用了多少次，被谁调用了， 平均每次调用花费多少时间等。这时候要用gprof,gprof是分析profile输出的。<br>   要想执行时输出profile文件编译时要加-pg选项, gcc -o helloworld.o -pg -g helloworld.c<br>   执行上面语句后会在当前目录下生成gmon.out文件, 然后用gprof去读取并显示出来，gprof -b -A -p -q helloworld.o gmon.out &gt;prof_info.txt </p>
<p>7, gdb也可以调试go语言的程序，采用”go build -gcflags “-N -l” test.go“编译，再’gdb test”即可。可能相比于C会多出一个‘info goroutines’命令。</p>
<p>附录1, 产生coredump文件的例子</p>
<p>#include <stdio.h><br>int core_dump() {<br>    int i;<br>    for (i = 5; i &gt;= 0; i–) {<br>        printf(“(%d, %d)\n”, i, 100 / i);<br>    }<br>    return 0;<br>}<br>int main() {<br>    core_dump();<br>    return 0;<br>}</stdio.h></p>
<p>附录2, 如何分析CoreDump文件</p>
<p>1, 安装dbgsym，注意安装的是librados2-dbg librbd1-dbg， 而不是librados2-dbgsym librbd1-dbgsym. （注意：有dbg内建包时优先安装dbg包，没有时才安装dbgsym非内建包，这点异常重要，否则会造成gdb调试时缺失符号表，这个网页有解释： <a href="https://wiki.ubuntu.com/DebuggingProgramCrash#Debug_Symbol_Packages）" target="_blank" rel="external">https://wiki.ubuntu.com/DebuggingProgramCrash#Debug_Symbol_Packages）</a><br>echo “deb <a href="http://ddebs.ubuntu.com" target="_blank" rel="external">http://ddebs.ubuntu.com</a> $(lsb_release -cs) main restricted universe multiverse” | sudo tee -a /etc/apt/sources.list.d/debuginfo_debs.list<br>echo “deb <a href="http://ddebs.ubuntu.com" target="_blank" rel="external">http://ddebs.ubuntu.com</a> $(lsb_release -cs)-updates main restricted universe multiverse” | sudo tee -a /etc/apt/sources.list.d/debuginfo_debs.list<br>sudo apt-key adv –keyserver keyserver.ubuntu.com –recv-keys C8CAB6595FDFF622<br>sudo apt update<br>sudo apt-get install qemu-system-x86-dbgsym librados2-dbg librbd1-dbg</p>
<p>For example: /usr/lib/x86_64-linux-gnu/libstdc++.so.6 and the debugging version is at /usr/lib/x86_64-linux-gnu/debug/libstdc++.so.6</p>
<p>(gdb) set debug-file-directory /usr/lib/x86_64-linux-gnu/debug/</p>
<p>(gdb) directory /xxx/qemu/qemu-2.5+dfsg     #sometimes directory doesn’t take effect, so use the following line</p>
<p>(gdb) set substitute-path /build/qemu-e2kucK/qemu-2.5+dfsg /xxx/qemu/qemu-2.5+dfsg</p>
<p>(gdb) l</p>
<p>(gdb) info sharedlibrary</p>
<p>2, 解压 - apport-unpack _usr_bin_qemu-system-x86_64.64055.crash ./tmp/</p>
<p>3, 分析CoreDump (确保/usr/bin/qemu-system-x86_64与版本与之一致）<br>   gdb /usr/bin/qemu-system-x86_64 ./tmp/CoreDump</p>
<p>4, 查看堆栈<br>(gdb) bt 1</p>
<p>#0  malloc_consolidate (av=av@entry=0x7fa810000020) at malloc.c:4175</p>
<p>5, 查看汇编，上面的malloc.c:4175可能由于编译器优化和源代码对不上，所以仍然需要通过编译代码一一比对<br>(gdb) p $rip<br>$5 = (void (*)()) 0x7fa84c275470 <malloc_consolidate+336><br>(gdb) x/2gi $rip<br>   0x7fa84c275320 <malloc_consolidate>: cmpq   $0x0,0x3484d0(%rip)        # 0x7fa84c5bd7f8 <global_max_fast><br>   0x7fa84c275328 <malloc_consolidate+8>: je     0x7fa84c275a8b <malloc_consolidate+1899></malloc_consolidate+1899></malloc_consolidate+8></global_max_fast></malloc_consolidate></malloc_consolidate+336></p>
<p>6, 采用汇编理解出错代码，结合源代码辅助分析（因为编译器会优化代码，所以不能完全相信CoreDump中的行号）</p>
<p>注：UCA缺乏debug symbol，例如为trusty上的mitaka uca的qemu包构建debug symbol，因为都是ppa编译的其编译器版本及设置都差不多这样编译出的debug symbol还可以近似地去用。<br>1, PPA中有”Build debug symbols”的选项（<a href="https://launchpad.net/~zhhuabj/+archive/ubuntu/trusty-mitaka-sru/+edit），再在" target="_blank" rel="external">https://launchpad.net/~zhhuabj/+archive/ubuntu/trusty-mitaka-sru/+edit），再在</a> “Add PPA dependency”里添加”~ubuntu-cloud-archive/+archive/ubuntu/mitaka-staging”</p>
<p>2, 进这个页面(<a href="https://launchpad.net/~ubuntu-cloud-archive/+archive/ubuntu/mitaka-staging），点击&quot;View" target="_blank" rel="external">https://launchpad.net/~ubuntu-cloud-archive/+archive/ubuntu/mitaka-staging），点击&quot;View</a> package details” -&gt; “copy packages”，在搜索框输入qemu并同时将其后的下拉列表从Published改为Superseded这样就可以选择客户所用的qemu版本。</p>
<h1 id="trusty-doesn’t-support-mitaka-uca-sudo-add-apt-repository-cloud-archive-mitaka-but-it-supports-mitaka-staging"><a href="#trusty-doesn’t-support-mitaka-uca-sudo-add-apt-repository-cloud-archive-mitaka-but-it-supports-mitaka-staging" class="headerlink" title="trusty doesn’t support mitaka uca (sudo add-apt-repository cloud-archive:mitaka), but it supports mitaka-staging"></a>trusty doesn’t support mitaka uca (sudo add-apt-repository cloud-archive:mitaka), but it supports mitaka-staging</h1><p>sudo add-apt-repository ppa:ubuntu-cloud-archive/mitaka-staging</p>
<p>sudo add-apt-repository ppa:xxxx</p>
<p>sudo apt update</p>
<p>sudo apt install qemu-system-x86=1:2.5+dfsg-5ubuntu10.16~cloud0</p>
<h1 id="seems-can’t-use-‘apt-cache’-to-qeury-dbgsym-in-PPA-so-change-to-use-wget"><a href="#seems-can’t-use-‘apt-cache’-to-qeury-dbgsym-in-PPA-so-change-to-use-wget" class="headerlink" title="seems can’t use ‘apt-cache’ to qeury dbgsym in PPA, so change to use wget"></a>seems can’t use ‘apt-cache’ to qeury dbgsym in PPA, so change to use wget</h1><p>wget <a href="http://ppa.launchpad.net/xxx/sf177500/ubuntu/pool/main/q/qemu/qemu-system-x86-dbgsym_2.5+dfsg-5ubuntu10.16~cloud0_amd64.ddeb" target="_blank" rel="external">http://ppa.launchpad.net/xxx/sf177500/ubuntu/pool/main/q/qemu/qemu-system-x86-dbgsym_2.5+dfsg-5ubuntu10.16~cloud0_amd64.ddeb</a><br>sudo dpkg -i qemu-system-x86-dbgsym_2.5+dfsg-5ubuntu10.16~cloud0_amd64.ddeb<br>sudo apt install qemu-system-x86-dbgsym=1:2.5+dfsg-5ubuntu10.16~cloud0<br>gdb /usr/bin/qemu-system-x86_64 10Apr18-instance-000a2f60-qemu-system-x86_64.core.2003745</p>
<p>#GDB调试<br>sysctl kernel.core_pattern<br>sudo service apport start force_start=1 enabled=1<br>grep enabled /etc/default/apport<br>sudo killall -SIGSEGV ovs-vswitchd<br>sudo cat /var/log/apport.log<br>sudo apt install openvswitch-dbg cgdb</p>
<p>#cgdb $(which ovs-vswitchd) $(pidof ovs-vswitchd)<br>cgdb ovs-vswitchd /var/crash/_usr_lib_openvswitch-switch_ovs-vswitchd.0.crash</p>
<p>但是上面killall生成coredump的方法会让ovs停掉，下面的不会：</p>
<p>sudo apt install gdb openvswitch-dbg -y<br>sudo gcore <code>pidof ovs-vswitchd</code><br>sudo gdb –core ./core.16524 /usr/sbin/ovs-vswitchd</p>
<p>sudo tail -f /var/log/openvswitch/ovs-vswitchd.log | awk ‘/blocked 1000 ms waiting for main to quiesce/ {system(“sudo /usr/bin/gcore <code>pidof ovs-vswitchd</code>“)}’<br>thread apply all bt<br>info proc mapping   #query all sysbol tables</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/12/RabbitMQ-Deep-Dive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/12/RabbitMQ-Deep-Dive/" itemprop="url">RabbitMQ Deep Dive</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-12-12T12:01:46+08:00">
                2020-12-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2015-06-03<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )<br>AMQP概念<br>通过消息机制，可以实现数据传输，非阻塞型操作，推送通知，发布/订阅，异步处理，work队列。<br>AMQP当中有四个概念非常重要：虚拟主机（virtual host），交换机（exchange），队列（queue）和绑定（binding）。</p>
<p>virutal host相当于namespace，用于不同tenant之间的exchange, queue, binding的隔离。<br> Queue队列, 每个消息都会被投入到一个或多个队列。消息就一直在里面，直到有客户端（也就是消费者，Consumer）连接到这个队列并且将其取走为止。队列是由消费者（Consumer）通过程序建立的，不是通过配置文件或者命令行工具。<br>Binding绑定, 它的作用就是把exchange和queue按照路由规则绑定起来。<br>Routing_Key路由关键字：exchange根据这个关键字进行消息投递。<br>Channele消息通道：在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。<br>Exchange交换机，对消息进行路由，当收到Publisher传递给它的消息后，Excahnge会根据路由键routing_key决定将消息加入到哪些消息队列中。<br>消息的类型：</p>
<p>Direct Exchange – 处理路由键。需要将一个队列绑定到交换机上，要求该消息与一个特定的路由键完全匹配。一对一交换类型。<br>Topic Exchange – 将路由键和某模式进行匹配。此时队列需要绑定要一个模式上。符号“#”匹配一个或多个词，符号“*”匹配不多不少一个词。一对多主题多播交换类型。<br>Fanout Exchange – 不处理路由键。你只需要简单的将队列绑定到交换机上。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。一对多广播交换类型。</p>
<p>RabbitMQ简介与特点<br>RabbitMQ是一个开源的AMQP协议的实现，它具有如下特点：可靠性（Reliability）, RabbitMQ使用一些机制来保证程序的可靠性，如持久化、传输确认机制、发布确认、高可用性。灵活的路由机制（Flexible Routing）, 在消息进入队列之前，通过Exchange来路由消息的。对于典型的路由功能，RabbitMQ已经提供了一些内置的Exchange来实现。针对更复杂的路由功能，可以将多个Exchange绑定在一起，也通过插件机制实现自己的Exchange。消息集群（Clustering）多个RabbitMQ服务器可以组成一个集群，形成单个逻辑Broker。Federation, For servers that need to be more loosely and unreliably connected than clustering allows, RabbitMQ offers a federation model.队列高可用（Highly Available Queues）, 队列可以在集群中的机器上进行镜像，以确保在硬件问题下还保证消息安全。多种协议的支持（Multi-protocol）, RabbitMQ支持多种消息队列协议。</p>
<p>一个rabbitmq python例子</p>
<p>#coding:utf-8<br>import sys<br>from amqplib import client_0_8 as amqp<br>if <strong>name</strong> == ‘<strong>main</strong>‘:<br>    if (len(sys.argv) &lt;= 1):<br>        ispublisher = ‘0’<br>        print “Then pls run ‘rabbittest 1’ to sent message.”<br>    else:<br>        ispublisher = sys.argv[1]<br>    conn = amqp.Connection(host=”localhost:5672 “, userid=”guest”, password=”password”, virtual_host=”/“, insist=False)</p>
<pre><code># 每个channel都被分配了一个整数标识
chan = conn.channel()
# 创建一个队列，它是durable的（重启后会重新建立）a
# 消费者断开时不会自动删除（auto_delte=False)
chan.queue_declare(queue=&quot;queue1&quot;, durable=True, exclusive=False, auto_delete=False)
# 创建交换机，参数意思和上面的队列是一样的，还有一个type类型：fanout, direct, topic
chan.exchange_declare(exchange=&quot;switch1&quot;, type=&quot;direct&quot;,
                      durable=True, auto_delete=False,)
# 绑定交换机和队列
chan.queue_bind(queue=&quot;queue1&quot;, exchange=&quot;switch1&quot;, routing_key=&quot;key1&quot;)
if (ispublisher == &apos;1&apos;):
    # 生产者
    msg = amqp.Message(&quot;Test message!&quot;)
    msg.properties[&quot;delivery_mode&quot;] = 2
    chan.basic_publish(msg, exchange=&quot;switch1&quot;, routing_key=&quot;key1&quot;)
else:
    # 主动从队列拉消息
    msg = chan.basic_get(&quot;queue1&quot;)
    print msg.body
    chan.basic_ack(msg.delivery_tag)
    # 消息来了通知回调
    # 如果no_ack=True可以使用chan.basic_ack()人工确认，使用delivery_tag参数
    def recv_callback(msg):
        print &apos;Received: &apos; + msg.body
    chan.basic_consume(queue=&apos;queue1&apos;, no_ack=False,
                       callback=recv_callback, consumer_tag=&quot;testtag&quot;)
    # chan.basic_cancel(&quot;testtag&quot;) # 取消回调函数
    while True:
        chan.wait()  # 等待在队列上，直到下一个消息到达队列。
chan.close()
conn.close()
</code></pre><p>RabbitMQ CLI<br>安装，sudo apt-get install rabbitmq-server<br>重启，sudo service rabbitmq-server restart<br>sudo rabbitmqctl list_vhostssudo rabbitmqctl add_vhost demo<br>sudo rabbitmqctl list_users<br>sudo rabbitmqctl add_user test password<br>sudo rabbitmqctl change_password test password<br>sudo rabbitmqctl clear_password test<br>sudo rabbitmqctl list_user_permissions test<br>sudo rabbitmqctl set_permissions -p demo test “.<em>“ “.</em>“ “.*”<br>sudo rabbitmqctl clear_permissions -p demo test<br>sudo rabbitmqctl list_queues -p demo name durable auto_delete slave_pids synchronised_slave_pids<br>sudo rabbitmqadmin delete queue name=’queuename’<br>sudo rabbitmqctl list_exchanges -p demosudo rabbitmqctl list_bindings -p demo<br>sudo rabbitmqctl list_consumers -p demosudo rabbitmqctl statussudo rabbitmqctl report</p>
<h1 id="fileds-can-be-name-durable-auto-delete-arguments-policy-pid-owner-pid-exclusive-exclusive-consumer-pid-exclusive-consumer-tag-messages-ready-messages-unacknowledged-messages-messages-ready-ram-messages-unacknowledged-ram-messages-ram-messages-persistent-message-bytes-message-bytes-ready-message-bytes-unacknowledged-message-bytes-ram-message-bytes-persistent-head-message-timestamp-disk-reads-disk-writes-consumers-consumer-utilisation-memory-slave-pids-synchronised-slave-pids-state"><a href="#fileds-can-be-name-durable-auto-delete-arguments-policy-pid-owner-pid-exclusive-exclusive-consumer-pid-exclusive-consumer-tag-messages-ready-messages-unacknowledged-messages-messages-ready-ram-messages-unacknowledged-ram-messages-ram-messages-persistent-message-bytes-message-bytes-ready-message-bytes-unacknowledged-message-bytes-ram-message-bytes-persistent-head-message-timestamp-disk-reads-disk-writes-consumers-consumer-utilisation-memory-slave-pids-synchronised-slave-pids-state" class="headerlink" title="fileds can be:  [name, durable, auto_delete, arguments, policy, pid, owner_pid, exclusive, exclusive_consumer_pid, exclusive_consumer_tag, messages_ready, messages_unacknowledged, messages, messages_ready_ram, messages_unacknowledged_ram, messages_ram, messages_persistent, message_bytes, message_bytes_ready, message_bytes_unacknowledged, message_bytes_ram, message_bytes_persistent, head_message_timestamp, disk_reads, disk_writes, consumers, consumer_utilisation, memory, slave_pids, synchronised_slave_pids, state]"></a>fileds can be:  [name, durable, auto_delete, arguments, policy, pid, owner_pid, exclusive, exclusive_consumer_pid, exclusive_consumer_tag, messages_ready, messages_unacknowledged, messages, messages_ready_ram, messages_unacknowledged_ram, messages_ram, messages_persistent, message_bytes, message_bytes_ready, message_bytes_unacknowledged, message_bytes_ram, message_bytes_persistent, head_message_timestamp, disk_reads, disk_writes, consumers, consumer_utilisation, memory, slave_pids, synchronised_slave_pids, state]</h1><p>sudo rabbitmqctl list_queues name slave_pids synchronised_slave_pids durable -p openstack<br>RabbitMQ GUI</p>
<p>Enable it, sudo rabbitmq-plugins enable rabbitmq_management<br><a href="http://localhost:15672" target="_blank" rel="external">http://localhost:15672</a>  (guest/guest)<br>RabbitMQ配置文件<br><a href="http://www.rabbitmq.com/configure.html#configuration-file" target="_blank" rel="external">http://www.rabbitmq.com/configure.html#configuration-file</a><br>sudo find / -name rabbitmq.config*<br>sudo mv /usr/share/doc/rabbitmq-server/rabbitmq.config.example.gz /etc/rabbitmq/cd /etc/rabbitmq/ &amp;&amp; sudo gunzip rabbitmq.config.example.gz<br>sudo mv rabbitmq.config.example rabbitmq.config<br>RabbitMQ调优</p>
<p>1, 流控(Flow Control)机制，默认RabbitMQ在使用机器的40%以上的内存时流控机制会起作用block掉所有连接。故确保使用64位操作系统与64位Erlang VM。当RabbitMQ是集群情况下，当其中有一台机器硬盘不足的时候，所有节点的producer链接也会被阻止。</p>
<p>rabbitmqctl  set_vm_memory_high_watermark 0.4<br>rabbitmqctl set_vm_memory_high_watermark_paging_ratio 0.75<br>rabbitmqctl status<br><a href="http://www.rabbitmq.com/memory.html" target="_blank" rel="external">http://www.rabbitmq.com/memory.html</a><br>Max open files，/etc/default/rabbitmq-server<br>ulimit -n 65535<br>cat /proc/$RABBITMQ_BEAM_PROCESS_PID/limits<br>2, Erlang的Hipe优化, 可以设置hipe_compiles设置。可以看到有20-50%的性能优化。而你只需要付出1分钟左右的延迟启动。 HiPE需要你检查是否编译进入你的Erlang安装环境。Ubuntu，需要安装erlang-base-hipe.默认有些平台不支持。如果Erlang VM segfaults,请关闭这个选项。</p>
<p>[{rabbit, [{hipe_compile, true}]}].<br>RabbitMQ集群</p>
<p>跨三个节点部署 RabbitMQ 集群和镜像消息队列。可以使用 HAProxy 提供负载均衡，或者将 RabbitMQ host list 配置给 OpenStack 组件（使用 rabbit_hosts 和 rabbit_ha_queues 配置项）。</p>
<p>先看第一种方式（采用HAproxy）：</p>
<h1 id="每个节点上执行下列命令配置RabbitMQ集群"><a href="#每个节点上执行下列命令配置RabbitMQ集群" class="headerlink" title="每个节点上执行下列命令配置RabbitMQ集群"></a>每个节点上执行下列命令配置RabbitMQ集群</h1><h1 id="根据需要设置当前节点的工作模式-ram-disk-，ROOT-NODE-HOSTNAME为集群根节点的主机名，注意在此必须使用主机名"><a href="#根据需要设置当前节点的工作模式-ram-disk-，ROOT-NODE-HOSTNAME为集群根节点的主机名，注意在此必须使用主机名" class="headerlink" title="根据需要设置当前节点的工作模式(ram/disk)，ROOT_NODE_HOSTNAME为集群根节点的主机名，注意在此必须使用主机名"></a>根据需要设置当前节点的工作模式(ram/disk)，ROOT_NODE_HOSTNAME为集群根节点的主机名，注意在此必须使用主机名</h1><p>apt-get install rabbitmq-server<br>rabbitmq-server -detached                   #detached为后台运行别占据终端<br>echo ‘MYRABBITMQCLUSTERABC’ &gt; /var/lib/rabbitmq/.erlang.cookie<br>chown rabbitmq:rabbitmq /var/lib/rabbitmq/.erlang.cookie<br>chmod 400 /var/lib/rabbitmq/.erlang.cookie<br>/usr/lib/rabbitmq/bin/rabbitmq-plugins enable rabbitmq_management<br>/usr/sbin/rabbitmqctl stop_app<br>/usr/sbin/rabbitmqctl reset<br>/usr/sbin/rabbitmqctl join_cluster –ram rabbit@${ROOT_NODE_HOSTNAME}<br>/usr/sbin/rabbitmqctl start_app<br>service rabbitmq-server restart</p>
<h1 id="在主节点上添加用户"><a href="#在主节点上添加用户" class="headerlink" title="在主节点上添加用户"></a>在主节点上添加用户</h1><p>/usr/sbin/rabbitmqctl add_user web_admin password<br>/usr/sbin/rabbitmqctl add_user mgmt_admin password<br>/usr/sbin/rabbitmqctl set_user_tags username monitoring<br>/usr/sbin/rabbitmqctl set_user_tags mgmt_admin administrator<br>/usr/sbin/rabbitmqctl rabbitmqctl list_users<br>/usr/sbin/rabbitmqctl set_permissions -p / mgmt_admin “.<em>“ “.</em>“ “.*”</p>
<h1 id="设置HAProxy-需要设置成镜像队列，可以访问http-192-168-64-87-8888，用户名web-admin-password进行访问"><a href="#设置HAProxy-需要设置成镜像队列，可以访问http-192-168-64-87-8888，用户名web-admin-password进行访问" class="headerlink" title="设置HAProxy, 需要设置成镜像队列，可以访问http://192.168.64.87:8888，用户名web_admin/password进行访问"></a>设置HAProxy, 需要设置成镜像队列，可以访问<a href="http://192.168.64.87:8888，用户名web_admin/password进行访问" target="_blank" rel="external">http://192.168.64.87:8888，用户名web_admin/password进行访问</a></h1><p>/usr/sbin/rabbitmqctl set_policy ha-all “^” ‘{“ha-mode”:”all”}’<br>修改文件：/etc/haproxy/haproxy.cfg<br>listen rabbitmq_cluster 0.0.0.0:5672<br>mode tcp<br>balance roundrobin<br>server   node1 192.168.1.1:5672 check inter 2000 rise 2 fall 3<br>/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -D<br>第二种使用 rabbit_hosts 和 rabbit_ha_queues 配置项：</p>
<p>rabbit_hosts = rabbit1:5672,rabbit2:5672<br>rabbit_host = rabbit1<br>rabbit_ha_queues = true<br>如果配置了rabbit_hosts，那么nova将会按照顺序连接一个RabbitMQ服务，如果正在使用的MQ服务断开则依次尝试连接下一个，由于所有MQ的消息都是同步的，所以消息不会丢失。<br>如果配置了rabbit_host，那么需要在集群前架设haproxy，保证集群VIP服务正常。</p>
<p>confirm that actual queue is connected and can consume that queue.  </p>
<p>sudo rabbitmq-plugins enable rabbitmq_management<br>wget <a href="http://127.0.0.1:15672/cli/rabbitmqadmin" target="_blank" rel="external">http://127.0.0.1:15672/cli/rabbitmqadmin</a> &amp;&amp; chmod 777 rabbitmqadmi<br>sudo rabbitmqctl add_user test password<br>sudo rabbitmqctl set_user_tags test administrator<br>sudo rabbitmqctl set_permissions -p openstack test “.<em>“ “.</em>“ “.*”<br><a href="http://10.5.0.6:15672/#/queues/openstack/compute.juju-a09725-xenial-mitaka-7" target="_blank" rel="external">http://10.5.0.6:15672/#/queues/openstack/compute.juju-a09725-xenial-mitaka-7</a><br>./rabbitmqadmin publish -V openstack -u test -p password exchange=nova routing_key=compute.juju-a09725-xenial-mitaka-7 payload=”test”<br>tail -f /var/log/nova/nova-compute.log</p>
<p>具体地见：<a href="http://m.blog.csdn.net/blog/gtt116/21083533" target="_blank" rel="external">http://m.blog.csdn.net/blog/gtt116/21083533</a><br>Debug Hacks<br>$ tshark -r xxx.pcap |awk ‘{arr[$5]++}END{for (a in arr) print a, arr[a]}’ |sort -n -k 2 -r | head -n 3<br>10.55.74.103 62756<br>10.55.74.142 12976<br>10.55.74.139 12228<br>juju run -u rabbitmq-server/0 ‘sudo rabbitmqctl list_queues -p openstack|grep -wv 0’</p>
<p>watch -c “sudo rabbitmqctl list_queues -p openstack | grep -E ‘log|neutron|agent’”<br>Reset rabbitmq slave<br>1) On juju-3182a3-69-lxd-2, back mnesia, stop the service<br>$ sudo mv /var/lib/rabbitmq/mnesia /var/lib/rabbitmq/mnesia-back<br>$ sudo service rabbitmq-server stop<br>2) Forget the cluster nodes from the rabbit master node<br>$ sudo rabbitmqctl stop_app<br>$ sudo rabbitmqctl forget_cluster_node rabbit@juju-3182a3-69-lxd-2<br>$ sudo rabbitmqctl start_app<br>如何恢复systemd管理的native mirror rabbitmq cluster</p>
<p>如何恢复systemd管理的native mirror rabbitmq cluster<br>1, 确保在3个节点上，rabbitmq-server先由systemd启动(随后会由pacemaker接管)，这样能可能运行rabbitmqctl cluster_status命令．假设此时3个节点各自为政．<br>juju run –application=rabbitmq-server ‘sudo rabbitmqctl cluster_status’</p>
<p>2, juju status看有没有error状态，例如现在看到rabbitmq-server/1因为下列日志为error状态, rabbitmq-server/1上运行：<br><a href="https://www.jianshu.com/p/498c63e4ace1" target="_blank" rel="external">https://www.jianshu.com/p/498c63e4ace1</a><br><a href="https://ywnz.com/linuxyffq/3899.html" target="_blank" rel="external">https://ywnz.com/linuxyffq/3899.html</a><br>2020-02-21 09:24:09 DEBUG config-changed subprocess.CalledProcessError: Command ‘[‘timeout’, ‘180’, ‘/usr/sbin/rabbitmqctl’, ‘wait’, ‘/var/lib/rabbitmq/mnesia/rabbit@juju-cbd760-octavia-10.pid’]’ returned non-zero exit status 70.<br>systemctl restart rabbitmq-server<br>rabbitmqctl status |grep pid   #write pid to /var/lib/rabbitmq/mnesia/rabbit@juju-cbd760-octavia-10.pid<br>rabbitmqctl wait /var/lib/rabbitmq/mnesia/rabbit@juju-cbd760-octavia-10.pid<br>juju resolved rabbitmq-server/1 –no-retry<br>[可选]确保juju status没有rabbitmq untis相关错误之后，触发hooks<br>juju run –application ha hooks/config-changed<br>juju run –application rabbitmq-server hooks/ha-relation-joined<br>juju show-status-log neutron-openvswitch/2</p>
<p>3, 没有ceph的情况下，代码显示必须有ha-vip-only=true<br>juju deploy -n 3 rabbitmq-server<br>juju deploy hacluster ha<br>juju add-relation rabbitmq-server ha<br>juju config rabbitmq-server vip=10.5.100.20<br>juju config rabbitmq-server vip_iface=ens3<br>juju config ha corosync_bindiface=ens3<br>juju config rabbitmq-server ha-vip-only=true<br>juju config ha cluster_count=3<br>juju config rabbitmq-server min-cluster-size=3</p>
<p>4, 找到leader，假如leader是rabbitmq-server/1，并在其上找到cluster_name<br>juju run –application rabbitmq-server “is-leader”   #assue rabbitmq-server/1 is the leader<br>root@juju-cbd760-octavia-10:~# rabbitmqctl cluster_status |grep cluster<br> {cluster_name,<a href="&#x6d;&#97;&#105;&#108;&#x74;&#111;&#58;&#x3c;&#x22;&#114;&#97;&#98;&#98;&#x69;&#116;&#x6d;&#113;&#45;&#115;&#x65;&#114;&#118;&#101;&#x72;&#64;&#106;&#117;&#106;&#x75;&#45;&#99;&#98;&#x64;&#x37;&#x36;&#48;&#x2d;&#111;&#x63;&#x74;&#x61;&#118;&#105;&#97;&#45;&#x31;&#48;&#x22;">&#x3c;&#x22;&#114;&#97;&#98;&#98;&#x69;&#116;&#x6d;&#113;&#45;&#115;&#x65;&#114;&#118;&#101;&#x72;&#64;&#106;&#117;&#106;&#x75;&#45;&#99;&#98;&#x64;&#x37;&#x36;&#48;&#x2d;&#111;&#x63;&#x74;&#x61;&#118;&#105;&#97;&#45;&#x31;&#48;&#x22;</a>&gt;},</p>
<p>5, rabbitmq-server/1, 把RABBITMQ_NODENAME由localhost改成juju-cbd760-octavia-10<br>root@juju-cbd760-octavia-10:~# grep -r ‘RABBITMQ_NODENAME’ /etc/rabbitmq/rabbitmq-env.conf<br>RABBITMQ_NODENAME=rabbitmq-server@juju-cbd760-octavia-10<br>root@juju-cbd760-octavia-10:~# cat /var/lib/rabbitmq/.erlang.cookie<br>CZIFVOYCELFFGUFWJBZY<br>systemctl restart rabbitmq-server<br>rabbitmqctl cluster_status</p>
<p>但代码中有这一句会在ha-vip-only=false时将RABBITMQ_NODENAME设为localhost, 所以ha-vip-only应为ha-vip-only，<br>同时，这里也说对于rabbitmq的hacluster方式的ha已经废弃了<br><a href="https://github.com/openstack/charm-rabbitmq-server/blob/master/hooks/rabbitmq_context.py#L250" target="_blank" rel="external">https://github.com/openstack/charm-rabbitmq-server/blob/master/hooks/rabbitmq_context.py#L250</a></p>
<pre><code># TODO: this is legacy HA and should be removed since it is now
# deprecated.
if relation_ids(&apos;ha&apos;):
    if not config(&apos;ha-vip-only&apos;):
        # TODO: do we need to remove this setting if it already exists
        # and the above is false?
        context[&apos;settings&apos;][&apos;RABBITMQ_NODENAME&apos;] = \
            &apos;{}@localhost&apos;.format(service_name())
</code></pre><p>6, 登录到rabbitmq-server/0,　修改hostname并加入集群<br>root@juju-cbd760-octavia-9:~# grep -r ‘RABBITMQ_NODENAME’ /etc/rabbitmq/rabbitmq-env.conf<br>RABBITMQ_NODENAME=rabbitmq-server@juju-cbd760-octavia-9<br>systemctl restart rabbitmq-server<br>rabbitmqctl cluster_status<br>rabbitmqctl stop_app<br>rabbitmqctl reset<br>rabbitmqctl join_cluster rabbitmq-server@juju-cbd760-octavia-10<br>rabbitmqctl cluster_status</p>
<p>7, 登录到rabbitmq-server/2重复上一步，只是hostname不同, 这里为juju-cbd760-octavia-11</p>
<p>8, 此时．<br>root@juju-cbd760-octavia-10:~# rabbitmqctl cluster_status<br>Cluster status of node ‘rabbitmq-server@juju-cbd760-octavia-10’<br>[{nodes,[{disc,[‘rabbitmq-server@juju-cbd760-octavia-10’,<br>                ‘rabbitmq-server@juju-cbd760-octavia-11’,<br>                ‘rabbitmq-server@juju-cbd760-octavia-9’]}]},<br> {running_nodes,[‘rabbitmq-server@juju-cbd760-octavia-10’]},<br> {cluster_name,<a href="&#109;&#97;&#x69;&#x6c;&#x74;&#111;&#x3a;&#60;&#34;&#x72;&#x61;&#x62;&#98;&#105;&#116;&#x6d;&#113;&#45;&#115;&#101;&#114;&#x76;&#101;&#x72;&#x40;&#106;&#117;&#106;&#x75;&#x2d;&#99;&#x62;&#x64;&#55;&#54;&#48;&#45;&#x6f;&#99;&#116;&#x61;&#x76;&#105;&#x61;&#x2d;&#x31;&#x30;&#34;">&#60;&#34;&#x72;&#x61;&#x62;&#98;&#105;&#116;&#x6d;&#113;&#45;&#115;&#101;&#114;&#x76;&#101;&#x72;&#x40;&#106;&#117;&#106;&#x75;&#x2d;&#99;&#x62;&#x64;&#55;&#54;&#48;&#45;&#x6f;&#99;&#116;&#x61;&#x76;&#105;&#x61;&#x2d;&#x31;&#x30;&#34;</a>&gt;},<br> {partitions,[]},<br> {alarms,[{‘rabbitmq-server@juju-cbd760-octavia-10’,[]}]}]</p>
<p>9, 但上面修复只是systemd管理的native集群.<br>   如何被pacemaker管理呢？ 在rabbmitmq-server/1上(juju-cbd760-octavia-10)停掉systemd,启动corosync与packemaker，但前提是hacluster charm已经成功为corosync配置了res_rabbitmq_vip resources (当ha-vip-only=true时只有这一个）<br>   此时看到crm status没有res_rabbitmq_vip这个resource，</p>
<p>#juju run –application rabbitmq-server hooks/ha-relation-joined<br>juju run –application ha hooks/config-changed<br>juju run –unit ha/0 “sudo corosync-quorumtool -s”<br>juju run –unit ha/0 “sudo crm status”<br>juju run –unit ha/0 “sudo crm resource restart res_rabbitmq_vip”<br>juju run –unit ha/0 “sudo crm resource clean res_rabbitmq_vip”</p>
<p>#<a href="https://github.com/ClusterLabs/resource-agents/blob/master/heartbeat/rabbitmq-cluster" target="_blank" rel="external">https://github.com/ClusterLabs/resource-agents/blob/master/heartbeat/rabbitmq-cluster</a><br>ls /usr/lib/ocf/resource.d/rabbitmq/rabbitmq-server-ha<br>　　　若运行上面hook无法加入res_rabbitmq_vip的话，检查代码是应该设置ha-vip-only=true，然后使用下面方法添加:<br>juju remove-relation rabbitmq-server ha<br>juju add-relation rabbitmq-server ha<br>      然后可以看到：<br>root@juju-cbd760-octavia-11:~# crm status |grep vip<br> res_rabbitmq_vip       (ocf::heartbeat:IPaddr2):       Started juju-cbd760-octavia-10<br>     但是仍然看到这种错误：<br>ubuntu@zhhuabj-bastion:~$ juju status |grep waiting<br>rabbitmq-server             3.6.10   waiting      3  rabbitmq-server             jujucharms  358  ubuntu<br>rabbitmq-server/0                waiting   idle   9        10.5.0.35       5672/tcp                    Unit has peers, but RabbitMQ not clustered<br>rabbitmq-server/1*               waiting   idle   10       10.5.0.32       5672/tcp                    Unit has peers, but RabbitMQ not clustered<br>rabbitmq-server/2                waiting   idle   11       10.5.0.28       5672/tcp                    Unit has peers, but RabbitMQ not clustered</p>
<p>10, 继续调试, ha relation的数目不对，所以停在’ Unit has peers, but RabbitMQ not clustered’<br>ubuntu@zhhuabj-bastion:~$ juju run –unit rabbitmq-server/0 “relation-ids ha”<br>ha:41<br>ubuntu@zhhuabj-bastion:~$ juju run –unit rabbitmq-server/0 “relation-list -r ha:41”<br>ha/3   #because hacluster was named to ha so name is ha/3 now<br>ubuntu@zhhuabj-bastion:~$ juju run –unit rabbitmq-server/0 “relation-get -r ha:41 - ha/3”<br>clustered: “yes”<br>egress-subnets: 10.5.0.35/32<br>ingress-address: 10.5.0.35<br>private-address: 10.5.0.35</p>
<p>它在找rabbitmqctl cluster_status中为running_nodes的个数<br> 828 @cached<br> 829 def clustered():<br> 830     ‘’’ Determine whether local rabbitmq-server is clustered ‘’’<br> 831     # NOTE: A rabbitmq node can only join a cluster once.<br> 832     # Simply checking for more than one running node tells us<br> 833     # if this unit is in a cluster.<br> 834     if len(running_nodes()) &gt; 1:<br> 835         return True<br> 836     else:<br> 837         return False</p>
<p> 787 @cached<br> 788 def running_nodes():<br> 789     ‘’’ Determine the current set of running nodes in the RabbitMQ cluster ‘’’<br> 790     return nodes(get_running=True)</p>
<p> 770 @cached<br> 771 def nodes(get_running=False):<br> 772     ‘’’ Get list of nodes registered in the RabbitMQ cluster ‘’’<br> 773     out = rabbitmqctl_normalized_output(‘cluster_status’)<br> 774     cluster_status = {}<br> 775     for m in re.finditer(“{([^,]+),(?![{)[([^]]*)”, out):<br> 776         state = m.group(1)<br> 777         items = m.group(2).split(‘,’)<br> 778         items = [x.replace(“‘“, ‘’).strip() for x in items]<br> 779         cluster_status.update({state: items})<br> 780<br> 781     if get_running:<br> 782         return cluster_status.get(‘running_nodes’, [])<br> 783<br> 784     return cluster_status.get(‘disc’, []) + cluster_status.get(‘ram’, [])<br>Fix a rabbitmq issue<br><a href="https://zhhuabj.blog.csdn.net/article/details/105847301" target="_blank" rel="external">https://zhhuabj.blog.csdn.net/article/details/105847301</a></p>
<p>Reference<br>[1] <a href="https://gist.github.com/niedbalski/69a72103adad4f0f9609a0857c9810a4" target="_blank" rel="external">https://gist.github.com/niedbalski/69a72103adad4f0f9609a0857c9810a4</a></p>
<p>[2] <a href="https://pastebin.ubuntu.com/p/sJ94RmmS5x/" target="_blank" rel="external">https://pastebin.ubuntu.com/p/sJ94RmmS5x/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/12/Fix-a-rabbitmq-issue/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/12/Fix-a-rabbitmq-issue/" itemprop="url">Fix a rabbitmq issue</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-12-12T12:00:58+08:00">
                2020-12-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>问题</strong><br>rabbitmq cluster的3个节点挂了. 3个节点是lxd容器:<br>11-lxd-8<br>69-lxd-2<br>9-lxd-9<br><strong>初步sosreport分析</strong><br>11-lxd-8上看到system_limit错误<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">=ERROR REPORT==== 17-Apr-2020::13:19:44 ===</span><br><span class="line">Too many processes</span><br><span class="line">=ERROR REPORT==== 17-Apr-2020::13:19:44 ===</span><br><span class="line">Ranch listener &#123;acceptor,&#123;0,0,0,0,0,0,0,0&#125;,5672&#125; connection process start failure; rabbit_connection_sup:start_link/4 crashed with reason: error:system_limit</span><br></pre></td></tr></table></figure></p>
<p>但是已经设置了LimitNOFILE<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ grep -r &apos;Limit&apos; lib/systemd/system/rabbitmq-server.service</span><br><span class="line">LimitNOFILE=65536</span><br></pre></td></tr></table></figure></p>
<p>不过LimitNOFILE似乎是管file_descriptors的, 而不是erlang processes的.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;file_descriptors,     [&#123;total_limit,65436&#125;,      &#123;total_used,6415&#125;,      &#123;sockets_limit,58890&#125;,      &#123;sockets_used,6413&#125;]&#125;,</span><br><span class="line">16:28:22  &#123;processes,[&#123;limit,1048576&#125;,&#123;used,118304&#125;]&#125;,</span><br></pre></td></tr></table></figure></p>
<p>上面的输出显示似乎用了118304个erlang processes还未超出limit. 不过, 这可能是重启机器之后抓的sosreport. 并且limit已经很大, 单纯增加limit似乎也并不是正道. 所以继续寻找线索.</p>
<p>在69-lxd-2里也看到了’Error while waiting for Mnesia tables’这种错误, 似乎是Mnesia数据库未同步.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">var/log/rabbitmq/rabbit@juju-3182a3-69-lxd-2.log.1</span><br><span class="line">=INFO REPORT==== 17-Apr-2020::13:27:26 ===</span><br><span class="line">Waiting for Mnesia tables for 30000 ms, 9 retries left</span><br><span class="line">=WARNING REPORT==== 17-Apr-2020::13:27:56 ===</span><br><span class="line">Error while waiting for Mnesia tables: &#123;timeout_waiting_for_tables,</span><br><span class="line">[rabbit_user,rabbit_user_permission,</span><br><span class="line">rabbit_vhost,rabbit_durable_route,</span><br><span class="line">rabbit_durable_exchange,</span><br><span class="line">rabbit_runtime_parameters,</span><br><span class="line">rabbit_durable_queue]&#125;</span><br></pre></td></tr></table></figure></p>
<p>3个units上用’netstat -s’看到大量的reset tcp<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sos_commands/networking/netstat_-s |head -n2</span><br><span class="line">7154216 connection resets received</span><br><span class="line">34025359 resets sent</span><br></pre></td></tr></table></figure></p>
<h2 id="深入分析"><a href="#深入分析" class="headerlink" title="深入分析"></a>深入分析</h2><p>9-lxd-9上 通过下列命令看到各个openstack组件上都有到9-lxd-9的rabbitmq tcp连接, 一个组件就有约四五百个连接, 是不是多了一点? 其他两个units没这么多.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat sos_commands/networking/netstat_-W_-neopa| awk &apos;/:5672/ &#123; print $5 &#125;&apos; | awk -F: &apos;&#123; a[$1]++ &#125;; END &#123; for (i in a) print i, a[i] &#125;&apos; |sort -n -k 2 -r |more |head -n 80</span><br></pre></td></tr></table></figure></p>
<p>但一个组件就有四五百个连接, 每个组件都这么多, 不可能每个组件都有问题吧. 除了大量tcp连接可以造成容器cpu升高, host机器的cpu升高也可以造成容器cpu升高的吧. 所以接着检查host机器的cpu占用率:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cat sos_commands/process/ps_auxwww |head -n 1</span><br><span class="line">USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND</span><br><span class="line">$ cat sos_commands/process/ps_auxwww |head -n1 &amp;&amp; cat sos_commands/process/ps_auxwww |sort -n -k3 -r | head -n 3</span><br><span class="line">USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND</span><br><span class="line">nova 1936435 130 0.0 347704 126140 ? Rs 11:40 0:01 /usr/bin/python2 /usr/bin/nova-api-metadata --config-file=/etc/nova/nova.conf --log-file=/var/log/nova/nova-api-metadata.log</span><br><span class="line">libvirt+ 1809025 100 0.0 51373088 236744 ? Sl Mar09 56456:32 qemu-system-x86_64 -enable-kvm -name guest=instance-000099e0,debug-threads=on -S -object secret,id=masterKey0,format=raw,file=/var/lib/libvirt/qemu/domain-26-instance-000099e0/master-key.aes -machine pc-i440fx-</span><br></pre></td></tr></table></figure></p>
<p>ok, 虚机占用cpu就是100%. 看样子是控制服务(rabbitmq)与计算服务(nova-compute)安装到同一台物理机了, 虚机占用的cpu或者内存大页什么的直接导致rabbitmq cluster挂掉.<br>注:<br>ps命令中第三列相加的cpu大于100%也不一定就意味着cpu一定高, 因为可以这些进程全跑在一个cpu核的, 它可能计算的是一个核的, 要想准确还得使用mpstat来查看</p>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><p>调整架构是不可能了, 可以暂时使用isolcpu隔离一些cpu单独通过taskset给rabbitmq使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mpstat -P ALL 能看到所有cpu核的负载情况</span><br><span class="line">cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq</span><br><span class="line">grub中添加isolcpus=1,3来隔离1和3的cpu待用, 然后运行update-grub后重启, 验证:</span><br><span class="line">1, cat /proc/cmdline |grep isolcpu</span><br><span class="line">2, ps -To &apos;pid,lwp,psr,cmd&apos; -p 310597</span><br><span class="line">3, ps -eo pid,cmd,psr |awk &apos;&#123;if($3=3) print $0&#125;&apos;</span><br><span class="line">taskset -p0x8 &lt;pid&gt;绑定&lt;pid&gt;到cpu3</span><br><span class="line">taskset -c 1 /etc/init.d/mysql start</span><br><span class="line">systemd manages the affinity for you. See &quot;man systemd.exec&quot; and CPUAffinity= option.</span><br></pre></td></tr></table></figure></p>
<h2 id="20201212更新-queue-master-locator-min-master"><a href="#20201212更新-queue-master-locator-min-master" class="headerlink" title="20201212更新 - queue_master_locator=min-master"></a>20201212更新 - queue_master_locator=min-master</h2><p>我们可能需要配置queue_master_locator=min-master - <a href="https://bugs.launchpad.net/charm-rabbitmq-server/+bug/1890759" target="_blank" rel="external">https://bugs.launchpad.net/charm-rabbitmq-server/+bug/1890759</a>, 进而可能造成这两个bug (控制平面居然影响了数据面） - <a href="https://bugs.launchpad.net/neutron/+bug/1871850" target="_blank" rel="external">https://bugs.launchpad.net/neutron/+bug/1871850</a><br><a href="https://bugs.launchpad.net/neutron/+bug/1869808" target="_blank" rel="external">https://bugs.launchpad.net/neutron/+bug/1869808</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Queue masters are mostly on 11-lxd-8</span><br><span class="line">&gt; cat rabbitmqctl_report | awk -F&apos;\t&apos; &apos;/^Queues on openstack/ &#123;a=1&#125;; a &amp;&amp; /rabbit/ &#123;split($1,s,&quot;.&quot;); b[s[1]]++&#125;; NF==0 &#123;a=0&#125;; END &#123;for(i in b) &#123;print i, b[i]&#125;&#125;&apos;</span><br><span class="line">&lt;rabbit@juju-0aa49a-9-lxd-9 15</span><br><span class="line">&lt;rabbit@juju-0aa49a-11-lxd-8 15426</span><br><span class="line">&lt;rabbit@juju-0aa49a-10-lxd-8 309</span><br><span class="line"></span><br><span class="line"># Most connections are made to 11-lxd-8</span><br><span class="line">&gt; cat rabbitmqctl_report| awk -F&apos;\t&apos; &apos;/^Connections/ &#123;a=1&#125;; a &amp;&amp; /rabbit/ &#123;split($1,s,&quot;.&quot;); b[s[1]]++&#125;; NF==0 &#123;a=0&#125;; END &#123;for(i in b) &#123;print i, b[i]&#125;&#125;&apos;</span><br><span class="line">&lt;rabbit@juju-0aa49a-9-lxd-9 8763</span><br><span class="line">&lt;rabbit@juju-0aa49a-11-lxd-8 14843</span><br><span class="line">&lt;rabbit@juju-0aa49a-10-lxd-8 6413</span><br><span class="line"></span><br><span class="line"># 11-lxd-8 uses the most memory</span><br><span class="line">&gt; cat rabbitmqctl_report| awk &apos;/^Status/ &#123;a=1; print&#125;; a &amp;&amp; /total,/; !NF &#123;a=0&#125;&apos;</span><br><span class="line">Status of node &apos;rabbit@juju-0aa49a-10-lxd-8&apos;</span><br><span class="line">     [&#123;total,3536412448&#125;,</span><br><span class="line">Status of node &apos;rabbit@juju-0aa49a-11-lxd-8&apos;</span><br><span class="line">     [&#123;total,7030459176&#125;,</span><br><span class="line">Status of node &apos;rabbit@juju-0aa49a-9-lxd-9&apos;</span><br><span class="line">     [&#123;total,4256377400&#125;,</span><br></pre></td></tr></table></figure></p>
<p>crontab检查rabbitmq memory使用率:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># process_memory_checker.sh</span><br><span class="line">MAILTO=root</span><br><span class="line">process=&quot;bin/beam.smp&quot;</span><br><span class="line">mem_percentage=`ps -o %mem,command ax | grep &quot;$&#123;process&#125;&quot; | grep -v grep | awk &apos;&#123;print $1&#125;&apos;`</span><br><span class="line">threshold_percentage=25</span><br><span class="line">if (( $(echo &quot;$&#123;mem_percentage&#125; &gt; $&#123;threshold_percentage&#125;&quot;|bc -l) ));</span><br><span class="line">then</span><br><span class="line">	echo &quot;Process $&#123;process&#125; on `hostname -f` is using $&#123;mem_percentage&#125;% of total memory (threshold is $&#123;threshold_percentage&#125;%).&quot; | \</span><br><span class="line">	mail -s &quot;Memory usage warning for process $&#123;process&#125; on $(hostname -s)&quot; $&#123;MAILTO&#125; 2&gt; /dev/null;</span><br><span class="line">	exit 1;</span><br><span class="line">fi</span><br><span class="line">echo &quot;No memory issues found for process $&#123;process&#125;&quot;</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure></p>
<p>另外，客户发现memory用到超过vm_memory_high_watermark_paging_ratio (<a href="https://www.rabbitmq.com/memory.html#paging" target="_blank" rel="external">https://www.rabbitmq.com/memory.html#paging</a> )时似乎memory也没有被page到硬盘造成memory一直在增大，这个网页（<a href="https://stackoverflow.com/questions/21666537/rabbitmq-memory-control-queue-is-full-and-is-not-paging-connection-hangs）说对“durable=true”queue才生效。" target="_blank" rel="external">https://stackoverflow.com/questions/21666537/rabbitmq-memory-control-queue-is-full-and-is-not-paging-connection-hangs）说对“durable=true”queue才生效。</a><br>“rabbitmqctl list_queues name  durable -p openstack”看到的durable都是false, 难道是在设置各组件的olso设置为(charm似乎不支持）amqp_durable_queues=True吗?<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[oslo_messaging_rabbit]</span><br><span class="line">amqp_durable_queues = True</span><br></pre></td></tr></table></figure></p>
<p>但这个patch说上面配置被废弃了 - <a href="https://bugs.launchpad.net/oslo.messaging/+bug/1433956" target="_blank" rel="external">https://bugs.launchpad.net/oslo.messaging/+bug/1433956</a>, 但master code中有这个配置，还没细查。另外，这个网页（<a href="https://elkano.org/blog/high-availability-rabbitmq-cluster-openstack/）说用这个配置：" target="_blank" rel="external">https://elkano.org/blog/high-availability-rabbitmq-cluster-openstack/）说用这个配置：</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[oslo_messaging_rabbit]</span><br><span class="line">rabbit_hosts=node1:5672,node2:5672,node3:5672</span><br><span class="line">rabbit_retry_interval=1</span><br><span class="line">rabbit_retry_backoff=2</span><br><span class="line">rabbit_max_retries=0</span><br><span class="line">rabbit_ha_queues=true</span><br><span class="line">rabbit_userid = openstack</span><br><span class="line">rabbit_password = openstack_pass</span><br><span class="line">amqp_auto_delete = true</span><br><span class="line">amqp_durable_queues=True</span><br></pre></td></tr></table></figure></p>
<p>charm ./charmhelpers/contrib/openstack/templates/section-rabbitmq-oslo 中有下面代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> 8 &#123;% if rabbitmq_ha_queues -%&#125;</span><br><span class="line"> 9 rabbit_ha_queues = True</span><br><span class="line">10 rabbit_durable_queues = False</span><br><span class="line">11 &#123;% endif -%&#125;</span><br></pre></td></tr></table></figure></p>
<p>其他debug手段:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo rabbitmqctl -p openstack list_queues|grep -vw 0</span><br><span class="line"></span><br><span class="line"># returns a list with info about memory dynamically allocated by the Erlang emulator</span><br><span class="line">rabbitmqctl eval &apos;erlang:memory().&apos;</span><br><span class="line">rabbitmq-diagnostics memory_breakdown  #for new version</span><br></pre></td></tr></table></figure></p>
<p>内存使用量一直突然增长可能是这个错误造成的， 详见：<a href="https://bugs.launchpad.net/oslo.messaging/+bug/1789177" target="_blank" rel="external">https://bugs.launchpad.net/oslo.messaging/+bug/1789177</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ grep -r &apos;no exchange&apos; var/log/rabbitmq/rabbit@juju-0aa49a-10-lxd-8.log |wc -l</span><br><span class="line">3511</span><br><span class="line">$ grep -r &apos;no exchange&apos; var/log/rabbitmq/rabbit@juju-0aa49a-10-lxd-8.log |head -n1</span><br><span class="line">operation basic.publish caused a channel exception not_found: no exchange &apos;reply_bee2ebfe01854e0595ddaa7462dc4054&apos; in vhost &apos;openstack&apos;</span><br></pre></td></tr></table></figure></p>
<p>这是关于rabbitm HA一个非常好的贴子（<a href="https://blog.csdn.net/zyz511919766/article/details/41896823" target="_blank" rel="external">https://blog.csdn.net/zyz511919766/article/details/41896823</a>), 也就是说，在rabbitmq non-ha中，exchange与 bindings也是在所在节点上的，而queue只处于一个节点。在rabbitmq ha环境中，只是将queue也根据policy放置在所有或某些节点上。当consumer从rabbitmq的某个节点消费queue时，consumer死掉了，consumer创建的reply-xxx queues也会被删掉但此时可能consumer没有收到basic cancel signal（eg：当reply-xxx被删后刚好consumer在重启）, 这样，consumer没ack消息这样server还会继续给consumer发, 但此时就会报no exchange (exchange与reply-xxx queue都是consumer创建的，reply-xxx queue为0时exchange也会被删除）。<br>但是，有一点没闹明白，consumer重启之后不是会调用 reconnect继续重建exchange与reploy-xxx queue么？不过在重建之前，server会继续发， 这段期间就会有no exchange错误吧，这样会耗费大量的cpu，这样或许也是cpu升级的原因 （Lots of exchanges create problems during failover under high load）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ grep -r &apos;^reply_&apos; sos_commands/rabbitmq/rabbitmqctl_report |grep exchange |head -n1</span><br><span class="line">reply_0003bee270e54c8cb9b78ba3b51ba4e2  exchange        reply_0003bee270e54c8cb9b78ba3b51ba4e2  queue   reply_0003bee270e54c8cb9b78ba3b51ba4e2  []      openstack</span><br><span class="line">$ grep -r &apos;^reply_&apos; sos_commands/rabbitmq/rabbitmqctl_report |grep exchange |wc -l</span><br><span class="line">24991</span><br></pre></td></tr></table></figure></p>
<p>24991肯定会造成memory一直升高，所以一个最好办法就是设置x-cancel-on-ha-failover让queue没了时也取消consumer。另一个办法是也可以哪出哪些consumer在作怪.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cat sos_commands/networking/netstat_-W_-neopa| awk &apos;/:5672/ &#123; print $5 &#125;&apos; | awk -F: &apos;&#123; a[$1]++ &#125;; END &#123; for (i in a) print i, a[i] &#125;&apos; |sort -n -k 2 -r |more |head -n 3</span><br><span class="line">10.160.0.106 96</span><br><span class="line">10.160.0.208 86</span><br><span class="line">10.160.0.75 83</span><br></pre></td></tr></table></figure></p>
<p>也可以用下面的policy缓解:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#rabbitmqctl set_policy min-masters-queue -p openstack &apos;.*&apos; &apos;&#123;&quot;queue-master-locator&quot;:&quot;min-masters&quot;&#125;&apos; --apply-to queues --priority 10</span><br><span class="line">rabbitmqctl set_policy HA -p openstack &apos;^(?!amq\\.).*&apos; &apos;&#123;&quot;queue-master-locator&quot;:&quot;min-masters&quot;, &quot;ha-mode&quot;:&quot;all&quot;, &quot;ha-sync-mode&quot;:&quot;automatic&quot;&#125;&apos;</span><br></pre></td></tr></table></figure></p>
<p>但是exchange只是记录的一个名称，是不占用内存的，queues可能会占用内存。但30481个queue也就1.2G左右，也不大啊。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat rabbitmq_report.txt |gawk -F&apos;\t&apos; &apos;/^Queues on openstack/ &#123;a=1;next&#125;; a &amp;&amp; NF &#123;mem+=$17; n+=1&#125;; !NF &#123;a=0&#125; END &#123;print n, mem&#125;&apos;</span><br><span class="line">30481 1248040000</span><br></pre></td></tr></table></figure></p>
<p>相较，rabbitmqctl status显示queue_procs与queue_slave_procs占用的内存更大, queue_procs占了约199G. 队列占用的内存指的是队列进程消耗的，并不包含消息体（在二进制中）。当内存不足时，这部分的内存将交换到磁盘上。</p>
<ul>
<li>queue_procs：主队列，索引和消息保存在内存中。排队的消息数量越多，通常会将此内容归因于此部分。但是，这在很大程度上取决于队列属性以及消息是否作为瞬态发布</li>
<li>queue_slave_procs：队列镜像，索引和消息保存在内存中。减少镜像（副本）的数量或不使用固有的瞬态数据镜像队列可以减少镜像使用的RAM量。排队的消息数量越多，通常会将此内容归因于此部分。但是，这在很大程度上取决于队列属性以及消息是否作为瞬态发布。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;queue_procs,199051279736&#125;,</span><br><span class="line">&#123;queue_slave_procs,1243762680&#125;,</span><br></pre></td></tr></table></figure>
<p>这个网页（<a href="https://www.rabbitmq.com/monitoring.html#diagnostics-observer）提到&#39;rabbitmq-diagnostics" target="_blank" rel="external">https://www.rabbitmq.com/monitoring.html#diagnostics-observer）提到&#39;rabbitmq-diagnostics</a> observer’命令可以像top一样查看erlang虚拟机内进程的内存使用量，但rabbitmq-server 3.8版本才支持啊。那perf是否可以查看erlang虚机机内进程的call trace呢？但这篇文章说了怎么查erlang下的进程所用内存：<br>RabbitMQ及Erlang内存使用分析 - <a href="https://blog.csdn.net/jaredcoding/article/details/78115235" target="_blank" rel="external">https://blog.csdn.net/jaredcoding/article/details/78115235</a><br>RabbitMQ运维经验分享 - <a href="https://my.oschina.net/hackandhike/blog/801052" target="_blank" rel="external">https://my.oschina.net/hackandhike/blog/801052</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rabbitmqctl status #single node status</span><br><span class="line">rabbitmqctl report #cluster status</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/27/Shell编程注意点/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/27/Shell编程注意点/" itemprop="url">Shell编程注意点</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-27T09:53:02+08:00">
                2020-11-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华 写于：发表于：2011-04-06<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</p>
<p>1在shell脚本中调用另一个脚本的三种不同方式(fork,exec, source)<br>       我们先谈谈在shell脚本中调用另一个脚本的三种不同方式的区别（fork,exec, source )</p>
<p>fork ( /directory/script.sh ), fork是最普通的,就是直接在脚本里面用/directory/script.sh来调用script.sh这个脚本.运行的时候开一个sub-shell执行调用的脚本，sub-shell执行的时候,parent-shell还在。sub-shell执行完毕后返回parent-shell.sub-shell从parent-shell继承环境变量.但是sub-shell中的环境变量不会带回parent-shell</p>
<p>exec(exec /directory/script.sh) exec与fork不同，不需要新开一个sub-shell来执行被调用的脚本. 被调用的脚本与父脚本在同一个shell内执行。但是使用exec调用一个新脚本以后,父脚本中exec行之后的内容就不会再执行了。这是exec和source的区别</p>
<p>source(source/directory/script.sh)与fork的区别是不新开一个sub-shell来执行被调用的脚本，而是在同一个shell中执行.所以被调用的脚本中声明的变量和环境变量,都可以在主脚本中得到和使用.</p>
<p>可以通过下面这两个脚本来体会三种调用方式的不同:</p>
<p>1.sh </p>
<p>#!/bin/bash<br>A=B<br>echo “PID for 1.sh before exec/source/fork:$$”<br>exportA<br>echo “1.sh: /$A is $A”<br>case $1 in<br>       exec)<br>               echo “using exec…”<br>               exec ./2.sh ;;<br>       source)<br>               echo “using source…”<br>               ../2.sh ;;<br>        *)<br>               echo”using fork by default…”<br>               ./2.sh ;;<br>esac<br>echo”PID for 1.sh after exec/source/fork:$$”<br>echo “1.sh:/$A is $A”<br>2.sh </p>
<p>#!/bin/bash<br>echo”PID for 2.sh: $$”<br>echo “2.sh get /$A=$A from1.sh”<br>A=C<br>export A<br>echo “2.sh: /$A is $A”</p>
<p>执行情况：<br>$./1.sh<br>PID for 1.sh beforeexec/source/fork:5845364<br>1.sh: $A is B<br>using fork bydefault…<br>PID for 2.sh: 5242940<br>2.sh get $A=B from 1.sh<br>2.sh:$A is C<br>PID for 1.sh after exec/source/fork:5845364<br>1.sh: $A isB<br>$ ./1.sh exec<br>PID for 1.sh beforeexec/source/fork:5562668<br>1.sh: $A is B<br>using exec…<br>PID for2.sh: 5562668<br>2.sh get $A=B from 1.sh<br>2.sh: $A is C<br>$./1.sh source<br>PID for 1.sh beforeexec/source/fork:5156894<br>1.sh: $A is B<br>using source…<br>PIDfor 2.sh: 5156894<br>2.sh get $A=B from 1.sh<br>2.sh: $A is C<br>PIDfor 1.sh after exec/source/fork:5156894<br>1.sh: $A is C<br>$<br>2函数调用<br>先看一个例子，执行mysql的函数mysqlExec,如下：</p>
<p>source“mysql.conf”</p>
<p>mysqlExec(){<br>sql=$1<br>sqlOp=<code>echo${sql:0:6}| tr A-Z a-z</code><br>if[ “$sqlOp” != “select” ]; then<br>  sql=$sql”;select row_count();”<br>fi</p>
<p>#use different mysql command depends on the password</p>
<p>if[ -z $MYSQL_PASSWORD ]<br>then<br>  $mysql $MYSQL_DATABASE -h$MYSQL_HOSTNAME -u$MYSQL_USERNAME -se “${sql};”<br>else<br>  $mysql $MYSQL_DATABASE -h$MYSQL_HOSTNAME -u$MYSQL_USERNAME -p$MYSQL_PASSWORD-se “${sql};”<br>fi<br>status=$?<br>if[ $status -eq 0 ]; then<br>  if[ “$sqlOp” != “select” ]; then<br>    log “OK $sql”<br>  fi<br>else<br>  log “Occur DB Error, can retry in 3 seconds later -&gt; $sql”<br>  sleep3<br>  echo “DB_ERROR”<br>fi<br>return $status<br>exit<br>}</p>
<p>函数调用要注意两点：<br>1）函数中可以用echo,如上面的echo “DB_ERROR”，在调用时要获取echo的值，应该这样:<br>campaign=<code>mysqlExec&quot;$sql&quot;</code><br>if[ “x$campaign” == “x” -o “$campaign” ==”DB_ERROR” ]; then<br>continue<br>fi<br>2)函数中也可以有返回值，如上面的return $status，在调用时应该通过$?获得，如：<br>if[ $? -eq 0 ]; then<br>echo“zhanghua”<br>fi</p>
<p>3) 如果想从被调用的函数处返回一个值，可以这样</p>
<p>   调用gen_conf函数，传一个引用（注意不是变量）config_file进去， gen_conf $host config_file</p>
<p>   在gen_conf函数中通过__resultvar变量返回值:</p>
<p>   gen_config{</p>
<pre><code> local  __resultvar=$2
eval $__resultvar=&quot;&apos;$config&apos;&quot;
</code></pre><p>   }</p>
<p>3shell中的要用局部变量很纠结<br>你会看到shell有一个非常大的缺点，就是它在函数调用时，没有局部变量与全局变量之分，如A脚本调用B脚本中的一个函数，在B脚本内部有一个变量vari（你可能受JAVA影响认为它是局部变量那就大错特错了），如果A脚本中也有这个名为vari的变量，那么在函数返回时，B脚本的那个vari变量会将A脚本的vari变量覆盖，举个例子：<br>updateWithOptimisticLock(){<br>rand=$1<br>campaignId=$2<br>seq=1<br>updateVal=-1<br>status=1<br>while[ true ]; do<br>if[ $seq -gt 3 ]; then<br>log”FATAL ERROR, Update num error, $updatesql”<br>break<br>fi<br>cur=<code>queryCur&quot;$campaignId&quot;</code><br>if[ “$cur” == “DB_ERROR” ]; then<br>continue<br>fi<br>updateVal=$(($cur+$rand))<br>if[ “$rand” == “0” ]; then<br>break<br>fi<br>updatesql=”updatet<em>campaign</em> set num=$updateVal where campaign<em>id=$campaignId andnum=$cur”<br>affectRows=<code>mysqlExec&quot;$updatesql&quot;</code><br>if[ “$affectRows” == “1” ]; then<br>status=0<br>break<br>fi<br>seq=$(($seq+1))<br>done<br>echo$updateVal<br>return$status<br>}<br>调用的伪码如下，这时里面的seq变量会被上述updateWithOptimisticLock函数中的变量seq给覆盖，所以在shell中没有局部变量一说<br>seq=1<br>while[ $seq -le $cycleNum ]; do<br>updateFakeNumWithOptimisticLock$rand $campaignId<br>done<br>4使用xargs来传参数<br>在shell中的管道符|很强大，可以将前一条命令的标准输出作为下一条命令的标准输入，但是如果下一条命令不是标准输入而是需要传参的话，那怎么办呢，用xargs即可，例如下列shell中xargs命令的-i选项告诉xargs用前一条命令的标准输出去替换{}。<br>find. | xargs zgrep “<url>/Search?” | sed’s/.*q=/([-</url></em><em>()~.%+0-9A-Za-z]</em>/).*//1/‘ | sort -nr | uniq -c | sort-nr | head -1000 | xargs -i php -r “echorawurldecode(‘{}’)./“/n/“;” &gt; result.out &amp;</p>
<p>另， 修改/etc/hosts, 能处理127或localhost打头的多个hostname项如(ubuntu.me.com  ubuntu)， 用‘/usr/bin/awk ‘$1 ~ /^127|localhost/ {print $0}’ /etc/hosts’是为了避免IPv6 中的node如ff02::1 ip6-allnodes</p>
<p>/usr/bin/awk ‘$1 ~ /^127|localhost/ {print $0}’ /etc/hosts |awk ‘$1 ~ /^127|localhost/ {print $0}’ | /bin/sed “s/\s<em>(${CURRENT_HOSTNAME})(\s</em>)/\t${NETCFG_HOSTNAME}/g”</p>
<p>当然exec也可以实现上述功能，只是exec都是一次性读入内存容易内存溢出，如：<br>find. -name “<em>.m4” -exec grep –color -H “catalina”{} /;<br>5shell中的sed命令使用的正则是缩水版<br>shell中的sed命令使用的正则引擎和我们java中平常所用正则引擎并不一样，功能比较弱。<br>如上节中的|sed ‘s/.</em>q=/([-_<em>()~.%+0-9A-Za-z]</em>/)，就是因为shell的很多正则不支持，才在使用sed命令时用了那么多枚举。</p>
<p>20191115更新</p>
<p>上面说法不正确, sed可以加-r参数不用枚举, 例:</p>
<p>grep -r ‘get_or_set_cached_cell_and_set_connections’ var/log/nova/ |sed -r ‘s/.+(waited|held) (.+) inner.+/\2/g;t;d’ |sort -nr |head -n 5</p>
<p>nova service-list –bi nova-compute | grep nova-compute | cut -d ‘ ‘ -f 4 | xargs -n 1 -I {} ssh -o StrictHostKeyChecking=no  ubuntu@{} “date; hostname; zgrep MessagingTimeout /var/log/nova/nova-compute.log*; echo -e ‘—————————–\n’”</p>
<p>数组</p>
<p>readarray -t cookies&lt;&lt;&lt;”<code>ls -1 /var/snap/ovs-stat/common/tmp/tmp.662kJWxfEg/juju-4f585d-sf00272961-cisco-7/ovs/bridges/br-int/flowinfo/cookies/| grep -v 6cc04af0837d3b42</code>“<br>for c in ${cookies[@]}; do grep -rl $c /var/snap/ovs-stat/common/tmp/tmp.662kJWxfEg/juju-4f585d-sf00272961-cisco-7/ovs/bridges/br-int/flowinfo/tables; done| sort| uniq -c</p>
<p>svcs=(<br>nova-compute-kvm<br>neutron-openvswitch<br>)<br>for svc in ${svcs[@]}; do<br>juju config $svc worker-multiplier<br>done</p>
<p>排序相加</p>
<p>cat ps.txt | sed ‘s/.<em>](.</em>)/\1/g’ | column -t | body sort -n -k4 -r<br>uid     tgid     total_vm  rss      pgtables_bytes  swapents  oom_score_adj  name<br>100112  832785   5760963   1650592  16789504        76362     0              beam.smp</p>
<p>cat ps.txt | sed ‘s/.<em>](.</em>)/\1/g’ | column -t | body sort -n -k4 -r | awk ‘{sum+=$4;} END{print sum;}’</p>
<p>rabbitmq相序相加举例</p>
<p>$ cat sos<em>commands/networking/netstat</em>-W_-neopa |head -n1<br>Proto Recv-Q Send-Q Local Address           Foreign Address         State       User       Inode      PID/Program name     Timer<br>tcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      101        1671174047 178/systemd-resolve  off (0.00/0/0)</p>
<p>$ cat sos<em>commands/networking/netstat</em>-W_-neopa| awk ‘/:5672/ { print $5 }’ | awk -F: ‘{ a[$1]++ }; END { for (i in a) print i, a[i] }’ |sort -n -k 2 -r |more |head -n 10<br>10.164.0.107 69</p>
<p>实例 - 抓取</p>
<p>#!/bin/bash</p>
<h1 id="Usage-nohup-proxychains4-crawl-sh-gt-log-txt-2-gt-1-amp"><a href="#Usage-nohup-proxychains4-crawl-sh-gt-log-txt-2-gt-1-amp" class="headerlink" title="Usage: nohup proxychains4 ./crawl.sh &gt; log.txt 2&gt;1&amp;"></a>Usage: nohup proxychains4 ./crawl.sh &gt; log.txt 2&gt;1&amp;</h1><p>#set -x<br>[[ -f page.txt ]] &amp;&amp; echo ‘skip lynx’ || lynx -dump ftp://ftp.hycom.org/datasets/force/ncep_cfsr/netcdf/ &gt;page.txt<br>grep -r “ftp://“ page.txt |awk ‘{print $2}’ &gt; urls.txt<br>readarray -t exist_files&lt;&lt;&lt;”<code>ls .</code>“<br>for url in $(cat urls.txt)<br>do<br>  skip=”0”<br>  name=$(echo $url |awk -F ‘/‘ ‘{print $NF}’)<br>  readarray -t exist_files&lt;&lt;&lt;”<code>ls .</code>“<br>  for f in ${exist_files[@]}; do<br>    [[ “$name” == “$f” ]] &amp;&amp; skip=”1”; break;<br>  done<br>  if [ “$skip” == “1” ]; then<br>    echo “skipping ${f}”;<br>  else<br>    echo “download ${url}”;<br>    wget -c ${url}<br>  fi<br>done<br>改进版</p>
<p>#!/bin/bash</p>
<h1 id="Usage-nohup-proxychains4-crawl-sh-gt-log-txt-2-gt-1-amp-1"><a href="#Usage-nohup-proxychains4-crawl-sh-gt-log-txt-2-gt-1-amp-1" class="headerlink" title="Usage: nohup proxychains4 ./crawl.sh &gt; log.txt 2&gt;1&amp;"></a>Usage: nohup proxychains4 ./crawl.sh &gt; log.txt 2&gt;1&amp;</h1><p>#set -x<br>[[ -f page.txt ]] &amp;&amp; echo ‘skip creating lynx’ || lynx -dump <a href="http://tds.hycom.org/thredds/catalog/datasets/force/ncep_cfsr/netcdf/catalog.html" target="_blank" rel="external">http://tds.hycom.org/thredds/catalog/datasets/force/ncep_cfsr/netcdf/catalog.html</a> &gt;page.txt<br>[[ -f urls.txt ]] &amp;&amp; echo ‘skip creating urls.txt’ || grep -r “http://“ page.txt |awk ‘{print $2}’ |grep -E ‘.nc$’ &gt; urls.txt<br>sed -i ‘/dswsfc/d’ urls.txt<br>sed -i ‘/dlwsfc/d’ urls.txt<br>readarray -t exist_files&lt;&lt;&lt;”<code>ls . |grep -E &#39;\.nc$&#39;</code>“;  #can’t use multiple commands in [[ ]]<br>[[ -f skip.txt ]] &amp;&amp; echo ‘will use skip.txt’ || printf “%s\n” “${exist_files[@]}” &gt; skip.txt<br>readarray -t skip_files&lt;&lt;&lt;”<code>cat skip.txt</code>“<br>for url in $(cat urls.txt)<br>do<br>  name=$(echo $url |awk -F ‘/‘ ‘{print $NF}’)<br>  realurl=’<a href="http://tds.hycom.org/thredds/fileServer/datasets/force/ncep_cfsr/netcdf/&#39;$name" target="_blank" rel="external">http://tds.hycom.org/thredds/fileServer/datasets/force/ncep_cfsr/netcdf/&#39;$name</a><br>  if <code>echo ${skip_files[@]} |grep -q &quot;$name&quot;</code>; then<br>    echo “skipping ${f}”;<br>  else<br>    echo “download ${realurl}”;</p>
<pre><code>#wget -c --limit-rate=3m ${realurl}
wget -c ${realurl}
#echo ${realurl} &gt;&gt; skip.txt
</code></pre><p>  fi<br>done<br>获取绝对目录</p>
<p>export OS_CACERT=$(dirname “$(realpath -s “${BASH_SOURCE[0]}”)”)/ssl/openstack-ssl/results/cacert.pem<br>从国外下载气象数据</p>
<p>#gdisk /dev/sdd1   #t, 0700</p>
<p>#sudo mkfs.ntfs -f -L win /dev/sdd1</p>
<p>#sudo ntfsfix /dev/sdd1<br>sudo mkfs.ext4 /dev/xvdb<br>sudo parted /dev/xvdb  #print<br>sudo mount /dev/xvdb /mnt/<br>sudo mkdir -p /mnt/ftp<br>sudo chown -R $USER /mnt/<br>sudo apt install curlftpfs -y</p>
<p>#sudo fusermount -zu /mnt/ftp<br>sudo curlftpfs ftp://ftp.hycom.org/datasets/global/GLBa0.08_rect/data/ /mnt/ftp<br>sudo curlftpfs -o rw,allow_other,uid=1000,gid=1000 ftp://ftp.hycom.org/datasets/global/GLBa0.08_rect/data/ /mnt/ftp<br>$ scp -i ~/.aws/zhhuabj.pem ubuntu@13.114.59.98:/mnt/ftp/uvel/rarchv.2012_205_00_3zu.nc4 /tmp/<br>rarchv.2012_205_00_3zu.nc4                                                                                                94%  236MB   7.6MB/s   00:01 ETA</p>
<h1 id="using-direct-io-and-cache-no-to-avoid-using-disk"><a href="#using-direct-io-and-cache-no-to-avoid-using-disk" class="headerlink" title="using direct_io and cache=no to avoid using disk"></a>using direct_io and cache=no to avoid using disk</h1><p>sudo bash -c ‘cat &gt;&gt;/etc/fstab’ &lt;&lt;EOF<br>curlftpfs#@ftp.hycom.org/datasets/global/GLBa0.08_rect/data/ /mnt/ftp fuse defaults,direct_io,cache=no,rw,allow_other,uid=1000,gid=1000,_netdev 0 0<br>EOF<br>sudo mount -a</p>
<p>rsync -avztur -e “ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i ~/.aws/lxj.pem” –progress ubuntu@3.18.107.xxx:/mnt/ftp .</p>
<p>注意：　上面加了direct_io,cache=no后总是hang，得去掉．</p>
<p>#debug curlftpfs<br>sudo fusermount -zu /mnt/ftp/2d<br>sudo curlftpfs -f -v -o debug,ftpfs_debug=3,rw,allow_other,uid=1000,gid=1000 ftp://ftp.hycom.org/datasets/global/GLBa0.08_rect/data/2d /mnt/ftp/2d<br>1, use lftp to mirror</p>
<h1 id="lftp-e-“mirror-–delete-–only-newer-–verbose-–parallel-2”-ftp-ftp-hycom-org-datasets-global-GLBa0-08-rect-data"><a href="#lftp-e-“mirror-–delete-–only-newer-–verbose-–parallel-2”-ftp-ftp-hycom-org-datasets-global-GLBa0-08-rect-data" class="headerlink" title="lftp -e “mirror –delete –only-newer –verbose –parallel=2” ftp://ftp.hycom.org/datasets/global/GLBa0.08_rect/data/"></a>lftp -e “mirror –delete –only-newer –verbose –parallel=2” ftp://ftp.hycom.org/datasets/global/GLBa0.08_rect/data/</h1><p>lftp -c “set ftp:list-options -a;<br>open ‘ftp://ftp.hycom.org/datasets/global/GLBa0.08_rect/data/‘;<br>lcd /home/ubuntu/test;<br>cd 2d<br>mirror -c –use-cache –verbose –allow-chown –allow-suid –no-umask –verbose –parallel=2”</p>
<p>2, use wget to mirror</p>
<p>wget -c -m ftp://ftp.hycom.org/datasets/global/GLBa0.08_rect/data/<br>lynx -dump <a href="http://13.59.199.151/new_01hr/" target="_blank" rel="external">http://13.59.199.151/new_01hr/</a> &gt; page.txt<br>grep -r “http://“ page.txt |awk ‘{print $2}’ |grep -E ‘.nc$’ &gt; urls.txt<br>aria2c -x 10 -i urls.txt &gt;/dev/null 2&gt;/dev/null &amp;</p>
<p>并行运行</p>
<p>token=’111’<br>seq $PARALLEL_REQS | xargs -I {} -n1 -P$PARALLEL_REQS echo “$token”</p>
<p>#!/bin/bash -eux<br>PARALLEL_REQS=5<br>SLEEP_SECS=0.1<br>TEMPLOG=$(mktemp).log<br>K8S_ENDPOINT=’/api’<br>export CLUSTER_NAME=”juju-cluster”<br>APISERVER=$(kubectl config view -o jsonpath=”{.clusters[?(@.name==\”$CLUSTER_NAME\”)].cluster.server}”)<br>TOKEN=$(kubectl get secrets -o jsonpath=”{.items[?(@.metadata.annotations[‘kubernetes.io/service-account.name’]==’default’)].data.token}”|base64 –decode)</p>
<h1 id="trap-ctrl-c-and-call-ctrl-c"><a href="#trap-ctrl-c-and-call-ctrl-c" class="headerlink" title="trap ctrl-c and call ctrl_c()"></a>trap ctrl-c and call ctrl_c()</h1><p>trap ctrl_c INT<br>function ctrl<em>c() {<br>  local DEST=query-kubeapiserver.$(date ‘+%Y%m%d</em>%H%M’).log<br>  mv $TEMPLOG $DEST<br>  echo “output at $DEST”<br>  exit 0<br>}</p>
<p>set +x<br>while true; do<br>  echo “in while loop”<br>  seq $PARALLEL_REQS | xargs -I {} -n1 -P$PARALLEL_REQS curl -s -X GET $APISERVER$K8S_ENDPOINT –header “Authorization: Bearer $TOKEN” –insecure 2&gt;&amp;1 &gt;&gt; $TEMPLOG</p>
<h1 id="seq-PARALLEL-REQS-xargs-I-P-PARALLEL-REQS-sudo-etcd-etcdctl-–cacert-root-cdk-etcd-client-ca-pem-–cert-root-cdk-etcd-client-cert-pem-–key-root-cdk-etcd-client-key-pem-–endpoints-ETCD-ENDPOINTS-get-w-json-KEY-2-gt-amp-1-gt-gt-TEMPLOG"><a href="#seq-PARALLEL-REQS-xargs-I-P-PARALLEL-REQS-sudo-etcd-etcdctl-–cacert-root-cdk-etcd-client-ca-pem-–cert-root-cdk-etcd-client-cert-pem-–key-root-cdk-etcd-client-key-pem-–endpoints-ETCD-ENDPOINTS-get-w-json-KEY-2-gt-amp-1-gt-gt-TEMPLOG" class="headerlink" title="seq $PARALLEL_REQS | xargs -I {} -P$PARALLEL_REQS sudo etcd.etcdctl –cacert /root/cdk/etcd/client-ca.pem –cert /root/cdk/etcd/client-cert.pem –key /root/cdk/etcd/client-key.pem –endpoints=$ETCD_ENDPOINTS get -w json $KEY 2&gt;&amp;1 &gt;&gt; $TEMPLOG"></a>seq $PARALLEL_REQS | xargs -I {} -P$PARALLEL_REQS sudo etcd.etcdctl –cacert /root/cdk/etcd/client-ca.pem –cert /root/cdk/etcd/client-cert.pem –key /root/cdk/etcd/client-key.pem –endpoints=$ETCD_ENDPOINTS get -w json $KEY 2&gt;&amp;1 &gt;&gt; $TEMPLOG</h1><p>  echo “sleeping..”<br>  /bin/sleep $SLEEP_SECS<br>  echo “sleep done”<br>done</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/13/恢复系统记录/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/13/恢复系统记录/" itemprop="url">恢复系统记录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-13T09:26:11+08:00">
                2020-11-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华 发表于：2017-02-09<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</strong></p>
<p>今天系统又无故crash并无法启动了，折腾了一下午，记录一下。</p>
<p>突然运行“sudo apt-get update”时发生错误，一看是写保护，所以运行”sudo mount -o rw,remount /“, 但是系统报”unknown filesystem”，接着就crash了。</p>
<p>重启后出现了grub resue界面，试图通过下列命令恢复grub时仍然报”unknown filesystem”错误。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ls (hd1,msdos5)</span><br><span class="line">set root=(hd1,msdos5)</span><br><span class="line">set prefix=(hd1,5)/boot/grub</span><br><span class="line">lsmod normal</span><br><span class="line">normal</span><br><span class="line"></span><br><span class="line">sudo update-grub</span><br><span class="line">sudo grub-install /dev/sdb</span><br></pre></td></tr></table></figure></p>
<p>通过usb启动盘启动后运行“sudo fsck.ext4 -y /dev/sda9”之后上面磁盘的问题是解决了，也出现了登录界面，但是却无法登录，原本想通过下列命令重置:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -fr ~/.cache/compizconfig-1</span><br><span class="line">sudo rm -fr ~/.Xauthority</span><br><span class="line">sudo apt-get install --reinstall ubuntu-desktop unity compizconfig-settings-manager</span><br><span class="line">sudo dconf reset -f /org/compiz/</span><br><span class="line">setsid unity</span><br><span class="line">sudo rm -fr .cache/</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">http://kuring.me/ref/x_window/X_client_server_example.svg.png</span><br><span class="line">linux itself –&gt; X Server(xorg|wayland) &lt;- [X Protocol] -&gt; unity-greeter -&gt; Display Manager(GDM|lightdm, login GUI, /etc/X11/default-display-manager, or sudo dpkg-reconfigure lightdm) -&gt; Desktop Manager(GNOME, KDE) -&gt; X Application(eg: xclock)</span><br><span class="line">1, ctrl+alt+fn [n: 1-12]: used to switch virtual control console, 1-6 is used for linux (eg: echo $DISPLAY &amp;&amp; xclock -display :0 &amp;&amp; DISPLAY=:0 xclock)</span><br><span class="line">2, startx process (login -&gt; bash -&gt; startx -&gt; xinit -&gt; X -&gt; ck-xinit-session -&gt; gnome-session), xinit is used to start X Server software.</span><br><span class="line">3, &apos;init 5&apos; is used to restart X window</span><br></pre></td></tr></table></figure>
<p>但是发现/var/lib/dpkg目录不存在了，另外也有其他很多程序出现少文件的问题，不是我删除的，应该是fsck命令没有全部正确恢复inode吧。这种情况只能重装操作系统了，将所有工作需要的应用都安装好后也做了一个备份（dd if=/dev/sdb conv=sync,noerror bs=64K | gzip -c  &gt; /images/working_os_bak.img.gz）， 今后再出问题时希望通过命令（gunzip -c /images/working_os_bak.img.gz | dd of=/dev/sdb conv=sync,noerror bs=64K）能快速恢复操作系统和所需要的应用吧。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># dd if=/dev/sdb conv=sync,noerror bs=64K | gzip -c  &gt; /images/working_os_bak.img.gz</span><br><span class="line">1831575+1 records in</span><br><span class="line">1831576+0 records out</span><br><span class="line">120034164736 bytes (120 GB, 112 GiB) copied, 914.123 s, 131 MB/s</span><br><span class="line"></span><br><span class="line">$ ll /images/working_os_bak.img.gz -h</span><br><span class="line">-rw-r--r-- 1 root root 4.7G Feb  9 17:36 /images/working_os_bak.img.gz</span><br></pre></td></tr></table></figure>
<p>硬盘损坏看起来像：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host0/scan</span><br><span class="line"></span><br><span class="line">#Unused HDD</span><br><span class="line">Mar  1 10:24:28 node1 kernel: [ 2697.930058] ata3: hard resetting link</span><br><span class="line">Mar  1 10:24:28 node1 kernel: [ 2698.245478] ata3: SATA link down (SStatus 0 SControl 300)</span><br><span class="line">Mar  1 10:24:28 node1 kernel: [ 2698.245490] ata3: EH complete</span><br><span class="line"></span><br><span class="line">#Good HDD</span><br><span class="line">Mar  1 10:23:43 node1 kernel: [ 2652.763243] ata1: hard resetting link</span><br><span class="line">Mar  1 10:23:43 node1 kernel: [ 2653.077298] ata1: SATA link up 6.0 Gbps (SStatus 133 SControl 300)</span><br><span class="line">Mar  1 10:23:43 node1 kernel: [ 2653.097249] ata1.00: configured for UDMA/133</span><br><span class="line">Mar  1 10:23:43 node1 kernel: [ 2653.097251] ata1: EH complete</span><br><span class="line"></span><br><span class="line">#Bad HDD</span><br><span class="line">Feb 28 16:00:30 node1 kernel: [  231.696088] ata2.00: exception Emask 0x0 SAct 0x80000 SErr 0x0 action 0x6 frozen</span><br><span class="line">Feb 28 16:00:30 node1 kernel: [  231.696098] ata2.00: failed command: READ FPDMA QUEUED</span><br><span class="line">Feb 28 16:00:30 node1 kernel: [  231.696108] ata2.00: cmd 60/10:98:b0:bd:3c/00:00:a6:00:00/40 tag 19 ncq 8192 in</span><br><span class="line">Feb 28 16:00:30 node1 kernel: [  231.696108]          res 40/00:00:00:00:00/00:00:00:00:00/00 Emask 0x4 (timeout)</span><br><span class="line">Feb 28 16:00:30 node1 kernel: [  231.696113] ata2.00: status: &#123; DRDY &#125;</span><br><span class="line">Feb 28 16:00:30 node1 kernel: [  231.696119] ata2: hard resetting link</span><br><span class="line">Feb 28 16:00:36 node1 kernel: [  237.059963] ata2: link is slow to respond, please be patient (ready=0)</span><br><span class="line">Feb 28 16:00:40 node1 kernel: [  241.707975] ata2: COMRESET failed (errno=-16)</span><br><span class="line">Feb 28 16:00:40 node1 kernel: [  241.707980] ata2: hard resetting link</span><br><span class="line">Feb 28 16:00:46 node1 kernel: [  247.067970] ata2: link is slow to respond, please be patient (ready=0)</span><br></pre></td></tr></table></figure></p>
<p>换硬盘不需要重装系统，将fstab文件修改一下即可:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LABEL=&quot;images&quot; /images         ext4    defaults        0       2</span><br><span class="line">LABEL=&quot;bak&quot; /bak         ext4    defaults        0       2</span><br><span class="line">192.168.99.122:/Public /nas nfs noauto,x-systemd.automount,x-systemd.device-timeout=10,timeo=14,x-systemd.idle-timeout=1min 0 0</span><br></pre></td></tr></table></figure></p>
<h2 id="201923更新-解决login-loop问题"><a href="#201923更新-解决login-loop问题" class="headerlink" title="201923更新 - 解决login loop问题"></a>201923更新 - 解决login loop问题</h2><p>反复出现登录界面, 根据下列流程, 似乎问题只可能出现在gnome这块出问题了才会回到lightdm的登录界面处.<br>linux itself –&gt; X Server(xorg|wayland) &lt;- [X Protocol] -&gt; unity-greeter -&gt; Display Manager(GDM|lightdm, login GUI, /etc/X11/default-display-manager, or sudo dpkg-reconfigure lightdm) -&gt; Desktop Manager(GNOME, KDE) -&gt; X Application(eg: xclock)<br>搜索kern.log的Call strace确认问题与nvidia驱动相关:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"> 733 Nov 16 22:47:03 localhost kernel: [    1.896228] Could not determine valid watermarks for inherited state</span><br><span class="line"> 734 Nov 16 22:47:03 localhost kernel: [    1.896290] WARNING: CPU: 2 PID: 183 at /build/linux-O4X9pa/linux-4.15.0/drivers/gpu/d</span><br><span class="line"> 735 Nov 16 22:47:03 localhost kernel: [    1.896293] Modules linked in: nvidia_drm(POE) nvidia_modeset(POE) nvidia(POE) rtsx_pc</span><br><span class="line"> 736 Nov 16 22:47:03 localhost kernel: [    1.896309] CPU: 2 PID: 183 Comm: systemd-udevd Tainted: P           OE    4.15.0-68-g</span><br><span class="line"> 737 Nov 16 22:47:03 localhost kernel: [    1.896311] Hardware name: LENOVO 20AN002LCD/20AN002LCD, BIOS GLET64WW (2.18 ) 12/18/2</span><br><span class="line"> 738 Nov 16 22:47:03 localhost kernel: [    1.896342] RIP: 0010:intel_modeset_init+0xfcf/0x1010 [i915]</span><br><span class="line"></span><br><span class="line">748 Nov 16 22:47:03 localhost kernel: [    1.896362] Call Trace:</span><br><span class="line"> 749 Nov 16 22:47:03 localhost kernel: [    1.896389]  i915_driver_load+0xa73/0xe60 [i915]</span><br><span class="line"> 750 Nov 16 22:47:03 localhost kernel: [    1.896414]  i915_pci_probe+0x42/0x70 [i915]</span><br><span class="line"> 751 Nov 16 22:47:03 localhost kernel: [    1.896418]  local_pci_probe+0x47/0xa0</span><br><span class="line"> 752 Nov 16 22:47:03 localhost kernel: [    1.896421]  pci_device_probe+0x10e/0x1c0</span><br><span class="line"> 753 Nov 16 22:47:03 localhost kernel: [    1.896424]  driver_probe_device+0x30c/0x490</span><br><span class="line"> 754 Nov 16 22:47:03 localhost kernel: [    1.896426]  __driver_attach+0xcc/0xf0</span><br><span class="line"> 755 Nov 16 22:47:03 localhost kernel: [    1.896429]  ? driver_probe_device+0x490/0x490</span><br><span class="line"> 756 Nov 16 22:47:03 localhost kernel: [    1.896431]  bus_for_each_dev+0x70/0xc0</span><br><span class="line"> 757 Nov 16 22:47:03 localhost kernel: [    1.896433]  driver_attach+0x1e/0x20</span><br><span class="line"> 758 Nov 16 22:47:03 localhost kernel: [    1.896436]  bus_add_driver+0x1c7/0x270</span><br><span class="line"> 759 Nov 16 22:47:03 localhost kernel: [    1.896438]  ? 0xffffffffc041b000</span><br><span class="line"> 760 Nov 16 22:47:03 localhost kernel: [    1.896440]  driver_register+0x60/0xe0</span><br><span class="line"> 761 Nov 16 22:47:03 localhost kernel: [    1.896442]  ? 0xffffffffc041b000</span><br><span class="line"> 762 Nov 16 22:47:03 localhost kernel: [    1.896444]  __pci_register_driver+0x5a/0x60</span><br><span class="line"> 763 Nov 16 22:47:03 localhost kernel: [    1.896465]  i915_init+0x5c/0x5f [i915]</span><br></pre></td></tr></table></figure>
<p>升级nvidia驱动从nvidia-driver-390到435看是否能解决问题<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">deb http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic main</span><br><span class="line">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys FCAE110B1118213C</span><br><span class="line">sudo apt purge nvidia-driver-390 &amp;&amp; sudo apt autoremove &amp;&amp; sudo apt install nvidia-driver-435</span><br></pre></td></tr></table></figure></p>
<p>也可以试试:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#https://launchpad.net/~canonical-kernel-team/+archive/ubuntu/ppa</span><br><span class="line">sudo apt upgrade-dist</span><br><span class="line">sudo add-apt-repository ppa:canonical-kernel-team/ppa</span><br><span class="line">#can install the latest hwe kernel by using above ppa</span><br><span class="line">sudo apt install --install-recommends linux-generic-hwe-18.04 xserver-xorg-hwe-18.04</span><br></pre></td></tr></table></figure></p>
<p>20200203更 , 还是不行, 用下列方法重装了desktop再观察:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">sudo rm /var/lib/apt/lists/lock</span><br><span class="line">sudo rm /var/lib/dpkg/lock</span><br><span class="line">sudo rm /var/lib/dpkg/lock-frontend</span><br><span class="line">sudo dpkg --configure -a</span><br><span class="line">sudo apt clean</span><br><span class="line">sudo apt update --fix-missing</span><br><span class="line">sudo apt install -f</span><br><span class="line">sudo dpkg --configure -a</span><br><span class="line">sudo apt upgrade</span><br><span class="line">sudo apt dist-upgrade</span><br><span class="line"></span><br><span class="line">sudo apt purge *unity*</span><br><span class="line">sudo apt purge *gnome*</span><br><span class="line">sudo apt autoremove</span><br><span class="line">sudo apt-get install --reinstall ubuntu-desktop</span><br><span class="line">sudo update-grub</span><br><span class="line">sudo apt install gdm3</span><br><span class="line">sudo dpkg-reconfigure gdm3</span><br><span class="line"></span><br><span class="line">#Install Gnome and set it as default</span><br><span class="line">sudo apt install gnome-session</span><br><span class="line">sudo update-alternatives --config gdm3.css</span><br><span class="line">sudo reboot</span><br><span class="line">#Switch to a Windows-like Taskbar - https://vitux.com/how-to-get-the-windows-look-feel-on-ubuntu/</span><br><span class="line">sudo apt install gnome-shell-extensions gnome-shell-extension-dash-to-panel gnome-tweaks adwaita-icon-theme-full</span><br><span class="line"></span><br><span class="line">#Install windows-style desktop Cinnamon, but it&apos;s bluetooth doesn&apos;t work</span><br><span class="line">sudo add-apt-repository ppa:embrosyn/cinnamon</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install cinnamon</span><br><span class="line">#sudo apt remove --autoremove cinnamon cinnamon-desktop-data</span><br><span class="line">#sudo add-apt-repository --remove ppa:embrosyn/cinnamon</span><br></pre></td></tr></table></figure>
<p>20201113更新，切换到使用wayland再试试:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hua@t440p:~$ grep -r &apos;Wayland&apos; /etc/gdm3/custom.conf</span><br><span class="line">WaylandEnable=true</span><br><span class="line">sudo systemctl restart gdm3</span><br><span class="line">hua@t440p:~$ echo $XDG_SESSION_TYPE</span><br><span class="line">wayland</span><br></pre></td></tr></table></figure>
<p>但是gdm3是超级难用啊，刚装上就遇到chrome在gdm3上在复制粘贴时chrome就无响应的问题，只得再切回x11了，但我删除了lightdm遗留并且添加了下列配置，再难容一下吧。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/gdm3/PostSession/Default</span><br><span class="line">#!/bin/sh</span><br><span class="line"></span><br><span class="line">killall -9 -u $USER</span><br><span class="line"></span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure></p>
<p>20210118继续尝试，今天继续看到”systemd-logind got pause“错误,以及”PowerSaveMode, Timeout was reached”相关错误， 将尝试一下使用lightdm试试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install lightdm</span><br></pre></td></tr></table></figure></p>
<p>另外，也将尝试下列命令是否能恢复</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reexec &amp;&amp; sudo systemctl start systemd-logind</span><br></pre></td></tr></table></figure>
<h2 id="20210122更新-－-台式机死机的问题"><a href="#20210122更新-－-台式机死机的问题" class="headerlink" title="20210122更新　－　台式机死机的问题"></a>20210122更新　－　台式机死机的问题</h2><p>台式机经常莫名其秒就死了，尤其在开kvm虚机时，今天又死了，然后在/var/crash目录发现了_usr_lib_x86_64-linux-gnu_indicator-keyboard_indicator-keyboard-service.108.crash<br>也发现了如下日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/var/log/kern.log</span><br><span class="line">Jan 22 17:46:21 node1 kernel: [ 2163.654654] indicator-keybo[2918]: segfault at 20 ip 00007f259e9213d0 sp 00007ffde892f540 error 6 in libglib-2.0.so.0.6400.3[7f259e919000+84000]</span><br><span class="line"></span><br><span class="line">/var/log/syslog</span><br><span class="line">Jan 22 17:46:22 node1 systemd[2065]: indicator-keyboard.service: Main process exited, code=dumped, status=11/SEGV</span><br><span class="line">Jan 22 17:46:22 node1 systemd[2065]: indicator-keyboard.service: Failed with result &apos;core-dump&apos;.</span><br><span class="line">Jan 22 17:46:22 node1 systemd[2065]: indicator-keyboard.service: Scheduled restart job, restart counter is at 1.</span><br><span class="line">Jan 22 17:46:22 node1 systemd[2065]: Stopped Indicator Keyboard Backend.</span><br><span class="line">Jan 22 17:46:22 node1 systemd[2065]: Started Indicator Keyboard Backend.</span><br><span class="line">Jan 22 17:46:22 node1 indicator-keyboard-service[18705]: Unable to init server: Could not connect: Connection refused</span><br><span class="line">Jan 22 17:46:22 node1 indicator-keybo[18705]: gtk_icon_theme_get_for_screen: assertion &apos;GDK_IS_SCREEN (screen)&apos; failed</span><br></pre></td></tr></table></figure></p>
<p>原本想运行”apt remove –purge indicator-keyboard“删除它，但使用ps -ef |grep indicator查看有lightdm的字眼，所以改用gdm3就好了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install gdm3 -y</span><br><span class="line">sudo dpkg-reconfigure gdm3</span><br></pre></td></tr></table></figure>
<p>但是笔记本上经常性登录crash，似乎是gdm3的问题，目前正在改成lightdm试。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">张华</p>
              <p class="site-description motion-element" itemprop="description">blog.csdn.net/quqi99</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">96</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张华</span>

  
</div>


  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
