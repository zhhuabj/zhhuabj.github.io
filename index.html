<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>技术并艺术着</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="blog.csdn.net/quqi99">
<meta property="og:type" content="website">
<meta property="og:title" content="技术并艺术着">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="blog.csdn.net/quqi99">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="技术并艺术着">
<meta name="twitter:description" content="blog.csdn.net/quqi99">
  
    <link rel="alternate" href="/atom.xml" title="技术并艺术着" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">技术并艺术着</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">张华的技术博客 - blog.csdn.net/quqi99</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-IPv6来啦" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/03/IPv6来啦/" class="article-date">
  <time datetime="2018-08-03T08:01:05.000Z" itemprop="datePublished">2018-08-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/03/IPv6来啦/">IPv6来啦</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-08-03)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>家里用的是中国移动的宽带, 一直挺稳定的, 而且昨天发现ISP下发了IPv6地址(不是子网, 形如: 2409:8a00:7805:xxxx:xxxx:xxxx:xxxx:xxxx/64, 打xxxx的部分是动态变化的). 好吧, 咱就用用.</p>
<h2 id="路由器配置"><a href="#路由器配置" class="headerlink" title="路由器配置"></a>路由器配置</h2><ul>
<li><p>配置/etc/config/network使用’option ip6assign ‘64’</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config interface &apos;lan&apos;</span><br><span class="line">        ...</span><br><span class="line">        option ip6assign &apos;64&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置/etc/confignetwork删除config globals ‘globals’段中和 IPv6 ULA-Prefix相关的配置 (注: 使用IPv6 ULA-Prefix的话, LAN中机器就会得到一个以它打头的IPv6地址, 但如何从外网访问这个地址呢? 有三种方式: 一是使用我们现在使用的relay方式得到是ISP提供的全球可路由的IPv6地址；二是配置ULA-Prefix=2409:8a00:7805:1::/80之后再使用下列的neigh proxy的方法解决, 但这种一般是子网长度80比64大, 但ISP并没有给我们分配subnet, 只是分配了IPv6地址, 所以无法保证2409:8a00:7805:1::/80这个前缀与ISP分配的2409:8a00:7805:xxxx:xxxx:xxxx:xxxx:xxxx/64一致；三是ULA-Prefix配置一个与ISP分配的不同的路由然后通过配置路由的方式但前提是也得有全球可路由的IPv6 subnet啊. 所以这里我们选择了relay模式来实现外网访问内网的目的.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv6.conf.all.proxy_ndp=1</span><br><span class="line">ip -6 neigh add proxy 2409:8a00:7805:1::430 dev pppoe-wan</span><br><span class="line">ip -6 neigh show proxy</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置/etc/config/dhcp使用relay模式, relay模式意味着openwrt通过默认的odhcpd作为中继自动为LAN的其他机器配置ISP的IPv6地址</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">config dhcp &apos;wan&apos;</span><br><span class="line">        option interface &apos;wan&apos;</span><br><span class="line">        option ignore &apos;1&apos;</span><br><span class="line">        option dhcpv6 &apos;relay&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br><span class="line">        option master &apos;1&apos;</span><br><span class="line">config dhcp &apos;lan&apos;</span><br><span class="line">        option interface &apos;lan&apos;</span><br><span class="line">        option start &apos;100&apos;</span><br><span class="line">        option limit &apos;150&apos;</span><br><span class="line">        option leasetime &apos;12h&apos;</span><br><span class="line">        list dhcp_option &apos;6,192.168.99.1&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br><span class="line">        option dhcpv6 &apos;relay&apos;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>配置完之后就可以通过下列命令重启路由器服务就可以在br-lan与pppoe-wan上获得ISP分配的IPv6地址了.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/network restart</span><br><span class="line">/etc/init.d/odhcpd restart</span><br></pre></td></tr></table></figure></p>
<p>内网机器直接通过’sudo /etc/init.d/network-manager restart’重启网络也会获取ISP分配的IPv6地址.</p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><ul>
<li>内网机器访问br-lan内网网关, 能通是因为下列路由的功能:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hua@t440p:~$ ip -6 route list |grep 2409:8a00:7805:b7df::/64</span><br><span class="line">2409:8a00:7805:b7df::/64 dev eth0  proto ra  metric 100  pref medium</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# route -A inet6 |grep ::/0</span><br><span class="line">::/0                                        fe80::200:5eff:fe00:134                 UG    1024   0        0</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>注: 后面我们会看到::/0的默认路由会造成很多问题.</p>
<ul>
<li><p>内网机器访问pppoe-wan外网网关<br>对于relay模式由于内网机器拿到的本来就是ISP分配的可路由的IP所以自然能通. 但对于nat模式由于内网机器分配的是和ISP不同网段的IP, 所以需要在路由器上做NAT6, 如:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#ip6tables -t nat -I POSTROUTING -o pppoe-wan -j MASQUERADE</span><br><span class="line">ip6tables -t nat -I POSTROUTING -s `uci get network.globals.ula_prefix` -j MASQUERADE &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
</li>
<li><p>外网访问内网机器<br>如果使用relay由于内网机器使用的是全球可路由的IPv6地址, 外网直接就是可以访问内网机器的；但如果是不同子网需要做路由；如果只是前缀相同只是子网长度不同可以做neigh proxy</p>
</li>
<li>但是此时我们发现内网机器无法访问外网(如ping6 ipv6.baidu.com), 但此时在路由器上却是可以访问外网的. 原因就在于上面使用::/0的默认路由似乎有问题(报这个错: Destination unreachable: Unknown code 5), 改成了2000::/3就好了:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route -A inet6 add 2000::/3 `route -A inet6 | grep ::/0 | awk &apos;NR==1&#123;print&quot;gw &quot;$2&quot; dev &quot;$7&#125;&apos;`</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>或者:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip -6 route add default from 2409:8a00:7805::48 dev pppoe-wan</span><br></pre></td></tr></table></figure></p>
<p>但上面两种方法仍然遇到了不稳定的问题, 感觉是openwrt的odhcpd不稳定, 照下列方法更换为6relayd之后仍然不好使.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">wget https://www.shintaku.cc/files/6relayd_2013-10-21_ar71xx.ipk</span><br><span class="line">opkg install 6relayd_2013-10-21_ar71xx.ipk</span><br><span class="line">vi /etc/config/6relayd</span><br><span class="line">config relay</span><br><span class="line">        option master &apos;wan&apos;</span><br><span class="line">        option network &apos;lan&apos;</span><br><span class="line">        option rd &apos;relay&apos;</span><br><span class="line">        option dhcpv6 &apos;relay&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">/etc/init.d/odhcpd disable</span><br><span class="line">/etc/init.d/odhcpd stop</span><br><span class="line">/etc/init.d/6relayd enable</span><br><span class="line">/etc/init.d/6relayd start</span><br></pre></td></tr></table></figure></p>
<p>接着使用tcpdump查看好像是DHCPv6 reply包从pppoe-wan过不来br-lan口:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">08:22:53.810272 IP6 2400:da00:2::29 &gt; 2409:8a00:7805:b7df:8d79:6c9:315a:9ca3: ICMP6, echo reply, seq 7, length 64</span><br></pre></td></tr></table></figure></p>
<p>所以接着, 在/etc/config/firewall文件的 Allow-ICMPv6-Forward项中添加了下列行后确认已经有了129(129就是reply)相关的iptables rules之后仍然不好使.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">        list icmp_type &apos;router-solicitation&apos;</span><br><span class="line">        list icmp_type &apos;neighbour-solicitation&apos;</span><br><span class="line">        list icmp_type &apos;router-advertisement&apos;</span><br><span class="line">        list icmp_type &apos;neighbour-advertisement&apos;</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# ip6tables-save |grep Allow-ICMPv6-Forward |grep 129</span><br><span class="line">-A zone_wan_forward -p ipv6-icmp -m icmp6 --icmpv6-type 129 -m limit --limit 1000/sec -m comment --comment Allow-ICMPv6-Forward -j ACCEPT</span><br></pre></td></tr></table></figure></p>
<p>google查到的和这个bug相同(<a href="https://github.com/openwrt/odhcpd/issues/37" target="_blank" rel="external">https://github.com/openwrt/odhcpd/issues/37</a>), 但里面的所有方法都试过了不成功.<br>似乎是ISP使用的是Statefull DHCPV6的方式, 6relayd可以把ra信息relay过来，但LAN端机器似乎无法跟DHCPV6服务器通信。</p>
<h2 id="2018-0805更新"><a href="#2018-0805更新" class="headerlink" title="2018-0805更新"></a>2018-0805更新</h2><p>今天通过这个帖子(<a href="https://bbs.pku.edu.cn/v2/post-read.php?bid=35&amp;threadid=15501646)解决了上面的问题" target="_blank" rel="external">https://bbs.pku.edu.cn/v2/post-read.php?bid=35&amp;threadid=15501646)解决了上面的问题</a>:<br>OpenWRT默认是在wan口使用DHCPv6 Client, 在LAN口使用odhcpd开启RA和DHCPv6. 这个默认配置适用于国外主流ISP, 因为他们DHCPv6-PD (prefix delegation)把一个至少/64地址段分配给客户使用(还有的使用小于64的地址段给客户分配静态IP).<br>不过中国移动给客户分配的是SLAAC地址, 没有使用DHCPv6, 也就没使用DHCPv6-PD, 这样拿不到前缀(ISP分配的2409:8a00:7805:xxx::/64地址的第4段总是变化的), 所以odhcpd也就无法根据这个前缀设置路由, 所以我们需要手工设置确保可以在OpenWrt上ping通内网机器, 这样才能保证reply消息到达br-lan之后能到达内网机器, 如:<br>route -A inet6 add 2409:8a00:7805:d9b1::/64 dev br-lan<br>所以最终添加在/etc/firewall.user的内容如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># make ipv6 relay to work</span><br><span class="line">PREFIX=`route -A inet6 |grep lo |grep 2409:8a00:7805 |grep ::/128 |awk -F &apos;::/&apos; &apos;&#123;print $1&quot;::/64&quot;&#125;&apos; |uniq`</span><br><span class="line">ip -6 route del $PREFIX dev br-lan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">ip -6 route del $PREFIX dev br-lan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">ip -6 route del $PREFIX dev pppoe-wan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">ip -6 route add $PREFIX dev br-lan</span><br><span class="line">ip -6 route add default from $PREFIX dev pppoe-wan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line"># make ipv6 nat to work</span><br><span class="line">#ip -6 route add default from $PREFIX dev pppoe-wan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">#route -A inet6 add 2000::/3 `route -A inet6 | grep ::/0 | awk &apos;NR==1&#123;print&quot;gw &quot;$2&quot; dev &quot;$7&#125;&apos;` &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure></p>
<p>再就是得配置replay消息能从pppoe-wan到达br-lan, 所以最终使用下列配置(也记得去掉IPv6 ULA-Prefix):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">config dhcp &apos;wan&apos;</span><br><span class="line">        option interface &apos;wan&apos;</span><br><span class="line">        option ignore &apos;1&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br><span class="line">        option master &apos;1&apos;</span><br><span class="line">config dhcp &apos;lan&apos;</span><br><span class="line">        option interface &apos;lan&apos;</span><br><span class="line">        option start &apos;100&apos;</span><br><span class="line">        option limit &apos;150&apos;</span><br><span class="line">        option leasetime &apos;12h&apos;</span><br><span class="line">        list dhcp_option &apos;6,192.168.99.1&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br></pre></td></tr></table></figure></p>
<h2 id="转试NAT6"><a href="#转试NAT6" class="headerlink" title="转试NAT6"></a>转试NAT6</h2><p>上面使用replay时的bug解不了, 无奈之下, 只好使用NAT6, 外面访问不了内网就访问不了吧, 起码可以内网访问外网啊.</p>
<ul>
<li><p>在/etc/config/network中配置了ula_prefix=2001:192:168:99::/64, 这时路由器上的br-lan除了ISP分配的IP之外, 也会多时我们这个自己配置的地址: 2001:192:168:99:0:0:0:1/64</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">config globals &apos;globals&apos;</span><br><span class="line">        option ula_prefix &apos;2001:192:168:99::/64&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改/etc/config/dhcp将relay模式改到server模式即NAT模式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">config dhcp &apos;lan&apos;</span><br><span class="line">        option interface &apos;lan&apos;</span><br><span class="line">        option start &apos;100&apos;</span><br><span class="line">        option limit &apos;150&apos;</span><br><span class="line">        option leasetime &apos;12h&apos;</span><br><span class="line">        list dhcp_option &apos;6,192.168.99.1&apos;</span><br><span class="line">        option dhcpv6 &apos;server&apos;</span><br><span class="line">        option ra_management &apos;2&apos;</span><br><span class="line">        option ra &apos;server&apos;</span><br><span class="line">        option ra_default &apos;1&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在/etc/firewall.user中添加下列SNAT规则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip6tables -t nat -I POSTROUTING -s `uci get network.globals.ula_prefix` -j MASQUERADE &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">route -A inet6 add 2000::/3 `route -A inet6 | grep ::/0 | awk &apos;NR==1&#123;print&quot;gw &quot;$2&quot; dev &quot;$7&#125;&apos;` &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>之后, 内网机器随便手动配置一个IP如2001:192:168:99:0:0:0:3/64并添加默认路由之后就可以访问外网了.<br>如果想外网访问2001:192:168:99::3/64, 是不能够使用下面的neigh proxy方式的, 因为网段和ISP分配的可路由网段根据就不一样嘛. 唯一的办法其实就是做DNAT<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv6.conf.all.proxy_ndp=1</span><br><span class="line">ip -6 neigh add proxy 2001:192:168:99:0:0:0:3 dev pppoe-wan</span><br><span class="line">ip -6 neigh show proxy</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/03/IPv6来啦/" data-id="cjkgczye70003kobptsv0oaop" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Using-kubeadm-to-deploy-k8s" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/13/Using-kubeadm-to-deploy-k8s/" class="article-date">
  <time datetime="2018-07-13T07:30:57.000Z" itemprop="datePublished">2018-07-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/13/Using-kubeadm-to-deploy-k8s/">Using kubeadm to deploy k8s</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-07-13)</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;deb http://apt.kubernetes.io/ kubernetes-xenial main&quot; |sudo tee /etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 6A030B21BA07F4FB</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install docker.io kubelet kubeadm kubectl kubernetes-cni</span><br><span class="line"></span><br><span class="line">sudo usermod -aG docker `whoami`</span><br><span class="line">sudo systemctl enable docker.service</span><br><span class="line">sudo systemctl enable kubelet.service</span><br><span class="line">echo &apos;KUBELET_EXTRA_ARGS=--fail-swap-on=false&apos; |sudo tee /etc/default/kubelet</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">#sudo swapoff -a</span><br><span class="line"></span><br><span class="line">#before this step, kubelet can&apos;t be up because no file /var/lib/kubelet/config.yaml</span><br><span class="line">sudo kubeadm reset</span><br><span class="line">sudo kubeadm init --pod-network-cidr 10.244.0.0/16 --ignore-preflight-errors=swap --kubernetes-version=v1.11.0</span><br><span class="line">sudo systemctl status kubelet</span><br><span class="line"></span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">#https://docs.projectcalico.org/v3.1/getting-started/kubernetes/</span><br><span class="line">wget https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/kubeadm/1.7/calico.yaml</span><br><span class="line">sed -i &apos;s/192.168.0.0/10.244.0.0/g&apos; ./calico.yaml</span><br><span class="line">kubectl apply -f ./calico.yaml</span><br><span class="line"></span><br><span class="line">kubectl get nodes</span><br><span class="line">kubectl get pods --all-namespaces</span><br><span class="line">kubectl get services --all-namespaces</span><br><span class="line">kubectl cluster-info</span><br><span class="line"></span><br><span class="line">#test</span><br><span class="line">kubectl run nginx --image=nginx</span><br><span class="line">kubectl expose deployment nginx --port=80 --target-port=80 --name=nginx-svc</span><br><span class="line"></span><br><span class="line">git clone https://github.com/kubernetes/kubernetes.github.io</span><br><span class="line">kubectl create -f ./content/en/examples/application/guestbook/</span><br><span class="line">#kubectl delete -f ./content/en/examples/application/guestbook/</span><br><span class="line"></span><br><span class="line">#scale test</span><br><span class="line">kubectl scale rc frontend --replicas=4</span><br><span class="line">kubectl get pods --all-namespaces</span><br><span class="line"></span><br><span class="line">#rolling-update for ReplicationController and apply for Deployment</span><br><span class="line">#kubectl rolling-update frontend --update-period=10s -f ./deploymentv2</span><br><span class="line">#kubectl rolling-update frontend --rollback</span><br><span class="line">kubectl get deployment frontend</span><br><span class="line">kubectl rollout history deployment/frontend</span><br><span class="line">kubectl rollout undo deployment/frontend</span><br><span class="line"></span><br><span class="line">#the single task</span><br><span class="line">$ cat pi.yaml</span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: pi</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: pi</span><br><span class="line">    spec:</span><br><span class="line">      restartPolicy: Never</span><br><span class="line">      containers:</span><br><span class="line">      - name: pi</span><br><span class="line">        image: perl</span><br><span class="line">        command: [&quot;perl&quot;, &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;]</span><br><span class="line">$ kubectl get job</span><br><span class="line">NAME      DESIRED   SUCCESSFUL   AGE</span><br><span class="line">pi        1         1            2m</span><br><span class="line">$ kubectl get pod |grep pi-</span><br><span class="line">pi-mqjz8                                           0/1       Completed     0          2m</span><br><span class="line">$ kubectl logs pi-mqjz8</span><br><span class="line">3.1415926...</span><br><span class="line"></span><br><span class="line">#the cron task</span><br><span class="line">$ cat cron-pi.yaml</span><br><span class="line">apiVersion: batch/v1beta1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: pi</span><br><span class="line">spec:</span><br><span class="line">  schedule: &quot;*/1 * * * *&quot;</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        metadata:</span><br><span class="line">          name: pi</span><br><span class="line">        spec:</span><br><span class="line">          restartPolicy: OnFailure</span><br><span class="line">          containers:</span><br><span class="line">          - name: pi</span><br><span class="line">            image: perl</span><br><span class="line">            command: [&quot;perl&quot;, &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;]</span><br><span class="line">$ kubectl get cronjob pi</span><br><span class="line">NAME      SCHEDULE      SUSPEND   ACTIVE    LAST SCHEDULE   AGE</span><br><span class="line">pi        */1 * * * *   False     0         &lt;none&gt;          28s</span><br><span class="line"></span><br><span class="line">#daemonSet</span><br><span class="line">$ kubectl get daemonset</span><br><span class="line">NAME                                         DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR                        AGE</span><br><span class="line">nginx-ingress-kubernetes-worker-controller   3         3         0         3            0           juju-application=kubernetes-worker   7d</span><br><span class="line"></span><br><span class="line">#storage</span><br><span class="line">$ cat hostpath.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pd</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: busybox</span><br><span class="line">    name: test-container</span><br><span class="line">    command:</span><br><span class="line">    - sleep</span><br><span class="line">    - &quot;3600&quot;</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test-pd</span><br><span class="line">      name: test-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    hostPath:</span><br><span class="line">      # directory location on host</span><br><span class="line">      path: /tmp</span><br><span class="line">      # this field is optional</span><br><span class="line">      type: Directory</span><br><span class="line">kubectl create -f hostpath.yaml</span><br><span class="line">kubectl exec -it test-pd -- /bin/sh</span><br><span class="line">kubectl exec test-pd -- ls /test-pd</span><br><span class="line"></span><br><span class="line">#secret</span><br><span class="line">$ cat secret.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: pass</span><br><span class="line">type: Opaque</span><br><span class="line">data:</span><br><span class="line">  pass: cGFzc3dvcmQ=</span><br><span class="line">$ cat secret-pd.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: secret-pd</span><br><span class="line">spec:</span><br><span class="line">  restartPolicy: Never</span><br><span class="line">  containers:</span><br><span class="line">  - image: busybox</span><br><span class="line">    name: secret-container</span><br><span class="line">    command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot; ]</span><br><span class="line">    env:</span><br><span class="line">      - name: DB_PASS</span><br><span class="line">        valueFrom:</span><br><span class="line">          secretKeyRef:</span><br><span class="line">            name: pass</span><br><span class="line">            key: pass</span><br><span class="line">$ kubectl logs secret-pd |grep DB_PASS</span><br><span class="line">DB_PASS=password</span><br><span class="line"></span><br><span class="line">#ingress</span><br><span class="line">$ kubectl get pods --all-namespaces |grep ingress</span><br><span class="line">default       nginx-ingress-kubernetes-worker-controller-2fkdr   1/1       Running     0          23h</span><br><span class="line">default       nginx-ingress-kubernetes-worker-controller-2khgp   1/1       Running     0          23h</span><br><span class="line">default       nginx-ingress-kubernetes-worker-controller-4c7kr   1/1       Running     0          23h</span><br><span class="line">kubectl run echoheaders --image=gcr.io/google_containers/echoserver:1.4 --replicas=1 --port=8080</span><br><span class="line">ubuntu@zhhuabj-bastion:~/work/k8s$ kubectl expose deployment echoheaders --port=80 --target-port=8080 --name=echoheaders</span><br><span class="line">$ cat ingress.yaml</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: echomap</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: foo.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /foo</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: echheaders</span><br><span class="line">          servicePort: 80</span><br><span class="line">kubectl exec -it nginx-ingress-kubernetes-worker-controller-2fkdr -- cat /etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">$ sudo kubeadm init --pod-network-cidr 10.244.0.0/16 --ignore-preflight-errors=swap --kubernetes-version=v1.11.0</span><br><span class="line">I0713 06:47:50.169410     362 feature_gate.go:230] feature gates: &amp;&#123;map[]&#125;</span><br><span class="line">[init] using Kubernetes version: v1.11.0</span><br><span class="line">[preflight] running pre-flight checks</span><br><span class="line">	[WARNING Swap]: running with swap on is not supported. Please disable swap</span><br><span class="line">I0713 06:47:50.213902     362 kernel_validator.go:81] Validating kernel version</span><br><span class="line">I0713 06:47:50.213996     362 kernel_validator.go:96] Validating kernel config</span><br><span class="line">	[WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 17.12.1-ce. Max validated version: 17.03</span><br><span class="line">[preflight/images] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight/images] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[preflight] Activating the kubelet service</span><br><span class="line">[certificates] Generated ca certificate and key.</span><br><span class="line">[certificates] Generated apiserver certificate and key.</span><br><span class="line">[certificates] apiserver serving cert is signed for DNS names [voltorb kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.230.56.118]</span><br><span class="line">[certificates] Generated apiserver-kubelet-client certificate and key.</span><br><span class="line">[certificates] Generated sa key and public key.</span><br><span class="line">[certificates] Generated front-proxy-ca certificate and key.</span><br><span class="line">[certificates] Generated front-proxy-client certificate and key.</span><br><span class="line">[certificates] Generated etcd/ca certificate and key.</span><br><span class="line">[certificates] Generated etcd/server certificate and key.</span><br><span class="line">[certificates] etcd/server serving cert is signed for DNS names [voltorb localhost] and IPs [127.0.0.1 ::1]</span><br><span class="line">[certificates] Generated etcd/peer certificate and key.</span><br><span class="line">[certificates] etcd/peer serving cert is signed for DNS names [voltorb localhost] and IPs [10.230.56.118 127.0.0.1 ::1]</span><br><span class="line">[certificates] Generated etcd/healthcheck-client certificate and key.</span><br><span class="line">[certificates] Generated apiserver-etcd-client certificate and key.</span><br><span class="line">[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;</span><br><span class="line">[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;</span><br><span class="line">[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[init] this might take a minute or longer if the control plane images have to be pulled</span><br><span class="line">[apiclient] All control plane components are healthy after 89.502565 seconds</span><br><span class="line">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.11&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[markmaster] Marking the node voltorb as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[markmaster] Marking the node voltorb as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;voltorb&quot; as an annotation</span><br><span class="line">[bootstraptoken] using token: 1yz24f.1hv4qn59rjxgj7cb</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of machines by running the following on each node</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 10.230.56.118:6443 --token 1yz24f.1hv4qn59rjxgj7cb --discovery-token-ca-cert-hash sha256:12dde7a18134d6d2effd66b17ad4e9b6b008ddfaa2c2d82232164e296d98ff0f</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br></pre></td><td class="code"><pre><span class="line">root@vps:~# ps -ef |grep kube</span><br><span class="line">root       704     1 99 06:48 ?        02:10:08 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --cgroup-driver=cgroupfs --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni --resolv-conf=/run/systemd/resolve/resolv.conf --fail-swap-on=false</span><br><span class="line">root      1169  1146  4 06:49 ?        00:01:51 etcd --advertise-client-urls=https://127.0.0.1:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --initial-advertise-peer-urls=https://127.0.0.1:2380 --initial-cluster=vps=https://127.0.0.1:2380 --key-file=/etc/kubernetes/pki/etcd/server.key --listen-client-urls=https://127.0.0.1:2379 --listen-peer-urls=https://127.0.0.1:2380 --name=vps --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/etc/kubernetes/pki/etcd/peer.key --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt --snapshot-count=10000 --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">root      1207  1190 10 06:49 ?        00:04:11 kube-apiserver --authorization-mode=Node,RBAC --advertise-address=10.230.56.118 --allow-privileged=true --client-ca-file=/etc/kubernetes/pki/ca.crt --disable-admission-plugins=PersistentVolumeLabel --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key</span><br><span class="line">root      1339  1320 14 06:49 ?        00:05:28 kube-controller-manager --address=127.0.0.1 --allocate-node-cidrs=true --cluster-cidr=10.244.0.0/16 --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt --cluster-signing-key-file=/etc/kubernetes/pki/ca.key --controllers=*,bootstrapsigner,tokencleaner --kubeconfig=/etc/kubernetes/controller-manager.conf --leader-elect=true --node-cidr-mask-size=24 --root-ca-file=/etc/kubernetes/pki/ca.crt --service-account-private-key-file=/etc/kubernetes/pki/sa.key --use-service-account-credentials=true</span><br><span class="line">root      1394  1365  2 06:49 ?        00:01:05 kube-scheduler --address=127.0.0.1 --kubeconfig=/etc/kubernetes/scheduler.conf --leader-elect=true</span><br><span class="line">root      1858  1840  0 06:49 ?        00:00:20 /usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/config.conf</span><br><span class="line">root     11432 11394  0 07:10 ?        00:00:01 /usr/bin/kube-controllers</span><br><span class="line">root     20581 19399  0 07:28 pts/1    00:00:00 grep --color=auto kube</span><br><span class="line"></span><br><span class="line">root@vps:~# cat /var/lib/kubelet/kubeadm-flags.env</span><br><span class="line">KUBELET_KUBEADM_ARGS=--cgroup-driver=cgroupfs --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni --resolv-conf=/run/systemd/resolve/resolv.conf</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /var/lib/kubelet/config.yaml</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.crt</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">cgroupDriver: cgroupfs</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line">failSwapOn: true</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line">port: 10250</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/admin.conf</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: xxx=</span><br><span class="line">    server: https://10.230.56.118:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: kubernetes-admin</span><br><span class="line">  name: kubernetes-admin@kubernetes</span><br><span class="line">current-context: kubernetes-admin@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: kubernetes-admin</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: xxx=</span><br><span class="line">    client-key-data: xxx=</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/kubelet.conf</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: xxx=</span><br><span class="line">    server: https://10.230.56.118:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: system:node:vps</span><br><span class="line">  name: system:node:vps@kubernetes</span><br><span class="line">current-context: system:node:vps@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: system:node:vps</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: xxx=</span><br><span class="line">    client-key-data: xxx==</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/controller-manager.conf</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: xxx=</span><br><span class="line">    server: https://10.230.56.118:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: system:kube-controller-manager</span><br><span class="line">  name: system:kube-controller-manager@kubernetes</span><br><span class="line">current-context: system:kube-controller-manager@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: system:kube-controller-manager</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: xxx==</span><br><span class="line">    client-key-data: xxx=</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/scheduler.conf</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: xxx=</span><br><span class="line">    server: https://10.230.56.118:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: system:kube-scheduler</span><br><span class="line">  name: system:kube-scheduler@kubernetes</span><br><span class="line">current-context: system:kube-scheduler@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: system:kube-scheduler</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: xxx==</span><br><span class="line">    client-key-data: xxx==</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/manifests/kube-apiserver.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    component: kube-apiserver</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: kube-apiserver</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-apiserver</span><br><span class="line">    - --authorization-mode=Node,RBAC</span><br><span class="line">    - --advertise-address=10.230.56.118</span><br><span class="line">    - --allow-privileged=true</span><br><span class="line">    - --client-ca-file=/etc/kubernetes/pki/ca.crt</span><br><span class="line">    - --disable-admission-plugins=PersistentVolumeLabel</span><br><span class="line">    - --enable-admission-plugins=NodeRestriction</span><br><span class="line">    - --enable-bootstrap-token-auth=true</span><br><span class="line">    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt</span><br><span class="line">    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key</span><br><span class="line">    - --etcd-servers=https://127.0.0.1:2379</span><br><span class="line">    - --insecure-port=0</span><br><span class="line">    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt</span><br><span class="line">    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key</span><br><span class="line">    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span><br><span class="line">    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt</span><br><span class="line">    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key</span><br><span class="line">    - --requestheader-allowed-names=front-proxy-client</span><br><span class="line">    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt</span><br><span class="line">    - --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">    - --requestheader-group-headers=X-Remote-Group</span><br><span class="line">    - --requestheader-username-headers=X-Remote-User</span><br><span class="line">    - --secure-port=6443</span><br><span class="line">    - --service-account-key-file=/etc/kubernetes/pki/sa.pub</span><br><span class="line">    - --service-cluster-ip-range=10.96.0.0/12</span><br><span class="line">    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt</span><br><span class="line">    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key</span><br><span class="line">    image: k8s.gcr.io/kube-apiserver-amd64:v1.11.0</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    livenessProbe:</span><br><span class="line">      failureThreshold: 8</span><br><span class="line">      httpGet:</span><br><span class="line">        host: 10.230.56.118</span><br><span class="line">        path: /healthz</span><br><span class="line">        port: 6443</span><br><span class="line">        scheme: HTTPS</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    name: kube-apiserver</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 250m</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /etc/kubernetes/pki</span><br><span class="line">      name: k8s-certs</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/ssl/certs</span><br><span class="line">      name: ca-certs</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /usr/share/ca-certificates</span><br><span class="line">      name: usr-share-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /usr/local/share/ca-certificates</span><br><span class="line">      name: usr-local-share-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/ca-certificates</span><br><span class="line">      name: etc-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  priorityClassName: system-cluster-critical</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/pki</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: k8s-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/ssl/certs</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: ca-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /usr/share/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: usr-share-ca-certificates</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /usr/local/share/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: usr-local-share-ca-certificates</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etc-ca-certificates</span><br><span class="line">status: &#123;&#125;</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/manifests/kube-controller-manager.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    component: kube-controller-manager</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: kube-controller-manager</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-controller-manager</span><br><span class="line">    - --address=127.0.0.1</span><br><span class="line">    - --allocate-node-cidrs=true</span><br><span class="line">    - --cluster-cidr=10.244.0.0/16</span><br><span class="line">    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt</span><br><span class="line">    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key</span><br><span class="line">    - --controllers=*,bootstrapsigner,tokencleaner</span><br><span class="line">    - --kubeconfig=/etc/kubernetes/controller-manager.conf</span><br><span class="line">    - --leader-elect=true</span><br><span class="line">    - --node-cidr-mask-size=24</span><br><span class="line">    - --root-ca-file=/etc/kubernetes/pki/ca.crt</span><br><span class="line">    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key</span><br><span class="line">    - --use-service-account-credentials=true</span><br><span class="line">    image: k8s.gcr.io/kube-controller-manager-amd64:v1.11.0</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    livenessProbe:</span><br><span class="line">      failureThreshold: 8</span><br><span class="line">      httpGet:</span><br><span class="line">        host: 127.0.0.1</span><br><span class="line">        path: /healthz</span><br><span class="line">        port: 10252</span><br><span class="line">        scheme: HTTP</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    name: kube-controller-manager</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 200m</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /usr/share/ca-certificates</span><br><span class="line">      name: usr-share-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /usr/local/share/ca-certificates</span><br><span class="line">      name: usr-local-share-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/ca-certificates</span><br><span class="line">      name: etc-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/kubernetes/pki</span><br><span class="line">      name: k8s-certs</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/ssl/certs</span><br><span class="line">      name: ca-certs</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/kubernetes/controller-manager.conf</span><br><span class="line">      name: kubeconfig</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec</span><br><span class="line">      name: flexvolume-dir</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  priorityClassName: system-cluster-critical</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/pki</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: k8s-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/ssl/certs</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: ca-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/controller-manager.conf</span><br><span class="line">      type: FileOrCreate</span><br><span class="line">    name: kubeconfig</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: flexvolume-dir</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /usr/share/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: usr-share-ca-certificates</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /usr/local/share/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: usr-local-share-ca-certificates</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etc-ca-certificates</span><br><span class="line">status: &#123;&#125;</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/manifests/kube-scheduler.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    component: kube-scheduler</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: kube-scheduler</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-scheduler</span><br><span class="line">    - --address=127.0.0.1</span><br><span class="line">    - --kubeconfig=/etc/kubernetes/scheduler.conf</span><br><span class="line">    - --leader-elect=true</span><br><span class="line">    image: k8s.gcr.io/kube-scheduler-amd64:v1.11.0</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    livenessProbe:</span><br><span class="line">      failureThreshold: 8</span><br><span class="line">      httpGet:</span><br><span class="line">        host: 127.0.0.1</span><br><span class="line">        path: /healthz</span><br><span class="line">        port: 10251</span><br><span class="line">        scheme: HTTP</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    name: kube-scheduler</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 100m</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /etc/kubernetes/scheduler.conf</span><br><span class="line">      name: kubeconfig</span><br><span class="line">      readOnly: true</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  priorityClassName: system-cluster-critical</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/scheduler.conf</span><br><span class="line">      type: FileOrCreate</span><br><span class="line">    name: kubeconfig</span><br><span class="line">status: &#123;&#125;</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/manifests/etcd.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    component: etcd</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: etcd</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - etcd</span><br><span class="line">    - --advertise-client-urls=https://127.0.0.1:2379</span><br><span class="line">    - --cert-file=/etc/kubernetes/pki/etcd/server.crt</span><br><span class="line">    - --client-cert-auth=true</span><br><span class="line">    - --data-dir=/var/lib/etcd</span><br><span class="line">    - --initial-advertise-peer-urls=https://127.0.0.1:2380</span><br><span class="line">    - --initial-cluster=vps=https://127.0.0.1:2380</span><br><span class="line">    - --key-file=/etc/kubernetes/pki/etcd/server.key</span><br><span class="line">    - --listen-client-urls=https://127.0.0.1:2379</span><br><span class="line">    - --listen-peer-urls=https://127.0.0.1:2380</span><br><span class="line">    - --name=vps</span><br><span class="line">    - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt</span><br><span class="line">    - --peer-client-cert-auth=true</span><br><span class="line">    - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key</span><br><span class="line">    - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">    - --snapshot-count=10000</span><br><span class="line">    - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">    image: k8s.gcr.io/etcd-amd64:3.2.18</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    livenessProbe:</span><br><span class="line">      exec:</span><br><span class="line">        command:</span><br><span class="line">        - /bin/sh</span><br><span class="line">        - -ec</span><br><span class="line">        - ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">          --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt --key=/etc/kubernetes/pki/etcd/healthcheck-client.key</span><br><span class="line">          get foo</span><br><span class="line">      failureThreshold: 8</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    name: etcd</span><br><span class="line">    resources: &#123;&#125;</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /var/lib/etcd</span><br><span class="line">      name: etcd-data</span><br><span class="line">    - mountPath: /etc/kubernetes/pki/etcd</span><br><span class="line">      name: etcd-certs</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  priorityClassName: system-cluster-critical</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/pki/etcd</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etcd-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /var/lib/etcd</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etcd-data</span><br><span class="line">status: &#123;&#125;</span><br><span class="line">root@vps:~#</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/13/Using-kubeadm-to-deploy-k8s/" data-id="cjkgczyew000gkobp797z5th5" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-用OpenSSL做自签名的证书" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/13/用OpenSSL做自签名的证书/" class="article-date">
  <time datetime="2018-07-13T05:10:13.000Z" itemprop="datePublished">2018-07-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/13/用OpenSSL做自签名的证书/">用OpenSSL做自签名的证书</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>作者：张华  发表于：2014-04-18<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</p>
<p>(<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</p>
<p>加密技术回顾<br>非对称加密算法如RSA的特点如下:<br>1, 公钥加密私钥解密, 大家都可以用我的公钥给我发加密的数据了, 因为只有我有私钥才能解密.<br>2, 私钥加密公钥解密叫数字签名(例如所谓的UEFI secure boot就是在主板硬件里集成一些操作系统的公钥，由主板硬件去校验操作系统是法合法，但关键是微软把持了公钥的申请，主板硬件厂商没有提供界面让用法自定义公钥，尤其在移动领域很多win8的硬件根本不提供关闭secure boot的选项这样就造成只能安装win8一种系统）, 大家收到我用私钥加密后的数据, 看用公钥能不能打得开, 能打开说明这数据确实是由我所发的, 因为别人没有我的私钥不可能伪造这些数据.<br>非对称加密去处很费时间, 我们一般采用对称密钥算法如DES来加密, 但对称密钥的保存是一个问题.<br>所以我们可以采用非对称加密算法来加密先协商交换对称密钥, 这就叫SSL. 假设客户端A的公私钥对是(P1,V1), 服务端B的公私钥对是(P2,V2), A需要确认和它通信的是B, 那么SSL的过程是:<br>首先, A和B都持有对方的公钥.<br>step1, A-&gt;B: hello 是step2, B-&gt;A: 用V2加密过的P1（即用户证书，A就用P2解密出P1, 这种数字签名方式让A确定了和它通信的是B）<br>step3, A-&gt;B: ok<br>step4, B-&gt;A: 用V1加密的一段信息<br>step5, A-&gt;B: 用P1加密一个自动生成的对称密钥K（用之前的P1解密成功这段信息则认为B是可信的了）<br>step6, B-&gt;A: 用K加密的数据（之后两对密钥功能结束，由K来加解密数据）<br>总结一下, 这里(P2,V2)就是certificate authority (CA)用来给客户签名用的公私钥。<br>(P1,V1)是客户自己的公私钥，提交给CA，CA所做的事情就是上述step2用(P2,V2)来给客户的(P1,V1)签名，简单吧？<br>V2是CA公司要保密的，而P2就是公用CA证书要安装到客户端</p>
<p>用V2加密过（签名过）的P1，称为用户证书，和用户私钥V1连起一个文件后, 一般被安装在服务器端。</p>
<p>X.509证书是一些标准字段的集合, 是包含有关用户或设备及其相应公钥信息的一种非常通用的证书格式, 目前版本是3. 必要字段包括:<br>1, 版本号<br>2, 由CA给每一个证书分配的序列号;<br>3, 证书使用的签名算法<br>4, 证书的认证机构<br>5, 证书的有效日期<br>6, 证书的所有人的唯一标识<br>7, 认证机构使用私钥的数字签名<br>8, 公钥信息<br>不同于PGP证书任何人都可以扮演认证者的角色, X.509证书的认证者只能是CA或由CA指定的人.要获得一份X.509证书，必须请求CA发给你证书。用户提供自己的公钥，证明自己拥有相应的私钥，并提供有关自己的某些特定信息。然后在这些信息上数字签名，并将整个数据包(称为证书请求)发给CA。CA做一些努力来验证用户提供的信息是正确的，然后就生成证书并返回给用户。<br>OpenSSL对X.509的支持如下:<br>(1) 证书请求管理<br>(2) 证书生成<br>(3) 证书吊销及CRL管理<br>(4) X509名字管理<br>(5) 属性管理<br>(6) 扩展管理<br>(7) 验证及信任管理</p>
<p>用OpenSSL做自签名的证书(pem格式)步骤:<br>1, 先生成CA的公私钥<br>   mkdir CA &amp; cd CA<br>   mkdir newcerts private<br>   echo ‘01’ &gt; serial #会生成以为个数字为名字的pem文件, 且每个数字自增1<br>   touch index.txt #生成记录数据库<br>   使用配置文件, 由于openssl命令行参数太多, 为避免写太多, 就使用一个配置文件代替, 如<a href="https://github.com/openstack/nova/blob/master/nova/CA/openssl.cnf.tmpl" target="_blank" rel="external">https://github.com/openstack/nova/blob/master/nova/CA/openssl.cnf.tmpl</a><br>   生成(P2,V2), 这时候P2=cacert.pem, V2=private/cakey.pem<br>   openssl req -new -x509 -extensions v3_ca -keyout private/cakey.pem -out cacert.pem -days 365 -config ./openssl.cnf -batch -nodes<br>   查看证书信息, openssl x509 -in cacert.pem -noout -text<br>2, 生成<p1,v1>,即Certificate signing Reqeust(CSR), P1=req.pem, V1=key.pem<br>   openssl req -new -nodes -out req.pem -config ./openssl.cnf<br>3, 用CA的私钥V2为P1签名, 即在newcerts目录生成用户证书cert.pem, 并更新数据库文件index.txt及serail文件<br>   openssl ca -out cert.pem -config ./openssl.cnf -infiles req.pem<br>   查看证书信息, openssl x509 -in cert.pem -noout -text<br>4, 安装证书<br>   用户私钥key.pem(V1)和用V2加密过的用户公钥(cert.pem)安装到服务端(有的服务器碉要把这两个文件连成一个,可以执行: cat key.pem cert.pem &gt; key-cert.pem), 如:<br>   /home/httpd/ssl/cert.pem Site certificate<br>   /home/httpd/ssl/key.pem Site private key<br>   最后将CA的公钥P2=cacert.pem安装到客户端</p1,v1></p>
<p>在OpenStack PKI认证中：<br>1, Keystone产生了CA公私钥: CA.pem, CA.key<br>2, Keystone产生了用户公私钥: keystone.pub, keystone.key<br>3, Keystone产生了用户证书: keystone.pem (即使用CA.key对keystone.pub进行了签名)<br>假如nova要使用PKI认证的话：<br>1, CA端，即keystone端，安装有: CA.pem, CA.key, keystone.key, keystone.pem<br>2, 用户端，即nova端，安装有：keystone.pem<br>过程：<br>1, 用户拿用户名和密码去keystone认证，keystone将用户信息通过keystone.key进行签名后作为token返回用户<br>2, 用户用这一token去访问nova, nova拿到token后，使用keystone.pem解密。（而原来的UUID方式nova还得再拿token去keystone那边验证一下是否有效，所以使用PKI方式能减轻keystone的压力。</p>
<p>再举个例子，如在安装openconnect时生成证书：</p>
<p>sudo apt-get -y install build-essential pkg-config libgnutls28-dev libreadline-dev libseccomp-dev libwrap0-dev libnl-nf-3-dev liblz4-dev gnutls-bin</p>
<p>#Create CA certificate<br>mkdir -p /tmp/cert &amp;&amp; cd /tmp/cert<br>cat &gt; /tmp/cert/ca.tmpl &lt;&lt; EOF<br>cn = “sts CA”<br>organization = “sts CA”<br>serial = 1<br>expiration_days = 3650<br>ca<br>signing_key<br>cert_signing_key<br>crl_signing_key<br>EOF</p>
<p>#Generate CA secret KEY: V2<br>certtool –generate-privkey –outfile CA.key</p>
<p>#Generate CA certifice: P2 signed by V2<br>certtool –generate-self-signed –load-privkey CA.key –template ca.tmpl –outfile CA.pem</p>
<p>#Create User certificate (here is for VPN server)<br>cat &gt; /tmp/cert/vpnserver.tmpl &lt;&lt; EOF<br>cn = “sts vpn server”<br>organization = “sts”<br>expiration_days = 3650<br>signing_key<br>encryption_key<br>tls_www_server<br>EOF</p>
<p>#Generate User secret KEY: V1<br>certtool –generate-privkey –outfile vpnserver.key</p>
<p>#Generate User certificate: <p1 signed="" by="" v2=""><br>certtool –generate-certificate –load-privkey vpnserver.key –load-ca-certificate CA.pem –load-ca-privkey CA.key –template vpnserver.tmpl –outfile vpnserver.pem</p1></p>
<p>#CA.pem,vpnserver,pem,vpnserver.key need to be installed in vpnserver<br>sudo cp CA.pem /etc/ssl/certs/CA.pem<br>sudo cp vpnserver.pem /etc/ssl/private/vpnserver.pem<br>sudo cp vpnserver.key /etc/ssl/private/vpnserver.key<br>OpenStack创建CA的方法：</p>
<p>openssl genrsa -out /etc/keystone/ssl/private/cakey.pem 1024<br>openssl req -new -x509 -extensions v3_ca -key /etc/keystone/ssl/private/cakey.pem -out /etc/keystone/ssl/certs/ca.pem -days 3650 -config /etc/keystone/ssl/certs/openssl.conf -subj /C=US/ST=Unset/L=Unset/O=Unset/CN=localhost<br>openssl genrsa -out /etc/keystone/ssl/private/keystonekey.pem 1024<br>openssl req -key /etc/keystone/ssl/private/keystonekey.pem -new -out /etc/keystone/ssl/certs/req.pem -config /etc/keystone/ssl/certs/openssl.conf -subj /C=US/ST=Unset/L=Unset/O=Unset/CN=localhost<br>openssl ca -batch -out /etc/keystone/ssl/certs/keystone.pem -config /etc/keystone/ssl/certs/openssl.conf -days 3650d -cert /etc/keystone/ssl/certs/ca.pem -keyfile /etc/keystone/ssl/private/cakey.pem -infiles /etc/keystone/ssl/certs/req.pem</p>
<p>再看一个使用easy-rsa为openvpn生成证书的实例：</p>
<p>sudo apt-get install easy-rsa openssl<br>sudo cp -r /usr/share/easy-rsa/ /etc/openvpn<br>cd /etc/openvpn/easy-rsa<br>sudo chown -R <code>whoami</code>:root /etc/openvpn<br>mkdir /etc/openvpn/easy-rsa/keys<br>source ./vars<br>export KEY_COUNTRY=CN<br>export KEY_PROVINCE=BJ<br>export KEY_CITY=BJ<br>export KEY_ORG=sts<br>export KEY_OU=sts<br>export KEY_NAME=sts<br>export KEY_EMAIL=root@sts<br>export KEY_NAME=”server”<br>./clean-all<br>./build-ca<br>$ ls keys/<br>ca.crt  ca.key  index.txt  serial<br>./build-key-server server<br>$ ls keys/<br>01.pem  ca.key     index.txt.attr  serial      server.crt  server.key<br>ca.crt  index.txt  index.txt.old   serial.old  server.csr<br>cp /etc/openvpn/easy-rsa/keys/{server.crt,server.key,ca.crt} /etc/openvpn</p>
<p>#It’s ideal for each client connecting to the VPN to have its own unique certificate and key.</p>
<p>#This is preferable to generating one general certificate and key to use among all client devices.<br>./build-key client1<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/client1.crt /etc/openvpn/<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/client1.key /etc/openvpn/<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/client.ovpn /etc/openvpn/<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/ca.crt /etc/openvpn/</server></server></server></server></p>
<p>常见证书格式及转换</p>
<p>PKCS(Public-Key Cryptography Standards), 是由RSA实验室与其他安全系统开发商共同制定的一个公钥密码标准<br>X.509是常用的通用的证书格式, 所有的证书都符合PKI(Public Key Infrastructure)制定的的ITU-T X509国际标准<br>.cer/.crt是用于存储证书, 以二进制形式存储, 不含私钥<br>.pem跟.cer/.crt的区别是它以ascii来表示<br>pfx/p12用于存放个人证书/私钥, 他通常包含保护密码, 二进制存储, 转换如:openssl pkcs12 -export -clcerts -in server-cert.cer -inkey server-key.key -out server.p12<br>JKS和JCEKS是Java密钥库(KeyStore)的两种比较常见类型, 可以使用java提供的证书工具keytool(openssl和keytool都是可以用来管理证书的工具而已)进行转换(如:keytool -import -v -trustcacerts -storepass 123456 -alias server -file cacert.pem -keystore server.jks)</p>
<p>例如： k8s中的dashboard若不在浏览器里导入p12证书在采用RBAC授权时就会什么也看不到：</p>
<h1 id="generate-client-certificate-data"><a href="#generate-client-certificate-data" class="headerlink" title="generate client-certificate-data"></a>generate client-certificate-data</h1><p>grep ‘client-certificate-data’ /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk ‘{print $2}’ | base64 -d &gt;&gt; kubecfg.crt</p>
<h1 id="generate-client-key-data"><a href="#generate-client-key-data" class="headerlink" title="generate client-key-data"></a>generate client-key-data</h1><p>grep ‘client-key-data’ /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk ‘{print $2}’ | base64 -d &gt;&gt; kubecfg.key</p>
<h1 id="generate-p12"><a href="#generate-p12" class="headerlink" title="generate p12"></a>generate p12</h1><p>openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name “kubernetes-client”</p>
<p>非对称算法可以使用开源的GPG工具，可参考文档： <a href="http://wenku.baidu.com/link?url=d5fWoN46-y7581212dDUEt7dkUfFkriW0bKy_gwUjps4zpKH64jytimWDm-yfuKIwAtu0jFoWW_ocVTJhSeRb2_QQLUz8oIBQulU6jSI133" target="_blank" rel="external">http://wenku.baidu.com/link?url=d5fWoN46-y7581212dDUEt7dkUfFkriW0bKy_gwUjps4zpKH64jytimWDm-yfuKIwAtu0jFoWW_ocVTJhSeRb2_QQLUz8oIBQulU6jSI133</a></p>
<p>及：<br><a href="https://help.ubuntu.com/community/GnuPrivacyGuardHowto" target="_blank" rel="external">https://help.ubuntu.com/community/GnuPrivacyGuardHowto</a></p>
<p>sudo apt-get install rng-tools<br>sudo rngd -r /dev/urandom</p>
<p>sudo apt-get install gnupg-agent<br>killall -q gpg-agent<br>eval $(gpg-agent –daemon)</p>
<p>创建密钥对：gpg –gen-key， 如创建了：”Zhang Hua (zhhuabj) <a href="&#x6d;&#x61;&#105;&#108;&#116;&#111;&#x3a;&#118;&#x65;&#x72;&#121;&#104;&#117;&#97;&#x32;&#48;&#48;&#x36;&#64;&#x67;&#109;&#97;&#x69;&#x6c;&#46;&#x63;&#111;&#x6d;">&#118;&#x65;&#x72;&#121;&#104;&#117;&#97;&#x32;&#48;&#48;&#x36;&#64;&#x67;&#109;&#97;&#x69;&#x6c;&#46;&#x63;&#111;&#x6d;</a>“</p>
<pre><code>export GPGKEY=A24B36AE
</code></pre><p>查看公钥：gpg –list-public<br>查看私钥：gpg –list-secret-key<br>查看签名：gpg –list-sig<br>查看公钥指纹：gpg –fingerprint $GPGKEY<br>提取公钥：gpg –armor –output public.key –export $GPGKEY  或者： gpg –export -a $GPGKEY &gt; public.key</p>
<p>提取私钥：gpg -a –export-secret-keys $KEYID &gt; customer-mirror.key<br>生成公钥回收证书，当私钥出问题时可将它上传密钥服务器声明公钥作废:<br>  gpg –output revoke.asc –gen-revoke $GPGKEY<br>  声明作废：gpg –keyserver Server Address –send-keys $GPGKEY</p>
<p>迁移KEY</p>
<p>gpg –output mygpgkey_pub.gpg –armor –export  $GPGKEY<br>gpg –output mygpgkey_sec.gpg –armor –export-secret-key $GPGKEY</p>
<p>gpg –import mygpgkey_pub.gpg<br>gpg –allow-secret-key-import –import mygpgkey_sec.gpg</p>
<p>上传公钥到密钥服务器，如：gpg –send-keys –keyserver keyserver.ubuntu.com $GPGKEY 或把公钥导成文本之后直接在<a href="http://keyserver.ubuntu.com/这里提交公钥。" target="_blank" rel="external">http://keyserver.ubuntu.com/这里提交公钥。</a></p>
<p>交互命令窗口：gpg –cert-digest-algo=SHA256 –edit-key $GPGKEY</p>
<p>给自己加密文件，加密是用公钥，gpg –encrypt -r veryhua2006@gmail.com test.txt, 会生成名为test.txt.gpg的加密文件<br>给自己解决文件，gpg –decrypt test.txt.gpg &gt; test.txt</p>
<p>给别人加密文件当然要先导入别人的公钥：gpg –import otherpublic.key<br>核对对方的公钥指纹：gpg –fingerprint other@gmail.com<br>为别人加密文件: gpg –encrypt –recipient other@gmail.com test.txt<br>对别人的公钥进行签名，这样别人知道是你发的： gpg –sign-key other@gmail.com</p>
<p>对文件进行签名： gpg –clearsign file<br>验证签名是否完整： gpg –verity file.asc</p>
<p>OpenPGP能用于加密邮件，将GPG指纹注册到launchpad中(<a href="https://launchpad.net/~zhhuabj)，这样launchpad将给你发签名或加密过的邮件，然后再用openPGP" target="_blank" rel="external">https://launchpad.net/~zhhuabj)，这样launchpad将给你发签名或加密过的邮件，然后再用openPGP</a> enabled的邮件客户端如thunderbird来接收解密邮件和验证签名。<br>thunderbird通过enigmail插件来支持OpenPGP, Configure OpenPGP support in Thunderbird under Enigmail-&gt;Preferences and add under GnuPG executable path. The path for GnuPG is /usr/bin/gpg.<br>如果不想用邮件客户端，直接用firefox来访问如gmail等webmail的话，安装firegpg插件即可。chrome不需要装插件直接支持pgp解密。</p>
<p>将GPG指纹（gpg –fingerprint)注册到launchpad中(<a href="https://launchpad.net/~zhhuabj)后会收到一封邮件，内容类似如下，将其存成一个文件，再解密(gpg" target="_blank" rel="external">https://launchpad.net/~zhhuabj)后会收到一封邮件，内容类似如下，将其存成一个文件，再解密(gpg</a> –decrypt file.txt)后就生成了一个验证链接如<a href="https://launchpad.net/token/Hc7J9x7kF55CHTZJs，点击验证即可。" target="_blank" rel="external">https://launchpad.net/token/Hc7J9x7kF55CHTZJs，点击验证即可。</a><br>—–BEGIN PGP MESSAGE—–<br>Version: GnuPG v1.4.11 (GNU/Linux)<br>…….<br>52gY/bZADAl0xhScHvvuYquGS3oApfgtNM3UJWXa<br>=ZgnD<br>—–END PGP MESSAGE—–</p>
<p>Signed Ubuntu Code of Conduct in <a href="https://launchpad.net/~zhhuabj，" target="_blank" rel="external">https://launchpad.net/~zhhuabj，</a><br>1, 先下载UbuntuCodeofConduct-2.0.txt, <a href="https://launchpad.net/codeofconduct/2.0/+download" target="_blank" rel="external">https://launchpad.net/codeofconduct/2.0/+download</a><br>2, gpg –clearsign UbuntuCodeofConduct-2.0.txt<br>3, 将生成的UbuntuCodeofConduct-2.0.txt.asc文件再上传至 <a href="https://launchpad.net/codeofconduct/2.0/+sign即可。" target="_blank" rel="external">https://launchpad.net/codeofconduct/2.0/+sign即可。</a></p>
<p>2014-5-23日添加，配置使用Google Authenticator服务</p>
<p>Google帐户支持密码+临时验证码的两阶段验证方式。<br>临时验证码也支持直接短信发到手机上，也可以在Android手机上安装Google Authenticator服务来接收临时验证码。<br>具体先在<a href="https://accounts.google.com/b/0/SmsAuthConfig页面配置，并先生成google服务端为安装了Google" target="_blank" rel="external">https://accounts.google.com/b/0/SmsAuthConfig页面配置，并先生成google服务端为安装了Google</a> Authenticator服务的客户端生成的密钥。然后再在Google Authenticator里输入这个密钥就可以实现一次一密了。</p>
<p>参考:<br><a href="http://www.blogjava.net/alwayscy/archive/2006/12/01/84852.html" target="_blank" rel="external">http://www.blogjava.net/alwayscy/archive/2006/12/01/84852.html</a><br><a href="http://blog.sina.com.cn/s/blog_9e9d2211010199yj.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_9e9d2211010199yj.html</a></p>
<p><a href="http://lingxiankong.github.io/blog/2014/02/06/openstack-ssl/" target="_blank" rel="external">http://lingxiankong.github.io/blog/2014/02/06/openstack-ssl/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/13/用OpenSSL做自签名的证书/" data-id="cjkgczyfi000qkobp3o7f5r2l" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Set-up-k8s-development-env-by-quqi99" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/10/Set-up-k8s-development-env-by-quqi99/" class="article-date">
  <time datetime="2018-07-10T09:47:57.000Z" itemprop="datePublished">2018-07-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/10/Set-up-k8s-development-env-by-quqi99/">Set up k8s development env (by quqi99)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-07-10)</strong></p>
<h2 id="Sign-the-CLA"><a href="#Sign-the-CLA" class="headerlink" title="Sign the CLA"></a>Sign the CLA</h2><p>Sign via Hellosign - <a href="https://github.com/kubernetes/community/blob/master/CLA.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/CLA.md</a><br>then set email for github - <a href="https://github.com/settings/emails" target="_blank" rel="external">https://github.com/settings/emails</a><br>git config –global user.email “xxx@gmail.com”</p>
<h2 id="Run-local-k8s-via-source-code"><a href="#Run-local-k8s-via-source-code" class="headerlink" title="Run local k8s  via source code"></a>Run local k8s  via source code</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># Install some packages</span><br><span class="line">sudo apt install -y gcc make socat git build-essential</span><br><span class="line"></span><br><span class="line"># Install docker</span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line">sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt-cache policy docker-ce</span><br><span class="line">sudo apt install docker-ce</span><br><span class="line"></span><br><span class="line"># Change default location of docker image</span><br><span class="line">service docker stop</span><br><span class="line">rsync -aXS /var/lib/docker/* /bak/.docker/</span><br><span class="line">rm -rf /var/lib/docker/*</span><br><span class="line">echo /bak/.docker/ /var/lib/docker none bind 0 0 &gt;&gt; /etc/fstab</span><br><span class="line">mount –a</span><br><span class="line">service docker start</span><br><span class="line"></span><br><span class="line"># Install etcd &gt; 3.2.13</span><br><span class="line">ETCD_VER=v3.2.18</span><br><span class="line">DOWNLOAD_URL=&quot;https://github.com/coreos/etcd/releases/download&quot;</span><br><span class="line">curl -L $&#123;DOWNLOAD_URL&#125;/$&#123;ETCD_VER&#125;/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz -o /tmp/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz</span><br><span class="line">tar xzvf /tmp/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz</span><br><span class="line">sudo /bin/cp -f etcd-$&#123;ETCD_VER&#125;-linux-amd64/&#123;etcd,etcdctl&#125; /usr/bin</span><br><span class="line">rm -rf /tmp/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz etcd-$&#123;ETCD_VER&#125;-linux-amd64</span><br><span class="line"></span><br><span class="line"># Install golang &gt; 1.10.2</span><br><span class="line">wget https://dl.google.com/go/go1.10.3.linux-amd64.tar.gz</span><br><span class="line">sudo rm -rf /usr/lib/go &amp;&amp; sudo tar -C /usr/lib -xzf go1.10.3.linux-amd64.tar.gz</span><br><span class="line">export GOROOT=/usr/lib/go</span><br><span class="line">export GOPATH=/bak/golang</span><br><span class="line">export PATH=$GOROOT/bin:$GOPATH/bin:$PATH</span><br><span class="line"></span><br><span class="line"># Install and run kubernetes in local env - https://www.cnblogs.com/edisonxiang/p/6951787.html</span><br><span class="line">mkdir -p $GOPATH/src/k8s.io</span><br><span class="line">#go get -d k8s.io/kubernetes</span><br><span class="line">git clone git@github.com:zhhuabj/kubernetes.git $GOPATH/src/k8s.io/kubernetes</span><br><span class="line">#make GOGCFLAGS=&quot;-N -l&quot;  #Debug it</span><br><span class="line">sudo usermod -a -G docker $&#123;USER&#125;</span><br><span class="line">sudo systemctl restart docker.service</span><br><span class="line">sudo systemctl disable kubelet.service</span><br><span class="line">sudo systemctl stop kubelet.service</span><br><span class="line"></span><br><span class="line">#注意：一直不成功的原因是需要用小写true，它是区分大小写的</span><br><span class="line">KUBE_ENABLE_CLUSTER_DASHBOARD=true ./hack/local-up-cluster.sh</span><br><span class="line">#注意：加GO_OUT可避免再次编译</span><br><span class="line">GO_OUT=/bak/golang/src/k8s.io/kubernetes/_output/bin</span><br><span class="line">KUBE_ENABLE_CLUSTER_DASHBOARD=true ./hack/local-up-cluster.sh</span><br><span class="line"></span><br><span class="line"># Test local env</span><br><span class="line">export KUBECONFIG=/var/run/kubernetes/admin.kubeconfig</span><br><span class="line">cluster/kubectl.sh get pods --all-namespaces</span><br></pre></td></tr></table></figure>
<h2 id="github-process"><a href="#github-process" class="headerlink" title="github process"></a>github process</h2><p><a href="https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md</a><br>k8s与openstack不一样，openstack使用gerrit来review code, 但是k8s使用github的PR机制。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">kubernetes提交PR的流程可以采用pull模型（Shared Repository Model，https://gist.github.com/seshness/3943237），也可以采用fork模型（https://www.cnblogs.com/edisonxiang/p/6951787.html）。我们采用fork模型：</span><br><span class="line"></span><br><span class="line"># Click &apos;Fork&apos; button to fork your own branch - https://github.com/kubernetes/kubernetes, then we have https://github.com/zhhuabj/kubernetes</span><br><span class="line">mkdir -p $GOPATH/src/k8s.io</span><br><span class="line">git clone git@github.com:zhhuabj/kubernetes.git $GOPATH/src/k8s.io/kubernetes</span><br><span class="line">cd kubernetes</span><br><span class="line">hack/local-up-cluster.sh</span><br><span class="line"></span><br><span class="line"># set up upstream branch</span><br><span class="line">git remote add upstream https://github.com/kubernetes/kubernetes.git</span><br><span class="line">git remote set-url --push upstream no_push</span><br><span class="line">git remote -v</span><br><span class="line"></span><br><span class="line"># Update our branch</span><br><span class="line">git fetch upstream</span><br><span class="line">git checkout master</span><br><span class="line">git rebase upstream/master</span><br><span class="line">#git pull upstream master</span><br><span class="line"></span><br><span class="line"># Add new branch myfeature</span><br><span class="line">git checkout -b myfeature</span><br><span class="line">git config --global user.email &quot;veryhua2006@gmail.com&quot;</span><br><span class="line">git config --global user.name &quot;zhhuabj&quot;</span><br><span class="line"># Add or Modify files</span><br><span class="line">...</span><br><span class="line">git add .</span><br><span class="line">git commit -a -F ./msg</span><br><span class="line">git commit --amend -a -F ./message</span><br><span class="line">git commit -m &quot;update&quot;</span><br><span class="line">git push origin myfeature</span><br><span class="line">git push origin :myfeature  #delete remote branch</span><br><span class="line"></span><br><span class="line"># Rebase unmerged PR into our repo</span><br><span class="line">git fetch upstream pull/56136/head:BRANCHNAME</span><br><span class="line"></span><br><span class="line"># Merge multiple local commits into a full commit by using &apos;git squash&apos;</span><br><span class="line">git log</span><br><span class="line">git rebase -i HEAD~6 把顶部的六个版本聚到一起进入编辑页面</span><br><span class="line">　　把需要压缩的日志前面的pick都改为s（squash的缩写）</span><br><span class="line">　　注意必须保留一个pick，如果将所有的pick都改为了s那就没有合并的载体了就会报如下错误</span><br><span class="line">　　依次输入CTRL+X Y ENTER三个命令完成编辑。</span><br><span class="line">　　最后Git Push orgin branchname</span><br><span class="line"></span><br><span class="line"># Pull Request - https://github.com/zhhuabj/kubernetes, 在新上传的Branch上，点击Compare &amp; Pull Request按钮创建一个Pull Requst</span><br><span class="line"></span><br><span class="line"># 最后https://github.com/kubernetes/kubernetes/pulls就可以找到刚刚提交的Pull Request。</span><br></pre></td></tr></table></figure></p>
<h2 id="Review-process"><a href="#Review-process" class="headerlink" title="Review process"></a>Review process</h2><p><a href="https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md#the-testing-and-merge-workflow" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md#the-testing-and-merge-workflow</a><br> openstack社区更开放，使用gerrit机制，新人都能review代码，并能+1。<br>但k8s使用github的PR，相对封闭一些，新人是不能review代码的，新人的角色叫contributor，可以修改issue (在issue上回复/assign)并提交代码。<br>只有每个子模块下OWNERS文件定义的reviewer, approver角色的人员(<a href="https://github.com/kubernetes/community/blob/master/community-membership.md)才能review代码(reviewer可以LDTM(looks" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/community-membership.md)才能review代码(reviewer可以LDTM(looks</a> good to me, +1), approver可以+2，一个+1一个+2就可以进代码，但openstack中是只能两个+2才可以)</p>
<p>如果要为某个issue创建PR, 需要在PR的描述里填写fixes #issue_num 。这样PR在 merge后issue会“自动”关闭。PR创建后，k8s机器人会做以下几件事：<br>在相应OWNER列表里选取一个人做为reviewer<br>如果是kubernetes member，则启动CI来检查PR，例如UT, e2e test；如果不是kuberentes member ，则需要一个member帮忙启动相应ci<br>待CI没有问题后，可以ping相应的reviewers来检查代码了</p>
<p>在reviewer认为可以后，需要标lgtm (look go to me) 标签；同时需要该模块的approver标记approve标签。两个标签都有了以后，就可以等待合并了。代码的合并也是由k8s机器人完成的，可以在 <a href="http://submit-queue.k8s.io/#/queue" target="_blank" rel="external">http://submit-queue.k8s.io/#/queue</a> 看到等待合并的PR。在合并之前，k8s机器人也会自动重新跑ci以保证代码没有问题。<br>以上三步差不多就可以将typo提交到主干上。其中大部分工作都有k8s机器人自动完成，比如分配reviewer。<br>  Bot命令如下：</p>
<ul>
<li>Jenkins verification: @k8s-bot verify test this</li>
<li>GCE E2E: @k8s-bot cvm gce e2e test this</li>
<li>Test all: @k8s-bot test this please, issue #IGNORE</li>
<li>CRI test: @k8s-bot cri test this.</li>
<li>Verity test: @k8s-bot verify test this</li>
<li>LGTM (only applied if you are one of assignees):: /lgtm</li>
<li>LGTM cancel: /lgtm cancel<br>更多命令见 <a href="https://prow.k8s.io/command-help" target="_blank" rel="external">https://prow.k8s.io/command-help</a><h2 id="How-to-do-test"><a href="#How-to-do-test" class="headerlink" title="How to do test"></a>How to do test</h2><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md</a><br>make verify<br>make test<br>make test-integration<h2 id="How-to-debug-k8s"><a href="#How-to-debug-k8s" class="headerlink" title="How to debug k8s"></a>How to debug k8s</h2>local-up-cluster.sh是通过_output/local/bin/linux/amd64/hyperkube在容器里启动k8s各服务的，那样是不方便使用(dlv exec ${OUTDIR}/bin/kubelet – $kubelet_flags)来调试基于B/S的k8s服务的，那首先将k8s各服务以本地进程的形式启动，这样调试k8s服务就变得像调试openstack服务一样。</li>
</ul>
<p>1， 第一步创建systemd启动配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line">$ cat /lib/systemd/system/kube-etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-etcd Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/bin/etcd -name etcd -data-dir /var/lib/etcd \</span><br><span class="line">          -listen-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001 \</span><br><span class="line">          -advertise-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-apiserver Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-apiserver \</span><br><span class="line">            --admission-control=NamespaceAutoProvision,LimitRanger,SecurityContextDeny \</span><br><span class="line">            --apiserver-count=1 \</span><br><span class="line">            --cors-allowed-origins=.* \</span><br><span class="line">            --enable-garbage-collector=false \</span><br><span class="line">            --etcd-servers=http://127.0.0.1:2379 \</span><br><span class="line">            --insecure-bind-address=0.0.0.0 \</span><br><span class="line">            --insecure-port=8080 \</span><br><span class="line">            --log-dir=~/.kube/log/kube-apiserver \</span><br><span class="line">            --logtostderr=false \</span><br><span class="line">            --service-cluster-ip-range=10.0.0.0/16 \</span><br><span class="line">            --v=5 \</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-controller-manager Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-controller-manager \</span><br><span class="line">          --enable-garbage-collector=false \</span><br><span class="line">          --logtostderr=false \</span><br><span class="line">          --log-dir=~/.kube/log/kube-controller-manager \</span><br><span class="line">          --pod-eviction-timeout=5m0s \</span><br><span class="line">          --master=http://0.0.0.0:8080 \</span><br><span class="line">          --node-monitor-grace-period=40s \</span><br><span class="line">          --terminated-pod-gc-threshold=12500 \</span><br><span class="line">          --leader-elect=true \</span><br><span class="line">          --v=4 \</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-scheduler.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-scheduler Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-scheduler \</span><br><span class="line">            --log-dir=~/.k8s/log/kube-scheduler \</span><br><span class="line">            --logtostderr=false \</span><br><span class="line">            --master=http://0.0.0.0:8080 \</span><br><span class="line">            --leader-elect=true \</span><br><span class="line">            --v=5 \</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line"># prepare kubelet.kubeconfig and kube-proxy.kubeconfig</span><br><span class="line">export KUBE_APISERVER=&quot;http://127.0.0.1:8080&quot;</span><br><span class="line">./_output/bin/kubectl config set-cluster myk8s --server=$&#123;KUBE_APISERVER&#125; --kubeconfig=kubelet.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-credentials kubelet --kubeconfig=kubelet.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-context myk8s-context --cluster=myk8s --user=kubelet --kubeconfig=kubelet.kubeconfig</span><br><span class="line">./_output/bin/kubectl config use-context myk8s-context --kubeconfig=kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">./_output/bin/kubectl config set-cluster myk8s --server=$&#123;KUBE_APISERVER&#125; --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-credentials kube-proxy --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-context myk8s-context --cluster=myk8s --user=kube-proxy --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">./_output/bin/kubectl config use-context myk8s-context --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">cp *.kubeconfig /home/hua/.kube/</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=kubelet: The Kubernetes Node Agent</span><br><span class="line">Documentation=http://kubernetes.io/docs/</span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kubelet \</span><br><span class="line">          --address=127.0.0.1 --port=10250 --hostname-override=127.0.0.1 \</span><br><span class="line">          --pod-infra-container-image=docker.io/kubernetes/pause \</span><br><span class="line">          --fail-swap-on=false --cgroup-driver=cgroupfs \</span><br><span class="line">          --kubeconfig=/home/hua/.kube/kubelet.kubeconfig \</span><br><span class="line">          --runtime-cgroups=/systemd/system.slice \</span><br><span class="line">          --kubelet-cgroups=/systemd/system.slice \</span><br><span class="line">          --eviction-hard=&apos;nodefs.available&lt;1%&apos; \</span><br><span class="line">          --logtostderr=false --log-dir=~/.kube/log/kubelet --v=4</span><br><span class="line">Restart=always</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">RestartSec=10</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-proxy.service[Unit]</span><br><span class="line">Description=Kube-proxy Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-proxy \</span><br><span class="line">            --log-dir=~/.k8s/log/kube-proxy \</span><br><span class="line">            --logtostderr=false \</span><br><span class="line">            --master=http://0.0.0.0:8080 \</span><br><span class="line">            --kubeconfig=/home/hua/.kube/kube-proxy.kubeconfig \</span><br><span class="line">            --proxy-mode=userspace \</span><br><span class="line">            --v=5</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br></pre></td></tr></table></figure></p>
<p>2， 第二步，启动各服务:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl --system daemon-reload</span><br><span class="line">sudo systemctl start kube-etcd.service</span><br><span class="line">etcdctl -C http://localhost:4001 cluster-health</span><br><span class="line">sudo systemctl start kube-apiserver.service</span><br><span class="line">sudo systemctl start kube-controller-manager.service</span><br><span class="line">sudo systemctl start kube-scheduler.service</span><br><span class="line">sudo systemctl start kubelet.service</span><br></pre></td></tr></table></figure></p>
<p>3, 第二步，验证安装是否正确：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">$ /bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl -s http://127.0.0.1:8080 get componentstatus</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">controller-manager   Healthy   ok</span><br><span class="line">scheduler            Healthy   ok</span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br><span class="line"></span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config set-cluster myk8s --server=http://127.0.0.1:8080</span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config set-context myk8s-context --cluster=myk8s --namespace=default --user=client</span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config use-context myk8s-context</span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config set preferences.colors true</span><br><span class="line">$ cat ~/.kube/config</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    server: http://127.0.0.1:8080</span><br><span class="line">  name: myk8s</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: myk8s</span><br><span class="line">    namespace: default</span><br><span class="line">    user: client</span><br><span class="line">  name: myk8s-context</span><br><span class="line">current-context: myk8s-context</span><br><span class="line">kind: Config</span><br><span class="line">preferences:</span><br><span class="line">  colors: true</span><br><span class="line">users: []</span><br><span class="line"></span><br><span class="line">$ /bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl get componentstatus</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">controller-manager   Healthy   ok</span><br><span class="line">scheduler            Healthy   ok</span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br><span class="line">$ ./_output/bin/kubectl get nodes</span><br><span class="line">NAME        STATUS    ROLES     AGE       VERSION</span><br><span class="line">127.0.0.1   Ready     &lt;none&gt;    11m       v1.12.0-alpha.0.1999+32dc6cc08aa034-dirty</span><br><span class="line">$ ./_output/bin/kubectl get events</span><br></pre></td></tr></table></figure></p>
<p>4，第四步，例如要调试kubelet服务的话，先停止该服务(sudo systemctl stop kubelet)，然后使用(dlv exec ${OUTDIR}/bin/kubelet – $kubelet_flags)命令启动，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sudo /bak/golang/bin/dlv --headless -l 127.0.0.1:1234 exec /bak/golang/src/k8s.io/kubernetes/_output/bin/kubelet -- --fail-swap-on=False --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice  --v=4</span><br><span class="line">API server listening at: 127.0.0.1:1234</span><br><span class="line"></span><br><span class="line">$ sudo /bak/golang/bin/dlv connect 127.0.0.1:1234</span><br><span class="line">Type &apos;help&apos; for list of commands.</span><br><span class="line">(dlv) b main.main</span><br><span class="line">Breakpoint 1 set at 0x2d08348 for main.main() ./_output/local/go/src/k8s.io/kubernetes/cmd/kubelet/kubelet.go:36</span><br><span class="line">(dlv) c</span><br></pre></td></tr></table></figure></p>
<h2 id="安装dashboard"><a href="#安装dashboard" class="headerlink" title="安装dashboard"></a>安装dashboard</h2><p>该命令(KUBE_ENABLE_CLUSTER_DASHBOARD=true ./hack/local-up-cluster.sh）会自动安装dashboard。<br>注意：如果不成功原因是需要用小写true，它是区分大小写的。</p>
<p>安装成功后使用命令（cluster/kubectl.sh cluster-info）查看它的访问地址如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://localhost:6443//api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure></p>
<p>这个链接有点问题，在api处有两个斜线会造成看不到UI，改成如下的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://localhost:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure></p>
<p>也可运行命令（kubectl proxy –port=8001 –kubeconfig=/var/run/kubernetes/admin.kubeconfig –accept-hosts=’^*$’）访问：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure></p>
<p>上面的’–accept-hosts’用于在非本机外部访问，但Dashboard只允许localhost和127.0.0.1使用HTTP连接进行访问，而其它地址只允许使用HTTPS。因此，如果需要在非本机访问Dashboard的话，只能采用NodePort:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system edit service kubernetes-dashboard</span><br><span class="line">$ kubectl -n kube-system get service kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.0.0.232   &lt;none&gt;        443:31050/TCP   1h</span><br><span class="line">visit: https://192.168.99.216:31050/</span><br></pre></td></tr></table></figure></p>
<p>这时访问dashboard仍然有下列问题:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;message&quot;: &quot;services \&quot;https:kubernetes-dashboard:\&quot; is forbidden: User \&quot;system:anonymous\&quot; cannot get services/proxy in the namespace \&quot;kube-system\&quot;: no RBAC policy matched&quot;,</span><br></pre></td></tr></table></figure></p>
<p>这是因为最新版的k8s默认启用了RBAC(–authorization-mode=Node,RBAC)，并为未认证用户赋予了一个默认的身份：anonymous<br>对于API Server来说，它是使用证书进行认证的，我们需要先创建一个证书：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># generate client-certificate-data</span><br><span class="line">grep &apos;client-certificate-data&apos; /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.crt</span><br><span class="line"># generate client-key-data</span><br><span class="line">grep &apos;client-key-data&apos; /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.key</span><br><span class="line"># generate p12</span><br><span class="line">openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name &quot;kubernetes-client&quot;</span><br></pre></td></tr></table></figure></p>
<p>然后将该p12证书导入到浏览器即可。此时默认的anonymous身份的token可以这样获取:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cluster/kubectl.sh get secret -n kube-system | grep dashboard</span><br><span class="line">cluster/kubectl.sh -n kube-system  get secret kubernetes-dashboard-token-kglhd -o jsonpath=&#123;.data.token&#125;| base64 -d</span><br></pre></td></tr></table></figure></p>
<p>anonymous身份可能看不到很多东西，所以我们再在kube-system名空间下再创建一个admin用户并和cluster-admin角色关联：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /tmp/admin-user.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line">cat &gt; /tmp/admin-user-role-binding.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line">cluster/kubectl.sh create -f /tmp/admin-user.yaml</span><br><span class="line">cluster/kubectl.sh create -f /tmp/admin-user-role-binding.yaml</span><br><span class="line">cluster/kubectl.sh -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin | awk &apos;&#123;print $1&#125;&apos;)</span><br></pre></td></tr></table></figure>
<p>##直接修改local-up-cluster.sh代替hyperkube用本地进程启动 ##<br>或者直接修改脚本去掉hyperkube, 然后运行ENABLE_CLUSTER_DASHBOARD=True ./hack/local-up-cluster.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">diff --git a/hack/local-up-cluster.sh b/hack/local-up-cluster.sh</span><br><span class="line">index 3b688d3..95de0df 100755</span><br><span class="line">--- a/hack/local-up-cluster.sh</span><br><span class="line">+++ b/hack/local-up-cluster.sh</span><br><span class="line">@@ -202,7 +202,8 @@ do</span><br><span class="line"> done</span><br><span class="line"></span><br><span class="line"> if [ &quot;x$GO_OUT&quot; == &quot;x&quot; ]; then</span><br><span class="line">-    make -C &quot;$&#123;KUBE_ROOT&#125;&quot; WHAT=&quot;cmd/kubectl cmd/hyperkube&quot;</span><br><span class="line">+    #make -C &quot;$&#123;KUBE_ROOT&#125;&quot; WHAT=&quot;cmd/kubectl cmd/hyperkube&quot;</span><br><span class="line">+    make -C &quot;$&#123;KUBE_ROOT&#125;&quot; GOGCFLAGS=&quot;-N -l&quot; WHAT=&quot;cmd/kubelet cmd/kube-proxy cmd/kube-apiserver cmd/kube-controller-manager cmd/cloud-controller-manager cmd/kube-scheduler cmd/kubectl&quot;</span><br><span class="line"> else</span><br><span class="line">     echo &quot;skipped the build.&quot;</span><br><span class="line"> fi</span><br><span class="line">@@ -578,7 +579,7 @@ function start_apiserver &#123;</span><br><span class="line">     fi</span><br><span class="line"></span><br><span class="line">     APISERVER_LOG=$&#123;LOG_DIR&#125;/kube-apiserver.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/hyperkube&quot; apiserver $&#123;swagger_arg&#125; $&#123;audit_arg&#125; $&#123;authorizer_arg&#125; $&#123;priv_arg&#125; $&#123;runtime_config&#125; \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/kube-apiserver&quot; $&#123;swagger_arg&#125; $&#123;audit_arg&#125; $&#123;authorizer_arg&#125; $&#123;priv_arg&#125; $&#123;runtime_config&#125; \</span><br><span class="line">       $&#123;cloud_config_arg&#125; \</span><br><span class="line">       $&#123;advertise_address&#125; \</span><br><span class="line">       $&#123;node_port_range&#125; \</span><br><span class="line">@@ -650,7 +651,7 @@ function start_controller_manager &#123;</span><br><span class="line">     fi</span><br><span class="line"></span><br><span class="line">     CTLRMGR_LOG=$&#123;LOG_DIR&#125;/kube-controller-manager.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/hyperkube&quot; controller-manager \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/kube-controller-manager&quot; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --vmodule=&quot;$&#123;LOG_SPEC&#125;&quot; \</span><br><span class="line">       --service-account-private-key-file=&quot;$&#123;SERVICE_ACCOUNT_KEY&#125;&quot; \</span><br><span class="line">@@ -685,7 +686,7 @@ function start_cloud_controller_manager &#123;</span><br><span class="line">     fi</span><br><span class="line"></span><br><span class="line">     CLOUD_CTLRMGR_LOG=$&#123;LOG_DIR&#125;/cloud-controller-manager.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; $&#123;EXTERNAL_CLOUD_PROVIDER_BINARY:-&quot;$&#123;GO_OUT&#125;/hyperkube&quot; cloud-controller-manager&#125; \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; $&#123;EXTERNAL_CLOUD_PROVIDER_BINARY:-&quot;$&#123;GO_OUT&#125;/cloud-controller-manager&quot;&#125; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --vmodule=&quot;$&#123;LOG_SPEC&#125;&quot; \</span><br><span class="line">       $&#123;node_cidr_args&#125; \</span><br><span class="line">@@ -791,7 +792,7 @@ function start_kubelet &#123;</span><br><span class="line">     )</span><br><span class="line"></span><br><span class="line">     if [[ -z &quot;$&#123;DOCKERIZE_KUBELET&#125;&quot; ]]; then</span><br><span class="line">-      sudo -E &quot;$&#123;GO_OUT&#125;/hyperkube&quot; kubelet &quot;$&#123;all_kubelet_flags[@]&#125;&quot; &gt;&quot;$&#123;KUBELET_LOG&#125;&quot; 2&gt;&amp;1 &amp;</span><br><span class="line">+      sudo -E &quot;$&#123;GO_OUT&#125;/kubelet&quot; &quot;$&#123;all_kubelet_flags[@]&#125;&quot; &gt;&quot;$&#123;KUBELET_LOG&#125;&quot; 2&gt;&amp;1 &amp;</span><br><span class="line">       KUBELET_PID=$!</span><br><span class="line">     else</span><br><span class="line"></span><br><span class="line">@@ -889,14 +890,14 @@ EOF</span><br><span class="line">       done</span><br><span class="line">     fi &gt;&gt;/tmp/kube-proxy.yaml</span><br><span class="line"></span><br><span class="line">-    sudo &quot;$&#123;GO_OUT&#125;/hyperkube&quot; proxy \</span><br><span class="line">+    sudo &quot;$&#123;GO_OUT&#125;/kube-proxy&quot; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --config=/tmp/kube-proxy.yaml \</span><br><span class="line">       --master=&quot;https://$&#123;API_HOST&#125;:$&#123;API_SECURE_PORT&#125;&quot; &gt;&quot;$&#123;PROXY_LOG&#125;&quot; 2&gt;&amp;1 &amp;</span><br><span class="line">     PROXY_PID=$!</span><br><span class="line"></span><br><span class="line">     SCHEDULER_LOG=$&#123;LOG_DIR&#125;/kube-scheduler.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/hyperkube&quot; scheduler \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/kube-scheduler&quot; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --kubeconfig &quot;$CERT_DIR&quot;/scheduler.kubeconfig \</span><br><span class="line">       --feature-gates=&quot;$&#123;FEATURE_GATES&#125;&quot; \</span><br></pre></td></tr></table></figure></p>
<h2 id="How-to-read-source-code"><a href="#How-to-read-source-code" class="headerlink" title="How to read source code"></a>How to read source code</h2><p><a href="http://dockone.io/article/895" target="_blank" rel="external">http://dockone.io/article/895</a></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://kubernetes.io/docs/imported/community/devel/" target="_blank" rel="external">https://kubernetes.io/docs/imported/community/devel/</a><br>[2] <a href="https://github.com/kubernetes/community/tree/master/contributors/devel" target="_blank" rel="external">https://github.com/kubernetes/community/tree/master/contributors/devel</a><br>[3] Bug - <a href="https://github.com/kubernetes/community/issues" target="_blank" rel="external">https://github.com/kubernetes/community/issues</a><br>[4] Submit code review - <a href="https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md</a><br>[5] Membership - <a href="https://github.com/kubernetes/community/blob/master/community-membership.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/community-membership.md</a><br>[6] CONTRIBUTING - <a href="https://github.com/kubernetes/community/blob/master/CONTRIBUTING.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/CONTRIBUTING.md</a><br>[7] Code format - <a href="https://github.com/golang/go/wiki/CodeReviewComments" target="_blank" rel="external">https://github.com/golang/go/wiki/CodeReviewComments</a><br>[8] Slack - <a href="https://kubernetes.slack.com/messages" target="_blank" rel="external">https://kubernetes.slack.com/messages</a><br>[9] Mail-list - <a href="https://groups.google.com/forum/#!forum/kubernetes-dev" target="_blank" rel="external">https://groups.google.com/forum/#!forum/kubernetes-dev</a><br>[10] SIG-list (Special Interest Groups) - <a href="https://github.com/kubernetes/community/blob/master/sig-list.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/sig-list.md</a><br>[11] open-bug - <a href="https://github.com/kubernetes/community/blob/master/contributors/guide/issue-triage.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/issue-triage.md</a><br>[12] BP - <a href="https://github.com/kubernetes/community/tree/master/contributors/design-proposals" target="_blank" rel="external">https://github.com/kubernetes/community/tree/master/contributors/design-proposals</a><br>[13] <a href="https://github.com/kubernetes/community/blob/master/community-membership.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/community-membership.md</a><br>[14] test - <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md</a><br>[15] <a href="https://ress.infoq.com/minibooks/Kubernetes-handbook/zh/pdf/kubernetes.pdf" target="_blank" rel="external">https://ress.infoq.com/minibooks/Kubernetes-handbook/zh/pdf/kubernetes.pdf</a><br>[16] <a href="https://kubernetes.io/docs/home/" target="_blank" rel="external">https://kubernetes.io/docs/home/</a><br>[17] <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way" target="_blank" rel="external">https://github.com/kelseyhightower/kubernetes-the-hard-way</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/10/Set-up-k8s-development-env-by-quqi99/" data-id="cjkgczyes000dkobpqrods6z4" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-温故OpenStack中的测试-by-Joshua" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/10/温故OpenStack中的测试-by-Joshua/" class="article-date">
  <time datetime="2018-07-10T08:28:15.000Z" itemprop="datePublished">2018-07-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/10/温故OpenStack中的测试-by-Joshua/">温故OpenStack中的测试(by Joshua)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-03-15)</strong></p>
<ol>
<li><p>沿用tox调用virtualenv自动创建的虚拟环境(virtualenv -p python3.5 .tox/py35)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source .tox/py35/bin/activate</span><br><span class="line">sudo pip install --upgrade -r requirements.txt</span><br><span class="line">sudo pip install --upgrade -r test-requirements.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用unittest和nose运行测试。nose是对unittest的扩展，使得python的测试更加简单，nose自动发现测试代码并执行，nose提供了大量的插件，比如覆盖报表等。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python -m unittest -v unit_tests.test_neutron_utils.TestNeutronUtils.test_get_packages_ovs_newton</span><br><span class="line">.tox/py35/bin/python nosetests -v unit_tests/test_neutron_utils.py:TestNeutronUtils.test_get_packages_ovs_newton</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>注意：上面采用nosetests运行时会报错，因为我们的测试采用了python3, 所以需要在安装了python3-nose之后（sudo apt-get install python3-nose python3-mock）再采用下列三种方式之一运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nosetests3 -v unit_tests/test_neutron_utils.py:TestNeutronUtils.test_restart_map_ovs_odl</span><br><span class="line">/bak/work/charms/neutron-gateway/.tox/py35/bin/python /usr/local/bin/nosetests -v unit_tests/test_neutron_utils.py:TestNeutronUtils.test_get_packages_ovs_newton</span><br><span class="line">python -m nose unit_tests/test_neutron_utils.py:TestNeutronUtils.test_restart_map_ovs_odl</span><br></pre></td></tr></table></figure></p>
<p>但实际上仍然找不找nose模块，那是因为nose与virtualenv结合地不大好，在这个网页找着了答案(<a href="https://stackoverflow.com/questions/864956/problems-using-nose-in-a-virtualenv" target="_blank" rel="external">https://stackoverflow.com/questions/864956/problems-using-nose-in-a-virtualenv</a>) - You need to have a copy of nose installed in the virtual environment. In order to force installation of nose into the virtualenv, even though it is already installed in the global site-packages, run pip install with the -I flag: pip install nose -I</p>
<ol>
<li><p>上面使用unittest与nose运行测试的方式只是将结果输出到stdout，不便于分析。所以可以使用python-subunit模块来运行测试，并将测试结果通过subunit协议输出到文件中便于日后分析。因为subunit是基于二进制的不便于人眼看，所以可使用subunit2pyunit工具将其人类可读化。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python -m subunit.run discover |subunit2pyunit</span><br><span class="line">python -m subunit.run discover -t ./ ./unit_tests |subunit2pyunit</span><br><span class="line">python -m subunit.run unit_tests.test_neutron_utils.TestNeutronUtils. |subunit2pyunit</span><br></pre></td></tr></table></figure>
</li>
<li><p>在大型应用中分析测试结果很重要，testrepository可以调用subunit来用python-subunit模块来运行测试，并将测试结果通过subunit协议输出到文件中，然后testrepository在些基础上有更多的分析，如分析哪些用例运行的时间最长，如显示失败的用例，如仅运行上次运行失败的用例。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">testr init</span><br><span class="line">testr run</span><br><span class="line">testr run --parallel</span><br><span class="line">$ cat .testr.conf</span><br><span class="line">[DEFAULT]</span><br><span class="line">test_command=OS_STDOUT_CAPTURE=$&#123;OS_STDOUT_CAPTURE:-1&#125; \</span><br><span class="line">             OS_STDERR_CAPTURE=$&#123;OS_STDERR_CAPTURE:-1&#125; \</span><br><span class="line">             OS_TEST_TIMEOUT=$&#123;OS_TEST_TIMEOUT:-60&#125; \</span><br><span class="line">             $&#123;PYTHON:-python&#125; -m subunit.run discover -t ./ ./unit_tests $LISTOPT $IDOPTION</span><br><span class="line">test_id_option=--load-list $IDFILE</span><br><span class="line">test_list_option=--list</span><br></pre></td></tr></table></figure>
</li>
<li><p>tox用于创建虚拟python环境，也可以集成上面的testrepository(commands = ostestr {posargs})</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">$ cat tox.ini</span><br><span class="line">[tox]</span><br><span class="line">envlist = pep8,py27,py35</span><br><span class="line">skipsdist = True</span><br><span class="line"></span><br><span class="line">[testenv]</span><br><span class="line">setenv = VIRTUAL_ENV=&#123;envdir&#125;</span><br><span class="line">         PYTHONHASHSEED=0</span><br><span class="line">         CHARM_DIR=&#123;envdir&#125;</span><br><span class="line">         AMULET_SETUP_TIMEOUT=5400</span><br><span class="line">install_command =</span><br><span class="line">  pip install --allow-unverified python-apt &#123;opts&#125; &#123;packages&#125;</span><br><span class="line">commands = ostestr &#123;posargs&#125;</span><br><span class="line">whitelist_externals = juju</span><br><span class="line">passenv = HOME TERM AMULET_* CS_API_*</span><br><span class="line"></span><br><span class="line">[testenv:py27]</span><br><span class="line">basepython = python2.7</span><br><span class="line">deps = -r&#123;toxinidir&#125;/requirements.txt</span><br><span class="line">       -r&#123;toxinidir&#125;/test-requirements.txt</span><br><span class="line">commands = /bin/true</span><br><span class="line"></span><br><span class="line">[testenv:py35]</span><br><span class="line">basepython = python3.5</span><br><span class="line">deps = -r&#123;toxinidir&#125;/requirements.txt</span><br><span class="line">       -r&#123;toxinidir&#125;/test-requirements.txt</span><br><span class="line"></span><br><span class="line">[testenv:pep8]</span><br><span class="line">basepython = python2.7</span><br><span class="line">deps = -r&#123;toxinidir&#125;/requirements.txt</span><br><span class="line">       -r&#123;toxinidir&#125;/test-requirements.txt</span><br><span class="line">commands = flake8 &#123;posargs&#125; hooks unit_tests tests actions lib</span><br><span class="line">           charm-proof</span><br><span class="line"></span><br><span class="line">[flake8]</span><br><span class="line">ignore = E402,E226</span><br><span class="line">exclude = */helpers</span><br></pre></td></tr></table></figure>
</li>
<li><p>pydev使用virtualenv中的py35<br>在eclipse的”Preferences -&gt; Pydev -&gt; Interpreters -&gt; Python Interpreters”菜单中定义python35=/bak/work/charms/neutron-gateway/.tox/py35/bin/python,然后在工程上点右键从”Properties -&gt; Pydev - Interpreter/Grammar”定义使用python35。注意，需要将/bak/work/charms/neutron-gateway/.tox/py35/lib/python3.5/site-packages也选到环境变量中，否则后面会报ImportError: No module named ‘mock。<br>为一个测试类定义”Python unitest”类型的”Debug Configurations”, 也在其Interpreter选项卡中定义使用python35 (结果：eclipse似乎有bug，此处选择了python35后无法保存)<br>所以无法成功，似乎是pydev与python3协作不大好。最后还是pudb好使(sudo pip install pudb, import pudb; pdb.set_trace())</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/10/温故OpenStack中的测试-by-Joshua/" data-id="cjkgczyfh000pkobp51ig18xy" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Play-with-ceph-radosgw" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/13/Play-with-ceph-radosgw/" class="article-date">
  <time datetime="2018-06-13T10:56:45.000Z" itemprop="datePublished">2018-06-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/13/Play-with-ceph-radosgw/">Play with ceph-radosgw</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-06-13)</strong></p>
<h2 id="Rapidly-install"><a href="#Rapidly-install" class="headerlink" title="Rapidly install"></a>Rapidly install</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/openstack/charm-ceph-radosgw</span><br><span class="line">juju deploy ceph-radosgw --series xenial</span><br><span class="line">juju add-relation ceph-radosgw ceph</span><br><span class="line">juju add-relation keystone ceph-radosgw</span><br><span class="line">juju expose ceph-radosgw</span><br><span class="line">curl http://juju-332891-mitaka-ceph-13</span><br><span class="line"></span><br><span class="line">juju ssh ceph/0 &apos;sudo radosgw-admin metadata list user&apos;</span><br><span class="line">sudo radosgw-admin user create --uid=&quot;admin&quot; --display-name=&quot;admin&quot;</span><br><span class="line">sudo radosgw-admin usage show --uid=admin</span><br><span class="line">sudo radosgw-admin usage show --show-log-entries=false</span><br><span class="line">sudo radosgw-admin caps add --uid=admin --caps=&quot;users=*&quot;</span><br><span class="line">sudo radosgw-admin caps add --uid=admin --caps=&quot;usage=read&quot;</span><br><span class="line">sudo radosgw-admin bucket stats</span><br><span class="line">sudo radosgw-admin bucket stats --uid=anonymous</span><br></pre></td></tr></table></figure>
<h2 id="Use-s3cmd-client-to-visit-RGW"><a href="#Use-s3cmd-client-to-visit-RGW" class="headerlink" title="Use s3cmd client to visit RGW"></a>Use s3cmd client to visit RGW</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install s3cmd</span><br><span class="line">s3cmd --configure</span><br><span class="line">check_ssl_certificate = False</span><br><span class="line">check_ssl_hostname = False</span><br><span class="line">access_key = EJECCFLCB0K53EMVM3DL</span><br><span class="line">secret_key = C281KRmdFFWxzOHyjZ3OsvQorCgf1mxdML7kYJ1t</span><br><span class="line">cloudfront_host = juju-332891-mitaka-ceph-13</span><br><span class="line">host_base = juju-332891-mitaka-ceph-13:80</span><br><span class="line">host_bucket = %(bucket)s.juju-332891-mitaka-ceph-13</span><br><span class="line"></span><br><span class="line">s3cmd mb s3://my_test1</span><br><span class="line">s3cmd ls  # qeury bucket</span><br><span class="line">s3cmd put testfile s3://my_test1</span><br><span class="line">s3cmd ls s3://my_test1</span><br><span class="line">s3cmd get s3://my_test1/diff</span><br></pre></td></tr></table></figure>
<h2 id="Enable-usage-log"><a href="#Enable-usage-log" class="headerlink" title="Enable usage.log"></a>Enable usage.log</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">http://www.yangguanjun.com/2016/08/30/rgw-user-statistics/</span><br><span class="line">Add the following configurations into ceph-radosgw/0 node</span><br><span class="line">[client.radosgw.gateway]</span><br><span class="line">rgw enable usage log = true</span><br><span class="line">rgw usage log tick interval = 30</span><br><span class="line">rgw usage log flush threshold = 1024</span><br><span class="line">rgw usage max shards = 32</span><br><span class="line">rgw usage max user shards = 1</span><br><span class="line"></span><br><span class="line">sudo ceph osd pool create .usage 64   # create a pool for usage, run in &apos;ceph/0&apos;</span><br><span class="line">sudo ceph osd pool create .rgw 128 128</span><br><span class="line">sudo ceph osd pool create .rgw.root 128 128</span><br><span class="line">sudo ceph osd pool create .rgw.control 128 128</span><br><span class="line">sudo ceph osd pool create .rgw.gc 128 128</span><br><span class="line">sudo ceph osd pool create .rgw.buckets 128 128</span><br><span class="line">sudo ceph osd pool create .rgw.buckets.index 128 128</span><br><span class="line">sudo ceph osd pool create .log 128 128</span><br><span class="line">sudo ceph osd pool create .intent-log 128 128</span><br><span class="line">sudo ceph osd pool create .usage 128 128</span><br><span class="line">sudo ceph osd pool create .users 128 128</span><br><span class="line">sudo ceph osd pool create .users.email 128 128</span><br><span class="line">sudo ceph osd pool create .users.swift 128 128</span><br><span class="line">sudo ceph osd pool create .users.uid 128 128</span><br><span class="line"></span><br><span class="line">sudo /etc/init.d/radosgw restart</span><br><span class="line">ceph daemon /var/run/ceph/ceph-client.radosgw.gateway.asok config show # verify config, run in radosgw node</span><br><span class="line">sudo radosgw-admin usage show --show-log-entries=false  # after 1 hour, use radosgw-admin to see usage data, run in ceph/0</span><br></pre></td></tr></table></figure>
<h2 id="REST-API"><a href="#REST-API" class="headerlink" title="REST API"></a>REST API</h2><p>用REST API调用时遇到一个问题(radosgw-admin usage show无此问题), 就是看到anonymous用户有很多空bucket<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">$ sudo radosgw-admin usage show --uid=anonymous</span><br><span class="line">user.init failed: (13) Permission denied</span><br><span class="line"></span><br><span class="line">$./get_anonymous.py</span><br><span class="line">DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): juju-332891-mitaka-ceph-13</span><br><span class="line">DEBUG:urllib3.connectionpool:http://juju-332891-mitaka-ceph-13:80 &quot;GET /admin/usage?format=json&amp;show-summary=False&amp;uid=anonymous HTTP/1.1&quot; 200 242</span><br><span class="line">&lt;Response [200]&gt;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;entries&quot;:[</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;buckets&quot;:[</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;bucket&quot;:&quot;&quot;,</span><br><span class="line">                    &quot;categories&quot;:[</span><br><span class="line">                        &#123;</span><br><span class="line">                            &quot;bytes_received&quot;:0,</span><br><span class="line">                            &quot;bytes_sent&quot;:940,</span><br><span class="line">                            &quot;category&quot;:&quot;list_buckets&quot;,</span><br><span class="line">                            &quot;ops&quot;:4,</span><br><span class="line">                            &quot;successful_ops&quot;:4</span><br><span class="line">                        &#125;</span><br><span class="line">                    ],</span><br><span class="line">                    &quot;epoch&quot;:1528275600,</span><br><span class="line">                    &quot;owner&quot;:&quot;anonymous&quot;,</span><br><span class="line">                    &quot;time&quot;:&quot;2018-06-06 09:00:00.000000Z&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            &quot;user&quot;:&quot;anonymous&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ cat get_anonymous.py</span><br><span class="line">#!/usr/bin/python</span><br><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">import logging</span><br><span class="line">import argparse</span><br><span class="line">from awsauth import S3Auth</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.DEBUG)</span><br><span class="line">server = &apos;juju-332891-mitaka-ceph-13&apos;</span><br><span class="line">aws_key = &apos;EJECCFLCB0K53EMVM3DL&apos;</span><br><span class="line">secret = &apos;C281KRmdFFWxzOHyjZ3OsvQorCgf1mxdML7kYJ1t&apos;</span><br><span class="line">url = &apos;http://%s/admin/usage?format=json&amp;show-summary=False&amp;uid=anonymous&apos; % server</span><br><span class="line">response = requests.get(url, auth=S3Auth(aws_key, secret, server))</span><br><span class="line">print response</span><br><span class="line">print json.dumps(response.json(), sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;:&apos;))</span><br></pre></td></tr></table></figure></p>
<h2 id="Set-up-ceph-debug-env-in-boinic"><a href="#Set-up-ceph-debug-env-in-boinic" class="headerlink" title="Set up ceph debug env in boinic"></a>Set up ceph debug env in boinic</h2><p>gdb can also debug python by using prefix py- in gdb comand - <a href="http://linux-debug.blogspot.com/2015/01/ceph-debugging-python-code-in-gdb.html" target="_blank" rel="external">http://linux-debug.blogspot.com/2015/01/ceph-debugging-python-code-in-gdb.html</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/ceph/ceph</span><br><span class="line">git submodule update --force --init --recursive</span><br><span class="line">git checkout master</span><br><span class="line">./install-deps.sh</span><br><span class="line">sudo apt install libatomic-ops-dev libboost-dev libboost-iostreams-dev libboost-thread-dev libboost-random-dev libboost-program-options-dev libcurl4-openssl-dev libcunit1 libcunit1-dev liblz4-dev liboath-dev liblttng-ust-dev libcrypto++ libcrypto++-dev libgoogle-perftools4 libtool cython libsnappy-dev libleveldb-dev libblkid-dev libudev-dev libkeyutils-dev libcrypto++-dev libcrypto++-doc libcrypto++-utils libfuse-dev libcurl4-openssl-dev libxml++2.6-dev libssl-dev libgoogle-perftools-dev libgoogle-perftools4 libatomic-ops-dev libaio-dev  xfslibs-dev libboost-iostreams-dev libfcgi-dev</span><br><span class="line">sudo apt install gcr libblockdev-crypto2 libhcrypto4-heimdal libhogweed4 libk5crypto3 libnettle6 libsodium23 openssl python-m2crypto python3-crypto python3-cryptography</span><br><span class="line">#./autogen.sh &amp;&amp; ./configure  #old way, need to modifty makefile to &apos;-O0-Wall -g&apos; for debug</span><br><span class="line">./do_cmake.sh -DCMAKE_BUILD_TYPE=Debug</span><br><span class="line">cd build</span><br><span class="line">make -j56</span><br><span class="line">make ceph-osd -j56</span><br><span class="line"></span><br><span class="line">MON=1 OSD=3 MDS=1 MGR=1 RGW=1 ../src/vstart.sh -n -d --without-dashboard</span><br><span class="line">../src/stop.sh</span><br><span class="line">./bin/ceph -s</span><br><span class="line">./bin/ceph osd pool stats</span><br><span class="line">ps aux|grep ceph</span><br><span class="line">pstree -p</span><br><span class="line"></span><br><span class="line">./bin/radosgw-admin user create --uid=admin --display-name=admin --access-key=admin --secret=password</span><br><span class="line">./bin/radosgw-admin usage show --uid=admin</span><br><span class="line">./bin/radosgw-admin bucket stats --uid=anonymous</span><br><span class="line"></span><br><span class="line">sudo gdb attach $(pidof radosgw)</span><br><span class="line">(gdb) set solib-search-path /bak/linux/ceph/src/.libs/</span><br><span class="line">(gdb) set pagination off</span><br><span class="line">(gdb) b rgw/rgw_process.cc:38</span><br><span class="line">(gdb) b process_request</span><br><span class="line">(gdb) c</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/06/13/Play-with-ceph-radosgw/" data-id="cjkgczyem000akobpvm0923bb" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Play-with-LDAP-Keystone-by-quqi99" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/08/Play-with-LDAP-Keystone-by-quqi99/" class="article-date">
  <time datetime="2018-06-08T10:09:28.000Z" itemprop="datePublished">2018-06-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/08/Play-with-LDAP-Keystone-by-quqi99/">Play with LDAP + Keystone (by quqi99)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-05-29)</strong></p>
<h2 id="Install-OpenLDAP"><a href="#Install-OpenLDAP" class="headerlink" title="Install OpenLDAP"></a>Install OpenLDAP</h2><p>OpenLDAP Server可以使用这个charm安装 - <a href="https://jujucharms.com/u/openstack-charmers/ldap-test-fixture/3" target="_blank" rel="external">https://jujucharms.com/u/openstack-charmers/ldap-test-fixture/3</a>, 最终要添加的yaml如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keystone-ldap:</span><br><span class="line">  charm: cs:keystone-ldap-10</span><br><span class="line">ldap-test-fixture:</span><br><span class="line">  charm: cs:~openstack-charmers/ldap-test-fixture</span><br><span class="line"></span><br><span class="line">- [ keystone-ldap, keystone ]</span><br></pre></td></tr></table></figure></p>
<p>也可以根据这个链接分步安装 - <a href="https://api.jujucharms.com/charmstore/v5/~openstack-charmers/ldap-test-fixture-3/archive/hooks/install" target="_blank" rel="external">https://api.jujucharms.com/charmstore/v5/~openstack-charmers/ldap-test-fixture-3/archive/hooks/install</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">export DEBIAN_FRONTEND=noninteractive</span><br><span class="line">echo -e &quot; \</span><br><span class="line">slapd slapd/internal/generated_adminpw password password</span><br><span class="line">slapd slapd/password2 password password</span><br><span class="line">slapd slapd/internal/adminpw password password</span><br><span class="line">slapd slapd/password1 password password</span><br><span class="line">&quot; | sudo debconf-set-selections</span><br><span class="line">sudo apt install slapd ldap-utils phpldapadmin</span><br><span class="line">sed -i &quot;s/dc=example/dc=test/g&quot; /etc/phpldapadmin/config.php</span><br><span class="line">service apache2 restart</span><br><span class="line">sudo service slapd restart</span><br><span class="line">#sudo dpkg-reconfigure slapd  #configure domain=test.com</span><br><span class="line">#slappasswd -h &#123;SSHA&#125; -s password</span><br><span class="line">#sudo apt-get install jxplorer  #GUI</span><br><span class="line"></span><br><span class="line"># How to test it</span><br><span class="line">sudo ldapsearch -h 10.5.0.72 -x -w password -D&quot;cn=admin,dc=test,dc=com&quot; -b dc=test,dc=com -s sub &apos;(objectclass=*)&apos; cn sn</span><br><span class="line">sudo ldapsearch -h 10.5.0.72 -x -w password -D&quot;cn=admin,dc=test,dc=com&quot; -b ou=users,dc=test,dc=com  &apos;(objectclass=*)&apos;  cn sn</span><br><span class="line">sudo ldapsearch -h 10.5.0.72 -x -w password -D&quot;cn=admin,dc=test,dc=com&quot; -b dc=test,dc=com</span><br></pre></td></tr></table></figure></p>
<h2 id="Modify-default-schema-to-support-OpenStack"><a href="#Modify-default-schema-to-support-OpenStack" class="headerlink" title="Modify default schema to support OpenStack"></a>Modify default schema to support OpenStack</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://api.jujucharms.com/charmstore/v5/~openstack-charmers/ldap-test-fixture-3/archive/files/backup.ldif</span><br><span class="line">slapadd -v -c -l .backup.ldif</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ldapsearch -h 10.5.0.72 -x -w password -D&quot;cn=admin,dc=test,dc=com&quot; -b dc=test,dc=com</span><br><span class="line"># extended LDIF</span><br><span class="line">#</span><br><span class="line"># LDAPv3</span><br><span class="line"># base &lt;dc=test,dc=com&gt; with scope subtree</span><br><span class="line"># filter: (objectclass=*)</span><br><span class="line"># requesting: ALL</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># test.com</span><br><span class="line">dn: dc=test,dc=com</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: dcObject</span><br><span class="line">objectClass: organization</span><br><span class="line">o: test</span><br><span class="line">dc: test</span><br><span class="line"></span><br><span class="line"># admin, test.com</span><br><span class="line">dn: cn=admin,dc=test,dc=com</span><br><span class="line">objectClass: simpleSecurityObject</span><br><span class="line">objectClass: organizationalRole</span><br><span class="line">cn: admin</span><br><span class="line">description: LDAP administrator</span><br><span class="line">userPassword:: e1NTSEF9Q1RxNU1nNHA5blhlL25WVjBqenZSYTZ2VkxQQnVJZjc=</span><br><span class="line"></span><br><span class="line"># groups, test.com</span><br><span class="line">dn: ou=groups,dc=test,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">objectClass: top</span><br><span class="line">ou: groups</span><br><span class="line"></span><br><span class="line"># admin, groups, test.com</span><br><span class="line">dn: cn=admin,ou=groups,dc=test,dc=com</span><br><span class="line">cn: admin</span><br><span class="line">gidNumber: 500</span><br><span class="line">memberUid: johndoe</span><br><span class="line">objectClass: posixGroup</span><br><span class="line">objectClass: top</span><br><span class="line"></span><br><span class="line"># openstack, groups, test.com</span><br><span class="line">dn: cn=openstack,ou=groups,dc=test,dc=com</span><br><span class="line">cn: openstack</span><br><span class="line">gidNumber: 501</span><br><span class="line">memberUid: johndoe</span><br><span class="line">objectClass: posixGroup</span><br><span class="line">objectClass: top</span><br><span class="line"></span><br><span class="line"># users, test.com</span><br><span class="line">dn: ou=users,dc=test,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">objectClass: top</span><br><span class="line">ou: users</span><br><span class="line"></span><br><span class="line"># janedoe, users, test.com</span><br><span class="line">dn: cn=janedoe,ou=users,dc=test,dc=com</span><br><span class="line">cn: janedoe</span><br><span class="line">gidNumber: 500</span><br><span class="line">givenName: Jane</span><br><span class="line">homeDirectory: /home/users/janedoe</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">objectClass: top</span><br><span class="line">sn: Jane Doe</span><br><span class="line">uid: janedoe</span><br><span class="line">uidNumber: 1001</span><br><span class="line">userPassword:: e01ENX1IT01SNHBNMTV0M2dZZDhXVXhNRzhnPT0=</span><br><span class="line"></span><br><span class="line"># johndoe, users, test.com</span><br><span class="line">dn: cn=johndoe,ou=users,dc=test,dc=com</span><br><span class="line">cn: johndoe</span><br><span class="line">gidNumber: 501</span><br><span class="line">givenName: John</span><br><span class="line">homeDirectory: /home/users/jdoe</span><br><span class="line">loginShell: /bin/sh</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">objectClass: top</span><br><span class="line">sn: John Doe</span><br><span class="line">uid: johndoe</span><br><span class="line">uidNumber: 1000</span><br><span class="line">userPassword:: e01ENX1IT01SNHBNMTV0M2dZZDhXVXhNRzhnPT0=</span><br><span class="line"></span><br><span class="line"># search result</span><br><span class="line">search: 2</span><br><span class="line">result: 0 Success</span><br><span class="line"></span><br><span class="line"># numResponses: 9</span><br><span class="line"># numEntries: 8</span><br></pre></td></tr></table></figure>
<h2 id="Configure-Keystone"><a href="#Configure-Keystone" class="headerlink" title="Configure Keystone"></a>Configure Keystone</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">juju config keystone preferred-api-version=3</span><br><span class="line">juju deploy keystone-ldap --series xenial</span><br><span class="line">juju add-relation keystone-ldap keystone</span><br><span class="line"></span><br><span class="line">juju config keystone-ldap ldap-server=&quot;ldap://10.5.0.72&quot; ldap-user=&quot;cn=admin,dc=test,dc=com&quot; ldap-password=&quot;crapper&quot; ldap-suffix=&quot;dc=test,dc=com&quot;</span><br><span class="line">juju config keystone-ldap domain-name=&quot;aaa_domain&quot;</span><br><span class="line">juju config keystone-ldap ldap-config-flags=&quot;&#123; user_tree_dn: &apos;dc=test,dc=com&apos;, query_scope: &apos;sub&apos;, user_objectclass: posixAccount, user_id_attribute: uid, user_name_attribute: uid, group_tree_dn: &apos;ou=groups,dc=test,dc=com&apos;, group_objectclass: posixGroup, group_id_attribute: gidNumber, group_name_attribute: cn, group_member_attribute: memberUid, group_members_are_ids: True&#125;&quot;</span><br><span class="line"></span><br><span class="line">root@juju-67d093-xenial-queens-ldap-2:~# cat /etc/keystone/domains/keystone.aaa_domain.conf</span><br><span class="line">[ldap]</span><br><span class="line">url = ldap://10.5.0.72</span><br><span class="line">user = cn=admin,dc=test,dc=com</span><br><span class="line">password = password</span><br><span class="line">suffix = dc=test,dc=com</span><br><span class="line"></span><br><span class="line">user_allow_create = False</span><br><span class="line">user_allow_update = False</span><br><span class="line">user_allow_delete = False</span><br><span class="line"></span><br><span class="line">group_allow_create = False</span><br><span class="line">group_allow_update = False</span><br><span class="line">group_allow_delete = False</span><br><span class="line"></span><br><span class="line"># User supplied configuration flags</span><br><span class="line">group_id_attribute = gidNumber</span><br><span class="line">group_member_attribute = memberUid</span><br><span class="line">group_members_are_ids = True</span><br><span class="line">group_name_attribute = cn</span><br><span class="line">group_objectclass = posixGroup</span><br><span class="line">group_tree_dn = ou=groups,dc=test,dc=com</span><br><span class="line">query_scope = sub</span><br><span class="line">#user_id_attribute = uidNumber</span><br><span class="line">user_id_attribute = uid</span><br><span class="line">user_name_attribute = uid</span><br><span class="line">user_objectclass = posixAccount</span><br><span class="line">user_tree_dn = dc=test,dc=com</span><br><span class="line">[identity]</span><br><span class="line">driver = ldap</span><br></pre></td></tr></table></figure>
<p>注意， 上面有几个重要参数，注意是group_members_are_ids = True，下面将要着重讲解。<br>query_scope = sub<br>user_tree_dn = dc=test,dc=com<br>user_id_attribute = uid<br>group_members_are_ids = True<br>下面配置也可以work:<br>query_scope = base<br>user_tree_dn = dc=users,test,dc=com<br>user_id_attribute = uid<br>group_members_are_ids = True</p>
<h2 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">source ~/stsstack-bundles/novarcv3_domain</span><br><span class="line">export OS_REGION_NAME=RegionOne</span><br><span class="line">export OS_USER_DOMAIN_NAME=admin_domain</span><br><span class="line">export OS_AUTH_VERSION=3</span><br><span class="line">export OS_IDENTITY_API_VERSION=3</span><br><span class="line">export OS_PASSWORD=openstack</span><br><span class="line">export OS_DOMAIN_NAME=admin_domain</span><br><span class="line">export OS_AUTH_URL=http://10.5.0.53:5000/v3</span><br><span class="line">export OS_USERNAME=admin</span><br><span class="line"></span><br><span class="line">openstack domain create --description &quot;aaa_domain&quot; aaa_domain</span><br><span class="line">openstack domain list</span><br><span class="line">openstack project create myproject --domain aaa_domain</span><br><span class="line">openstack project list --domain aaa_domain</span><br><span class="line">#The token used to make the request was project scoped but the policy requires [&apos;system&apos;] scope</span><br><span class="line">#so it should be &apos;openstack  group create aaa_group&apos;</span><br><span class="line">#openstack group create aaa_group --domain aaa_domain</span><br><span class="line">#openstack group create aaa_group        #we use the default openstack instead</span><br><span class="line">openstack group list --domain aaa_domain</span><br><span class="line">openstack role list</span><br><span class="line">openstack user list --domain aaa_domain</span><br><span class="line">openstack user list --group openstack --domain aaa_domain</span><br><span class="line"></span><br><span class="line">#Assign Role to a user in a Domain, it used --domain</span><br><span class="line">#openstack role add --user johndoe --domain aaa_domain Member</span><br><span class="line">#Assign Role to a group in a project, it used --group-domain</span><br><span class="line">openstack role add --group openstack --group-domain aaa_domain --project myproject Member</span><br><span class="line">openstack role add --group openstack --group-domain aaa_domain --project myproject Admin</span><br><span class="line">openstack role list --group openstack --group-domain aaa_domain --project myproject</span><br><span class="line"></span><br><span class="line">$ openstack user list --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| 5d15ad6474b1f212d159d974eba4d6b402636e67a7253bf7acb64403ff8c2c53 | janedoe |</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line"></span><br><span class="line">$ openstack group contains user --group-domain aaa_domain --user-domain aaa_domain openstack johndoe</span><br><span class="line">johndoe in group openstack</span><br><span class="line"></span><br><span class="line">source ~/stsstack-bundles/novarcv3_project</span><br><span class="line">export OS_USER_DOMAIN_NAME=aaa_domain</span><br><span class="line">export OS_PROJECT_DOMAIN_NAME=aaa_domain</span><br><span class="line">export OS_PROJECT_NAME=myproject</span><br><span class="line">export OS_USERNAME=johndoe</span><br><span class="line">export OS_PASSWORD=crapper</span><br><span class="line">export OS_AUTH_URL=http://10.5.0.72:5000/v3</span><br><span class="line">export OS_AUTH_VERSION=3</span><br><span class="line">export OS_IDENTITY_API_VERSION=3</span><br><span class="line">export OS_REGION_NAME=RegionOne</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user show johndoe</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line">| Field               | Value                                                            |</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line">| domain_id           | ae678292805a4db7917137c0621fe4cc                                 |</span><br><span class="line">| id                  | dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 |</span><br><span class="line">| name                | johndoe                                                          |</span><br><span class="line">| options             | &#123;&#125;                                                               |</span><br><span class="line">| password_expires_at | None                                                             |</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list</span><br><span class="line">You are not authorized to perform the requested action: identity:list_users. (HTTP 403) (Request-ID: req-8c373161-37d7-4d33-9dda-16bdbd2cecb7)</span><br><span class="line"></span><br><span class="line">Why we are not authorized to run &apos;openstack user list&apos;, that&apos;s because the following policy rules.</span><br><span class="line"></span><br><span class="line">&quot;admin_required&quot;: &quot;role:Admin&quot;,</span><br><span class="line">&quot;cloud_admin&quot;: &quot;rule:admin_required and (is_admin_project:True or domain_id:59d6b9c88f654dba9d06772ec1b197f0 or project_id:bbbb856f30b042a9a64d6646273a9ae2)&quot;,</span><br><span class="line">&quot;owner&quot; : &quot;user_id:%(user_id)s or user_id:%(target.token.user_id)s&quot;,</span><br><span class="line">&quot;admin_and_matching_group_domain_id&quot;: &quot;rule:admin_required and domain_id:%(group.domain_id)s&quot;,</span><br><span class="line">&quot;admin_and_matching_domain_id&quot;: &quot;rule:admin_required and domain_id:%(domain_id)s&quot;,</span><br><span class="line"></span><br><span class="line">&quot;identity:get_user&quot;: &quot;rule:cloud_admin or rule:admin_and_matching_target_user_domain_id or rule:owner&quot;,</span><br><span class="line">&quot;identity:list_users&quot;: &quot;rule:cloud_admin or rule:admin_and_matching_domain_id&quot;,</span><br></pre></td></tr></table></figure>
<h2 id="问题一，找不着用户的调试"><a href="#问题一，找不着用户的调试" class="headerlink" title="问题一，找不着用户的调试"></a>问题一，找不着用户的调试</h2><p>找不着用户时, 可查看日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(keystone.common.ldap.core): 2018-06-08 12:13:23,145 DEBUG LDAP bind: who=cn=admin,dc=cloud,dc=sts</span><br><span class="line">(keystone.common.ldap.core): 2018-06-08 12:13:23,145 DEBUG LDAP search: base=dc=cloud,dc=sts scope=2 filterstr=(&amp;(uidNumber=10002)(objectClass=inetOrgPerson)) attrs=[&apos;description&apos;, &apos;uidNumber&apos;, &apos;userPassword&apos;, &apos;enabled&apos;, &apos;mail&apos;, &apos;uid&apos;] attrsonly=0</span><br></pre></td></tr></table></figure></p>
<p>转换成下列命令看是否能运行:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ldapsearch -h 10.5.0.53 -x -b &apos;dc=cloud,dc=sts&apos; -s sub &quot;(&amp;(uidNumber=10002)(objectClass=inetOrgPerson))&quot; description uidNumber userPassword enabled mail uid attrsonly=0</span><br></pre></td></tr></table></figure></p>
<h2 id="问题二，group-members-are-ids-True"><a href="#问题二，group-members-are-ids-True" class="headerlink" title="问题二，group_members_are_ids = True"></a>问题二，group_members_are_ids = True</h2><p>例如本例数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># Entry 5: cn=openstack,ou=groups,dc=test,dc=com</span><br><span class="line">dn: cn=openstack,ou=groups,dc=test,dc=com</span><br><span class="line">cn: openstack</span><br><span class="line">gidnumber: 501</span><br><span class="line">memberuid: johndoe</span><br><span class="line">objectclass: posixGroup</span><br><span class="line">objectclass: top</span><br><span class="line"></span><br><span class="line"># Entry 8: cn=johndoe,ou=users,dc=test,dc=com</span><br><span class="line">dn: cn=johndoe,ou=users,dc=test,dc=com</span><br><span class="line">cn: johndoe</span><br><span class="line">gidnumber: 501</span><br><span class="line">givenname: John</span><br><span class="line">homedirectory: /home/users/jdoe</span><br><span class="line">loginshell: /bin/sh</span><br><span class="line">objectclass: inetOrgPerson</span><br><span class="line">objectclass: posixAccount</span><br><span class="line">objectclass: top</span><br><span class="line">sn: John Doe</span><br><span class="line">uid: johndoe</span><br><span class="line">uidnumber: 1000</span><br><span class="line">userpassword: &#123;MD5&#125;HOMR4pM15t3gYd8WUxMG8g==</span><br><span class="line"># password is crapper</span><br></pre></td></tr></table></figure></p>
<p>根据这个bug描述 - <a href="https://bugs.launchpad.net/keystone/+bug/1526462" target="_blank" rel="external">https://bugs.launchpad.net/keystone/+bug/1526462</a><br>我们得知在posixGroup类型的group下可以有很多memberuid属性，如本例中为id的形式：<br>memberuid: johndoe<br>也可能为下列dn的形式：<br>memberuid: johndoe,ou=users,dc=test,dc=com<br>在使用rpdb (import rpdb;rpdb.set_trace())对代码调试(nc 127.0.0.1 4444)时会发现， 当group_members_are_ids=true时，list_group_users就不会再根据dn找id了。<br>同时下面的一个if语句(if group_member_id == user_id)决定配置中得是：user_id_attribute = uid<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">(Pdb) p group_member_id</span><br><span class="line">u&apos;johndoe&apos;</span><br><span class="line">(Pdb) p user_id</span><br><span class="line">u&apos;johndoe&apos;</span><br><span class="line">(Pdb) l</span><br><span class="line">142             # work.</span><br><span class="line">143             self.get_user(user_id)</span><br><span class="line">144             import rpdb;rpdb.set_trace()</span><br><span class="line">145             member_list = self.group.list_group_users(group_id)</span><br><span class="line">146             for group_member_id in self._transform_group_member_ids(member_list):</span><br><span class="line">147  -&gt;             if group_member_id == user_id:</span><br><span class="line">148                     break</span><br><span class="line">149             else:</span><br><span class="line">150                 raise exception.NotFound(_(&quot;User &apos;%(user_id)s&apos; not found in&quot;</span><br><span class="line">151                                            &quot; group &apos;%(group_id)s&apos;&quot;) %</span><br><span class="line">152                                          &#123;&apos;user_id&apos;: user_id,</span><br></pre></td></tr></table></figure></p>
<h2 id="问题三，怎么用LDAP里的用户"><a href="#问题三，怎么用LDAP里的用户" class="headerlink" title="问题三，怎么用LDAP里的用户"></a>问题三，怎么用LDAP里的用户</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line">1, Confirm the user johndoe is in the domain aaa_domain</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| 5d15ad6474b1f212d159d974eba4d6b402636e67a7253bf7acb64403ff8c2c53 | janedoe |</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line"></span><br><span class="line">2, Create a project myproject</span><br><span class="line"></span><br><span class="line">openstack project create myproject --domain aaa_domain</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack project list --domain aaa_domain</span><br><span class="line">+----------------------------------+-----------+</span><br><span class="line">| ID                               | Name      |</span><br><span class="line">+----------------------------------+-----------+</span><br><span class="line">| f239a9aebc974664b3fb7823d7d873fa | myproject |</span><br><span class="line">+----------------------------------+-----------+</span><br><span class="line"></span><br><span class="line">3, LDAP has two groups, one is admin, one is openstack, see https://api.jujucharms.com/charmstore/v5/~openstack-charmers/ldap-test-fixture-3/archive/files/backup.ldif</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack group list --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+-----------+</span><br><span class="line">| ID                                                               | Name      |</span><br><span class="line">+------------------------------------------------------------------+-----------+</span><br><span class="line">| a202723c28709cef142842b452fc93caf45d6b661e5d636a96cd10b9379fe0d2 | admin     |</span><br><span class="line">| c94536ce5d46380996999782dacf490b640385cd9b75450782cb279501238eac | openstack |</span><br><span class="line">+------------------------------------------------------------------+-----------+</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --group openstack --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --group admin --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line"></span><br><span class="line">3, Assign Role to a group in a project</span><br><span class="line"></span><br><span class="line">openstack role add --group openstack --project myproject --group-domain aaa_domain Member</span><br><span class="line">openstack role add --group openstack --project myproject --group-domain aaa_domain Admin</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack role list --group openstack --project myproject --group-domain aaa_domain</span><br><span class="line">Listing assignments using role list is deprecated. Use role assignment list --group &lt;group-name&gt; --project &lt;project-name&gt; --names instead.</span><br><span class="line">+----------------------------------+--------+-----------+-----------+</span><br><span class="line">| ID                               | Name   | Project   | Group     |</span><br><span class="line">+----------------------------------+--------+-----------+-----------+</span><br><span class="line">| 578a7eca0d184945b57ed0b718e59ae0 | Member | myproject | openstack |</span><br><span class="line">| 64c64c90886d4f3cb13d3c599748086b | Admin  | myproject | openstack |</span><br><span class="line">+----------------------------------+--------+-----------+-----------+</span><br><span class="line"></span><br><span class="line">4, Confirm the user johndoe in the the domain aaa_domain and group openstack</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --group openstack --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line"></span><br><span class="line">5, Switch to use the user johndoe</span><br><span class="line"></span><br><span class="line">source ~/stsstack-bundles/novarcv3_project</span><br><span class="line">export OS_USER_DOMAIN_NAME=aaa_domain</span><br><span class="line">export OS_PROJECT_DOMAIN_NAME=aaa_domain</span><br><span class="line">export OS_PROJECT_NAME=myproject</span><br><span class="line">export OS_USERNAME=johndoe</span><br><span class="line">export OS_PASSWORD=crapper</span><br><span class="line">export OS_AUTH_URL=http://10.5.0.72:5000/v3</span><br><span class="line">export OS_AUTH_VERSION=3</span><br><span class="line">export OS_IDENTITY_API_VERSION=3</span><br><span class="line">export OS_REGION_NAME=RegionOne</span><br><span class="line"></span><br><span class="line">6, Test the user johndoe</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user show johndoe</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line">| Field               | Value                                                            |</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line">| domain_id           | ae678292805a4db7917137c0621fe4cc                                 |</span><br><span class="line">| id                  | dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 |</span><br><span class="line">| name                | johndoe                                                          |</span><br><span class="line">| options             | &#123;&#125;                                                               |</span><br><span class="line">| password_expires_at | None                                                             |</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list</span><br><span class="line">You are not authorized to perform the requested action: identity:list_users. (HTTP 403) (Request-ID: req-8c373161-37d7-4d33-9dda-16bdbd2cecb7)</span><br><span class="line"></span><br><span class="line">Why we are not authorized to run &apos;openstack user list&apos;, that&apos;s because the following policy rules.</span><br><span class="line"></span><br><span class="line">&quot;admin_required&quot;: &quot;role:Admin&quot;,</span><br><span class="line">&quot;cloud_admin&quot;: &quot;rule:admin_required and (is_admin_project:True or domain_id:59d6b9c88f654dba9d06772ec1b197f0 or project_id:bbbb856f30b042a9a64d6646273a9ae2)&quot;,</span><br><span class="line">&quot;owner&quot; : &quot;user_id:%(user_id)s or user_id:%(target.token.user_id)s&quot;,</span><br><span class="line">&quot;admin_and_matching_group_domain_id&quot;: &quot;rule:admin_required and domain_id:%(group.domain_id)s&quot;,</span><br><span class="line">&quot;admin_and_matching_domain_id&quot;: &quot;rule:admin_required and domain_id:%(domain_id)s&quot;,</span><br><span class="line"></span><br><span class="line">&quot;identity:get_user&quot;: &quot;rule:cloud_admin or rule:admin_and_matching_target_user_domain_id or rule:owner&quot;,</span><br><span class="line">&quot;identity:list_users&quot;: &quot;rule:cloud_admin or rule:admin_and_matching_domain_id&quot;,</span><br><span class="line"></span><br><span class="line">怎么才能让openstack user list生效呢？</span><br><span class="line">1, LDAP中的两个组openstack与admin, johndoe都在这两个组下。</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --group openstack --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --group admin --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">2, policy rules中在用project_id:bbbb856f30b042a9a64d6646273a9ae2</span><br><span class="line">所以首先得用admin权限为bbbb856f30b042a9a64d6646273a9ae2这个project添加Admin role：</span><br><span class="line">openstack role add --group admin --project bbbb856f30b042a9a64d6646273a9ae2 --group-domain aaa_domain Admin</span><br><span class="line">其将环境变量得使用这个group：</span><br><span class="line">unset OS_PROJECT_NAME</span><br><span class="line">export OS_PROJECT_ID=bbbb856f30b042a9a64d6646273a9ae2</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list</span><br><span class="line">+----------------------------------+-------------------+</span><br><span class="line">| ID                               | Name              |</span><br><span class="line">+----------------------------------+-------------------+</span><br><span class="line">| 12507a988b8a438e85ee36617302fd34 | neutron           |</span><br><span class="line">| 1b8ad6f6fc4c479a90b7a34c8187cd3b | cinderv2_cinderv3 |</span><br><span class="line">| 2c6d8f3b156c45b5bb7998cca056edc4 | nova_placement    |</span><br><span class="line">| feaaf07467f142a5a5901ab066af9dca | glance            |</span><br><span class="line">+----------------------------------+-------------------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ env |grep OS_</span><br><span class="line">OS_PROJECT_ID=bbbb856f30b042a9a64d6646273a9ae2</span><br><span class="line">OS_REGION_NAME=RegionOne</span><br><span class="line">OS_USER_DOMAIN_NAME=aaa_domain</span><br><span class="line">OS_AUTH_VERSION=3</span><br><span class="line">OS_IDENTITY_API_VERSION=3</span><br><span class="line">OS_PASSWORD=crapper</span><br><span class="line">OS_AUTH_URL=http://10.5.0.72:5000/v3</span><br><span class="line">OS_USERNAME=johndoe</span><br><span class="line">OS_PROJECT_DOMAIN_NAME=aaa_domain</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/06/08/Play-with-LDAP-Keystone-by-quqi99/" data-id="cjkgczyek0008kobpxpbdlgx0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-回顾OpenStack中的测试" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/15/回顾OpenStack中的测试/" class="article-date">
  <time datetime="2018-03-15T06:28:01.000Z" itemprop="datePublished">2018-03-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/15/回顾OpenStack中的测试/">回顾OpenStack中的测试</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-03-15)</strong></p>
<ol>
<li><p>沿用tox调用virtualenv自动创建的虚拟环境(virtualenv -p python3.5 .tox/py35)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source .tox/py35/bin/activate</span><br><span class="line">sudo pip install --upgrade -r requirements.txt</span><br><span class="line">sudo pip install --upgrade -r test-requirements.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用unittest和nose运行测试。nose是对unittest的扩展，使得python的测试更加简单，nose自动发现测试代码并执行，nose提供了大量的插件，比如覆盖报表等。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python -m unittest -v unit_tests.test_neutron_utils.TestNeutronUtils.test_get_packages_ovs_newton</span><br><span class="line">.tox/py35/bin/python nosetests -v unit_tests/test_neutron_utils.py:TestNeutronUtils.test_get_packages_ovs_newton</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>注意：上面采用nosetests运行时会报错，因为我们的测试采用了python3, 所以需要在安装了python3-nose之后（sudo apt-get install python3-nose python3-mock）再采用下列三种方式之一运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nosetests3 -v unit_tests/test_neutron_utils.py:TestNeutronUtils.test_restart_map_ovs_odl</span><br><span class="line">/bak/work/charms/neutron-gateway/.tox/py35/bin/python /usr/local/bin/nosetests -v unit_tests/test_neutron_utils.py:TestNeutronUtils.test_get_packages_ovs_newton</span><br><span class="line">python -m nose unit_tests/test_neutron_utils.py:TestNeutronUtils.test_restart_map_ovs_odl</span><br></pre></td></tr></table></figure></p>
<p>但实际上仍然找不找nose模块，那是因为nose与virtualenv结合地不大好，在这个网页找着了答案(<a href="https://stackoverflow.com/questions/864956/problems-using-nose-in-a-virtualenv" target="_blank" rel="external">https://stackoverflow.com/questions/864956/problems-using-nose-in-a-virtualenv</a>) - You need to have a copy of nose installed in the virtual environment. In order to force installation of nose into the virtualenv, even though it is already installed in the global site-packages, run pip install with the -I flag: pip install nose -I</p>
<ol>
<li><p>上面使用unittest与nose运行测试的方式只是将结果输出到stdout，不便于分析。所以可以使用python-subunit模块来运行测试，并将测试结果通过subunit协议输出到文件中便于日后分析。因为subunit是基于二进制的不便于人眼看，所以可使用subunit2pyunit工具将其人类可读化。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python -m subunit.run discover |subunit2pyunit</span><br><span class="line">python -m subunit.run discover -t ./ ./unit_tests |subunit2pyunit</span><br><span class="line">python -m subunit.run unit_tests.test_neutron_utils.TestNeutronUtils. |subunit2pyunit</span><br></pre></td></tr></table></figure>
</li>
<li><p>在大型应用中分析测试结果很重要，testrepository可以调用subunit来用python-subunit模块来运行测试，并将测试结果通过subunit协议输出到文件中，然后testrepository在些基础上有更多的分析，如分析哪些用例运行的时间最长，如显示失败的用例，如仅运行上次运行失败的用例。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">testr init</span><br><span class="line">testr run</span><br><span class="line">testr run --parallel</span><br><span class="line">$ cat .testr.conf</span><br><span class="line">[DEFAULT]</span><br><span class="line">test_command=OS_STDOUT_CAPTURE=$&#123;OS_STDOUT_CAPTURE:-1&#125; \</span><br><span class="line">             OS_STDERR_CAPTURE=$&#123;OS_STDERR_CAPTURE:-1&#125; \</span><br><span class="line">             OS_TEST_TIMEOUT=$&#123;OS_TEST_TIMEOUT:-60&#125; \</span><br><span class="line">             $&#123;PYTHON:-python&#125; -m subunit.run discover -t ./ ./unit_tests $LISTOPT $IDOPTION</span><br><span class="line">test_id_option=--load-list $IDFILE</span><br><span class="line">test_list_option=--list</span><br></pre></td></tr></table></figure>
</li>
<li><p>tox用于创建虚拟python环境，也可以集成上面的testrepository(commands = ostestr {posargs})</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">$ cat tox.ini</span><br><span class="line">[tox]</span><br><span class="line">envlist = pep8,py27,py35</span><br><span class="line">skipsdist = True</span><br><span class="line"></span><br><span class="line">[testenv]</span><br><span class="line">setenv = VIRTUAL_ENV=&#123;envdir&#125;</span><br><span class="line">         PYTHONHASHSEED=0</span><br><span class="line">         CHARM_DIR=&#123;envdir&#125;</span><br><span class="line">         AMULET_SETUP_TIMEOUT=5400</span><br><span class="line">install_command =</span><br><span class="line">  pip install --allow-unverified python-apt &#123;opts&#125; &#123;packages&#125;</span><br><span class="line">commands = ostestr &#123;posargs&#125;</span><br><span class="line">whitelist_externals = juju</span><br><span class="line">passenv = HOME TERM AMULET_* CS_API_*</span><br><span class="line"></span><br><span class="line">[testenv:py27]</span><br><span class="line">basepython = python2.7</span><br><span class="line">deps = -r&#123;toxinidir&#125;/requirements.txt</span><br><span class="line">       -r&#123;toxinidir&#125;/test-requirements.txt</span><br><span class="line">commands = /bin/true</span><br><span class="line"></span><br><span class="line">[testenv:py35]</span><br><span class="line">basepython = python3.5</span><br><span class="line">deps = -r&#123;toxinidir&#125;/requirements.txt</span><br><span class="line">       -r&#123;toxinidir&#125;/test-requirements.txt</span><br><span class="line"></span><br><span class="line">[testenv:pep8]</span><br><span class="line">basepython = python2.7</span><br><span class="line">deps = -r&#123;toxinidir&#125;/requirements.txt</span><br><span class="line">       -r&#123;toxinidir&#125;/test-requirements.txt</span><br><span class="line">commands = flake8 &#123;posargs&#125; hooks unit_tests tests actions lib</span><br><span class="line">           charm-proof</span><br><span class="line"></span><br><span class="line">[flake8]</span><br><span class="line">ignore = E402,E226</span><br><span class="line">exclude = */helpers</span><br></pre></td></tr></table></figure>
</li>
<li><p>pydev使用virtualenv中的py35<br>在eclipse的”Preferences -&gt; Pydev -&gt; Interpreters -&gt; Python Interpreters”菜单中定义python35=/bak/work/charms/neutron-gateway/.tox/py35/bin/python,然后在工程上点右键从”Properties -&gt; Pydev - Interpreter/Grammar”定义使用python35。注意，需要将/bak/work/charms/neutron-gateway/.tox/py35/lib/python3.5/site-packages也选到环境变量中，否则后面会报ImportError: No module named ‘mock。<br>为一个测试类定义”Python unitest”类型的”Debug Configurations”, 也在其Interpreter选项卡中定义使用python35 (结果：eclipse似乎有bug，此处选择了python35后无法保存)<br>所以无法成功，似乎是pydev与python3协作不大好。最后还是pudb好使(sudo pip install pudb, import pudb; pdb.set_trace())</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/15/回顾OpenStack中的测试/" data-id="cjkgczyf7000kkobpfp71zjoj" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Libvirt支持的三种CPU模式与热迁移-by-Joshua" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/09/Libvirt支持的三种CPU模式与热迁移-by-Joshua/" class="article-date">
  <time datetime="2018-03-09T03:42:14.000Z" itemprop="datePublished">2018-03-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/09/Libvirt支持的三种CPU模式与热迁移-by-Joshua/">Libvirt支持的三种CPU模式与热迁移(by Joshua)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-03-09)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>原始的nova配置(cpu_mode=”host-passthrough”)导致无法热迁移，改成(cpu_mode=”custom”, cpu_model=”kvm64”)之后解决了热迁移问题但是嵌套虚拟化又不好便了，接着又改成(cpu_mode=’host-model’)但热迁移仍然失败。有两全其美的方法吗？</p>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">1, working solution was to create a custom CPU definition in /usr/share/libvirt/cpu_map.xml called SandyBridge-vmx, which contained the full feature flags for that CPU, not just the subset that differs from Westmere/etc., and includes the needed &apos;vmx&apos; feature for nested kvm</span><br><span class="line">&lt;model name=&apos;SandyBridge-vmx&apos;&gt;</span><br><span class="line">&lt;vendor name=&apos;Intel&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;aes&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;apic&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;avx&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;clflush&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;cmov&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;cx16&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;cx8&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;de&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;fpu&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;fxsr&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;lahf_lm&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;lm&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;mca&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;mce&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;mmx&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;msr&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;mtrr&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;nx&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;pae&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;pat&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;pclmuldq&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;pge&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;pni&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;popcnt&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;pse&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;pse36&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;rdtscp&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;sep&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;sse&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;sse2&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;sse4.1&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;sse4.2&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;ssse3&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;syscall&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;tsc&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;tsc-deadline&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;x2apic&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;xsave&apos;/&gt;</span><br><span class="line">&lt;feature name=&apos;vmx&apos;/&gt;</span><br><span class="line">&lt;/model&gt;</span><br><span class="line"></span><br><span class="line">2, And in /etc/nova/nova.conf, we use:</span><br><span class="line">$ sudo grep ^cpu_m /etc/nova/nova.conf</span><br><span class="line">cpu_mode = custom</span><br><span class="line">cpu_model = SandyBridge-vmx</span><br></pre></td></tr></table></figure>
<h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>Libvirt主要支持三种 CPU mode：</p>
<ol>
<li>host-passthrough: libvirt 令 KVM 把宿主机的 CPU 指令集全部透传给虚拟机。因此虚拟机能够最大限度的使用宿主机 CPU 指令集，故性能是最好的。但是在热迁移时，它要求目的节点的 CPU 和源节点的一致。</li>
<li>host-model: libvirt 根据当前宿主机 CPU 指令集从配置文件 /usr/share/libvirt/cpu_map.xml 选择一种最相配的 CPU 型号。在这种 mode 下，虚拟机的指令集往往比宿主机少，性能相对 host-passthrough 要差一点，但是热迁移时，它允许目的节点 CPU 和源节点的存在一定的差异。</li>
<li>custom: 这种模式下虚拟机 CPU 指令集数最少，故性能相对最差，但是它在热迁移时跨不同型号 CPU 的能力最强。此外，custom 模式下支持用户添加额外的指令集。</li>
<li>三种mode的性能排序是：host-passthrough &gt; host-model &gt; custom</li>
<li>三种mode的热迁移通用性是： custom &gt; host-model &gt; host-passthrough</li>
</ol>
<p>实际环境中多采用Intel E5系列的CPU，但是该系列的CPU也有多种型号，常见的有Xeon，Haswell，IvyBridge，SandyBridge等等。即使是host-model，在这些不同型号的CPU之间热迁移虚拟机也可能失败。所以从热迁移的角度，在选择 host-mode时：</p>
<ul>
<li>需要充分考虑既有宿主机类型，以后采购扩容时，也需要考虑相同问题</li>
<li>除非不存在热迁移的场景，否则不应用选择host-passthrough</li>
<li><p>host-model下不同型号的 CPU 最好能以aggregate hosts划分，在迁移时可以使用aggregate filter来匹配相同型号的物理机</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">openstack aggregate create Broadwell</span><br><span class="line">openstack aggregate create Haswell</span><br><span class="line">openstack aggregate set --property cpu=broadwell Broadwell</span><br><span class="line">openstack aggregate set --property cpu=haswell Haswell</span><br><span class="line">opentack aggregate add host &lt;host1&gt; Haswell</span><br><span class="line">openstack flavor set --property aggregate_instance_extra_specs:cpu=broadwell &lt;flavor1&gt;</span><br><span class="line">openstack flavor set --property aggregate_instance_extra_specs:cpu=haswell &lt;flavor2&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果CPU型号过多，且不便用aggregate hosts划分，建议使用custom mode</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/09/Libvirt支持的三种CPU模式与热迁移-by-Joshua/" data-id="cjkgczye80004kobpvr66tbfg" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-OpenStack-SSL" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/02/07/OpenStack-SSL/" class="article-date">
  <time datetime="2018-02-07T05:25:04.000Z" itemprop="datePublished">2018-02-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/07/OpenStack-SSL/">OpenStack SSL</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-02-07)</strong></p>
<h2 id="OpenStack-Charm如何支持SSL"><a href="#OpenStack-Charm如何支持SSL" class="headerlink" title="OpenStack Charm如何支持SSL"></a>OpenStack Charm如何支持SSL</h2><p>OpenStack Charm需为每个OpenStack服务配置证书（/var/lib/keystone/juju_ssl/, /usr/local/share/ca-certificates/)与https endpoint，同时也会生成/etc/apache2/ssl/keystone配置。</p>
<ol>
<li><p>一种方式有证书就直接指定证书</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">juju config &lt;openstack-charm&gt; os-admin-hostname=&apos;X.xxx.com&apos; os-public-hostname=&apos;X.xxx.com&apos; os-internal-hostname=&apos;X.xxx.com&apos; ssl_ca=&apos;$cat ~/ssl_ca.crt&apos; ssl_cert=&apos;$cat ~/ssl_cert.crt&apos; ssl_key=&apos;&apos;$cat ~/ssl_key.key&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>第二种方式是由charm来自动生成证书。如果用户没有指定ssl_cert与ssl_key，那么is_cert_provided_in_config=False，charm将自动生成证书。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def is_cert_provided_in_config():</span><br><span class="line">    cert = config(&apos;ssl_cert&apos;)</span><br><span class="line">    key = config(&apos;ssl_key&apos;)</span><br><span class="line">    return bool(cert and key)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>具体命令如下，也可参考：<a href="https://paste.ubuntu.com/26533565/" target="_blank" rel="external">https://paste.ubuntu.com/26533565/</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">juju config keystone use-https=true</span><br><span class="line">juju config keystone https-service-endpoints=true</span><br><span class="line">tree /var/lib/keystone/juju_ssl/</span><br><span class="line">grep -r &apos;ssl&apos; /etc/keystone/</span><br><span class="line">grep -r &apos;ssl&apos; /etc/nova/  #on nova node</span><br><span class="line">select * from endpoint;</span><br><span class="line">juju run --unit keystone/0 &quot;relation-ids identity-service&quot;</span><br><span class="line">juju run --unit keystone/0 &quot;relation-list -r identity-service:13&quot;</span><br><span class="line">juju run --unit keystone/0 &quot;relation-get -r identity-service:13 - nova-cloud-controller/0&quot;</span><br><span class="line"></span><br><span class="line">export OS_REGION_NAME=RegionOne</span><br><span class="line">export OS_PROJECT_NAME=admin</span><br><span class="line">export OS_PASSWORD=openstack</span><br><span class="line">export OS_AUTH_URL=https://10.5.0.28:5000/v2.0</span><br><span class="line">export OS_USERNAME=admin</span><br><span class="line">openstack --insecure endpoint list</span><br><span class="line">openstack --insecure server list</span><br><span class="line">openstack --insecure --debug server list</span><br><span class="line">openstack --insecure --debug volume list</span><br></pre></td></tr></table></figure></p>
<h2 id="OpenStack-HA-Charm如何支持SSL"><a href="#OpenStack-HA-Charm如何支持SSL" class="headerlink" title="OpenStack HA Charm如何支持SSL"></a>OpenStack HA Charm如何支持SSL</h2><p>如果如nova-cloud-controller服务前又运行了下列命令添加了HA服务时呢？<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">juju add-unit nova-cloud-controller -n 2  </span><br><span class="line">juju deploy hacluster ncc-hacluster --series xenial  </span><br><span class="line">juju add-relation nova-cloud-controller ncc-hacluster  </span><br><span class="line">juju config nova-cloud-controller vip=10.5.104.1</span><br></pre></td></tr></table></figure></p>
<p>corosync将通过下列配置将VIP=10.5.104.1创建在juju-2f3cc6-mitaka-10上。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">root@juju-2f3cc6-mitaka-10:~# crm status</span><br><span class="line">Last updated: Wed Feb  7 04:18:31 2018		Last change: Wed Feb  7 04:09:33 2018 by hacluster via crmd on juju-2f3cc6-mitaka-10</span><br><span class="line">Stack: corosync</span><br><span class="line">Current DC: juju-2f3cc6-mitaka-6 (version 1.1.14-70404b0) - partition with quorum</span><br><span class="line">3 nodes and 4 resources configured</span><br><span class="line">Online: [ juju-2f3cc6-mitaka-10 juju-2f3cc6-mitaka-11 juju-2f3cc6-mitaka-6 ]</span><br><span class="line">Full list of resources:</span><br><span class="line"> Resource Group: grp_nova_vips</span><br><span class="line">     res_nova_ens3_vip	(ocf::heartbeat:IPaddr2):	Started juju-2f3cc6-mitaka-10</span><br><span class="line"> Clone Set: cl_nova_haproxy [res_nova_haproxy]</span><br><span class="line">     Started: [ juju-2f3cc6-mitaka-10 juju-2f3cc6-mitaka-11 juju-2f3cc6-mitaka-6 ]</span><br><span class="line"></span><br><span class="line">root@juju-2f3cc6-mitaka-10:~# ip addr show ens3 |grep 10.5.104.1</span><br><span class="line">    inet 10.5.104.1/16 brd 10.5.255.255 scope global secondary ens3</span><br></pre></td></tr></table></figure></p>
<p>同时，三个HA节点上的haproxy的配置(/etc/haproxy/haproxy.cfg)将创建代理。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">frontend tcp-in_nova-api-os-compute</span><br><span class="line">    bind *:8774</span><br><span class="line">    bind :::8774</span><br><span class="line">    acl net_10.5.0.15 dst 10.5.0.15/255.255.0.0</span><br><span class="line">    use_backend nova-api-os-compute_10.5.0.15 if net_10.5.0.15</span><br><span class="line">    default_backend nova-api-os-compute_10.5.0.15</span><br><span class="line">backend nova-api-os-compute_10.5.0.15</span><br><span class="line">    balance leastconn</span><br><span class="line">    server nova-cloud-controller-1 10.5.0.15:8764 check</span><br><span class="line">    server nova-cloud-controller-0 10.5.0.37:8764 check</span><br><span class="line">    server nova-cloud-controller-2 10.5.0.52:8764 check</span><br></pre></td></tr></table></figure></p>
<p>最重要的是，三个HA节点上Apache都将设置代理“RequestHeader set X-Forwarded-Proto “https””，完整的配置如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">root@juju-2f3cc6-mitaka-10:~# cat /etc/apache2/sites-available/openstack_https_frontend.conf </span><br><span class="line">Listen 8764</span><br><span class="line">&lt;VirtualHost 10.5.0.15:8764&gt;</span><br><span class="line">    ServerName 10.5.104.1</span><br><span class="line">    SSLEngine on</span><br><span class="line">    SSLProtocol +TLSv1 +TLSv1.1 +TLSv1.2</span><br><span class="line">    SSLCipherSuite HIGH:!RC4:!MD5:!aNULL:!eNULL:!EXP:!LOW:!MEDIUM</span><br><span class="line">    SSLCertificateFile /etc/apache2/ssl/nova/cert_10.5.104.1</span><br><span class="line">    # See LP 1484489 - this is to support &lt;= 2.4.7 and &gt;= 2.4.8</span><br><span class="line">    SSLCertificateChainFile /etc/apache2/ssl/nova/cert_10.5.104.1</span><br><span class="line">    SSLCertificateKeyFile /etc/apache2/ssl/nova/key_10.5.104.1</span><br><span class="line">    ProxyPass / http://localhost:8754/</span><br><span class="line">    ProxyPassReverse / http://localhost:8754/</span><br><span class="line">    ProxyPreserveHost on</span><br><span class="line">    RequestHeader set X-Forwarded-Proto &quot;https&quot;</span><br><span class="line">&lt;/VirtualHost&gt;</span><br><span class="line">&lt;Proxy *&gt;</span><br><span class="line">    Order deny,allow</span><br><span class="line">    Allow from all</span><br><span class="line">&lt;/Proxy&gt;</span><br><span class="line">&lt;Location /&gt;</span><br><span class="line">    Order allow,deny</span><br><span class="line">    Allow from all</span><br><span class="line">&lt;/Location&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="OpenStack-Horizon和Apache代理之间如何支持SSL"><a href="#OpenStack-Horizon和Apache代理之间如何支持SSL" class="headerlink" title="OpenStack Horizon和Apache代理之间如何支持SSL"></a>OpenStack Horizon和Apache代理之间如何支持SSL</h2><p>openstack horizon使用了Django框架，Django中有如下代码（<a href="https://github.com/django/django/blob/2.0.2/django/http/request.py#L191），" target="_blank" rel="external">https://github.com/django/django/blob/2.0.2/django/http/request.py#L191），</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@property</span><br><span class="line">def scheme(self):</span><br><span class="line">    if settings.SECURE_PROXY_SSL_HEADER:</span><br><span class="line">        try:</span><br><span class="line">            header, value = settings.SECURE_PROXY_SSL_HEADER</span><br><span class="line">        except ValueError:</span><br><span class="line">            raise ImproperlyConfigured(</span><br><span class="line">                &apos;The SECURE_PROXY_SSL_HEADER setting must be a tuple containing two values.&apos;</span><br><span class="line">            )</span><br><span class="line">        if self.META.get(header) == value:</span><br><span class="line">            return &apos;https&apos;</span><br><span class="line">    return self._get_scheme()</span><br></pre></td></tr></table></figure>
<p>它会根据django中是否配置了SECURE_PROXY_SSL_HEADER，然后比较和header中传过来的SECURE_PROXY_SSL_HEADER(self.META.get(header))是否相等, 若相等才返回https给前端代理。所以这说明需要做两件事情：</p>
<ol>
<li>一是在django的conf/global_settings.py模板中配置： SECURE_PROXY_SSL_HEADER = (‘HTTP_X_FORWARDED_PROTO’, ‘https’)</li>
<li>二是前端代理apache中的配置传过来名为X-Forwarded-Proto的header: RequestHeader set X-Forwarded-Proto “https”<br>更多见： <a href="https://design.canonical.com/2015/08/django-behind-a-proxy-fixing-absolute-urls/" target="_blank" rel="external">https://design.canonical.com/2015/08/django-behind-a-proxy-fixing-absolute-urls/</a></li>
</ol>
<h2 id="OpenStack其他工程和Apache代理之间如何支持SSL"><a href="#OpenStack其他工程和Apache代理之间如何支持SSL" class="headerlink" title="OpenStack其他工程和Apache代理之间如何支持SSL"></a>OpenStack其他工程和Apache代理之间如何支持SSL</h2><p>至于其它openstack工程如nova则需要使用olso.middleware中的http_proxy_to_wsgi.py(<a href="https://github.com/openstack/oslo.middleware/blob/stable/ocata/oslo_middleware/http_proxy_to_wsgi.py)用于解析前端代理apache传过来的X-Forwarded-Proto" target="_blank" rel="external">https://github.com/openstack/oslo.middleware/blob/stable/ocata/oslo_middleware/http_proxy_to_wsgi.py)用于解析前端代理apache传过来的X-Forwarded-Proto</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># World before RFC7239</span><br><span class="line">forwarded_proto = req.environ.get(&quot;HTTP_X_FORWARDED_PROTO&quot;)</span><br><span class="line">if forwarded_proto:</span><br><span class="line">    req.environ[&apos;wsgi.url_scheme&apos;] = forwarded_proto</span><br></pre></td></tr></table></figure></p>
<p>nova-api中再根据wsgi.url_scheme（<a href="https://github.com/openstack/nova/blob/stable/ocata/nova/api/openstack/urlmap.py）决定是使用80还是ssl的443" target="_blank" rel="external">https://github.com/openstack/nova/blob/stable/ocata/nova/api/openstack/urlmap.py）决定是使用80还是ssl的443</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if environ[&apos;wsgi.url_scheme&apos;] == &apos;http&apos;:</span><br><span class="line">    port = &apos;80&apos;</span><br><span class="line">else:</span><br><span class="line">    port = &apos;443&apos;</span><br></pre></td></tr></table></figure></p>
<p>配置http_proxy_to_wsgi的方法是在/etc/nova/api-paste.ini中添加http_proxy_to_wsgi（ eg: <a href="https://bugs.launchpad.net/keystone/+bug/1590608" target="_blank" rel="external">https://bugs.launchpad.net/keystone/+bug/1590608</a>)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[composite:openstack_compute_api_v21]</span><br><span class="line">use = call:nova.api.auth:pipeline_factory_v21</span><br><span class="line">noauth2 = cors http_proxy_to_wsgi compute_req_id faultwrap sizelimit noauth2 osapi_compute_app_v21</span><br><span class="line">keystone = cors http_proxy_to_wsgi compute_req_id faultwrap sizelimit authtoken keystonecontext osapi_compute_app_v21</span><br><span class="line">[filter:http_proxy_to_wsgi]</span><br><span class="line">paste.filter_factory = oslo_middleware.http_proxy_to_wsgi:HTTPProxyToWSGI.factory</span><br></pre></td></tr></table></figure>
<h2 id="附录-原生OpenStack配置SSL的方法"><a href="#附录-原生OpenStack配置SSL的方法" class="headerlink" title="附录 - 原生OpenStack配置SSL的方法"></a>附录 - 原生OpenStack配置SSL的方法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">1, Create ssl certifate</span><br><span class="line"></span><br><span class="line">$ sudo keystone-manage ssl_setup --keystone-user keystone --keystone-group keystone</span><br><span class="line">$ chown -R keystone:keystone /etc/keystone/ssl</span><br><span class="line">$ sudo ls /etc/keystone/ssl/certs</span><br><span class="line">01.pem	ca.pem	index.txt  index.txt.attr  index.txt.old  keystone.pem	openssl.conf  req.pem  serial  serial.old</span><br><span class="line">$ sudo ls /etc/keystone/ssl/private</span><br><span class="line">cakey.pem  keystonekey.pem</span><br><span class="line"></span><br><span class="line">openssl genrsa -out /etc/keystone/ssl/private/cakey.pem 1024</span><br><span class="line">openssl req -new -x509 -extensions v3_ca -key /etc/keystone/ssl/private/cakey.pem -out /etc/keystone/ssl/certs/ca.pem -days 3650 -config /etc/keystone/ssl/certs/openssl.conf -subj /C=US/ST=Unset/L=Unset/O=Unset/CN=localhost</span><br><span class="line">openssl genrsa -out /etc/keystone/ssl/private/keystonekey.pem 1024</span><br><span class="line">openssl req -key /etc/keystone/ssl/private/keystonekey.pem -new -out /etc/keystone/ssl/certs/req.pem -config /etc/keystone/ssl/certs/openssl.conf -subj /C=US/ST=Unset/L=Unset/O=Unset/CN=localhost</span><br><span class="line">openssl ca -batch -out /etc/keystone/ssl/certs/keystone.pem -config /etc/keystone/ssl/certs/openssl.conf -days 3650d -cert /etc/keystone/ssl/certs/ca.pem -keyfile /etc/keystone/ssl/private/cakey.pem -infiles /etc/keystone/ssl/certs/req.pem</span><br><span class="line"></span><br><span class="line">2, Keystone ssl configuration</span><br><span class="line"></span><br><span class="line"># vi /etc/keystone/keystone.conf</span><br><span class="line">[signing]</span><br><span class="line">certfile = /var/lib/keystone/juju_ssl/pki/certs/signing_cert.pem</span><br><span class="line">keyfile = /var/lib/keystone/juju_ssl/pki/privates/signing_key.pem</span><br><span class="line">ca_certs = /var/lib/keystone/juju_ssl/pki/certs/ca.pem</span><br><span class="line">ca_key = /var/lib/keystone/juju_ssl/pki/certs/ca_key.pem</span><br><span class="line"></span><br><span class="line">export OS_AUTH_URL=https://&#123;keystoneHost&#125;:5000/v2.0</span><br><span class="line"></span><br><span class="line"># create new https endpoint</span><br><span class="line">keystone endpoint-create</span><br><span class="line">--service keystone --region RegionOne --publicurl</span><br><span class="line">https://&#123;keystoneHost&#125;:5000/v2.0 --internalurl</span><br><span class="line">https://&#123;keystoneHost&#125;:35357/v2.0 --adminurl</span><br><span class="line">https://&#123;keystoneHost&#125;:35357/v2.0</span><br><span class="line"></span><br><span class="line"># delete old http endpoint</span><br><span class="line">keystone –-insecure endpoint-delete &#123;old endpoint id&#125;</span><br><span class="line"></span><br><span class="line">3, Nova ssl configuration</span><br><span class="line"></span><br><span class="line"># configure nova to use https to connect keystone</span><br><span class="line"># vi /etc/nova/api-paste.ini</span><br><span class="line">auth_uri = https://10.1.0.92:5000/v2.0</span><br><span class="line">auth_protocol = https</span><br><span class="line">insecure = True</span><br><span class="line"></span><br><span class="line">service openstack-nova-api restart</span><br><span class="line">service openstack-nova-compute restart</span><br><span class="line">service openstack-nova-scheduler restart</span><br><span class="line">service openstack-nova-cert restart</span><br><span class="line">service openstack-nova-conductor restart</span><br><span class="line">service openstack-nova-consoleauth restart</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># vi /etc/nova/nova.conf [DEFAULT]</span><br><span class="line">enabled_ssl_apis=osapi_compute</span><br><span class="line">ssl_cert_file=/etc/nova/ssl/keystone.pem</span><br><span class="line">ssl_key_file=/etc/nova/ssl/keystonekey.pem</span><br><span class="line"></span><br><span class="line"># test it, at this time other component has not be configured to use https, so use --insecure</span><br><span class="line">nova --insecure hypervisor-list</span><br><span class="line"></span><br><span class="line"># copy ssl certifate for nova</span><br><span class="line"># mkdir /etc/nova/ssl</span><br><span class="line"># cp /etc/keystone/ssl/certs/keystone.pem /etc/nova/ssl/</span><br><span class="line"># cp /etc/keystone/ssl/private/keystonekey.pem /etc/nova/ssl/</span><br><span class="line"># chown -R nova:nova /etc/nova/ssl/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># create new https endpoint for nova</span><br><span class="line"># keystone --insecure</span><br><span class="line">endpoint-create --service nova --region RegionOne --publicurl</span><br><span class="line">&quot;https://&#123;novaHost&#125;:8774/v2/%(tenant_id)s&quot; --internalurl</span><br><span class="line">&quot;https://&#123;novaHost&#125;:8774/v2/%(tenant_id)s&quot; --adminurl</span><br><span class="line">&quot;https://&#123;novaHost&#125;:8774/v2/%(tenant_id)s&quot;</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/02/07/OpenStack-SSL/" data-id="cjkgczyeb0005kobp6jms8b46" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/08/03/IPv6来啦/">IPv6来啦</a>
          </li>
        
          <li>
            <a href="/2018/07/13/Using-kubeadm-to-deploy-k8s/">Using kubeadm to deploy k8s</a>
          </li>
        
          <li>
            <a href="/2018/07/13/用OpenSSL做自签名的证书/">用OpenSSL做自签名的证书</a>
          </li>
        
          <li>
            <a href="/2018/07/10/Set-up-k8s-development-env-by-quqi99/">Set up k8s development env (by quqi99)</a>
          </li>
        
          <li>
            <a href="/2018/07/10/温故OpenStack中的测试-by-Joshua/">温故OpenStack中的测试(by Joshua)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 张华<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>