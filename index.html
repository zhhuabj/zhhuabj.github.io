<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>技术并艺术着</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="blog.csdn.net/quqi99">
<meta property="og:type" content="website">
<meta property="og:title" content="技术并艺术着">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="blog.csdn.net/quqi99">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="技术并艺术着">
<meta name="twitter:description" content="blog.csdn.net/quqi99">
  
    <link rel="alternate" href="/atom.xml" title="技术并艺术着" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">技术并艺术着</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">张华的技术博客 - blog.csdn.net/quqi99</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS-каналы"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Поиск"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-virtio-vhost中的限速机制" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/09/virtio-vhost中的限速机制/" class="article-date">
  <time datetime="2018-01-09T08:00:31.000Z" itemprop="datePublished">2018-01-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/09/virtio-vhost中的限速机制/">virtio/vhost中的限速机制</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-01-09)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>日前遇到这么一个问题，客户反应虚机往外发包时丢包并看到”No buffer space available”相关的错误，虚机是windows虚机，宿主机是ubuntu并采用vhost-net机制。</p>
<h2 id="systemtap"><a href="#systemtap" class="headerlink" title="systemtap"></a>systemtap</h2><p>刚开始我们怀疑是这两个patches导致的问题：<br><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/drivers/vhost?id=8d65843c44269c21e95c98090d9bb4848d473853" target="_blank" rel="external">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/drivers/vhost?id=8d65843c44269c21e95c98090d9bb4848d473853</a><br><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/drivers/vhost?id=809ecb9bca6a9424ccd392d67e368160f8b76c92" target="_blank" rel="external">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/drivers/vhost?id=809ecb9bca6a9424ccd392d67e368160f8b76c92</a></p>
<p>所以写了个systemtap脚本在宿主机监控vhost模块中的vhost_signal函数将vring的相关信息打印如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">RX 0 values: old=34264 new=34264 last_used_event=34263 vring_used=0 vring_avail=0</span><br><span class="line">TX 6297677760 values: old=30401 new=30402 last_used_event=0 vring_used=30402 vring_avail=30402</span><br><span class="line"></span><br><span class="line">RX 0 values: old=34264 new=34264 last_used_event=34263 vring_used=0 vring_avail=0</span><br><span class="line">TX 6297677760 values: old=30403 new=30404 last_used_event=0 vring_used=30404 vring_avail=30404</span><br></pre></td></tr></table></figure></p>
<p>根据打印的值，我们算出下面两个公式的结果均为False (<a href="https://github.com/torvalds/linux/blob/v4.10/drivers/vhost/vhost.c#L2189" target="_blank" rel="external">https://github.com/torvalds/linux/blob/v4.10/drivers/vhost/vhost.c#L2189</a> )。<br>vring_need_event(vq-&gt;last_used_event, new + vq-&gt;num, new)<br>vring_need_event(vq-&gt;last_used_event, new, old)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">TX 34936796160 values: old=7077 new=7077 last_used_event=0 vring_used=7077 vring_avail=7077 </span><br><span class="line">1. False: (7077 + 256) - 0 - 1 &lt; (7077 + 256) - 7077 </span><br><span class="line">2. False: 7077 - 0 - 1 &lt; 7077 - 7077</span><br></pre></td></tr></table></figure>
<p>上面为False的话，vhost_notify()就为False，那样vhost也不会调用eventfd_signal通过中断向guest发通知(<a href="https://github.com/torvalds/linux/blob/v4.10/drivers/vhost/vhost.c#L2211" target="_blank" rel="external">https://github.com/torvalds/linux/blob/v4.10/drivers/vhost/vhost.c#L2211</a>)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void vhost_signal(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span><br><span class="line">&#123;</span><br><span class="line">	/* Signal the Guest tell them we used something up. */</span><br><span class="line">	if (vq-&gt;call_ctx &amp;&amp; vhost_notify(dev, vq))</span><br><span class="line">		eventfd_signal(vq-&gt;call_ctx, 1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="理论分析"><a href="#理论分析" class="headerlink" title="理论分析"></a>理论分析</h2><ul>
<li>Guest发数据：guest将发送报文Buffer的head index加入avial_ring中， 在合适的时间点通过ioeventfds消息来通知backend。backend发完报文后再将其加入到used_ring中，并在一个合适的时间点来通过irqdfs中断来通知guest。</li>
<li>Guest收数据：两个queue都需要guest填充buffer, guest将空白Buffer的head index加入avail_ring中，在合适的时间点通过ioeventfds消息来通知backend。backend收完报文后再将其加入到used_ring中，并在一个合适的时间点来通过irqdfs中断来通知guest。</li>
<li>Flags, avail_ring与used_ring中都有flags字段，例如avail_ring中的flags字段代表guest告诉host在host发完报文之后是否需要通知guest。<h2 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h2>在打开VIRTIO_RING_F_EVENT_IDX特性之后，virtio/vhost将不再依据flags来决定是否向对方发送消息(guest到host根据消息通知，host到guest通过中断)，而是guest/host在发送一批报文后(flags是每个包发送性能较差)自行决定是否向对方发消息。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">/* The standard layout for the ring is a continuous chunk of memory which looks</span><br><span class="line"> * like this.  We assume num is a power of 2.</span><br><span class="line"> *</span><br><span class="line"> * struct vring</span><br><span class="line"> * &#123;</span><br><span class="line"> *	// The actual descriptors (16 bytes each)</span><br><span class="line"> *	struct vring_desc desc[num];</span><br><span class="line"> *</span><br><span class="line"> *	// A ring of available descriptor heads with free-running index.</span><br><span class="line"> *	__virtio16 avail_flags;</span><br><span class="line"> *	__virtio16 avail_idx;</span><br><span class="line"> *	__virtio16 available[num];</span><br><span class="line"> *	__virtio16 used_event_idx;</span><br><span class="line"> *</span><br><span class="line"> *	// Padding to the next align boundary.</span><br><span class="line"> *	char pad[];</span><br><span class="line"> *</span><br><span class="line"> *	// A ring of used descriptor heads with free-running index.</span><br><span class="line"> *	__virtio16 used_flags;</span><br><span class="line"> *	__virtio16 used_idx;</span><br><span class="line"> *	struct vring_used_elem used[num];</span><br><span class="line"> *	__virtio16 avail_event_idx;</span><br><span class="line"> * &#125;;</span><br><span class="line"> */</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>此时，在数据结构方面，在used_ring中有avail_event_idx字段，在avail_ring中有used_event_idx字段，用下列方法相互填充。如：vring_avail_event(&amp;vq-&gt;vring)用于将avail_ring中的index填充到used_ring的最后一个字段used_event_idx中去，反之亦然。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/* We publish the used event index at the end of the available ring, and vice</span><br><span class="line"> * versa. They are at the end for backwards compatibility. */</span><br><span class="line">#define vring_used_event(vr) ((vr)-&gt;avail-&gt;ring[(vr)-&gt;num])</span><br><span class="line">#define vring_avail_event(vr) (*(__virtio16 *)&amp;(vr)-&gt;used-&gt;ring[(vr)-&gt;num])</span><br></pre></td></tr></table></figure></p>
<p>1, guest端virtio驱动, 根据vring_need_event()公式，guest在发送缓冲区满了之后才kick消息给host.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/torvalds/linux/blob/v4.10/drivers/virtio/virtio_ring.c#L547</span><br><span class="line"></span><br><span class="line">bool virtqueue_kick_prepare(struct virtqueue *_vq)&#123;</span><br><span class="line">	old = vq-&gt;avail_idx_shadow - vq-&gt;num_added;</span><br><span class="line">	new = vq-&gt;avail_idx_shadow;</span><br><span class="line">	vq-&gt;num_added = 0;</span><br><span class="line">        ...</span><br><span class="line">	if (vq-&gt;event) &#123;</span><br><span class="line">		needs_kick = vring_need_event(virtio16_to_cpu(_vq-&gt;vdev, vring_avail_event(&amp;vq-&gt;vring)),</span><br><span class="line">					      new, old);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		needs_kick = !(vq-&gt;vring.used-&gt;flags &amp; cpu_to_virtio16(_vq-&gt;vdev, VRING_USED_F_NO_NOTIFY));</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">vq-&gt;event = virtio_has_feature(vdev, VIRTIO_RING_F_EVENT_IDX);</span><br><span class="line"></span><br><span class="line">static inline int vring_need_event(__u16 event_idx, __u16 new_idx, __u16 old)</span><br><span class="line">&#123;</span><br><span class="line">	return (__u16)(new_idx - event_idx - 1) &lt; (__u16)(new_idx - old);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct vring_virtqueue &#123;</span><br><span class="line">	/* Last written value to avail-&gt;idx in guest byte order */</span><br><span class="line">	u16 avail_idx_shadow;</span><br><span class="line">	/* Head of free buffer list. */</span><br><span class="line">	unsigned int free_head;</span><br></pre></td></tr></table></figure></p>
<p>注： vring_need_event的公式(return (<strong>u16)(new_idx - event_idx - 1) &lt; (</strong>u16)(new_idx - old);)实际是一种限速，new指针在前, old指标在后，如果：</p>
<ul>
<li>如果event_idx也就是avail.idx的位置超过了old， vring_need_event=True, 表示后端处理的快(<strong>event_idx是后端通知给前端处理的索引值</strong>)，此时guest将发通知给host请它继续处理。</li>
<li>如果event_idx在old之前，vring_need_event=False, <strong>说明后端处理的慢</strong>，此时guest不会向host发通知。</li>
</ul>
<p>2, guest端virtio驱动是如何发包的呢？ xmit_skb会高用virtqueue_add_outbuf最终会调用virtqueue_add, 设置完ring的相关字段之后最后调virtqueue_kick<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">static int xmit_skb(struct send_queue *sq, struct sk_buff *skb)</span><br><span class="line">&#123;</span><br><span class="line">...</span><br><span class="line">   return virtqueue_add_outbuf(sq-&gt;vq, sq-&gt;sg, num_sg, skb, GFP_ATOMIC);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">static inline int virtqueue_add(struct virtqueue *_vq,</span><br><span class="line">				struct scatterlist *sgs[],</span><br><span class="line">				unsigned int total_sg,</span><br><span class="line">				unsigned int out_sgs,</span><br><span class="line">				unsigned int in_sgs,</span><br><span class="line">				void *data,</span><br><span class="line">				gfp_t gfp)</span><br><span class="line">&#123;</span><br><span class="line">...</span><br><span class="line">	head = vq-&gt;free_head;</span><br><span class="line">	/* Put entry in available array (but don&apos;t update avail-&gt;idx until they</span><br><span class="line">	 * do sync). */</span><br><span class="line">	avail = vq-&gt;avail_idx_shadow &amp; (vq-&gt;vring.num - 1);</span><br><span class="line">	vq-&gt;vring.avail-&gt;ring[avail] = cpu_to_virtio16(_vq-&gt;vdev, head);</span><br><span class="line"></span><br><span class="line">	/* Descriptors and available array need to be set before we expose the</span><br><span class="line">	 * new available array entries. */</span><br><span class="line">	virtio_wmb(vq-&gt;weak_barriers);</span><br><span class="line">	vq-&gt;avail_idx_shadow++;</span><br><span class="line">	vq-&gt;vring.avail-&gt;idx = cpu_to_virtio16(_vq-&gt;vdev, vq-&gt;avail_idx_shadow);</span><br><span class="line">	vq-&gt;num_added++;</span><br><span class="line"></span><br><span class="line">	pr_debug(&quot;Added buffer head %i to %p\n&quot;, head, vq);</span><br><span class="line">	END_USE(vq);</span><br><span class="line"></span><br><span class="line">	/* This is very unlikely, but theoretically possible.  Kick</span><br><span class="line">	 * just in case. */</span><br><span class="line">	if (unlikely(vq-&gt;num_added == (1 &lt;&lt; 16) - 1))</span><br><span class="line">		virtqueue_kick(_vq);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>从上面的代码分析中我们已经完成能够确定:<br>1, vhost后端没有给guest通过中断通知event_idx(avail_idx)值。<br>2，virtio前端也在根据vring_need_event的公式(return (<strong>u16)(new_idx - event_idx - 1) &lt; (</strong>u16)(new_idx - old);)决定是否向vhost后端kick消息时， 由于event_idx在old的前面，vring_need_event值为False，所以前端就不会给后端发消息。这样前端就会丢包，所以前端也会看到“No buffer space available”之类的错误。通过上面的代码分析，我们也知道了造成这个的原因是因为后端发送的比前端慢。在检查宿主机的syslog后，发现了大量的MTU相关的日志”br-int: dropped over-mtu packet: 1500 &gt; 1458”。OK，问题就在这里了，虚机里需要设置合适的MTU值，如sudo ip link set eth0 mtu 1400</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/01/09/virtio-vhost中的限速机制/" data-id="cjc7ckhyh0005bjbpcakuajy3" class="article-share-link">Поделиться</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-OpenStack-s-multiattach-Feature" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/22/OpenStack-s-multiattach-Feature/" class="article-date">
  <time datetime="2017-12-22T05:31:50.000Z" itemprop="datePublished">2017-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/22/OpenStack-s-multiattach-Feature/">OpenStack&#39;s multiattach Feature</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>作者：张华  发表于：2017-12-22<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</strong></p>
<h2 id="什么是multiattach特性"><a href="#什么是multiattach特性" class="headerlink" title="什么是multiattach特性"></a>什么是multiattach特性</h2><p>OpenStack’s multiattach Feature允许一个read only volume经iscsi/FC被attached到多个VM。</p>
<h2 id="代码实现原理"><a href="#代码实现原理" class="headerlink" title="代码实现原理"></a>代码实现原理</h2><ul>
<li>用户首先通过cinder定义一个shareable标志的volume.</li>
<li>在attach的时候，nova需要修改即使在in-use状态下仍然可以attach, nova为每一个attachment指定read-write或者read-only, cinder端修改在available和in-use状态下仍然可attach，multiattach标志设置可以被attach多次。attach之后将volume和instance的关系记录到attachment表中。libvirt端需要将这个volume设置shareable标, 这样hypervisor将不会在volume上设置独占锁及相关针对vm的SELinux隔离设置。</li>
<li>在detach的时候，nova需要传递attachment_id到clinderclient告诉cinder哪个attahment需要detach, 然后cinder结合instance_id与attachment_id做detach。如果cinder设置了multiattach标志又没有传attachment_id(os-detach-&gt;attachment_id)过来应该失败。</li>
</ul>
<p>数据表设计：<br>volume_attachment(id, volume_id, attached_host, instance_uuid, mountpoint, attach_time, attach_mode, sttach_status, time)</p>
<p>代码实现：<br>1, cinder side<br>   <a href="https://review.openstack.org/#/c/85847/" target="_blank" rel="external">https://review.openstack.org/#/c/85847/</a><br>2, cinderclient side<br>   <a href="https://review.openstack.org/#/c/85856/" target="_blank" rel="external">https://review.openstack.org/#/c/85856/</a><br>3, nova side<br>   <a href="https://review.openstack.org/#/c/526182/" target="_blank" rel="external">https://review.openstack.org/#/c/526182/</a><br>   <a href="https://review.openstack.org/#/c/525787/" target="_blank" rel="external">https://review.openstack.org/#/c/525787/</a><br>   <a href="https://review.openstack.org/#/c/330285/" target="_blank" rel="external">https://review.openstack.org/#/c/330285/</a><br>   <a href="https://review.openstack.org/#/c/527468/" target="_blank" rel="external">https://review.openstack.org/#/c/527468/</a>  </p>
<p>CLI如何使用：<br>openstack volume create –size 1 –multi-attach multi_attach_test</p>
<h2 id="已知问题"><a href="#已知问题" class="headerlink" title="已知问题"></a>已知问题</h2><p>RDB驱动不支持multiattach - <a href="https://review.openstack.org/#/c/283695/" target="_blank" rel="external">https://review.openstack.org/#/c/283695/</a>, 关于它的讨论 - <a href="https://openstack.nimeyo.com/103230/openstack-dev-multi-attach-volume-for-rbd，但根据这个说法（https://bugs.launchpad.net/cinder/+bug/1535815/comments/6）似乎用这个特性是安全的。" target="_blank" rel="external">https://openstack.nimeyo.com/103230/openstack-dev-multi-attach-volume-for-rbd，但根据这个说法（https://bugs.launchpad.net/cinder/+bug/1535815/comments/6）似乎用这个特性是安全的。</a></p>
<h2 id="容器虚机通过multiattach特性使用同一个存储卷"><a href="#容器虚机通过multiattach特性使用同一个存储卷" class="headerlink" title="容器虚机通过multiattach特性使用同一个存储卷"></a>容器虚机通过multiattach特性使用同一个存储卷</h2><p>我们知道Docker容器本身是无状态的，意味着容器退出后不会保存任何数据。但实际使用场景，肯定是需要保存业务数据的，Docker通过volume实现数据的持久化存储以及共享。Docker有很多种使用OpenStack Cinder的驱动：</p>
<ul>
<li>Docker Cinder Driver - <a href="https://github.com/j-griffith/cinder-docker-driver" target="_blank" rel="external">https://github.com/j-griffith/cinder-docker-driver</a>, 如何使用见<a href="http://superuser.openstack.org/articles/how-to-use-openstack-cinder-for-docker/与http://superuser.openstack.org/articles/how-to-use-cinder-with-swarm/" target="_blank" rel="external">http://superuser.openstack.org/articles/how-to-use-openstack-cinder-for-docker/与http://superuser.openstack.org/articles/how-to-use-cinder-with-swarm/</a></li>
<li>OpenStack Fuxi - 华为主导的OpenStack官方工程，让Docker容器使用Cinder和Manila - <a href="https://docs.openstack.org/fuxi/latest/readme.html" target="_blank" rel="external">https://docs.openstack.org/fuxi/latest/readme.html</a></li>
<li>Flocker - 是一款针对容器的存储方案</li>
<li>REX-Ray - 也是一款进一步封装之后针对容器的存储方案 - rexray/cinder驱动(<a href="https://rexray.readthedocs.io/en/stable/user-guide/schedulers/docker/plug-ins/)实现了Docker的provider.Provider存储Plugin接口，rexray/cinder最终通过rexray的cinder驱动去挂载cinder" target="_blank" rel="external">https://rexray.readthedocs.io/en/stable/user-guide/schedulers/docker/plug-ins/)实现了Docker的provider.Provider存储Plugin接口，rexray/cinder最终通过rexray的cinder驱动去挂载cinder</a> volume (<a href="https://github.com/thecodeteam/rexray/blob/master/libstorage/drivers/storage/cinder/storage/cinder_storage.go)。" target="_blank" rel="external">https://github.com/thecodeteam/rexray/blob/master/libstorage/drivers/storage/cinder/storage/cinder_storage.go)。</a></li>
</ul>
<p>什么是REX-Ray:</p>
<ul>
<li>REX-Ray是一个开源的存储编排引擎(<a href="http://blog.daocloud.io/swarm-emc/" target="_blank" rel="external">http://blog.daocloud.io/swarm-emc/</a>), 进一步封装整合了不同的存储如Ceph, Cinder, EBS等，来主要为Docker, Mesos等容器来提供持续的存储访问, 似乎没有看到REX-Ray下挂到OpenStack Cinder的驱动（见: <a href="https://rexray.readthedocs.io/en/stable/）。" target="_blank" rel="external">https://rexray.readthedocs.io/en/stable/）。</a></li>
<li>REX-Ray下可以直接挂ceph驱动, 见：<a href="http://www.stillhq.com/docker/000001.html和https://blog.thecodeteam.com/2017/01/27/rexray-ceph/" target="_blank" rel="external">http://www.stillhq.com/docker/000001.html和https://blog.thecodeteam.com/2017/01/27/rexray-ceph/</a></li>
<li>REX-Ray下也可以挂cinder驱动，然后通过cinder ceph驱动来支持ceph。见：<a href="https://github.com/thecodeteam/rexray/blob/master/libstorage/drivers/storage/cinder/storage/cinder_storage.go" target="_blank" rel="external">https://github.com/thecodeteam/rexray/blob/master/libstorage/drivers/storage/cinder/storage/cinder_storage.go</a></li>
</ul>
<p>Cinder不仅是给nova用的，也可以绕开nova单独使用，见<a href="https://specs.openstack.org/openstack/cinder-specs/specs/mitaka/use-cinder-without-nova.html" target="_blank" rel="external">https://specs.openstack.org/openstack/cinder-specs/specs/mitaka/use-cinder-without-nova.html</a> ：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cinder local-attach [--mountpoint /mnt/disk] [--multipath True] [--enforce-multipath True] [--mode rw] &lt;volume_id&gt;</span><br></pre></td></tr></table></figure></p>
<p>如果通过rexray/cinder让Docker容器使用了cinder ceph volume的话，如果这个volume是有状态需要需要在容器和虚机间共享的话，这个volume也可以通过上面说的nova multiattach特性给nova instance使用的， 还可以使用这个特性’cinder local-attach’特性给non-nova instance使用。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/12/22/OpenStack-s-multiattach-Feature/" data-id="cjc7ckhyl0006bjbpwajmbmll" class="article-share-link">Поделиться</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-如何修改网卡名称由enp0s25为eth0" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/06/如何修改网卡名称由enp0s25为eth0/" class="article-date">
  <time datetime="2017-12-06T04:07:47.000Z" itemprop="datePublished">2017-12-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/06/如何修改网卡名称由enp0s25为eth0/">如何修改网卡名称由enp0s25为eth0</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>今天用下列配置创建测试用的VLAN网卡，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y vlan</span><br><span class="line">sudo modprobe 8021q</span><br><span class="line"></span><br><span class="line">auto enp0s25.1</span><br><span class="line">iface enp0s25.1 inet static</span><br><span class="line">    address 10.12.1.1/24</span><br><span class="line">    netmask 255.255.255.0</span><br><span class="line">    network 10.12.1.0/24</span><br><span class="line">    broadcast 10.12.1.255</span><br><span class="line">    mtu 1492</span><br><span class="line"></span><br><span class="line">sudo ifup enp0s25.1</span><br></pre></td></tr></table></figure></p>
<p>但是失败，报下列错。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Dec  6 08:54:50 localhost ifup[29785]: Cannot find device &quot;enp0s25.1&quot;</span><br><span class="line">Dec  6 08:54:50 localhost ifup[29785]: Failed to bring up enp0s25.1.</span><br></pre></td></tr></table></figure></p>
<p>原因是需要将enp0s25改为eth0。在谷歌上搜索一百篇文章起码有九十九篇都说要修改70-persistent-net.rules文件，但是照着改了就是不成功，那是怎么一回事呢？</p>
<h2 id="enp0s25代表什么"><a href="#enp0s25代表什么" class="headerlink" title="enp0s25代表什么"></a>enp0s25代表什么</h2><p>根据systemd中udev的代码(<a href="https://github.com/systemd/systemd/blob/master/src/udev/udev-builtin-net_id.c#L20" target="_blank" rel="external">https://github.com/systemd/systemd/blob/master/src/udev/udev-builtin-net_id.c#L20</a> ), enp0s25 意为: en:ethernet, p0:bus_num=0, s25:slot_num=25<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@t440p:~# lspci |grep Ethernet</span><br><span class="line">00:19.0 Ethernet controller: Intel Corporation Ethernet Connection I217-LM (rev 04) </span><br><span class="line"></span><br><span class="line">root@t440p:~# lspci -n -s 00:19.0</span><br><span class="line">00:19.0 0200: 8086:153a (rev 04)</span><br><span class="line"></span><br><span class="line">root@t440p:~# find /sys/devices -type d -wholename &apos;/sys/devices/pci*/net&apos; -print</span><br><span class="line">/sys/devices/pci0000:00/0000:00:19.0/net</span><br><span class="line">/sys/devices/pci0000:00/0000:00:1c.1/0000:04:00.0/net</span><br><span class="line">/sys/devices/pci0000:00/0000:00:14.0/usb3/3-3/3-3:1.0/net</span><br><span class="line"></span><br><span class="line">hua@t440p:~$ sudo udevadm info /sys/class/net/enp0s25 |grep DEVPATH</span><br><span class="line">E: DEVPATH=/devices/pci0000:00/0000:00:19.0/net/enp0s25</span><br></pre></td></tr></table></figure></p>
<h2 id="方法一，修改70-persistent-net-rules"><a href="#方法一，修改70-persistent-net-rules" class="headerlink" title="方法一，修改70-persistent-net.rules"></a>方法一，修改70-persistent-net.rules</h2><p>修改/etc/udev/rules.d/70-persistent-net.rules文件如下内容(注：ubuntu 16.04上由systemd.link管理默认无此文件，直接添加即可，并将如下ATTR{address}改为网卡的MAC地址，其他不变）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;address&#125;==&quot;28:d2:44:52:31:1d&quot;, ATTR&#123;dev_id&#125;==&quot;0x0&quot;, ATTR&#123;type&#125;==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth0&quot;</span><br></pre></td></tr></table></figure></p>
<p><strong>但这样修改后并不生效，原因是动了udev的文件需要下列命令更新initrd</strong>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure></p>
<p>将上面配置改为下面的内容也行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;dev_id&#125;==&quot;0x0&quot;, ATTR&#123;type&#125;==&quot;1&quot;, KERNELS==&quot;0000:00:19.0&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth0&quot;</span><br></pre></td></tr></table></figure>
<p>该配置可直接运行这段脚本生成：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scansys() &#123;</span><br><span class="line">    find /sys/devices -type d -wholename &apos;/sys/devices/pci*/net&apos; -print</span><br><span class="line">&#125;</span><br><span class="line">extract() &#123;</span><br><span class="line">    awk -F/ &apos;&#123;printf &quot;%s eth%u\n&quot;,$(NF-1),NR-1;&#125;&apos;</span><br><span class="line">&#125;</span><br><span class="line">generate() &#123;</span><br><span class="line">    echo &apos;# these rules are for persistence based on bus device address&apos;</span><br><span class="line">    awk &apos;&#123;printf &quot;SUBSYSTEM==\&quot;net\&quot;, ACTION==\&quot;add\&quot;, DRIVERS==\&quot;?*\&quot;, ATTR&#123;dev_id&#125;==\&quot;0x0\&quot;, ATTR&#123;type&#125;==\&quot;1\&quot;, KERNELS==\&quot;%s\&quot;, KERNEL==\&quot;eth*\&quot;, NAME=\&quot;%s\&quot;\n&quot;,$1,$2;&#125;&apos;</span><br><span class="line">&#125;</span><br><span class="line">scansys | extract | sort | generate</span><br></pre></td></tr></table></figure></p>
<p>一般地，上面方法就会成功，至少我成功了，如果你重启机器后还不成功，可以考虑如下方法去Disable the Predictable Network Interface Names，见：<a href="https://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames/" target="_blank" rel="external">https://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames/</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv /lib/udev/rules.d/80-net-setup-link.rules /bak/bin/</span><br><span class="line">ln -s /dev/null /lib/udev/rules.d/80-net-setup-link.rules  #Disable the Predictable Network Interface Names</span><br></pre></td></tr></table></figure></p>
<h2 id="方法二，使用systemd’s-systemd-link"><a href="#方法二，使用systemd’s-systemd-link" class="headerlink" title="方法二，使用systemd’s systemd.link"></a>方法二，使用systemd’s systemd.link</h2><p>修改文件/etc/systemd/network/10-internet.link添加如下内容后重启机器即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Match]</span><br><span class="line">MACAddress=28:d2:44:52:31:1d</span><br><span class="line">[Link]</span><br><span class="line">Name=eth0</span><br></pre></td></tr></table></figure></p>
<p>但参考该网页 (<a href="http://manpages.ubuntu.com/manpages/zesty/man5/systemd.link.5.html)做如下配置却不成功：" target="_blank" rel="external">http://manpages.ubuntu.com/manpages/zesty/man5/systemd.link.5.html)做如下配置却不成功：</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Match]</span><br><span class="line">Path=pci-0000:0000:19.0-*</span><br><span class="line">[Link]</span><br><span class="line">Name=eth0</span><br></pre></td></tr></table></figure></p>
<h2 id="方法三，修改grub的方式"><a href="#方法三，修改grub的方式" class="headerlink" title="方法三，修改grub的方式"></a>方法三，修改grub的方式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash net.ifnames=0&quot;</span><br><span class="line">sudo update-grub</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/12/06/如何修改网卡名称由enp0s25为eth0/" data-id="cjc7ckhzi000ebjbpolncaxqw" class="article-share-link">Поделиться</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-三种方式使用vlan" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/06/三种方式使用vlan/" class="article-date">
  <time datetime="2017-12-06T03:47:59.000Z" itemprop="datePublished">2017-12-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/06/三种方式使用vlan/">三种方式使用vlan</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>作者：张华  发表于：2016-04-22<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</p>
<p>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</p>
<p>Use OVS port in QEMU</p>
<p>sudo apt-get install qemu-system qemu-kvm virtinst libvirt-bin openvswitch-datapath-source openvswitch-controller openvswitch-switch virt-top virt-manager Python-libvirt</p>
<p>sudo ovs-vsctl add-br br-mano<br>sudo ovs-vsctl add-port br-mano eth2</p>
<p>sudo virsh net-destroy default<br>sudo virsh net-define /tmp/br-mano.xml</p>
<p><network><br>  <name>br-mano</name><br>  <forward mode="bridge"><br>  <bridge name="br-mano"><br>  <virtualport type="openvswitch"><br></virtualport></bridge></forward></network></p>
<p>#sudo virsh net-undefine default<br>sudo virsh net-start br-mano<br>sudo virsh net-autostart br-mano</p>
<p>Linux Bridge VLAN</p>
<p>sudo modprobe 8021q<br>sudo ip link add link eth1 name eth1.2 type vlan id 2</p>
<p>#sudo vconfig add eth1 2</p>
<p>#sudo ifconfig eth1.2 down</p>
<p>#sudo vconfig rem eth1.2<br>sudo ip link set eth1.2 up<br>sudo brctl addbr br2<br>sudo brctl setfd br2 0<br>sudo brctl stp br2 on<br>sudo ip link set br2 up<br>sudo brctl addif br2 eth1.2<br>sudo ifconfig br2 192.168.9.122/24<br>sudo ip tuntap add gw2 mode tap<br>sudo ip link set gw2 up<br>sudo brctl addif br2 gw2<br>hua@node1:~$ ip -d link show eth1.2<br>22: eth1.2@eth1: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue master br2 state UP mode DEFAULT group default qlen 1000<br>    link/ether 2c:53:4a:02:20:3c brd ff:ff:ff:ff:ff:ff promiscuity 1<br>    vlan protocol 802.1Q id 2 <reorder_hdr></reorder_hdr></broadcast,multicast,up,lower_up></p>
<p>可用如下方法定义VLAN</p>
<p>auto eth0.2<br>iface eth0.2 inet static<br>    address 10.12.2.2/24<br>    netmask 255.255.255.0<br>    network 10.12.2.0/24<br>    broadcast 10.12.2.255</p>
<p>如果失败，先确保安装了vlan包 （sudo apt install -y vlan），并且启用了vlan模块（sudo modprobe 8021q）， 如果还报下列错的话是因为需要将网卡名改成规范的eth0之类的。</p>
<p>Dec  6 08:54:50 localhost ifup[29785]: Cannot find device “enp0s25.2”<br>Dec  6 08:54:50 localhost ifup[29785]: Failed to bring up enp0s25.2.<br>OVS Bridge VLAN</p>
<p>sudo ovs-vsctl add-br br-veth0<br>sudo ovs-vsctl add-port br-veth0 eth1<br>sudo ip link add veth0 type veth peer name veth1<br>sudo ovs-vsctl add-port br-veth0 veth0<br>sudo ovs-vsctl add-port br-mano veth1<br>sudo ip link set veth0 up<br>sudo ip link set veth1 up</p>
<p>#sudo ovs-vsctl add-port br-veth0 veth0 – set Interface veth0 type=patch options:peer=veth1</p>
<p>#sudo ovs-vsctl add-port br-mano veth1 – set Interface veth1 type=patch options:peer=veth0</p>
<p>#sudo ovs-vsctl del-port br-mano veth1</p>
<p>#sudo ovs-vsctl del-port br-veth0 veth0</p>
<p>#Create ACCESS VLAN:<br>sudo ovs-vsctl set port vnet0 tag=2</p>
<p>#sudo ovs-vsctl remove port vnet0 tag 2</p>
<p>#Enable both ACCESS VLAN as well as TRUNK VLAN:<br>sudo ovs-vsctl set port vnet0 vlan_mode=trunk trunks=2 #access, native-tagged, native-untagged, trunk</p>
<p>#sudo ovs-vsctl set port eth2 vlan_mode=access trunks=[]</p>
<p>Verify VLAN</p>
<p>Inside VM: ping 10.0.3.1 -I eth0</p>
<p>sudo  tcpdump -i eth1  -e -n ‘arp or icmp’ and src host 10.0.3.1</p>
<p>listening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes<br>11:38:20.754894 52:54:00:f2:17:37 &gt; ff:ff:ff:ff:ff:ff, ethertype 802.1Q (0x8100), length 46: vlan 2, p 0, ethertype ARP, Request who-has 10.0.3.1 tell 10.0.3.2, length 28<br>Conclusion</p>
<p>OVS Bridge br-mano上的VM无论是采用在VM里打Tag还是在br-mano vnet0处打Tag后的vlan流量能到达eth1(vlan数据只在物理网卡上能使用tcpdump看到），但无法到达同一机器上linux bridge br2上的eth1.2，反之亦然</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/12/06/三种方式使用vlan/" data-id="cjc7ckhyz000cbjbpd9tsds6p" class="article-share-link">Поделиться</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-OpenWRT与QNAP上通过PXE安装Xenial" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/02/OpenWRT与QNAP上通过PXE安装Xenial/" class="article-date">
  <time datetime="2017-12-02T12:04:42.000Z" itemprop="datePublished">2017-12-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/02/OpenWRT与QNAP上通过PXE安装Xenial/">OpenWRT与QNAP上通过PXE安装Xenial</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本文将打开OpenWRT dnsmasq上的PXE支持并设置和QNAP上的tftp关联，然后根据preseed自动安装Ubuntu 16.04 (注：kickstart是Redhat用于自动安装的机制）。</p>
<h2 id="Set-up-tftp-on-QNAP"><a href="#Set-up-tftp-on-QNAP" class="headerlink" title="Set up tftp on QNAP"></a>Set up tftp on QNAP</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># NOTE: We need to configure PXE dir and authority to /Public/tftpboot in QNPA GUI, then use &apos;tftp 192.168.99.122&apos; to test</span><br><span class="line"># /etc/init.d/opentftp.sh restart</span><br><span class="line"># [/share/HDA_DATA/Public/tftpboot] # ps |grep tftp</span><br><span class="line"># 15861 admin      1016 S   /usr/sbin/opentftpd -i /etc/opentftpd.ini -l /share/HDA_DATA/Public/tftpboot/opentftpd.log</span><br><span class="line">sudo mount -o loop /bak/images/ubuntu-16.04.2-server-amd64.iso /mnt/</span><br><span class="line">mkdir /tmp/tftpboot &amp;&amp; sudo cp -r /mnt/install/netboot/* /tmp/tftpboot/</span><br><span class="line">sudo bash -c &apos;cat &gt; /tmp/tftpboot/pxelinux.cfg/default &lt;&lt; EOF</span><br><span class="line">default linux </span><br><span class="line">label linux</span><br><span class="line">    kernel ubuntu-installer/amd64/linux</span><br><span class="line">    append vga=normal initrd=ubuntu-installer/amd64/initrd.gz --</span><br><span class="line">EOF&apos;</span><br><span class="line">scp -r /tmp/tftpboot/* admin@192.168.99.122:/share/HDA_DATA/Public/tftpboot/</span><br></pre></td></tr></table></figure>
<h2 id="Configure-dnsmasq-on-OpenWRT-to-use-external-tftp-server"><a href="#Configure-dnsmasq-on-OpenWRT-to-use-external-tftp-server" class="headerlink" title="Configure dnsmasq on OpenWRT to use external tftp server"></a>Configure dnsmasq on OpenWRT to use external tftp server</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/dnsmasq.conf &lt;&lt; EOF</span><br><span class="line">enable-tftp</span><br><span class="line">dhcp-boot=pxelinux.0,pxeboot,192.168.99.122</span><br><span class="line">EOF</span><br><span class="line">/etc/init.d/dnsmasq restart</span><br></pre></td></tr></table></figure>
<h2 id="Create-Preseed-file-on-QNAP"><a href="#Create-Preseed-file-on-QNAP" class="headerlink" title="Create Preseed file on QNAP"></a>Create Preseed file on QNAP</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /home/httpd/ubuntu-auto.seed &lt;&lt; EOF</span><br><span class="line">##https://help.ubuntu.com/16.04/installation-guide/example-preseed.txt</span><br><span class="line">##https://gist.github.com/eldondev/33366c2842df9d1b4a0e</span><br><span class="line">## Options to set on the command line</span><br><span class="line">d-i debian-installer/locale string en_US.UTF-8</span><br><span class="line">d-i console-setup/ask_detect boolean false</span><br><span class="line">d-i console-setup/layout string us</span><br><span class="line"></span><br><span class="line">d-i netcfg/get_hostname string ubuntu</span><br><span class="line">d-i netcfg/get_domain string local</span><br><span class="line"></span><br><span class="line">### Clock and time zone setup</span><br><span class="line">d-i time/zone string UTC</span><br><span class="line">d-i clock-setup/utc boolean true</span><br><span class="line">d-i clock-setup/ntp boolean false</span><br><span class="line"></span><br><span class="line">d-i kbd-chooser/method select us</span><br><span class="line"></span><br><span class="line">d-i mirror/country string manual</span><br><span class="line">d-i mirror/http/hostname string nova.clouds.archive.ubuntu.com</span><br><span class="line">d-i mirror/http/directory string /ubuntu</span><br><span class="line">d-i mirror/http/proxy string</span><br><span class="line"></span><br><span class="line">d-i partman-auto/choose_recipe select root</span><br><span class="line">d-i partman-auto/disk string /dev/[sv]da</span><br><span class="line">d-i partman-auto/method string regular</span><br><span class="line">d-i partman-auto/expert_recipe string root :: \</span><br><span class="line">500 10000 1000000 ext4 \</span><br><span class="line">          $primary&#123; &#125; \</span><br><span class="line">          $bootable&#123; &#125; \</span><br><span class="line">          method&#123; format &#125; \</span><br><span class="line">          format&#123; &#125; \</span><br><span class="line">          use_filesystem&#123; &#125; \</span><br><span class="line">          filesystem&#123; ext4 &#125; \</span><br><span class="line">          mountpoint&#123; / &#125; .</span><br><span class="line"></span><br><span class="line">d-i partman-basicfilesystems/no_swap boolean false</span><br><span class="line">d-i partman-partitioning/confirm_write_new_label boolean true</span><br><span class="line">d-i partman/choose_partition select finish</span><br><span class="line">d-i partman/confirm boolean true</span><br><span class="line">d-i partman/confirm_nooverwrite boolean true</span><br><span class="line"></span><br><span class="line">d-i base-installer/kernel/image string linux-virtual</span><br><span class="line">d-i debian-installer/quiet  boolean false</span><br><span class="line">d-i debian-installer/splash boolean false</span><br><span class="line"></span><br><span class="line">d-i tasksel/first select openssh-server</span><br><span class="line">d-i pkgsel/include string openssh-server ntp python sudo</span><br><span class="line">d-i pkgsel/install-language-support boolean false</span><br><span class="line">d-i pkgsel/upgrade select none</span><br><span class="line">d-i pkgsel/update-policy select none</span><br><span class="line">d-i pkgsel/updatedb boolean true</span><br><span class="line"></span><br><span class="line"># Account setup</span><br><span class="line">d-i passwd/root-login boolean true</span><br><span class="line">d-i passwd/root-password password password</span><br><span class="line">d-i passwd/root-password-again password password</span><br><span class="line">d-i passwd/make-user boolean false</span><br><span class="line">d-i user-setup/password-weak boolean true</span><br><span class="line">d-i user-setup/allow-password-weak boolean true</span><br><span class="line">d-i user-setup/encrypt-home boolean false</span><br><span class="line"></span><br><span class="line"># Disable WEP dialog</span><br><span class="line">d-i netcfg/wireless_wep string</span><br><span class="line"></span><br><span class="line"># Security</span><br><span class="line">d-i apt-setup/services-select multiselect security</span><br><span class="line">d-i apt-setup/security_host string archive.ubuntu.com</span><br><span class="line">d-i apt-setup/security_path string /ubuntu</span><br><span class="line"></span><br><span class="line"># No multiarch by default</span><br><span class="line">d-i apt-setup/multiarch string</span><br><span class="line"></span><br><span class="line">d-i grub-installer/only_debian boolean true</span><br><span class="line">d-i grub-installer/with_other_os boolean true</span><br><span class="line"></span><br><span class="line">d-i finish-install/reboot_in_progress note</span><br><span class="line"></span><br><span class="line">d-i debian-installer/exit/halt boolean false</span><br><span class="line">d-i debian-installer/exit/poweroff boolean false</span><br><span class="line"></span><br><span class="line"># Late command for Packer to auth as root with password</span><br><span class="line">d-i preseed/late_command string \</span><br><span class="line">    sed -i -e &apos;s/^#\?PasswordAuthentication.*/PasswordAuthentication yes/g&apos; /target/etc/ssh/sshd_config;\</span><br><span class="line">    sed -i -e &apos;s/^#\?PermitRootLogin.*/PermitRootLogin yes/g&apos; /target/etc/ssh/sshd_config</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="Use-preseed"><a href="#Use-preseed" class="headerlink" title="Use preseed"></a>Use preseed</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">## Modify the file /share/HDA_DATA/Public</span><br><span class="line">#https://help.ubuntu.com/lts/installation-guide/armhf/apbs02.html</span><br><span class="line">/tftpbootdefault linux</span><br><span class="line">label linux</span><br><span class="line">    kernel ubuntu-installer/amd64/linux</span><br><span class="line">    append vga=normal initrd=ubuntu-installer/amd64/initrd.gz locale=en_US keyboard-configuration/layoutcode=us ipv6.disable=1 hostname=maas auto url=http://192.168.99.122:8080/ubuntu-auto.seed --</span><br></pre></td></tr></table></figure>
<p>注意：Ubuntu只要preseed即可。kickstart是Redhat自动安装的机制，如果要同时安装Ubuntu和Redhat，可以二者都设置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">append ks=http://192.168.99.122:8080/ks.cfg preseed/url=http://192.168.99.122:8080/ubuntu-auto.seed vga=normal initrd=ubuntu-installer/amd64/initrd.gz --</span><br></pre></td></tr></table></figure></p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">images_root=/bak/images</span><br><span class="line">rootdisk=$images_root/test.img</span><br><span class="line">domain_xml=test.xml</span><br><span class="line">dpkg -s virtinst &amp;&gt;/dev/null || sudo apt install virtinst -y</span><br><span class="line">if ! [ -e &quot;$rootdisk&quot; ]; then</span><br><span class="line">    qemu-img create -f qcow2 $rootdisk 20G</span><br><span class="line">fi</span><br><span class="line">sudo bash -c &apos;cat &gt;&gt; /etc/network/interfaces &lt;&lt; EOF</span><br><span class="line">auto enp0s25</span><br><span class="line">iface enp0s25 inet manual</span><br><span class="line">    mtu 1500</span><br><span class="line">auto br-enp0s25</span><br><span class="line">iface br-enp0s25 inet static</span><br><span class="line">    address 192.168.99.135/24</span><br><span class="line">    gateway 192.168.99.1</span><br><span class="line">    bridge_ports enp0s25</span><br><span class="line">EOF&apos;</span><br><span class="line">ifup br-enp0s25</span><br><span class="line">sudo virt-install \</span><br><span class="line">    --name=bootstrap \</span><br><span class="line">    --connect=qemu:///system --ram=2048 --vcpus=1 --hvm \</span><br><span class="line">    --virt-type=kvm \</span><br><span class="line">    --pxe --boot network,hd \</span><br><span class="line">    --graphics vnc --noautoconsole --os-type=linux --accelerate \</span><br><span class="line">    --disk=$&#123;rootdisk&#125;,bus=virtio,format=qcow2 \</span><br><span class="line">    --network=bridge=juju-vm-br,model=virtio \</span><br><span class="line">    --print-xml 2 &gt; $domain_xml</span><br><span class="line">echo &quot;test domain definition is now available at $domain_xml&quot;</span><br></pre></td></tr></table></figure>
<h2 id="相关日志"><a href="#相关日志" class="headerlink" title="相关日志"></a>相关日志</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[/home/httpd] # tail -f /share/HDA_DATA/Public/tftpboot/opentftpd.log           </span><br><span class="line">[02-Dec-17 19:54:25] Client 192.168.99.150:49162 /share/HDA_DATA/Public/tftpboot/pxelinux.cfg/default, 2 Blocks Served</span><br><span class="line">[02-Dec-17 19:54:44] Client 192.168.99.150:49163 /share/HDA_DATA/Public/tftpboot/ubuntu-installer/amd64/linux, 5025 Blocks Served</span><br><span class="line">[02-Dec-17 19:56:30] Client 192.168.99.150:49164 /share/HDA_DATA/Public/tftpboot/ubuntu-installer/amd64/initrd.gz, 28718 Blocks Served</span><br><span class="line">[02-Dec-17 20:20:44] Client 192.168.99.136:59249 /share/HDA_DATA/Public/tftpboot/pxelinux.0, 31 Blocks Served</span><br><span class="line">[02-Dec-17 20:20:45] Client 192.168.99.136:49152 /share/HDA_DATA/Public/tftpboot/ldlinux.c32, 84 Blocks Served</span><br><span class="line">[02-Dec-17 20:20:45] Client 192.168.99.136:49163 /share/HDA_DATA/Public/tftpboot/pxelinux.cfg/default, 2 Blocks Served</span><br><span class="line">[02-Dec-17 20:21:01] Client 192.168.99.136:49164 /share/HDA_DATA/Public/tftpboot/ubuntu-installer/amd64/linux, 5025 Blocks Served</span><br><span class="line">[02-Dec-17 20:22:44] Client 192.168.99.136:49165 /share/HDA_DATA/Public/tftpboot/ubuntu-installer/amd64/initrd.gz, 28718 Blocks Served</span><br></pre></td></tr></table></figure>
<h2 id="附录-一个KickStart的例子"><a href="#附录-一个KickStart的例子" class="headerlink" title="附录 - 一个KickStart的例子"></a>附录 - 一个KickStart的例子</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"># then can visit via - http://192.168.99.122:8080/ks.cfg, so the key line is &apos;url --url http://192.168.99.122:8080&apos;</span><br><span class="line">cat &gt; /home/httpd/ks.cfg &lt;&lt; EOF</span><br><span class="line">#Generated by Kickstart Configurator</span><br><span class="line">#platform=AMD64 or Intel EM64T</span><br><span class="line">#System language</span><br><span class="line">lang en_US</span><br><span class="line">#Language modules to install</span><br><span class="line">langsupport en_US</span><br><span class="line">#System keyboard</span><br><span class="line">keyboard us</span><br><span class="line">#System mouse</span><br><span class="line">mouse</span><br><span class="line">#System timezone</span><br><span class="line">timezone Asia/Chongqing</span><br><span class="line">#Root password</span><br><span class="line">rootpw --disabled</span><br><span class="line">#Initial user</span><br><span class="line">user hua --fullname hua --password password</span><br><span class="line">#Reboot after installation</span><br><span class="line">reboot</span><br><span class="line">#Use text mode install</span><br><span class="line">text</span><br><span class="line">#Install OS instead of upgrade</span><br><span class="line">install</span><br><span class="line">#Use Web installation media</span><br><span class="line">url --url http://192.168.99.122:8080</span><br><span class="line">#System bootloader configuration</span><br><span class="line">bootloader --location=mbr </span><br><span class="line">#Clear the Master Boot Record</span><br><span class="line">zerombr yes</span><br><span class="line">#Partition clearing information</span><br><span class="line">clearpart --all --initlabel </span><br><span class="line">#Disk partitioning information</span><br><span class="line">part swap --size 2048 </span><br><span class="line">part /boot --fstype ext4 --size 512 </span><br><span class="line">part / --fstype ext4 --size 1 --grow </span><br><span class="line">#System authorization infomation</span><br><span class="line">auth  --useshadow  --enablemd5 </span><br><span class="line">#Network information</span><br><span class="line">network --bootproto=dhcp --device=eth0</span><br><span class="line">#network --bootproto=static--ip=192.168.5.168 --netmask=255.255.255.0 --gateway=192.168.100.1--nameserver=8.8.8.8 --device=eth0</span><br><span class="line">#Firewall configuration</span><br><span class="line">firewall --disabled </span><br><span class="line">#Do not configure the X Window System</span><br><span class="line">skipx</span><br><span class="line"># Additional packages to install</span><br><span class="line">%packages</span><br><span class="line">ca-certificates</span><br><span class="line">openssl</span><br><span class="line">python</span><br><span class="line">openssh-server</span><br><span class="line">vim</span><br><span class="line">ubuntu-desktop</span><br><span class="line">unity</span><br><span class="line"># Add your custom post installation script here</span><br><span class="line">%post</span><br><span class="line"># Add post installation script to /usr/local/bin/ directory</span><br><span class="line">ls .</span><br><span class="line"># Fix locale</span><br><span class="line">echo &apos;LANG=&quot;en_US.UTF-8&quot;&apos; &gt; /etc/default/locale</span><br><span class="line">echo &apos;LANGUAGE=&quot;en_US:en&quot;&apos; &gt;&gt; /etc/default/locale</span><br><span class="line">echo &apos;LC_ALL=&quot;en_US.UTF-8&quot;&apos; &gt;&gt; /etc/default/locale</span><br><span class="line"># Clean</span><br><span class="line">apt-get -f -y install</span><br><span class="line">apt-get -y autoremove</span><br><span class="line">apt-get clean</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/12/02/OpenWRT与QNAP上通过PXE安装Xenial/" data-id="cjc7ckhy70001bjbpgn2l5oer" class="article-share-link">Поделиться</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Test-multipath-feature-by-openstack-lioadm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/29/Test-multipath-feature-by-openstack-lioadm/" class="article-date">
  <time datetime="2017-11-29T08:08:13.000Z" itemprop="datePublished">2017-11-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/29/Test-multipath-feature-by-openstack-lioadm/">Test multipath feature by openstack lioadm</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>之前写过一篇关于使用tgtadm测试OpenStack Multipath特性的<a href="http://blog.csdn.net/quqi99/article/details/54973369" target="_blank" rel="external">文章</a>。tgt是一个用户态的iscsi target，lio是内核核的iscsi target并且它已经被集成到了Linux内核。<br>在OpenStack Icehouse版本，由于仅支持单target (即cinder还不支持iscsi_secondary_ip_addresses选项用于配置第二个target)，所以基于Icehouse的tgtadm将无法支持multipath。但使用lioadm改点配置可以支持。</p>
<h2 id="基于OpenStack环境"><a href="#基于OpenStack环境" class="headerlink" title="基于OpenStack环境"></a>基于OpenStack环境</h2><p>搭建一个简单带cinder的openstack环境即可，不需要ceph支持。可参考<a href="http://blog.csdn.net/quqi99/article/details/54973369" target="_blank" rel="external">这篇文章</a>的一小部分安装。</p>
<h2 id="cinder节点安装LIO-target与加载target-core-mod模块"><a href="#cinder节点安装LIO-target与加载target-core-mod模块" class="headerlink" title="cinder节点安装LIO-target与加载target_core_mod模块"></a>cinder节点安装LIO-target与加载target_core_mod模块</h2><p>先加载target_core_mod模块<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">juju ssh cinder/0</span><br><span class="line">sudo apt install linux-image-extra-$(uname -r)  #Avoid the error &apos;Module target_core_mod not found&apos;</span><br><span class="line">sudo apt build-dep linux-image-$(uname -r)</span><br><span class="line">sudo modprobe target_core_mod</span><br></pre></td></tr></table></figure></p>
<p>cinder节点上需要安装LIO-target<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#Install LIO-target - https://www.thomas-krenn.com/de/wiki/Linux-IO_Target_(LIO)_unter_Ubuntu_14.04</span><br><span class="line">sudo apt install open-iscsi targetcli python-urwid lio-utils python-pyparsing python-prettytable python-rtslib python-configshell</span><br><span class="line">sudo pip install &apos;rtslib-fb&gt;=2.1.39&apos;</span><br></pre></td></tr></table></figure></p>
<p>需要说明的是，这里面有一个bug，因为Icehouse版本 /usr/bin/cinder-rtstool文件中使用了rtslib-fb&gt;=2.1.39，所以我们必须使用“sudo pip install ‘rtslib-fb&gt;=2.1.39’”命令安装它。但是rtslib-fb这个模块比较老又被废弃了，targetcli工具又使用了比较新的rtslib模块。<br>如果我们删除rtslib-fb模块(sudo pip uninstall y rtslib-fb)而使用rtslib模块targetcli工具将会恢复正常，但是/usr/bin/cinder-rtstool工具在运行下列命令时会报错：’ImportError: No module named rtslib_fb’<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cinder-rootwrap /etc/cinder/rootwrap.conf cinder-rtstool create /dev/cinder-volumes/volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea zAXMzsNKJ4kBvDYCZBec VyhWebHq3GBKE22zYjpX</span><br></pre></td></tr></table></figure></p>
<p>幸好，/usr/bin/cinder-rtstool里没有使用targetcli，所以我们必须使用‘rtslib-fb&gt;=2.1.39’模块。<br>下面是正常使用targetcli工具的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root@juju-c0c753-trusty-icehouse-0:~# targetcli</span><br><span class="line">targetcli GIT_VERSION (rtslib GIT_VERSION)</span><br><span class="line">Copyright (c) 2011-2013 by Datera, Inc.</span><br><span class="line">All rights reserved.</span><br><span class="line">/&gt; ls</span><br><span class="line">o- / ............................................................................................................... [...]</span><br><span class="line">  o- backstores .................................................................................................... [...]</span><br><span class="line">  | o- fileio ......................................................................................... [0 Storage Object]</span><br><span class="line">  | o- iblock ......................................................................................... [0 Storage Object]</span><br><span class="line">  | o- pscsi .......................................................................................... [0 Storage Object]</span><br><span class="line">  | o- rd_dr .......................................................................................... [0 Storage Object]</span><br><span class="line">  | o- rd_mcp ......................................................................................... [0 Storage Object]</span><br><span class="line">  o- ib_srpt ................................................................................................. [0 Targets]</span><br><span class="line">  o- iscsi ................................................................................................... [0 Targets]</span><br><span class="line">  o- loopback ................................................................................................ [0 Targets]</span><br><span class="line">  o- qla2xxx ................................................................................................. [0 Targets]</span><br><span class="line">  o- tcm_fc .................................................................................................. [0 Targets]</span><br><span class="line">/&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Cinder节点继续修改"><a href="#Cinder节点继续修改" class="headerlink" title="Cinder节点继续修改"></a>Cinder节点继续修改</h2><p>Icehouse的lioadm默认也是只支持一个iscsi target的，要想支持多个，需要做如下的修改，<strong>让一个cinder节点(10.5.0.22)的两个端口(3260, 3261)去做multipath</strong>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo sed -i &apos;s/import rtslib/import rtslib_fb as rtslib/g&apos; /usr/bin/cinder-rtstool</span><br><span class="line">sudo sed -i &apos;s/if target == None:/if not target:/g&apos; /usr/bin/cinder-rtstool</span><br><span class="line"># For this step, you must replace IPADDRESS with the actual IP of the cinder/0 node.</span><br><span class="line">sudo sed -i &quot;s/rtslib.NetworkPortal(tpg_new, &apos;0.0.0.0&apos;, 3260, mode=&apos;any&apos;)/rtslib.NetworkPortal(tpg_new, &apos;10.5.0.22&apos;, 3260, mode=&apos;any&apos;)\n\t rtslib.NetworkPortal(tpg_new, &apos;10.5.0.22&apos;, 3261, mode=&apos;any&apos;)/g&quot; /usr/bin/cinder-rtstool</span><br></pre></td></tr></table></figure></p>
<p>通过charm变更使用lioadm，当然也可以手工修改<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http_proxy=http://squid.internal:3128 git clone https://github.com/openstack/charm-cinder.git</span><br><span class="line">cd charm-cinder</span><br><span class="line">sed -i &apos;s/tgtadm/lioadm/g&apos; templates/icehouse/cinder.conf</span><br><span class="line">juju upgrade-charm cinder --path $PWD</span><br></pre></td></tr></table></figure></p>
<p>停止tgt服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">juju ssh cinder/0 sudo service tgt stop</span><br></pre></td></tr></table></figure></p>
<p>使用lioadm时，<strong>不需要</strong>像tgtadm那样在计算节点的nova.conf中配置下列参考支持multipath:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[libvirt]</span><br><span class="line">iscsi_use_multipath = True</span><br></pre></td></tr></table></figure></p>
<h2 id="使用windows镜像"><a href="#使用windows镜像" class="headerlink" title="使用windows镜像"></a>使用windows镜像</h2><p>我们使用windows镜像测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">source ~/novarc &amp;&amp; glance image-download --file windows2012R2_virtio.raw --progress 31dd4e9f-ccd3-4c57-b10e-6b5e99366240</span><br><span class="line">source novarc &amp;&amp; glance image-create --name windows2012R2 --file /bak/windows2012R2_virtio.raw --visibility public --progress --container-format bare --disk-format raw</span><br><span class="line">nova keypair-add --pub-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">nova flavor-create myflavor auto 3200 45 1 </span><br><span class="line">openstack server create --wait --image windows2012R2 --flavor myflavor --key-name mykey --nic net-id=dd269a94-5b76-4e24-8046-4d377fa3be5f --min 1 --max 1 i1</span><br><span class="line">nova floating-ip-create</span><br><span class="line">nova floating-ip-associate i1 10.5.150.2</span><br><span class="line">./tools/sec_groups.sh</span><br></pre></td></tr></table></figure></p>
<p>Windows镜像比较大，有31G，所以默认创建的glance硬盘不够会失败，删除glance节点再通过‘root-disk=90G’参数重新安装：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">juju remove-unit glance/0</span><br><span class="line">juju remove-application glance</span><br><span class="line">juju deploy cs:~openstack-charmers-next/glance --constraints &quot;mem=1G root-disk=90G&quot; --series trusty</span><br><span class="line">juju add-relation nova-cloud-controller glance</span><br><span class="line">juju add-relation nova-compute glance</span><br><span class="line">juju add-relation glance mysql</span><br><span class="line">juju add-relation glance keystone</span><br><span class="line">juju add-relation glance &quot;cinder:image-service&quot;</span><br><span class="line">juju add-relation glance rabbitmq-server</span><br></pre></td></tr></table></figure></p>
<p>至于如何在多层内网情况下仍然能够通过图形化RDP界面而不是命令行来访问windows虚机，可<a href="http://blog.csdn.net/quqi99/article/details/78662647" target="_blank" rel="external">参考文章</a>。</p>
<h2 id="为虚机创建磁盘"><a href="#为虚机创建磁盘" class="headerlink" title="为虚机创建磁盘"></a>为虚机创建磁盘</h2><p>为虚机创建磁盘：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cinder create --display_name test_volume 1</span><br><span class="line">nova volume-attach i1 1a3e3146-5df7-49ed-8041-de1de257a300</span><br><span class="line"></span><br><span class="line">root@juju-c0c753-trusty-icehouse-7:~# sudo iscsiadm -m session</span><br><span class="line">tcp: [1] 10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-8237a312-7512-41f5-a02a-34856fa3896e</span><br><span class="line">tcp: [2] 10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1a3e3146-5df7-49ed-8041-de1de257a300</span><br><span class="line">root@juju-c0c753-trusty-icehouse-7:~# sudo iscsiadm -m node</span><br><span class="line">10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1a3e3146-5df7-49ed-8041-de1de257a300</span><br><span class="line">10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-8237a312-7512-41f5-a02a-34856fa3896e</span><br></pre></td></tr></table></figure></p>
<p>登录windows虚机后在Powershell中使用”Get-Disk”命令可以看到一个新磁盘。<br>同时登录计算节点看到libvirt已经为windows虚机生成了配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;disk type=&apos;block&apos; device=&apos;disk&apos;&gt;</span><br><span class="line">     &lt;driver name=&apos;qemu&apos; type=&apos;raw&apos; cache=&apos;none&apos;/&gt;</span><br><span class="line">     &lt;source dev=&apos;/dev/mapper/360014050fd353e4dd274f20b1abd70e4&apos;/&gt;</span><br><span class="line">     &lt;target dev=&apos;vdb&apos; bus=&apos;virtio&apos;/&gt;</span><br><span class="line">     &lt;serial&gt;1035ee80-339e-4e4e-b4c9-6c925cb259ea&lt;/serial&gt;</span><br><span class="line">     &lt;alias name=&apos;virtio-disk1&apos;/&gt;</span><br><span class="line">     &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x05&apos; function=&apos;0x0&apos;/&gt;</span><br><span class="line">   &lt;/disk&gt;</span><br></pre></td></tr></table></figure></p>
<p>mutlipath信息如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install multipath-tools</span><br><span class="line"># multipath -ll</span><br><span class="line">360014050fd353e4dd274f20b1abd70e4 dm-0 LIO-ORG ,IBLOCK          </span><br><span class="line">size=1.0G features=&apos;0&apos; hwhandler=&apos;0&apos; wp=rw</span><br><span class="line">|-+- policy=&apos;round-robin 0&apos; prio=1 status=active</span><br><span class="line">| `- 4:0:0:0 sdc   8:32   active ready  running</span><br><span class="line">`-+- policy=&apos;round-robin 0&apos; prio=1 status=enabled</span><br><span class="line">  `- 5:0:0:0 sdd   8:48   active ready  running</span><br><span class="line"></span><br><span class="line">root@juju-c0c753-trusty-icehouse-7:~# sudo iscsiadm -m session</span><br><span class="line">tcp: [1] 10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-8237a312-7512-41f5-a02a-34856fa3896e</span><br><span class="line">tcp: [2] 10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1a3e3146-5df7-49ed-8041-de1de257a300</span><br><span class="line">tcp: [3] 10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br><span class="line">tcp: [4] 10.5.0.22:3261,1 iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br><span class="line">root@juju-c0c753-trusty-icehouse-7:~# sudo iscsiadm -m node</span><br><span class="line">10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1a3e3146-5df7-49ed-8041-de1de257a300</span><br><span class="line">10.5.0.22:3261,1 iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br><span class="line">10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br><span class="line">10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-8237a312-7512-41f5-a02a-34856fa3896e</span><br><span class="line"></span><br><span class="line">root@juju-c0c753-trusty-icehouse-7:~# ls /dev/mapper/360014050fd353e4dd274f20b1abd70e4</span><br><span class="line">/dev/mapper/360014050fd353e4dd274f20b1abd70e4</span><br></pre></td></tr></table></figure></p>
<h2 id="detach磁盘"><a href="#detach磁盘" class="headerlink" title="detach磁盘"></a>detach磁盘</h2><p>detach磁盘，在syslog中看到了一系列的错误日志，但是功能正常，能够正常detach<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nova volume-dettach i1  1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">2017-11-29 07:30:13.641 25277 WARNING cinder.context [-] Arguments dropped when creating context: &#123;&apos;user&apos;: u&apos;186c37006bd94287ae768e1f80676584&apos;, &apos;tenant&apos;: u&apos;becbf8797c954e2492d62a42a43a4324&apos;, &apos;user_identity&apos;: u&apos;186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -&apos;&#125;</span><br><span class="line">2017-11-29 07:30:13.867 25277 WARNING cinder.context [-] Arguments dropped when creating context: &#123;&apos;user&apos;: u&apos;186c37006bd94287ae768e1f80676584&apos;, &apos;tenant&apos;: u&apos;becbf8797c954e2492d62a42a43a4324&apos;, &apos;user_identity&apos;: u&apos;186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -&apos;&#125;</span><br><span class="line">2017-11-29 07:30:13.876 25277 DEBUG cinder.openstack.common.lockutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Got semaphore &quot;1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume&quot; for method &quot;lvo_inner2&quot;... inner /usr/lib/python2.7/dist-packages/cinder/openstack/common/lockutils.py:191</span><br><span class="line">2017-11-29 07:30:13.877 25277 DEBUG cinder.openstack.common.lockutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Attempting to grab file lock &quot;1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume&quot; for method &quot;lvo_inner2&quot;... inner /usr/lib/python2.7/dist-packages/cinder/openstack/common/lockutils.py:202</span><br><span class="line">2017-11-29 07:30:13.878 25277 DEBUG cinder.openstack.common.lockutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Got file lock &quot;1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume&quot; at /var/lock/cinder/cinder-1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume for method &quot;lvo_inner2&quot;... inner /usr/lib/python2.7/dist-packages/cinder/openstack/common/lockutils.py:232</span><br><span class="line">2017-11-29 07:30:14.245 25277 DEBUG cinder.volume.manager [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] volume 1035ee80-339e-4e4e-b4c9-6c925cb259ea: removing export detach_volume /usr/lib/python2.7/dist-packages/cinder/volume/manager.py:687</span><br><span class="line">2017-11-29 07:30:14.263 25277 INFO cinder.brick.iscsi.iscsi [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Removing iscsi_target: 1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br><span class="line">2017-11-29 07:30:14.264 25277 DEBUG cinder.openstack.common.processutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Running cmd (subprocess): sudo cinder-rootwrap /etc/cinder/rootwrap.conf cinder-rtstool delete iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea execute /usr/lib/python2.7/dist-packages/cinder/openstack/common/processutils.py:147</span><br><span class="line">2017-11-29 07:30:14.738 25277 DEBUG cinder.openstack.common.processutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Result was 0 execute /usr/lib/python2.7/dist-packages/cinder/openstack/common/processutils.py:171</span><br><span class="line">2017-11-29 07:30:14.754 25277 DEBUG cinder.openstack.common.lockutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Released file lock &quot;1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume&quot; at /var/lock/cinder/cinder-1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume for method &quot;lvo_inner2&quot;... inner /usr/lib/python2.7/dist-packages/cinder/openstack/common/lockutils.py:239</span><br><span class="line">2017-11-29 07:31:02.297 25277 DEBUG cinder.openstack.common.periodic_task [-] Running periodic task VolumeManager._publish_service_capabilities run_periodic_tasks /usr/lib/python2.7/dist-packages/cinder/openstack/common/periodic_task.py:178</span><br><span class="line">2017-11-29 07:31:02.300 25277 DEBUG cinder.manager [-] Notifying Schedulers of capabilities ... _publish_service_capabilities /usr/lib/python2.7/dist-packages/cinder/manager.py:128</span><br><span class="line">2017-11-29 07:31:02.321 25277 DEBUG cinder.openstack.common.periodic_task [-] Running periodic task VolumeManager._report_driver_status run_periodic_tasks /usr/lib/python2.7/dist-packages/cinder/openstack/common/periodic_task.py:178</span><br><span class="line">2017-11-29 07:31:02.323 25277 INFO cinder.volume.manager [-] Updating volume status</span><br><span class="line">2017-11-29 07:31:02.323 25277 DEBUG cinder.volume.drivers.lvm [-] Updating volume stats _update_volume_stats /usr/lib/python2.7/dist-packages/cinder/volume/drivers/lvm.py:346</span><br><span class="line">2017-11-29 07:31:02.325 25277 DEBUG cinder.openstack.common.processutils [-] Running cmd (subprocess): sudo cinder-rootwrap /etc/cinder/rootwrap.conf env LC_ALL=C vgs --noheadings --unit=g -o name,size,free,lv_count,uuid --separator : --nosuffix cinder-volumes execute /usr/lib/python2.7/dist-packages/cinder/openstack/common/processutils.py:147</span><br><span class="line">2017-11-29 07:31:02.469 25277 DEBUG cinder.openstack.common.processutils [-] Result was 0 execute /usr/lib/python2.7/dist-packages/cinder/openstack/common/processutils.py:171</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Nov 29 07:29:57 juju-c0c753-trusty-icehouse-7 kernel: [86241.589558]  connection1:0: detected conn error (1020)</span><br><span class="line"></span><br><span class="line">Nov 29 07:29:57 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:29:57 juju-c0c753-trusty-icehouse-7 kernel: [86242.360928]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:29:58 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:00 juju-c0c753-trusty-icehouse-7 kernel: [86244.630641]  connection1:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:00 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:00 juju-c0c753-trusty-icehouse-7 kernel: [86245.399222]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:01 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:03 juju-c0c753-trusty-icehouse-7 kernel: [86247.672850]  connection1:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:03 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:03 juju-c0c753-trusty-icehouse-7 kernel: [86248.442433]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:04 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:06 juju-c0c753-trusty-icehouse-7 kernel: [86250.702435]  connection1:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:06 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:06 juju-c0c753-trusty-icehouse-7 kernel: [86251.461198]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:07 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:09 juju-c0c753-trusty-icehouse-7 kernel: [86253.725045]  connection1:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:09 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 kernel: [86254.494474]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 kernel: [86254.659090] type=1400 audit(1511940610.186:17): apparmor=&quot;STATUS&quot; operation=&quot;profile_replace&quot; profile=&quot;unconfined&quot; name=&quot;libvirt-6e468b3b-6cb4-4d5d-a9d6-6ba32b4bd8cb&quot; pid=16120 comm=&quot;apparmor_parser&quot;</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: dm-0: add map (uevent)</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: dm-0: devmap already registered</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: dm-0: remove map (uevent)</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: 360014050fd353e4dd274f20b1abd70e4: devmap removed</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: 360014050fd353e4dd274f20b1abd70e4: stop event checker thread (140170797860608)</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: dm-0: remove map (uevent)</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: sdc: remove path (uevent)</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 kernel: [86255.657776] sd 4:0:0:0: [sdc] Synchronizing SCSI cache</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: sdd: remove path (uevent)</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 kernel: [86256.365042] sd 5:0:0:0: [sdd] Synchronizing SCSI cache</span><br><span class="line">Nov 29 07:30:12 juju-c0c753-trusty-icehouse-7 iscsid: Connection3:0 to [target: iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea, portal: 10.5.0.22,3260] through [iface: default] is shutdown.</span><br><span class="line">Nov 29 07:30:12 juju-c0c753-trusty-icehouse-7 iscsid: Connection4:0 to [target: iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea, portal: 10.5.0.22,3261] through [iface: default] is shutdown.</span><br><span class="line">Nov 29 07:30:12 juju-c0c753-trusty-icehouse-7 kernel: [86257.129920]  connection1:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:13 juju-c0c753-trusty-icehouse-7 kernel: [86257.893417]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:13 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:14 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:16 juju-c0c753-trusty-icehouse-7 iscsid: connect to 10.5.0.22:3260 failed (Connection refused)</span><br><span class="line">Nov 29 07:30:16 juju-c0c753-trusty-icehouse-7 iscsid: connect to 10.5.0.22:3260 failed (Connection refused)</span><br><span class="line">Nov 29 07:30:19 juju-c0c753-trusty-icehouse-7 iscsid: connect to 10.5.0.22:3260 failed (Connection refused)</span><br><span class="line">Nov 29 07:30:20 juju-c0c753-trusty-icehouse-7 iscsid: connect to 10.5.0.22:3260 failed (Connection refused)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/29/Test-multipath-feature-by-openstack-lioadm/" data-id="cjc7ckhyb0002bjbpq4mz7jgh" class="article-share-link">Поделиться</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-远程访问双层嵌套Openstack云下的Windows虚机" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/29/远程访问双层嵌套Openstack云下的Windows虚机/" class="article-date">
  <time datetime="2017-11-29T02:42:21.000Z" itemprop="datePublished">2017-11-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/29/远程访问双层嵌套Openstack云下的Windows虚机/">远程访问双层嵌套Openstack云下的Windows虚机</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>遇到这么一个奇葩组合问题，一个Bug只在Windows虚机上出现，实验环境是远程OpenStack云上再嵌套OpenStack云上提供的一个Windows虚机，两个OpenStack云都采用内网IP，现在的问题是如何远程登录到Windows虚机中。环境如下：</p>
<ul>
<li>Bastion中转机，是由Underlying OpenStack提供的一台虚机，它的floating ip是10.230.65.8，可通过VPN连接到该IP。众所周知的原因，VPN连接是容易断的。所以平时是先ssh连接到VPS，再在VPS启动VPN连接这台机器的。由于平时都是使用命令行所以没遇到问题，但是现在是采用RDP图形化界面连接Windows虚机的，那么网速就跟不上了。无奈，只能继续将VPN创建在本机上。</li>
<li>Tenant OpenStack -  最上层的OpenStack是由Underlying OpenStack提供的虚机创建的。上层Tenant OpenStack的为这台Windows虚机提供的浮动IP是10.5.150.2</li>
<li>如果我们将Windows虚机创建在Underlying OpenStack上，那么它可以分到10.230网段的IP，那么问题就简化了，登录VPN打通网络后直接通过remmina远程连接即可。但由于Underlying OpenStack我无权限控制，Windows虚机创建在Tenant OpenStack上，那样问题就复杂化了。 <h2 id="访问Tenant-OpenStack的Horizon界面"><a href="#访问Tenant-OpenStack的Horizon界面" class="headerlink" title="访问Tenant OpenStack的Horizon界面"></a>访问Tenant OpenStack的Horizon界面</h2>这个简单，登录VPN后，再在本机运行sshuttle命令即可访问horizon界面。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sshuttle -D -r ubuntu@10.230.65.8 10.5.0.0/24</span><br><span class="line">http://10.5.0.52/horizon</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="通过noVNC访问Tenant-OpenStack提供的Linux虚机"><a href="#通过noVNC访问Tenant-OpenStack提供的Linux虚机" class="headerlink" title="通过noVNC访问Tenant OpenStack提供的Linux虚机"></a>通过noVNC访问Tenant OpenStack提供的Linux虚机</h2><p>Linux虚机要是通过命令行来访问，那就没这些问题了。若要图形化访问，可以采用novnc方案。<br>1， 在控制节点上安装下列四个组件。计算节点不需要安装包。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nova-consoleauth novnc python-novnc nova-novncproxy</span><br><span class="line">sudo service nova-consoleauth restart</span><br><span class="line">sudo service nova-novncproxy restart</span><br><span class="line">sudo service libvirt-bin restart</span><br></pre></td></tr></table></figure></p>
<p>2， 在控制节点和计算节点上同时配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vnc_enabled = True</span><br><span class="line">novnc_enabled = True</span><br><span class="line">vncserver_proxyclient_address=10.5.0.49</span><br><span class="line">vncserver_listen=0.0.0.0</span><br><span class="line">novncproxy_base_url=http://10.5.0.43:6080/vnc_auto.html</span><br></pre></td></tr></table></figure></p>
<p>3, 通过下列命令就可以获得novnc连接并访问了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nova get-vnc-console i1 novnc</span><br><span class="line">sshuttle -D -r ubuntu@10.230.65.8 10.5.0.0/24</span><br></pre></td></tr></table></figure></p>
<p>上面命令相当于手动打开虚机的vnc支持：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo virsh edit i1</span><br><span class="line">   &lt;graphics type=&apos;vnc&apos; port=&apos;-1&apos; autoport=&apos;yes&apos; listen=&apos;192.168.99.124&apos; passwd=&apos;password&apos; keymap=&apos;en-us&apos;/&gt;</span><br><span class="line">sudo virsh shutdown i1 &amp;&amp; sudo virsh start i1</span><br><span class="line">#sudo virsh -c qemu+ssh://hua@node1/system vncdisplay i1</span><br><span class="line">sudo virsh vncdisplay i1</span><br><span class="line">vncviewer 192.168.99.124:1</span><br></pre></td></tr></table></figure></p>
<p>如果本机开了VPN后通过’ssh -X’远程连接中转机，再通过上面的vncviewer也是可以连接Linux虚机的。<br>但是该Windows虚机不支持VNC，但它默认启动了RDP。同理，我们也可以本机开了VPN后通过’ssh -X’远程连接中转机，再通过remmina访问(或者采用rdesktop命令行方式 )，但是这种方式奇慢无比，于是有了本文的探讨。</p>
<h2 id="通过tunnel-remmina访问Tenant-OpenStack提供的Windows虚机"><a href="#通过tunnel-remmina访问Tenant-OpenStack提供的Windows虚机" class="headerlink" title="通过tunnel+remmina访问Tenant OpenStack提供的Windows虚机"></a>通过tunnel+remmina访问Tenant OpenStack提供的Windows虚机</h2><p>设想的方案是通过如果的ssh正向隧道方式，本机上执行如下命令，本机的13389端口通过ssh server 10.230.65.8映射到远程的10.5.150.2:3389上。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 22 -L localhost:13389:10.5.150.2:3389 ubuntu@10.230.65.8 -N -v</span><br><span class="line">#sudo rdesktop 127.0.0.1:13389</span><br><span class="line">sudo rdesktop -z -r sound:local -g workarea -D -K -a 16 -u Administrator -p password 127.0.0.1:13389</span><br></pre></td></tr></table></figure></p>
<p>但是发现不好使，原因在于在中转机10.230.65.8上都无法运行telnet 10.5.150.2 3389’命令。<br>VNC的5900-5910这些端口与RDP的3389端口似乎还有点不一样，<strong>5900-5910是运行虚机的物理机上的端口，而3389是Windows虚机的端口</strong>。</p>
<p>所以第一步，应该将Windows虚机所在的物理机的Security group规则打开，这个得在Tenant OpenStack环境中执行如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">nova secgroup-add-rule default tcp 3389 3389 0.0.0.0/0</span><br><span class="line">nova secgroup-add-rule default udp 3389 3389 0.0.0.0/0</span><br><span class="line">#secgroup=$&#123;1:-`openstack security group list --project admin| grep default| awk &apos;&#123;print $2&#125;&apos;`&#125;</span><br><span class="line">#openstack security group rule create $secgroup --protocol tcp --remote-ip 0.0.0.0/0 --dst-port 3389 --project admin</span><br><span class="line"></span><br><span class="line">#计算节点上通过下列命令验证：</span><br><span class="line">$ sudo iptables-save |grep 3389</span><br><span class="line">-A neutron-openvswi-i2f32d9bf-6 -p tcp -m tcp --dport 3389 -j RETURN</span><br><span class="line">-A neutron-openvswi-i2f32d9bf-6 -p udp -m udp --dport 3389 -j RETURN</span><br><span class="line"></span><br><span class="line">#网络节点上继续通过下列命令验证通过：</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 telnet 192.168.21.2 3389</span><br></pre></td></tr></table></figure></p>
<p>第二步，要想通过192.168.21.2的floating ip (10.5.150.2)访问，还得将Tenant OpenStack的FWaaS服务中的3389端口打开。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">neutron firewall-rule-create --protocol tcp --destination-port 80 --action allow --name tcp_3389</span><br><span class="line">neutron firewall-rule-create --protocol udp --destination-port 80 --action allow --name udp_3389</span><br><span class="line">neutron firewall-policy-create --firewall-rules &quot;tcp_3389 udp_3389&quot; policy_3389</span><br><span class="line">neutron firewall-create policy_3389 --name myfirewall</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 iptables-save |grep 3389</span><br><span class="line"></span><br><span class="line">#也可以通过下列命令直接手动添加：</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 iptables -A neutron-vpn-agen-iv49ecd7359 -p tcp -m tcp --dport 3389 -j ACCEPT</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 iptables -A neutron-vpn-agen-iv49ecd7359 -p udp -m udp --dport 3389 -j ACCEPT</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 iptables -A neutron-vpn-agen-ov49ecd7359 -p tcp -m tcp --dport 3389 -j ACCEPT</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 iptables -A neutron-vpn-agen-ov49ecd7359 -p udp -m udp --dport 3389 -j ACCEPT</span><br><span class="line"></span><br><span class="line">#添加成功后在网络节点上通过下列命令验证成功：</span><br><span class="line">telnet 10.5.150.2 3389</span><br></pre></td></tr></table></figure></p>
<p>第三步，要想在中断机上也能成功运行’telnet 10.5.150.2 3389’, 由于中断机和Tenant OpenStack的网络节点都是由Underlying OpenStack提供的虚机，所以还需要在Underlying OpenStack中的Security Group设置3389支持。具体命令可以参考第一步，但由于我没有Underlying OpenStack的权限，所以这步做不了，此路不通，做罢，但理论应该是对的。</p>
<h2 id="通过端口映射的方案访问Tenant-OpenStack提供的Windows虚机"><a href="#通过端口映射的方案访问Tenant-OpenStack提供的Windows虚机" class="headerlink" title="通过端口映射的方案访问Tenant OpenStack提供的Windows虚机"></a>通过端口映射的方案访问Tenant OpenStack提供的Windows虚机</h2><p>理论上也可以在中转机上将3389端口映射到Windows虚机的3389端口解决，但同样由于我没有Underlying OpenStack的权限无法解决在中转机上’telent 10.5.150.2 3389’，所以此方案也无法测试。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 3389 -j DNAT --to-destination 10.10.10.7:3389</span><br><span class="line">iptables -A FORWARD -p tcp --dport 3389 -j ACCEPT</span><br></pre></td></tr></table></figure></p>
<h2 id="最后的方案"><a href="#最后的方案" class="headerlink" title="最后的方案"></a>最后的方案</h2><p>没了Underlying OpenStack的权限，这个实验似乎做不下去了，还剩下两个手段：</p>
<ul>
<li><p>一个使用Underlying OpenStack环境的tenant用户为Tenant OpenStack的网络节点再分配一个10.230打头的floating ip （如10.230.65.118)，因为Tenant Network上的网络节点上是可以运行’telent 10.5.150.2 3389’的，同时，10.230的IP也可以在登录VPN后直接访问。但是10.230.65.118代表的网络节点是由Tenant OpenStack提供的，所以从本机登录时应该从中转机拷贝~/.local/share/juju/ssh/juju_id_rsa。这种方式目前已经测试成功。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scp ubuntu@10.230.65.8:/home/ubuntu/.local/share/juju/ssh/juju_id_rsa /home/hua/.ssh/</span><br><span class="line">#ssh -i ~/.ssh/juju_id_rsa ubuntu@10.230.65.118</span><br><span class="line">ssh -i ~/.ssh/juju_id_rsa -p 22 -L localhost:13389:10.5.150.2:3389 ubuntu@10.230.65.118 -N -v</span><br><span class="line">#sudo rdesktop 127.0.0.1:13389</span><br><span class="line">sudo rdesktop -z -r sound:local -g workarea -D -K -a 16 -u Administrator -p password 127.0.0.1:13389</span><br></pre></td></tr></table></figure>
<p>-在Windows虚机中通过下列命令打开Powershell Remote, 再通过pywinrm库(<a href="https://github.com/diyan/pywinrm)通过命令行或程序(https://gist.github.com/vtapia/c4a87289298c73b9f75afcf36ed6a89b)操作Windows，这种方式蛮麻烦。" target="_blank" rel="external">https://github.com/diyan/pywinrm)通过命令行或程序(https://gist.github.com/vtapia/c4a87289298c73b9f75afcf36ed6a89b)操作Windows，这种方式蛮麻烦。</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Set-ExecutionPolicy -ExecutionPolicy Bypass -Force</span><br><span class="line">Enable-PSRemoting -force</span><br><span class="line">Set-Item WSMan:\localhost\Client\TrustedHosts * -force</span><br><span class="line">winrm set winrm/config/service/auth &apos;@&#123;Basic=&quot;true&quot;&#125;&apos;</span><br><span class="line">winrm set winrm/config/service &apos;@&#123;AllowUnencrypted=&quot;true&quot;&#125;&apos;</span><br><span class="line">restart-Service winrm</span><br></pre></td></tr></table></figure>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/29/远程访问双层嵌套Openstack云下的Windows虚机/" data-id="cjc7ckhzm000fbjbpqvzwqglp" class="article-share-link">Поделиться</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-通配符中一个星号两个星号和globstar的关系" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/16/通配符中一个星号两个星号和globstar的关系/" class="article-date">
  <time datetime="2017-11-16T07:48:59.000Z" itemprop="datePublished">2017-11-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/16/通配符中一个星号两个星号和globstar的关系/">通配符中一个星号两个星号和globstar的关系</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>今天在处理一个AppArmor的问题时，遇到一个奇怪的问题，在/etc/apparmor.d/usr.bin.nova-compute文件中明明已经有了下面对/tmp及/var/tmp目录的配置。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/tmp/* rw,</span><br><span class="line">/tmp/*/ rw,</span><br><span class="line">/tmp/** rw,</span><br><span class="line">/var/tmp/* rw,</span><br></pre></td></tr></table></figure></p>
<p>但是在运行”sudo /etc/init.d/apparmor reload &amp;&amp; sudo service nova-compute restart“命令后仍然在syslog里能看到下列错误信息。奇了怪了，这是怎么一回事呢？<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Nov 15 12:49:36 juju-864213-xenial-mitaka-ceph-11 kernel: [705198.766810] audit: type=1400 audit(1510750176.727:10140): apparmor=&quot;DENIED&quot; operation=&quot;open&quot; profile=&quot;/usr/bin/nova-compute&quot; name=&quot;/tmp/&quot; pid=16922 comm=&quot;nova-compute&quot; requested_mask=&quot;r&quot; denied_mask=&quot;r&quot; fsuid=113 ouid=0</span><br><span class="line">Nov 15 12:49:36 juju-864213-xenial-mitaka-ceph-11 kernel: [705198.766828] audit: type=1400 audit(1510750176.727:10141): apparmor=&quot;DENIED&quot; operation=&quot;open&quot; profile=&quot;/usr/bin/nova-compute&quot; name=&quot;/var/tmp/&quot; pid=16922 comm=&quot;nova-compute&quot; requested_mask=&quot;r&quot; denied_mask=&quot;r&quot; fsuid=113 ouid=0</span><br></pre></td></tr></table></figure></p>
<h2 id="globstar模式下的通配符"><a href="#globstar模式下的通配符" class="headerlink" title="globstar模式下的通配符"></a>globstar模式下的通配符</h2><p>通配符有一个星号，两个星号，还有逗号，globstar模式可以开启，还可以关闭。这些混在一起会有什么影响呢？<br>如果想要很方便地遍历所有的目录和文件得用两个星号的通配符。globstar是Bash 4.0才引入的选项，当设置启用globstar(shopt -s globstar)时，两个星号意为对通配符进行展开就可以匹配任何当前目录(包括子目录)以及其的文件；若不启用globstar(shopt -u globstar)，两个星号通配符的作用和一个星号通配符是相同的。</p>
<ul>
<li>~/tmp/* -  匹配当前目录的文件，及当前目录的下一级目录(不包括当前目录），与’ls ~/tmp’及”ls ~/tmp/“的效果同。</li>
<li>~/tmp/*/ - 匹配当前目录的下一级目录(不包括当前目录）</li>
<li>~/tmp/<em>* - 禁用globstar时，与~/tmp/</em>完全一样(不包括当前目录）；但启用globstar时，不止取一级，递归取所有级的文件和目录（也包括当前目录）</li>
<li>~/tmp/<em>*/ - 禁用globstar时，与~/tmp/</em>/ 完全一样(不包括当前目录）；但启用globstar时，不止取一级，递归取所有级的目录（也包括当前目录）</li>
</ul>
<p>当启用globstar时，英语的解释如下（注：里面说的file包括文件和目录，在Linux里目录是特殊的文件）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Substitutes for any number of characters, except /.</span><br><span class="line">/tmp/* matches any file in /tmp. </span><br><span class="line">/tmp/*/ matches any directory in /tmp</span><br><span class="line"></span><br><span class="line">Substitutes for any number of characters, including /.</span><br><span class="line">/tmp/** matches all files and directories underneath /tmp.</span><br><span class="line">/tmp/**/ matches all directories underneath /tmp.</span><br></pre></td></tr></table></figure>
<p>请看实验数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">hua@t440p:~/tmp$ tree .</span><br><span class="line">.</span><br><span class="line">├── l0_dir1</span><br><span class="line">│   ├── l1_dir</span><br><span class="line">│   │   ├── l2_dir</span><br><span class="line">│   │   │   └── l3_file</span><br><span class="line">│   │   └── l2_file</span><br><span class="line">│   └── l1_file</span><br><span class="line">├── l0_dir2</span><br><span class="line">└── l0_file</span><br><span class="line">4 directories, 4 files</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ shopt -s globstar</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/*</span><br><span class="line">/home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/*/</span><br><span class="line">/home/hua/tmp/l0_dir1/:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2/:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/**</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir/l2_dir/l3_file  /home/hua/tmp/l0_dir1/l1_file</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir/l2_file         /home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/:</span><br><span class="line">l0_dir1  l0_dir2  l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir:</span><br><span class="line">l2_dir  l2_file</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir/l2_dir:</span><br><span class="line">l3_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/**/</span><br><span class="line">/home/hua/tmp/:</span><br><span class="line">l0_dir1  l0_dir2  l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1/:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir/:</span><br><span class="line">l2_dir  l2_file</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir/l2_dir/:</span><br><span class="line">l3_file</span><br><span class="line">/home/hua/tmp/l0_dir2/:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/&#123;,**&#125;</span><br><span class="line">/home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/:</span><br><span class="line">l0_dir1  l0_dir2  l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ shopt -u globstar</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/*</span><br><span class="line">/home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/*/</span><br><span class="line">/home/hua/tmp/l0_dir1/:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2/:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/**</span><br><span class="line">/home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/**/</span><br><span class="line">/home/hua/tmp/l0_dir1/:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2/:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/&#123;,**&#125;</span><br><span class="line">/home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/:</span><br><span class="line">l0_dir1  l0_dir2  l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br></pre></td></tr></table></figure>
<h2 id="问题的解决"><a href="#问题的解决" class="headerlink" title="问题的解决"></a>问题的解决</h2><p>学习了上面的理论之后，是不是想到了问题所在了，那就是下列两个配置没有包括当前目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/tmp/** rw,</span><br><span class="line">/var/tmp/* rw,</span><br></pre></td></tr></table></figure></p>
<p>所以它应该修改为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/tmp/&#123;,**&#125; rw,</span><br><span class="line">/var/tmp/&#123;,**&#125; rw,</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/16/通配符中一个星号两个星号和globstar的关系/" data-id="cjc7ckhzo000gbjbptegwibyh" class="article-share-link">Поделиться</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Use-hexo-to-create-blog" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/13/Use-hexo-to-create-blog/" class="article-date">
  <time datetime="2017-11-13T09:02:52.000Z" itemprop="datePublished">2017-11-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/13/Use-hexo-to-create-blog/">Use hexo to create blog</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>独立博客可以采用wordpress搭建动态博客，也可以采用Markdown语法编写静态博客(no db, no cms, simple, minimal)发布到有git版本控制的github上, jekyll与hexo是一个将markdown文件产生目录生成静态网站的程序。</p>
<p>1, 登陆GitHub，新建一个repository, 命名为你的用户名 + github.io。如我的用户名为zhhuabj，所以repository命名为zhhuabj.github.io</p>
<p>2, 创建第一个网页index.html</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/zhhuabj/zhhuabj.github.io.git</span><br><span class="line">cd zhhuabj.github.io</span><br><span class="line">echo “my blog” &gt;&gt; index.html</span><br><span class="line">git add .</span><br><span class="line">git commit -m “first commit”</span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure>
<p>3, 访问<a href="https://zhhuabj.github.io/" target="_blank" rel="external">https://zhhuabj.github.io/</a></p>
<p>4, [使用jekyll可省略]打开<a href="https://github.com/zhhuabj/zhhuabj.github.io/settings，" target="_blank" rel="external">https://github.com/zhhuabj/zhhuabj.github.io/settings，</a> 点击Launch automatic page generator按钮开始设置样式。</p>
<p>5, CSDN博客迁移</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install beautifulsoup</span><br><span class="line">git clone https://github.com/gaocegege/csdn-blog-export.git</span><br><span class="line">cd csdn-blog-export</span><br><span class="line">./main.py -u quqi99 -f html</span><br><span class="line">./main.py -u quqi99 -f markdown</span><br></pre></td></tr></table></figure>
<p>6, 使用jekyll本地写博客</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install ruby ruby-dev</span><br><span class="line">gem sources --remove https://rubygems.org/</span><br><span class="line">gem sources -a https://ruby.taobao.org/</span><br><span class="line">gem sources -l</span><br><span class="line">sudo gem install jekyll</span><br><span class="line">cd zhhuabj.github.io/jekyll</span><br><span class="line">jekyll new .</span><br><span class="line">cp -r ../csdn-blog-export/*.md _posts/</span><br><span class="line">jekyll serve  #http://localhost:4000/</span><br><span class="line">vi _config.yml</span><br></pre></td></tr></table></figure>
<p>7, 改用jekyll-bootstrap, 先扫描 _post，layout, 然后是目录和 page，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">装入一个 site 对象后，用什么 Liquide render出来</span><br><span class="line">git clone https://github.com/plusjade/jekyll-bootstrap.git</span><br><span class="line">cp -r jekyll-bootstrap/* zhhuabj.github.io/*</span><br><span class="line">vi _config.yml</span><br><span class="line">cd zhhuabj.github.io</span><br><span class="line">sudo gem install jekyll-sitemap</span><br><span class="line">jekyll serve #http://127.0.0.1:4000/</span><br></pre></td></tr></table></figure>
<p>8, 改用hexo</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">   sudo apt install npm node.js nodejs-legacy </span><br><span class="line">   sudo npm install hexo hexo-generator-feed -g</span><br><span class="line">   sudo npm install hexo-deployer-git --save</span><br><span class="line">   sudo npm install git --save</span><br><span class="line">   cd zhhuabj.github.io</span><br><span class="line">   hexo init .</span><br><span class="line">   hexo server    #http://localhost:4000/</span><br><span class="line">   hexo new &quot;my test post&quot;</span><br><span class="line">   </span><br><span class="line">   $ vim _config.yml</span><br><span class="line">deploy:</span><br><span class="line">  type: git  #注意前面有两个空格，冒号后有一个空格</span><br><span class="line">  #repository: https://github.com/zhhuabj/zhhuabj.github.io.git</span><br><span class="line">  # 如果使用ssh免密码方式除了github上提交公钥，同时改成下面一句</span><br><span class="line">  repository: git@github.com:zhhuabj/zhhuabj.github.io.git</span><br><span class="line">  branch: master</span><br><span class="line">  #user: zhhuabj</span><br><span class="line">  #pass: password</span><br><span class="line">  </span><br><span class="line">   cp -r ../csdn-blog-export/*.md source/_posts/</span><br><span class="line">   hexo generate</span><br><span class="line">   hexo deploy  #cp -r public/* .</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/13/Use-hexo-to-create-blog/" data-id="cjc7ckhys0008bjbp210pzvaj" class="article-share-link">Поделиться</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-使用Juju将OpenStack部署在单机的LXD容器上" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/13/使用Juju将OpenStack部署在单机的LXD容器上/" class="article-date">
  <time datetime="2017-11-13T07:18:08.000Z" itemprop="datePublished">2017-11-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/13/使用Juju将OpenStack部署在单机的LXD容器上/">使用Juju将OpenStack部署在单机的LXD容器上</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>作者：张华  发表于：2016-08-05<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br><a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</strong></p>
<h2 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h2><ol>
<li>iscsi还不能运行在容器里（因为netlink还不支持namesapce)，本文采用rbd使用ceph代替iscsi</li>
<li>ovs, kvm通过定义profile支持运行在容器里。ovs目前只支持security.privileged: “true”</li>
</ol>
<h2 id="配置LXD"><a href="#配置LXD" class="headerlink" title="配置LXD"></a>配置LXD</h2><p>参考<a href="http://blog.csdn.net/quqi99/article/details/52131486" target="_blank" rel="external">Play with LXD</a>一文 在ubuntu 16.04上部署LXD环境。</p>
<h2 id="LXD上部署OpenStack"><a href="#LXD上部署OpenStack" class="headerlink" title="LXD上部署OpenStack"></a>LXD上部署OpenStack</h2><p>1, 从这个<a href="https://jujucharms.com/openstack-base/" target="_blank" rel="external">链接</a>下载 ‘openstack-base.zip’ ，里面有下面要用到的bundle.yaml<br>2, 运行’juju bootstrap’，注意：运行这一步时先不要修改profile<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#sudo snap install lxd</span><br><span class="line">export PATH=/snap/bin:$PATH</span><br><span class="line">juju bootstrap --debug --config bootstrap-series=xenial --config agent-stream=devel localhost lxd-controller</span><br><span class="line">lxc exec `lxc list |grep juju- |awk -F &apos;|&apos; &apos;&#123;print $2&#125;&apos;` bash</span><br></pre></td></tr></table></figure></p>
<p>3,  创建model，且<strong>它会自动生成juju-openstack-model profile</strong> （’juju add-model’会自动执行这一句‘lxc profile create juju-openstack-model 2&gt;/dev/null || echo “juju-openstack-model profile already exists”’）, <strong>如果不定义model，就会有一个名为default的model，那么这时下面第4步要编辑juju-default profile</strong>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">juju add-model openstack-model</span><br><span class="line">juju models</span><br><span class="line">lxc profile show juju-openstack-model</span><br></pre></td></tr></table></figure></p>
<p>4, 编辑juju-openstack-model profile。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install --reinstall linux-image-extra-$(uname -r)</span><br><span class="line">sudo modprobe nbd</span><br><span class="line">sudo modprobe ip_tables</span><br><span class="line">sudo modprobe openvswitch</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; juju-openstack-model.yaml</span><br><span class="line">name: juju-openstack-model</span><br><span class="line">config:</span><br><span class="line">  boot.autostart: &quot;true&quot;</span><br><span class="line">  security.nesting: &quot;true&quot;</span><br><span class="line">  security.privileged: &quot;true&quot;</span><br><span class="line">  raw.lxc: lxc.aa_profile=unconfined</span><br><span class="line">  linux.kernel_modules: openvswitch,nbd,ip_tables,ip6_tables,ebtables,netlink_diag,nf_nat,overlay</span><br><span class="line">devices:</span><br><span class="line">  eth0:</span><br><span class="line">    mtu: &quot;9000&quot;</span><br><span class="line">    name: eth0</span><br><span class="line">    nictype: bridged</span><br><span class="line">    parent: lxdbr1</span><br><span class="line">    type: nic</span><br><span class="line">  eth1:</span><br><span class="line">    mtu: &quot;9000&quot;</span><br><span class="line">    name: eth1</span><br><span class="line">    nictype: bridged</span><br><span class="line">    parent: lxdbr1</span><br><span class="line">    type: nic</span><br><span class="line">  kvm:</span><br><span class="line">    path: /dev/kvm</span><br><span class="line">    type: unix-char</span><br><span class="line">  mem:</span><br><span class="line">    path: /dev/mem</span><br><span class="line">    type: unix-char</span><br><span class="line">  root:</span><br><span class="line">    path: /</span><br><span class="line">    pool: default</span><br><span class="line">    type: disk</span><br><span class="line">  tun:</span><br><span class="line">    path: /dev/net/tun</span><br><span class="line">    type: unix-char</span><br><span class="line">EOF</span><br><span class="line">cat lxd-profile.yaml | lxc profile edit juju-openstack-model</span><br><span class="line">#其他命令演示</span><br><span class="line">#lxc profile set juju-openstack-model raw.lxc lxc.aa_profile=unconfined</span><br><span class="line">#lxc profile device add juju-openstack-model fuse unix-char path=/dev/fuse</span><br><span class="line">#/snap/bin/lxc network create lxdbr1 ipv4.address=auto ipv4.nat=true ipv6.address=none</span><br></pre></td></tr></table></figure></p>
<p>5, 使用juju一键部署openstack</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://api.jujucharms.com/charmstore/v5/openstack-base/archive/bundle.yaml</span><br><span class="line">juju deploy bundle.yaml</span><br><span class="line">juju status</span><br><span class="line">juju debug-log</span><br></pre></td></tr></table></figure>
<h2 id="安装过程中遇到的问题"><a href="#安装过程中遇到的问题" class="headerlink" title="安装过程中遇到的问题"></a>安装过程中遇到的问题</h2><ul>
<li>如果报这个错 - failed to bootstrap model: cannot start bootstrap instance: The container’s root device is missing the pool property， 那是要在profile中的root元素下添加：pool: default</li>
<li>bootstrap时报这个错 - FATAL: Module ip6_tables，ebtables，netlink_diag not found in directory /lib/modules/4.4.0-98-generic - 运行‘sudo apt-get install –reinstall linux-image-extra-$(uname -r)’安装模块（/lib/modules/$(uname -r)/kernel/net/netlink/netlink_diag.ko）。<strong>此外是因为profile中写的这些模块名是从网页拷过来的存在乱码</strong>。</li>
</ul>
<h2 id="配置使用OpenStack"><a href="#配置使用OpenStack" class="headerlink" title="配置使用OpenStack"></a>配置使用OpenStack</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">source novarc</span><br><span class="line">$ cat novarc </span><br><span class="line">#!/bin/bash</span><br><span class="line">export OS_USERNAME=admin</span><br><span class="line">export OS_PASSWORD=openstack</span><br><span class="line">export OS_TENANT_NAME=admin</span><br><span class="line">export OS_REGION_NAME=RegionOne</span><br><span class="line">export OS_AUTH_URL=$&#123;OS_AUTH_PROTOCOL:-http&#125;://`juju run --unit  keystone/0 &quot;unit-get private-address&quot;`:5000/v2.0</span><br><span class="line"></span><br><span class="line">curl http://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img</span><br><span class="line">openstack image create --public --container-format=bare --disk-format=qcow2 xenial</span><br><span class="line"></span><br><span class="line">./neutron-ext-net -g 10.0.8.1 -c 10.0.8.0/24 \ -f 10.0.8.201:10.0.8.254 ext_net</span><br><span class="line">./neutron-tenant-net -t admin -r provider-router \ -N 10.0.8.1 internal 192.168.20.0/24</span><br><span class="line"></span><br><span class="line">nova keypair-add --pub-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">nova boot --image xenial --flavor m1.small --key-name mykey --nic net-id=$(neutron net-list | grep internal | awk &apos;&#123; print $2 &#125;&apos;) i1</span><br><span class="line"></span><br><span class="line">cinder create --name testvolume 10</span><br><span class="line">nova volume-attach xenial $(cinder list | grep testvolume | awk &apos;&#123; print $2 &#125;&apos;) /dev/vdc</span><br><span class="line"></span><br><span class="line">nova floating-ip-create </span><br><span class="line">nova add-floating-ip &lt;uuid-of-instance&gt; &lt;new-floating-ip&gt;</span><br><span class="line"></span><br><span class="line">neutron security-group-rule-create --protocol icmp --direction ingress $(nova secgroup-list | grep default | awk &apos;&#123; print $2 &#125;&apos;) </span><br><span class="line">neutron security-group-rule-create --protocol tcp  --port-range-min 22 --port-range-max 22  --direction ingress $(nova secgroup-list | grep default | awk &apos;&#123; print $2 &#125;&apos;)</span><br><span class="line"></span><br><span class="line">ssh ubuntu@&lt;new-floating-ip&gt;</span><br></pre></td></tr></table></figure>
<h2 id="又一例-部署opencontrail在lxd单机上"><a href="#又一例-部署opencontrail在lxd单机上" class="headerlink" title="又一例 - 部署opencontrail在lxd单机上"></a>又一例 - 部署opencontrail在lxd单机上</h2><p>下面的yaml是juju2.0的，如果是juju1.x可见：<a href="http://pastebin.ubuntu.com/24170320/" target="_blank" rel="external">http://pastebin.ubuntu.com/24170320/</a><br>实际上,opencontrail vrouter部署在容器里会报下列错，此例子只是说明yaml怎么写。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2017-03-13 11:46:06 INFO juju-log Loading kernel module vrouter</span><br><span class="line">2017-03-13 11:46:06 INFO install modprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file &apos;/lib/modules/4.8.0-34-generic/modules.dep.bin&apos;</span><br><span class="line">2017-03-13 11:46:06 INFO juju-log vrouter kernel module failed to load, clearing pagecache and retrying</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">series: trusty</span><br><span class="line">services:</span><br><span class="line">  # openstack</span><br><span class="line">  ubuntu:</span><br><span class="line">    charm: cs:trusty/ubuntu</span><br><span class="line">    num_units: 1</span><br><span class="line">  ntp:</span><br><span class="line">    charm: cs:trusty/ntp</span><br><span class="line">  mysql:</span><br><span class="line">    charm: cs:trusty/mysql</span><br><span class="line">    options:</span><br><span class="line">      dataset-size: 15%</span><br><span class="line">      max-connections: 1000</span><br><span class="line">    num_units: 1</span><br><span class="line">  rabbitmq-server:</span><br><span class="line">    charm: cs:trusty/rabbitmq-server</span><br><span class="line">    num_units: 1</span><br><span class="line">  keystone:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/keystone</span><br><span class="line">    options:</span><br><span class="line">      admin-password: password</span><br><span class="line">      admin-role: admin</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  nova-cloud-controller:</span><br><span class="line">    charm: cs:trusty/nova-cloud-controller</span><br><span class="line">    options:</span><br><span class="line">      network-manager: Neutron</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  neutron-api:</span><br><span class="line">    charm: cs:trusty/neutron-api</span><br><span class="line">    options:</span><br><span class="line">      manage-neutron-plugin-legacy-mode: false</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  glance:</span><br><span class="line">    charm: cs:trusty/glance</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  openstack-dashboard:</span><br><span class="line">    charm: cs:trusty/openstack-dashboard</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  nova-compute:</span><br><span class="line">    charm: cs:trusty/nova-compute</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  # contrail</span><br><span class="line">  cassandra:</span><br><span class="line">    charm: cs:trusty/cassandra</span><br><span class="line">    options:</span><br><span class="line">      authenticator: AllowAllAuthenticator</span><br><span class="line">      install_sources: |</span><br><span class="line">        - deb http://www.apache.org/dist/cassandra/debian 22x main</span><br><span class="line">        - ppa:openjdk-r/ppa</span><br><span class="line">        - ppa:stub/cassandra</span><br><span class="line">    num_units: 1</span><br><span class="line">  zookeeper:</span><br><span class="line">    charm: cs:~charmers/trusty/zookeeper</span><br><span class="line">    num_units: 1</span><br><span class="line">  kafka:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/apache-kafka</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-configuration:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-configuration</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-control:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-control</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-analytics:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-analytics</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-webui:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-webui</span><br><span class="line">    num_units: 1</span><br><span class="line">  neutron-api-contrail:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/neutron-api-contrail</span><br><span class="line">    num_units: 0</span><br><span class="line">  neutron-contrail:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/neutron-contrail</span><br><span class="line">    num_units: 0</span><br><span class="line"></span><br><span class="line">relations:</span><br><span class="line">  # openstack</span><br><span class="line"> - [ ubuntu, ntp ]</span><br><span class="line"> - [ keystone, mysql ]</span><br><span class="line"> - [ glance, mysql ]</span><br><span class="line"> - [ glance, keystone ]</span><br><span class="line"> - [ nova-cloud-controller, mysql ]</span><br><span class="line"> - [ nova-cloud-controller, rabbitmq-server ]</span><br><span class="line"> - [ nova-cloud-controller, keystone ]</span><br><span class="line"> - [ nova-cloud-controller, glance ]</span><br><span class="line"> - [ neutron-api, mysql ]</span><br><span class="line"> - [ neutron-api, rabbitmq-server ]</span><br><span class="line"> - [ neutron-api, nova-cloud-controller ]</span><br><span class="line"> - [ neutron-api, keystone ]</span><br><span class="line"> - [ neutron-api, neutron-api-contrail ]</span><br><span class="line"> - [ &quot;nova-compute:shared-db&quot;, &quot;mysql:shared-db&quot; ]</span><br><span class="line"> - [ &quot;nova-compute:amqp&quot;, &quot;rabbitmq-server:amqp&quot; ]</span><br><span class="line"> - [ nova-compute, glance ]</span><br><span class="line"> - [ nova-compute, nova-cloud-controller ]</span><br><span class="line"> - [ nova-compute, ntp ]</span><br><span class="line"> - [ openstack-dashboard, keystone ]</span><br><span class="line">  # contrail</span><br><span class="line"> - [ kafka, zookeeper ]</span><br><span class="line"> - [ &quot;contrail-configuration:cassandra&quot;, &quot;cassandra:database&quot; ]</span><br><span class="line"> - [ contrail-configuration, zookeeper ]</span><br><span class="line"> - [ contrail-configuration, rabbitmq-server ]</span><br><span class="line"> - [ &quot;contrail-configuration:identity-admin&quot;, &quot;keystone:identity-admin&quot; ]</span><br><span class="line"> - [ &quot;contrail-configuration:identity-service&quot;, &quot;keystone:identity-service&quot; ]</span><br><span class="line"> - [ neutron-api-contrail, contrail-configuration ]</span><br><span class="line"> - [ neutron-api-contrail, keystone ]</span><br><span class="line"> - [ &quot;contrail-control:contrail-api&quot;, &quot;contrail-configuration:contrail-api&quot; ]</span><br><span class="line"> - [ &quot;contrail-control:contrail-discovery&quot;, &quot;contrail-configuration:contrail-discovery&quot; ]</span><br><span class="line"> - [ &quot;contrail-control:contrail-ifmap&quot;, &quot;contrail-configuration:contrail-ifmap&quot; ]</span><br><span class="line"> - [ contrail-control, keystone ]</span><br><span class="line"> - [ &quot;contrail-analytics:cassandra&quot;, &quot;cassandra:database&quot; ]</span><br><span class="line"> - [ contrail-analytics, kafka ]</span><br><span class="line"> - [ contrail-analytics, zookeeper ]</span><br><span class="line"> - [ &quot;contrail-analytics:contrail-api&quot;, &quot;contrail-configuration:contrail-api&quot; ]</span><br><span class="line"> - [ &quot;contrail-analytics:contrail-discovery&quot;, &quot;contrail-configuration:contrail-discovery&quot; ]</span><br><span class="line"> - [ &quot;contrail-analytics:identity-admin&quot;, &quot;keystone:identity-admin&quot; ]</span><br><span class="line"> - [ &quot;contrail-analytics:identity-service&quot;, &quot;keystone:identity-service&quot; ]</span><br><span class="line"> - [ &quot;contrail-configuration:contrail-analytics-api&quot;, &quot;contrail-analytics:contrail-analytics-api&quot; ]</span><br><span class="line"> - [ nova-compute, neutron-contrail ]</span><br><span class="line"> - [ &quot;neutron-contrail:contrail-discovery&quot;, &quot;contrail-configuration:contrail-discovery&quot; ]</span><br><span class="line"> - [ &quot;neutron-contrail:contrail-api&quot;, &quot;contrail-configuration:contrail-api&quot; ]</span><br><span class="line"> - [ neutron-contrail, keystone ]</span><br><span class="line"> - [ contrail-webui, keystone ]</span><br><span class="line"> - [ &quot;contrail-webui:cassandra&quot;, &quot;cassandra:database&quot; ]</span><br></pre></td></tr></table></figure>
<h2 id="通过conjure-up安装OpenStack"><a href="#通过conjure-up安装OpenStack" class="headerlink" title="通过conjure-up安装OpenStack"></a>通过conjure-up安装OpenStack</h2><p>我们也可以通过conjure-up安装OpenStack,</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">#Install a lxd container</span><br><span class="line">sudo lxc init ubuntu:16.04 openstack -c security.privileged=true -c security.nesting=true -c &quot;linux.kernel_modules=iptable_nat, ip6table_nat, ebtables, openvswitch, nbd&quot;</span><br><span class="line">printf &quot;lxc.cap.drop=\nlxc.aa_profile=unconfined\n&quot; | sudo lxc config set openstack raw.lxc -</span><br><span class="line">sudo lxc config get openstack raw.lxc</span><br><span class="line">lxc config device add openstack mem unix-char path=/dev/mem</span><br><span class="line">lxc start openstack</span><br><span class="line">lxc list</span><br><span class="line"></span><br><span class="line">#Install conjure-up inside the lxd container</span><br><span class="line">#lxc exec openstack bash</span><br><span class="line">lxc exec openstack -- apt update</span><br><span class="line">#lxc exec openstack -- apt dist-upgrade -y</span><br><span class="line">lxc exec openstack -- apt install squashfuse -y</span><br><span class="line">lxc exec openstack -- ln -s /bin/true /usr/local/bin/udevadm</span><br><span class="line">lxc exec openstack -- snap install conjure-up --classic</span><br><span class="line"></span><br><span class="line">#Init lxd container</span><br><span class="line">#Use the “dir” storage backend (“zfs” doesn’t work in a nested container)</span><br><span class="line">#Do NOT configure IPv6 networking (conjure-up/juju don’t play well with it)</span><br><span class="line">#lxc exec openstack -- lxd init</span><br><span class="line">lxc exec openstack -- snap install lxd</span><br><span class="line">sleep 10  #avoid the error &apos;Unable to talk to LXD: Get http://unix.socket/1.0&apos;</span><br><span class="line">lxc exec openstack -- /snap/bin/lxd init --auto</span><br><span class="line">lxc exec openstack -- /snap/bin/lxc network create lxdbr0 ipv4.address=auto ipv4.nat=true ipv6.address=none</span><br><span class="line">lxc exec openstack -- /snap/bin/lxc profile show default</span><br><span class="line"></span><br><span class="line">#Deploying OpenStack with conjure-up in nested LXD</span><br><span class="line">#conjure-up is a nice, user friendly, tool that interfaces with Juju to deploy complex services.</span><br><span class="line">#Step 1, select “OpenStack with NovaLXD”</span><br><span class="line">#Step 2, select “localhost” as the deployment target (uses LXD)</span><br><span class="line">#Step 3, select default in all middle steps, and click “Deploy all remaining applications”</span><br><span class="line">lxc exec openstack -- sudo -u ubuntu -i conjure-up</span><br><span class="line">hua@node1:~$ sudo lxc list</span><br><span class="line">+-----------+---------+--------------------------------+------+------------+-----------+</span><br><span class="line">|   NAME    |  STATE  |              IPV4              | IPV6 |    TYPE    | SNAPSHOTS |</span><br><span class="line">+-----------+---------+--------------------------------+------+------------+-----------+</span><br><span class="line">| openstack | RUNNING | 10.73.227.154 (eth0)           |      | PERSISTENT | 0         |</span><br><span class="line">|           |         | 10.164.92.1 (lxdbr0)           |      |            |           |</span><br><span class="line">|           |         | 10.101.0.1 (conjureup0)        |      |            |           |</span><br><span class="line">+-----------+---------+--------------------------------+------+------------+-----------+</span><br><span class="line"></span><br><span class="line">#Or deploy OpenStack with conjure-up in physical node</span><br><span class="line">sudo snap install lxd</span><br><span class="line">export PATH=/snap/bin:$PATH</span><br><span class="line">sudo /snap/bin/lxd init --auto</span><br><span class="line">sudo /snap/bin/lxc network create lxdbr0 ipv4.address=auto ipv4.nat=true ipv6.address=none</span><br><span class="line">sudo -i</span><br><span class="line">conjure-up openstack #but I hit the error &apos;This should _not_ be run as root or with sudo&apos; even though I&apos;ve already used root</span><br></pre></td></tr></table></figure>
<p>下面粘一些使用conjure-up过程中的截图：<br><img src="http://img.blog.csdn.net/20171112101736564?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171112101801150?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171112101813090?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://stgraber.org/2016/10/26/lxd-2-0-lxd-and-openstack-1112/" target="_blank" rel="external">https://stgraber.org/2016/10/26/lxd-2-0-lxd-and-openstack-1112/</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/13/使用Juju将OpenStack部署在单机的LXD容器上/" data-id="cjc7ckhyv000abjbpkmw90ore" class="article-share-link">Поделиться</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Архив</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Недавние записи</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/01/09/virtio-vhost中的限速机制/">virtio/vhost中的限速机制</a>
          </li>
        
          <li>
            <a href="/2017/12/22/OpenStack-s-multiattach-Feature/">OpenStack&#39;s multiattach Feature</a>
          </li>
        
          <li>
            <a href="/2017/12/06/如何修改网卡名称由enp0s25为eth0/">如何修改网卡名称由enp0s25为eth0</a>
          </li>
        
          <li>
            <a href="/2017/12/06/三种方式使用vlan/">三种方式使用vlan</a>
          </li>
        
          <li>
            <a href="/2017/12/02/OpenWRT与QNAP上通过PXE安装Xenial/">OpenWRT与QNAP上通过PXE安装Xenial</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 张华<br>
      Создано с помощью <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>