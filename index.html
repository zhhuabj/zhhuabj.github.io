<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>技术并艺术着</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="blog.csdn.net/quqi99">
<meta property="og:type" content="website">
<meta property="og:title" content="技术并艺术着">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="blog.csdn.net/quqi99">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="技术并艺术着">
<meta name="twitter:description" content="blog.csdn.net/quqi99">
  
    <link rel="alternate" href="/atom.xml" title="技术并艺术着" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">技术并艺术着</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">张华的技术博客 - blog.csdn.net/quqi99</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/10/hello-world/" class="article-date">
  <time datetime="2018-09-10T05:57:54.513Z" itemprop="datePublished">2018-09-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/10/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/10/hello-world/" data-id="cjm8trj69000gbobpwesrvymo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Win-10-UEFI-Ubuntu-18-04-UEFI-双系统" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/09/Win-10-UEFI-Ubuntu-18-04-UEFI-双系统/" class="article-date">
  <time datetime="2018-09-08T17:28:15.000Z" itemprop="datePublished">2018-09-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/09/Win-10-UEFI-Ubuntu-18-04-UEFI-双系统/">Win 10 UEFI + Ubuntu 18.04 UEFI 双系统</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本人昨天买了一块SSD, 结果后来发现原来这块SSD存在硬件质量问题, 造成了软件上的种种诡异问题, 如U盘时而识别时而不识别, 如触摸屏左键时而抽风, 如ghost安装win10时几乎到100%的进度时忽然来一个无响应, 重启系统后出现了”To interrupt normal start up, press the blue ThinkVantage button.”, 此时键盘无反应, 既进不了系统, 也进不了BIOS. 拨CMOS电源也无效. 最后发现是这块SSD有质量问题. 估计是SSD有控制器主要是软件吧, 控制器软件有bug导致运行ghost这种软件时也能导致硬件挂住.<br>也正是因为这个问题吧, 七搞八搞, 一不小心在重试的过程中将之前的一块linux分区误删了, 于是之前打算的迁移双系统的想法泡汤(当然, 那些通过分区助手或者ghost来迁移分区的网上文章照着做没一个是成功的).<br>这样, 有机会事隔多年再一次重装双系统的机会, 但是发现世道变了, 之前百试不爽的方法现在行不通了. 后经查证, 主要原因是ubuntu 18.04开始默认采用UEFI, 而win10默认仍然是MBR. 这样会导致一系列的问题, 如报错: grub-efi-amd64-signed failed to install 18.04, 统一采用UEFI安装.</p>
<h2 id="BIOS设置"><a href="#BIOS设置" class="headerlink" title="BIOS设置"></a>BIOS设置</h2><p>在BIOS中将Boot Mode设置为UEFI Only, 如果有Secure Boot选项还要disable它(不做这一步可能会造成按F12键之后无法找到U盘)<br>注: 改成UEFI only之后, 运行双系统, 四系统都没问题, 但后来进不了U盘的livecd, 报: couldn’t get UEFI db list, 所以只得改回Both, 但UEFI优先.</p>
<h2 id="安装win10"><a href="#安装win10" class="headerlink" title="安装win10"></a>安装win10</h2><ul>
<li>下载大白菜UEFI专版 - <a href="http://www.bigbaicai.com/download.html?down2" target="_blank" rel="external">http://www.bigbaicai.com/download.html?down2</a></li>
<li>下载win10 ghost - axel -n 10 <a href="http://xz.win10cjb.com/18.5/win10_64/DEEP_Win10x64_201805.rar" target="_blank" rel="external">http://xz.win10cjb.com/18.5/win10_64/DEEP_Win10x64_201805.rar</a></li>
<li>制作大白菜启动U盘, 如果界面上有UEFI字眼就点上(不记得了, 有就点上), 还要注意一点, 记得点里面的格式转换, 将FAT32格式(HDD-FAT32)转换成NTFS(HDD-NTFS)转换, 否则HDD-FAT32格式不能拷贝大于4G的ghost文件哦,</li>
<li>按F12选U盘启动进入大白菜后, 用DiskGenius工具重新分区, 必须将BIOS+MBR格式转UEFI+GPT格式. 分区表格式为GUID而不是MBR, window上管EFI分区叫ESP/MSR分区</li>
<li><p>注意, 不要修改推荐的卷标, 这个卷就是指向的ESP/MSR分区.</p>
<h2 id="安装win10后"><a href="#安装win10后" class="headerlink" title="安装win10后"></a>安装win10后</h2><p>安装win10后需要将禁用掉快速启动, 否则会造成按F12无法选择U盘启动. 菜单路径为: “设置 -&gt; 系统 -&gt; 电源与睡眠 -&gt; 其他电源设置 -&gt; 选择电源按钮的功能 -&gt; 更改当前不可用的设置 -&gt; 启动快速启动”</p>
<h2 id="安装ubuntu-18-04"><a href="#安装ubuntu-18-04" class="headerlink" title="安装ubuntu 18.04"></a>安装ubuntu 18.04</h2><p>像安装win10一样, 一样要注意重要一点, 需创建大概300M左右的UEF分区, 另外, 还可以创建一个根分区和一个备份文件用的bak分区.<br>注意, windows非常霸道, 它是总修改bios里的启动顺序, 将它的”Windows boot Manager”放在”ubuntu grub”的前面, 可以在bios里锁定启动顺序</p>
<h2 id="安装win7"><a href="#安装win7" class="headerlink" title="安装win7"></a>安装win7</h2><p>win7若没有sata的驱动, 所以得先改回IDE, 装完win7之后再改回AHCI, 否则也容易挂在启动界面不动了.<br>注: 我未遇到以上问题, 可能因为我装的win7并不是原版的, 已经带了sata驱动</p>
<h2 id="加装SSD"><a href="#加装SSD" class="headerlink" title="加装SSD"></a>加装SSD</h2><p>如果加装了SSD之后呢? 那得注意:</p>
</li>
<li><p>装win10时同样需要进大白菜或老毛桃后用DiskGenius在SSD上划分ESP/MSR分区</p>
</li>
<li>装ubuntu时, 分区处也要创建EFI分区, 同时grub设置安装在SSD上, 相当于: grub-install /dev/sdX.</li>
<li>bios里选择哪块硬盘启动. 其实在SSD上安装grub后, 这个grub会连HDD上原先的win10与ubuntu一起放在启动列表里. 注意, windows非常霸道, 它是总修改bios里的启动顺序, 将它的”Windows boot Manager”放在”ubuntu grub”的前面, 可以在bios里锁定启动顺序</li>
<li><p>有时候需要对ssd优化, 例如不要将swap分区放在ssd以延长寿命, 如更改i/o调度策略为noop, 如使用bcache</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>装完之后进入win10发现thinkpad小红点左键失灵, 再切换进ubuntu发现小红点左键正常(实际上, 5次大概有一次有问题, 只是登录界面左键与右键似乎混乱了, 登录之后就正常了. 再换PE进系统发现小红点左键依然有问题. 所以基本断定和硬件没有关系, 应该是win10上的小红点驱动有问题.<br>但搜索了很多帖子, 没一个能解决问题的, 联想的小红点win10驱动做得太烂了. 所以决定回到win7, 回到win7之后该问题解决. 另外, PE回到win7的过程中不会伤害之前SSD上安装的ubuntu系统, 也不会伤害原HDD里的双系统.</p>
<h2 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h2><p>现在在笔记本x220t上装了win10, 也装了ubuntu 18.04, 但是如何将工作机t440p的根分区迁移到x220t的根分区呢? 因为我们已经在x220t上安装了ubuntu 18.04, 这样省去了采用命令划分EFI分区, 以及最后填充EFI分区的步骤. 现在将精力集中在如何快速迁移根分区上.</p>
</li>
<li><p>目的机x220t因为有写操作, 故要以livecd启动, 启动ssh server, 并将根分区加载到/mnt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo -i</span><br><span class="line">apt install openssh-server</span><br><span class="line">passwd</span><br><span class="line">echo &apos;PermitRootLogin yes&apos; &gt;&gt; /etc/ssh/sshd_config</span><br><span class="line">service ssh restart</span><br><span class="line">fdisk -l</span><br><span class="line">mount /dev/sdb8 /mnt</span><br></pre></td></tr></table></figure>
</li>
<li><p>源机t440p最好也以livecd启动, 注意: 例如源机上有一个软链指向了/bak分区, 但因为此时没有挂载/bak分区, 所以在rsync命令迁移时会报错退出. 人工删除该软链重新运行即可.  且需要注意 rsync命令中的/mnt/后应该有/, 否则会将mnt目录迁移到根分区的mnt目录下.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo -i</span><br><span class="line">fdisk -l</span><br><span class="line">mount /dev/sda9 /mnt</span><br><span class="line"></span><br><span class="line"># rsync will now copy all files, directories, permissions and owners over to the destination machine.</span><br><span class="line"># It also skips all files and directories that are not on the root filesystem, like /dev/, /sys/, /proc/.</span><br><span class="line"># If there are filesystems that are mounted separately on the source machine and your want those copied too, use rsync again on those mountpoints too.</span><br><span class="line">rsync -xavP --numeric-ids --exclude=&apos;tmp&apos; /mnt root@192.168.99.128:/</span><br><span class="line">#rsync -xavP --numeric-ids --exclude=&apos;tmp&apos; --exclude=&apos;/nas&apos; /mnt/ root@192.168.99.128:/mnt/</span><br></pre></td></tr></table></figure>
</li>
<li><p>更新grub, 此时会报”canot find EFI directory”, 这样会导致这时生成grub时无法找到原HDD中的双系统, 不要紧, 只要找到目前SSD中的双系统即可. 呆会下一步再运行一下grub命令即可解决</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/sdb8 /mnts</span><br><span class="line">for d in dev sys proc; do mount --bind /$d /mnt/$d; done</span><br><span class="line">chroot /mnt/ grub-install /dev/sdb   # canot find EFI directory</span><br><span class="line">chroot /mnt/ update-grub</span><br></pre></td></tr></table></figure>
</li>
<li><p>修复fstab, 之前运行上述迁移命令前忘了备份x220t上的fstab系统, 导致它被覆盖, OK, 我们修复它.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">blkid</span><br><span class="line">e2label /dev/sdb8 &quot;ROOT_SSD&quot;</span><br><span class="line">tee &quot;/mnt/etc/fstab&quot; &lt;&lt;EOF</span><br><span class="line">#UUID can be found via blkid command</span><br><span class="line">#LABEL=boot /boot ext2 sync 0 2</span><br><span class="line">#UUID=735b3be3-779c-4d21-a944-b033225f3ab4 none   swap    sw      0       0</span><br><span class="line">#LABEL=SWAP none swap sw 0 0</span><br><span class="line">UUID=9401-D2EA /boot/efi vfat defaults 0 2</span><br><span class="line">LABEL=ROOT_SSD / ext4 errors=remount-ro 0 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
<li><p>这时重启系统, 就可以以grub选择启动SSD上的双系统了, 如果还想把HDD的原有的双系统也加到grub的话, 那进ubuntu系统后再执行一次update-grub命令即可.</p>
</li>
<li>这种迁移方式效果非常好, 各种工作软件不需要再重装了. 呵呵<h2 id="调整分区"><a href="#调整分区" class="headerlink" title="调整分区"></a>调整分区</h2>一个分区不够用时, 可以使用gpartd合并相邻的空闲分区.注意一点, 要合并的分区必须是umount状态时才能合并.<h2 id="SSD优化"><a href="#SSD优化" class="headerlink" title="SSD优化"></a>SSD优化</h2></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"># disable scanning for btrfs filesystems when boot</span><br><span class="line">sudo apt-get purge btrfs-tools</span><br><span class="line">sudo update-initramfs -ukall</span><br><span class="line"></span><br><span class="line"># enable TRIM feature by adding discard option</span><br><span class="line"># what&apos;s TRIM - https://blog.csdn.net/quqi99/article/details/50963308</span><br><span class="line"># the option noatime is used to disable access time for a file</span><br><span class="line">sudo hdparm -I /dev/sdb |grep TRIM</span><br><span class="line">vi /etc/fstab</span><br><span class="line">LABEL=ROOT_SSD /               ext4    noatime,discard,errors=remount-ro 0       1</span><br><span class="line">sudo mount -o remount /dev/sdb8</span><br><span class="line">sudo mount |grep sdb8 |grep discard</span><br><span class="line"></span><br><span class="line"># Try not to use swap space unless it&apos;s running out of memory.</span><br><span class="line">echo 1 &gt; /proc/sys/vm/swappiness</span><br><span class="line"></span><br><span class="line"># avoid visiting ssd by using ramdisk for /tmp instead of tmpfs</span><br><span class="line">vim /etc/fstab</span><br><span class="line">tmpfs /tmp tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">tmpfs /var/tmp tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">tmpfs /var/log tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">sudo mount -o remount /</span><br><span class="line"></span><br><span class="line"># Set chrome to use ramdisk cache</span><br><span class="line">cd ~/.cache/google-chrome/Default</span><br><span class="line">rm -rf Cache</span><br><span class="line">sudo ln -s /tmp Cache</span><br><span class="line">rm -rf Media\ Cache/</span><br><span class="line">sudo ln -s /tmp Media\ Cache</span><br><span class="line"></span><br><span class="line"># Use noop for I/O elevator</span><br><span class="line">cat /sys/block/sda/queue/scheduler</span><br><span class="line">sudo vi /etc/default/grub</span><br><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=&quot;elevator=noop&quot;</span><br><span class="line">sudo update-grub</span><br><span class="line"></span><br><span class="line"># Test SSD speed</span><br><span class="line">$ sudo hdparm -Tt /dev/sdb</span><br><span class="line">/dev/sdb:</span><br><span class="line"> Timing cached reads:   9128 MB in  2.00 seconds = 4569.28 MB/sec</span><br><span class="line"> Timing buffered disk reads: 818 MB in  3.01 seconds = 272.07 MB/sec</span><br><span class="line"></span><br><span class="line"># Make sure 4K align</span><br><span class="line">$ sudo fdisk -lu |grep sdb |grep sectors</span><br><span class="line">Disk /dev/sdb: 232.9 GiB, 250059350016 bytes, 488397168 sectors</span><br><span class="line"></span><br><span class="line"># Health check</span><br><span class="line">$ sudo smartctl -s on -a /dev/sdb |grep PASSED</span><br><span class="line">SMART overall-health self-assessment test result: PASSED</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/09/Win-10-UEFI-Ubuntu-18-04-UEFI-双系统/" data-id="cjm8trj67000ebobp6upo070q" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-也谈wifi断流问题" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/03/也谈wifi断流问题/" class="article-date">
  <time datetime="2018-09-03T04:02:42.000Z" itemprop="datePublished">2018-09-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/03/也谈wifi断流问题/">也谈wifi断流问题</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-09-03)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>笔者最近应该是遇到了常听大家说起的wifi断流问题, 新入一款安卓原生系统手机, 但是在使用wifi上网时会感觉到某些APP上网不流畅, 尤其是使用京东APP搜索商品时会总说找不着网络, 但此时显然是有网络的. 为此, 笔者先做了一系统排除性实验:</p>
<ul>
<li>排除法测试, 使用京东APP搜索商品时说找不着网络, 但使用京东APP的其他功能没有问题, 并且使用京东以外的其他APP也没问题</li>
<li>排除法测试, 切换为4G网络使用京东APP搜索商品正常, 仅仅只是使用WIFI网络时才会出问题.</li>
<li>排除法测试, 去麦当劳使用WIFI确认无问题, 但速度也不快, 但能打开页面.</li>
<li>排除法测试, 难道是家里的WIFI有问题吗? 但换个手机型号使用京东APP搜索商品却又正常.</li>
<li>排除法测试, 难道是VPN的问题? 关掉VPN, 恢复DNS国内设置依然有问题. </li>
<li>排除法测试, 继续换一个没有VPN的干净的OpenWRT路由器依然有问题, 可惜家里没有Non-OpenWRT路由器可供测试.</li>
<li>排除法测试, 路由器上修改802.11g, 802.11n, 802.11ac等设置后问题依旧.</li>
<li>排除法测试, 检查了路由器上的MAC地址是否与其他机器重复, 未发现异常</li>
<li>排除法测试, 使用114.114.114.114作为DNS, 问题依旧</li>
<li>排除法测试, OpenWRT路由器使用tcpdump抓包, 干扰条目过多, 未深入</li>
<li>排除法测试, 现在问题看起来只是发生在这款特定手机型号与特定的OpenWRT路由器与特定的某些APP如京东, 手机刷机到android 8.1与7.1两个版本问题依旧.</li>
<li>排除法测试, google搜索大量京东或别的某些应用在各种手机型号上出问题的帖子, 试着更改帖子中的各种切换手机配置的操作, 如不对京东使用电源优化,问题依旧.</li>
<li>排除法测试, 绝大多数时候打不开京东的这个搜索商品的功能, 但极少数情况又能打开, 但非常慢, 使用别家的wifi网络时也是非常慢, 很难说清楚现象.<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2>上述一系列排除性测试让我相信该问题仅和我使用特定的手机型号, 使用特定的OpenWRT路由器, 使用特定的某些APP如京东有关.<br>京东APP, 一个上层应用而已, 理论上只有下列几个因素会影响到上层应用:</li>
<li>DNS</li>
<li>IPv6/IPv4 fallback</li>
<li>MTU<br>理论让我将目光回到MTU, 修改OpenWRT路由器WAN口的MTU=1492后问题依旧.继续深挖:</li>
<li>路由器背后的手机操作系统应该有/proc/sys/net/ipv4/ip_no_pmtu_disc=0让手机可以根据pmtu来确实应用所需的mss值. 遗憾地是, 手机没有root, 无法检查此项值.</li>
<li>OpenWRT路由器tcpdump抓包, 看到的mss值确实不小. 既然无root权限无法修改手机的ip_no_pmtu_disc参数, 那有没有方法直接修改OpenWRT路由器强迫修改mss值呢?<br>OK, 在路由器上添加如下两个命令, 问题就这么解决了:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#iptables -A FORWARD -j ACCEPT</span><br><span class="line">iptables -t mangle -A FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# iptables-save |grep mss</span><br><span class="line">:mssfix - [0:0]</span><br><span class="line">-A FORWARD -j mssfix</span><br><span class="line">-A FORWARD -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">-A mssfix -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -m comment --comment &quot;wan (mtu_fix)&quot; -j TCPMSS --clamp-mss-to-pmtu</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这款手机的操作系统没有设置ip_no_pmtu_disc参数去协商mss值, 而OpenWRT路由器刚好缺一条iptables rule (iptables -t mangle -A FORWARD -p tcp –tcp-flags SYN,RST SYN -j TCPMSS –clamp-mss-to-pmtu), 这样遭遇了pppoe的1492 MTU问题.<br>换句话说, 当我外出时, 如果所连的路由器没有加这条设置, 那么这个问题仍然又遇到. 手机操作系统ip_no_pmtu_disc设置才能彻底解决某些应用wifi网络不能上网的问题. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/03/也谈wifi断流问题/" data-id="cjm8trj6b000jbobpsxozwph8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-IPv6来啦" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/03/IPv6来啦/" class="article-date">
  <time datetime="2018-08-03T08:01:05.000Z" itemprop="datePublished">2018-08-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/03/IPv6来啦/">IPv6来啦</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-08-03)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>家里用的是中国移动的宽带, 一直挺稳定的, 而且昨天发现ISP下发了IPv6地址(不是子网, 形如: 2409:8a00:7805:xxxx:xxxx:xxxx:xxxx:xxxx/64, 打xxxx的部分是动态变化的). 好吧, 咱就用用.</p>
<h2 id="路由器配置"><a href="#路由器配置" class="headerlink" title="路由器配置"></a>路由器配置</h2><ul>
<li><p>配置/etc/config/network使用’option ip6assign ‘64’</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config interface &apos;lan&apos;</span><br><span class="line">        ...</span><br><span class="line">        option ip6assign &apos;64&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置/etc/confignetwork删除config globals ‘globals’段中和 IPv6 ULA-Prefix相关的配置 (注: 使用IPv6 ULA-Prefix的话, LAN中机器就会得到一个以它打头的IPv6地址, 但如何从外网访问这个地址呢? 有三种方式: 一是使用我们现在使用的relay方式得到是ISP提供的全球可路由的IPv6地址；二是配置ULA-Prefix=2409:8a00:7805:1::/80之后再使用下列的neigh proxy的方法解决, 但这种一般是子网长度80比64大, 但ISP并没有给我们分配subnet, 只是分配了IPv6地址, 所以无法保证2409:8a00:7805:1::/80这个前缀与ISP分配的2409:8a00:7805:xxxx:xxxx:xxxx:xxxx:xxxx/64一致；三是ULA-Prefix配置一个与ISP分配的不同的路由然后通过配置路由的方式但前提是也得有全球可路由的IPv6 subnet啊. 所以这里我们选择了relay模式来实现外网访问内网的目的.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv6.conf.all.proxy_ndp=1</span><br><span class="line">ip -6 neigh add proxy 2409:8a00:7805:1::430 dev pppoe-wan</span><br><span class="line">ip -6 neigh show proxy</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置/etc/config/dhcp使用relay模式, relay模式意味着openwrt通过默认的odhcpd作为中继自动为LAN的其他机器配置ISP的IPv6地址</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">config dhcp &apos;wan&apos;</span><br><span class="line">        option interface &apos;wan&apos;</span><br><span class="line">        option ignore &apos;1&apos;</span><br><span class="line">        option dhcpv6 &apos;disabled&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br><span class="line">        option master &apos;1&apos;</span><br><span class="line">config dhcp &apos;lan&apos;</span><br><span class="line">        option interface &apos;lan&apos;</span><br><span class="line">        option start &apos;100&apos;</span><br><span class="line">        option limit &apos;150&apos;</span><br><span class="line">        option leasetime &apos;12h&apos;</span><br><span class="line">        list dhcp_option &apos;6,192.168.99.1&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br><span class="line">        option dhcpv6 &apos;relay&apos;</span><br><span class="line"></span><br><span class="line"># actually I use 60, not 64</span><br><span class="line">cat /etc/config/network</span><br><span class="line">config interface &apos;lan&apos;</span><br><span class="line">	...</span><br><span class="line">	option ip6assign &apos;60&apos;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>配置完之后就可以通过下列命令重启路由器服务就可以在br-lan与pppoe-wan上获得ISP分配的IPv6地址了.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/network restart</span><br><span class="line">/etc/init.d/odhcpd restart</span><br></pre></td></tr></table></figure></p>
<p>内网机器直接通过’sudo /etc/init.d/network-manager restart’重启网络也会获取ISP分配的IPv6地址.</p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><ul>
<li>内网机器访问br-lan内网网关, 能通是因为下列路由的功能:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hua@t440p:~$ ip -6 route list |grep 2409:8a00:7805:b7df::/64</span><br><span class="line">2409:8a00:7805:b7df::/64 dev eth0  proto ra  metric 100  pref medium</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# route -A inet6 |grep ::/0</span><br><span class="line">::/0                                        fe80::200:5eff:fe00:134                 UG    1024   0        0</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>注: 后面我们会看到::/0的默认路由会造成很多问题.</p>
<ul>
<li><p>内网机器访问pppoe-wan外网网关<br>对于relay模式由于内网机器拿到的本来就是ISP分配的可路由的IP所以自然能通. 但对于nat模式由于内网机器分配的是和ISP不同网段的IP, 所以需要在路由器上做NAT6, 如:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#ip6tables -t nat -I POSTROUTING -o pppoe-wan -j MASQUERADE</span><br><span class="line">ip6tables -t nat -I POSTROUTING -s `uci get network.globals.ula_prefix` -j MASQUERADE &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
</li>
<li><p>外网访问内网机器<br>如果使用relay由于内网机器使用的是全球可路由的IPv6地址, 外网直接就是可以访问内网机器的；但如果是不同子网需要做路由；如果只是前缀相同只是子网长度不同可以做neigh proxy</p>
</li>
<li>但是此时我们发现内网机器无法访问外网(如ping6 ipv6.baidu.com), 但此时在路由器上却是可以访问外网的. 原因就在于上面使用::/0的默认路由似乎有问题(报这个错: Destination unreachable: Unknown code 5), 改成了2000::/3就好了:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route -A inet6 add 2000::/3 `route -A inet6 | grep ::/0 | awk &apos;NR==1&#123;print&quot;gw &quot;$2&quot; dev &quot;$7&#125;&apos;`</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>或者:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip -6 route add default from 2409:8a00:7805::48 dev pppoe-wan</span><br></pre></td></tr></table></figure></p>
<p>但上面两种方法仍然遇到了不稳定的问题, 感觉是openwrt的odhcpd不稳定, 照下列方法更换为6relayd之后仍然不好使.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">wget https://www.shintaku.cc/files/6relayd_2013-10-21_ar71xx.ipk</span><br><span class="line">opkg install 6relayd_2013-10-21_ar71xx.ipk</span><br><span class="line">vi /etc/config/6relayd</span><br><span class="line">config relay</span><br><span class="line">        option master &apos;wan&apos;</span><br><span class="line">        option network &apos;lan&apos;</span><br><span class="line">        option rd &apos;relay&apos;</span><br><span class="line">        option dhcpv6 &apos;relay&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">/etc/init.d/odhcpd disable</span><br><span class="line">/etc/init.d/odhcpd stop</span><br><span class="line">/etc/init.d/6relayd enable</span><br><span class="line">/etc/init.d/6relayd start</span><br></pre></td></tr></table></figure></p>
<p>接着使用tcpdump查看好像是DHCPv6 reply包从pppoe-wan过不来br-lan口:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">08:22:53.810272 IP6 2400:da00:2::29 &gt; 2409:8a00:7805:b7df:8d79:6c9:315a:9ca3: ICMP6, echo reply, seq 7, length 64</span><br></pre></td></tr></table></figure></p>
<p>所以接着, 在/etc/config/firewall文件的 Allow-ICMPv6-Forward项中添加了下列行后确认已经有了129(129就是reply)相关的iptables rules之后仍然不好使.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">        list icmp_type &apos;router-solicitation&apos;</span><br><span class="line">        list icmp_type &apos;neighbour-solicitation&apos;</span><br><span class="line">        list icmp_type &apos;router-advertisement&apos;</span><br><span class="line">        list icmp_type &apos;neighbour-advertisement&apos;</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# ip6tables-save |grep Allow-ICMPv6-Forward |grep 129</span><br><span class="line">-A zone_wan_forward -p ipv6-icmp -m icmp6 --icmpv6-type 129 -m limit --limit 1000/sec -m comment --comment Allow-ICMPv6-Forward -j ACCEPT</span><br></pre></td></tr></table></figure></p>
<p>google查到的和这个bug相同(<a href="https://github.com/openwrt/odhcpd/issues/37" target="_blank" rel="external">https://github.com/openwrt/odhcpd/issues/37</a>), 但里面的所有方法都试过了不成功.<br>似乎是ISP使用的是Statefull DHCPV6的方式, 6relayd可以把ra信息relay过来，但LAN端机器似乎无法跟DHCPV6服务器通信。</p>
<h2 id="2018-0805更新"><a href="#2018-0805更新" class="headerlink" title="2018-0805更新"></a>2018-0805更新</h2><p>今天通过这个帖子(<a href="https://bbs.pku.edu.cn/v2/post-read.php?bid=35&amp;threadid=15501646)解决了上面的问题" target="_blank" rel="external">https://bbs.pku.edu.cn/v2/post-read.php?bid=35&amp;threadid=15501646)解决了上面的问题</a>:<br>OpenWRT默认是在wan口使用DHCPv6 Client, 在LAN口使用odhcpd开启RA和DHCPv6. 这个默认配置适用于国外主流ISP, 因为他们DHCPv6-PD (prefix delegation)把一个至少/64地址段分配给客户使用(还有的使用小于64的地址段给客户分配静态IP).<br>不过中国移动给客户分配的是SLAAC地址, 没有使用DHCPv6, 也就没使用DHCPv6-PD, 这样拿不到前缀(ISP分配的2409:8a00:7805:xxx::/64地址的第4段总是变化的), 所以odhcpd也就无法根据这个前缀设置路由, 所以我们需要手工设置确保可以在OpenWrt上ping通内网机器, 这样才能保证reply消息到达br-lan之后能到达内网机器, 如:<br>route -A inet6 add 2409:8a00:7805:d9b1::/64 dev br-lan<br>所以最终添加在/etc/firewall.user的内容如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># make ipv6 relay to work</span><br><span class="line">PREFIX=`route -A inet6 |grep lo |grep 2409:8a00:7805 |grep ::/128 |awk -F &apos;::/&apos; &apos;&#123;print $1&quot;::/64&quot;&#125;&apos; |uniq`</span><br><span class="line">ip -6 route del $PREFIX dev br-lan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">route -A inet6 add $PREFIX dev br-lan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line"># make ipv6 nat to work</span><br><span class="line">#ip -6 route add default from $PREFIX dev pppoe-wan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">#route -A inet6 add 2000::/3 `route -A inet6 | grep ::/0 | awk &apos;NR==1&#123;print&quot;gw &quot;$2&quot; dev &quot;$7&#125;&apos;` &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure></p>
<p>再就是得配置replay消息能从pppoe-wan到达br-lan, 所以最终使用下列配置(也记得去掉IPv6 ULA-Prefix):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">config dhcp &apos;wan&apos;</span><br><span class="line">        option interface &apos;wan&apos;</span><br><span class="line">        option ignore &apos;1&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br><span class="line">        option master &apos;1&apos;</span><br><span class="line">config dhcp &apos;lan&apos;</span><br><span class="line">        option interface &apos;lan&apos;</span><br><span class="line">        option start &apos;100&apos;</span><br><span class="line">        option limit &apos;150&apos;</span><br><span class="line">        option leasetime &apos;12h&apos;</span><br><span class="line">        list dhcp_option &apos;6,192.168.99.1&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br></pre></td></tr></table></figure></p>
<p>可新问题又来了, 这条路由总是过期, 如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2409:8a00:7805:da41::/64 dev br-lan  proto kernel  metric 256  expires 259019sec</span><br></pre></td></tr></table></figure></p>
<p>重新执行一下上面的命令又能恢复, 太不稳定了, 还是转回ipv6 NAT模式吧.</p>
<h2 id="20180902更新"><a href="#20180902更新" class="headerlink" title="20180902更新"></a>20180902更新</h2><p>上述静态路由过期的问题原因找到, 原因是需要添加metric</p>
<ul>
<li>route -A inet6 add 2409:8a00:7805:d9b1::/64 dev br-lan               # 会有过期时间</li>
<li>route -A inet6 add 2409:8a00:7805:d9b1::/64 dev br-lan metric 1 # 无过期时间<br>或者使用ip命令它添加的无过期时间 - ip -6 route del 2409:8a00:7805:d9b1::/64 dev br-lan</li>
</ul>
<h2 id="转试NAT6"><a href="#转试NAT6" class="headerlink" title="转试NAT6"></a>转试NAT6</h2><p>上面使用replay时的bug解不了, 无奈之下, 只好使用NAT6, 外面访问不了内网就访问不了吧, 起码可以内网访问外网啊.</p>
<ul>
<li><p>在/etc/config/network中配置了ula_prefix=2001:192:168:99::/64, 这时路由器上的br-lan除了ISP分配的IP之外, 也会多时我们这个自己配置的地址: 2001:192:168:99:0:0:0:1/64</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">config globals &apos;globals&apos;</span><br><span class="line">        option ula_prefix &apos;2001:192:168:99::/64&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改/etc/config/dhcp将relay模式改到server模式即NAT模式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">config dhcp &apos;lan&apos;</span><br><span class="line">        option interface &apos;lan&apos;</span><br><span class="line">        option start &apos;100&apos;</span><br><span class="line">        option limit &apos;150&apos;</span><br><span class="line">        option leasetime &apos;12h&apos;</span><br><span class="line">        list dhcp_option &apos;6,192.168.99.1&apos;</span><br><span class="line">        option dhcpv6 &apos;server&apos;</span><br><span class="line">        option ra_management &apos;2&apos;</span><br><span class="line">        option ra &apos;server&apos;</span><br><span class="line">        option ra_default &apos;1&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在/etc/firewall.user中添加下列SNAT规则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip6tables -t nat -I POSTROUTING -s `uci get network.globals.ula_prefix` -j MASQUERADE &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">route -A inet6 add 2000::/3 `route -A inet6 | grep ::/0 | awk &apos;NR==1&#123;print&quot;gw &quot;$2&quot; dev &quot;$7&#125;&apos;` &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>之后, 内网机器随便手动配置一个IP如2001:192:168:99:0:0:0:3/64并添加默认路由之后就可以访问外网了.<br>如果想外网访问2001:192:168:99::3/64, 是不能够使用下面的neigh proxy方式的, 因为网段和ISP分配的可路由网段根据就不一样嘛. 唯一的办法其实就是做DNAT<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv6.conf.all.proxy_ndp=1</span><br><span class="line">ip -6 neigh add proxy 2001:192:168:99:0:0:0:3 dev pppoe-wan</span><br><span class="line">ip -6 neigh show proxy</span><br></pre></td></tr></table></figure></p>
<h2 id="VPS不支持IPv6时如何使用IPv6"><a href="#VPS不支持IPv6时如何使用IPv6" class="headerlink" title="VPS不支持IPv6时如何使用IPv6"></a>VPS不支持IPv6时如何使用IPv6</h2><p>VPS若不支持IPv6, 可以通过tunnelbroker来配置6in4隧道支持IPv6, 但前提是VPS要能支持配置允许proto-41流量通过 (iptables -A INPUT -p 41 -j ACCEPT), 目前google cloud VPS是无法配置这个的.<br>若您的VPS支持这个, 可以继续. 先在<a href="https://www.tunnelbroker.net/" target="_blank" rel="external">https://www.tunnelbroker.net/</a> 登录后在’User Functions -&gt; Create Regular Tunnel’菜单创建 Create Regular Tunnel, 然后:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt; EOF | sudo tee -a /etc/network/interfaces</span><br><span class="line">auto he-ipv6</span><br><span class="line">iface he-ipv6 inet6 v4tunnel</span><br><span class="line">        address 2001:470:a:xx::2</span><br><span class="line">        netmask 64</span><br><span class="line">        endpoint 216.218.226.xx</span><br><span class="line">        local 162.xx.xx.xx</span><br><span class="line">        ttl 255</span><br><span class="line">        gateway 2001:470:a:4c4::1</span><br><span class="line">EOF</span><br><span class="line">cat &lt;&lt; EOF | sudo tee -a /etc/sysctl.conf</span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 0</span><br><span class="line">EOF</span><br><span class="line">sudo sysctl -p</span><br><span class="line">sudo apt install -y ifupdown</span><br><span class="line">sudo ifup he-ipv6</span><br><span class="line"># can&apos;t do tunnelbroker as 6in4 is unsupported (NAT/gateways won&apos;t pass proto-41)</span><br><span class="line">#sudo iptables -t nat -A PREROUTING -p 41 -d &lt;VPS-IP&gt; -j DNAT --to-destination &lt;tunnelbroker-ip&gt;</span><br><span class="line">#sudo iptables -t nat -A POSTROUTING -p 41 -d &lt;tunnelbroker-ip&gt; -j SNAT --to-source &lt;VPS-IP&gt;</span><br><span class="line">#sudo iptables -A INPUT -p 41 -j ACCEPT</span><br></pre></td></tr></table></figure>
<p>使用tunnelbroker需要VPS有公网IPv4地址, 若没有, 可以使用miredo(sudo apt-get install miredo), 但前提也是要防火墙允许proto-41的流量</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/03/IPv6来啦/" data-id="cjm8trj5u0002bobpyi8uptim" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Using-kubeadm-to-deploy-k8s" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/13/Using-kubeadm-to-deploy-k8s/" class="article-date">
  <time datetime="2018-07-13T07:30:57.000Z" itemprop="datePublished">2018-07-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/13/Using-kubeadm-to-deploy-k8s/">Using kubeadm to deploy k8s</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-07-13)</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;deb http://apt.kubernetes.io/ kubernetes-xenial main&quot; |sudo tee /etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 6A030B21BA07F4FB</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install docker.io kubelet kubeadm kubectl kubernetes-cni</span><br><span class="line"></span><br><span class="line">sudo usermod -aG docker `whoami`</span><br><span class="line">sudo systemctl enable docker.service</span><br><span class="line">sudo systemctl enable kubelet.service</span><br><span class="line">echo &apos;KUBELET_EXTRA_ARGS=--fail-swap-on=false&apos; |sudo tee /etc/default/kubelet</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">#sudo swapoff -a</span><br><span class="line"></span><br><span class="line">#before this step, kubelet can&apos;t be up because no file /var/lib/kubelet/config.yaml</span><br><span class="line">sudo kubeadm reset</span><br><span class="line">sudo kubeadm init --pod-network-cidr 10.244.0.0/16 --ignore-preflight-errors=swap --kubernetes-version=v1.11.0</span><br><span class="line">sudo systemctl status kubelet</span><br><span class="line"></span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">#https://docs.projectcalico.org/v3.1/getting-started/kubernetes/</span><br><span class="line">wget https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/kubeadm/1.7/calico.yaml</span><br><span class="line">sed -i &apos;s/192.168.0.0/10.244.0.0/g&apos; ./calico.yaml</span><br><span class="line">kubectl apply -f ./calico.yaml</span><br><span class="line"></span><br><span class="line">kubectl get nodes</span><br><span class="line">kubectl get pods --all-namespaces</span><br><span class="line">kubectl get services --all-namespaces</span><br><span class="line">kubectl cluster-info</span><br><span class="line"></span><br><span class="line">#test</span><br><span class="line">kubectl run nginx --image=nginx</span><br><span class="line">kubectl expose deployment nginx --port=80 --target-port=80 --name=nginx-svc</span><br><span class="line"></span><br><span class="line">git clone https://github.com/kubernetes/kubernetes.github.io</span><br><span class="line">kubectl create -f ./content/en/examples/application/guestbook/</span><br><span class="line">#kubectl delete -f ./content/en/examples/application/guestbook/</span><br><span class="line"></span><br><span class="line">#scale test</span><br><span class="line">kubectl scale rc frontend --replicas=4</span><br><span class="line">kubectl get pods --all-namespaces</span><br><span class="line"></span><br><span class="line">#rolling-update for ReplicationController and apply for Deployment</span><br><span class="line">#kubectl rolling-update frontend --update-period=10s -f ./deploymentv2</span><br><span class="line">#kubectl rolling-update frontend --rollback</span><br><span class="line">kubectl get deployment frontend</span><br><span class="line">kubectl rollout history deployment/frontend</span><br><span class="line">kubectl rollout undo deployment/frontend</span><br><span class="line"></span><br><span class="line">#the single task</span><br><span class="line">$ cat pi.yaml</span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: pi</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: pi</span><br><span class="line">    spec:</span><br><span class="line">      restartPolicy: Never</span><br><span class="line">      containers:</span><br><span class="line">      - name: pi</span><br><span class="line">        image: perl</span><br><span class="line">        command: [&quot;perl&quot;, &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;]</span><br><span class="line">$ kubectl get job</span><br><span class="line">NAME      DESIRED   SUCCESSFUL   AGE</span><br><span class="line">pi        1         1            2m</span><br><span class="line">$ kubectl get pod |grep pi-</span><br><span class="line">pi-mqjz8                                           0/1       Completed     0          2m</span><br><span class="line">$ kubectl logs pi-mqjz8</span><br><span class="line">3.1415926...</span><br><span class="line"></span><br><span class="line">#the cron task</span><br><span class="line">$ cat cron-pi.yaml</span><br><span class="line">apiVersion: batch/v1beta1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: pi</span><br><span class="line">spec:</span><br><span class="line">  schedule: &quot;*/1 * * * *&quot;</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        metadata:</span><br><span class="line">          name: pi</span><br><span class="line">        spec:</span><br><span class="line">          restartPolicy: OnFailure</span><br><span class="line">          containers:</span><br><span class="line">          - name: pi</span><br><span class="line">            image: perl</span><br><span class="line">            command: [&quot;perl&quot;, &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;]</span><br><span class="line">$ kubectl get cronjob pi</span><br><span class="line">NAME      SCHEDULE      SUSPEND   ACTIVE    LAST SCHEDULE   AGE</span><br><span class="line">pi        */1 * * * *   False     0         &lt;none&gt;          28s</span><br><span class="line"></span><br><span class="line">#daemonSet</span><br><span class="line">$ kubectl get daemonset</span><br><span class="line">NAME                                         DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR                        AGE</span><br><span class="line">nginx-ingress-kubernetes-worker-controller   3         3         0         3            0           juju-application=kubernetes-worker   7d</span><br><span class="line"></span><br><span class="line">#storage</span><br><span class="line">$ cat hostpath.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pd</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: busybox</span><br><span class="line">    name: test-container</span><br><span class="line">    command:</span><br><span class="line">    - sleep</span><br><span class="line">    - &quot;3600&quot;</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test-pd</span><br><span class="line">      name: test-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    hostPath:</span><br><span class="line">      # directory location on host</span><br><span class="line">      path: /tmp</span><br><span class="line">      # this field is optional</span><br><span class="line">      type: Directory</span><br><span class="line">kubectl create -f hostpath.yaml</span><br><span class="line">kubectl exec -it test-pd -- /bin/sh</span><br><span class="line">kubectl exec test-pd -- ls /test-pd</span><br><span class="line"></span><br><span class="line">#secret</span><br><span class="line">$ cat secret.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: pass</span><br><span class="line">type: Opaque</span><br><span class="line">data:</span><br><span class="line">  pass: cGFzc3dvcmQ=</span><br><span class="line">$ cat secret-pd.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: secret-pd</span><br><span class="line">spec:</span><br><span class="line">  restartPolicy: Never</span><br><span class="line">  containers:</span><br><span class="line">  - image: busybox</span><br><span class="line">    name: secret-container</span><br><span class="line">    command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot; ]</span><br><span class="line">    env:</span><br><span class="line">      - name: DB_PASS</span><br><span class="line">        valueFrom:</span><br><span class="line">          secretKeyRef:</span><br><span class="line">            name: pass</span><br><span class="line">            key: pass</span><br><span class="line">$ kubectl logs secret-pd |grep DB_PASS</span><br><span class="line">DB_PASS=password</span><br><span class="line"></span><br><span class="line">#ingress</span><br><span class="line">$ kubectl get pods --all-namespaces |grep ingress</span><br><span class="line">default       nginx-ingress-kubernetes-worker-controller-2fkdr   1/1       Running     0          23h</span><br><span class="line">default       nginx-ingress-kubernetes-worker-controller-2khgp   1/1       Running     0          23h</span><br><span class="line">default       nginx-ingress-kubernetes-worker-controller-4c7kr   1/1       Running     0          23h</span><br><span class="line">kubectl run echoheaders --image=gcr.io/google_containers/echoserver:1.4 --replicas=1 --port=8080</span><br><span class="line">ubuntu@zhhuabj-bastion:~/work/k8s$ kubectl expose deployment echoheaders --port=80 --target-port=8080 --name=echoheaders</span><br><span class="line">$ cat ingress.yaml</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: echomap</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: foo.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /foo</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: echheaders</span><br><span class="line">          servicePort: 80</span><br><span class="line">kubectl exec -it nginx-ingress-kubernetes-worker-controller-2fkdr -- cat /etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">$ sudo kubeadm init --pod-network-cidr 10.244.0.0/16 --ignore-preflight-errors=swap --kubernetes-version=v1.11.0</span><br><span class="line">I0713 06:47:50.169410     362 feature_gate.go:230] feature gates: &amp;&#123;map[]&#125;</span><br><span class="line">[init] using Kubernetes version: v1.11.0</span><br><span class="line">[preflight] running pre-flight checks</span><br><span class="line">	[WARNING Swap]: running with swap on is not supported. Please disable swap</span><br><span class="line">I0713 06:47:50.213902     362 kernel_validator.go:81] Validating kernel version</span><br><span class="line">I0713 06:47:50.213996     362 kernel_validator.go:96] Validating kernel config</span><br><span class="line">	[WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 17.12.1-ce. Max validated version: 17.03</span><br><span class="line">[preflight/images] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight/images] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[preflight] Activating the kubelet service</span><br><span class="line">[certificates] Generated ca certificate and key.</span><br><span class="line">[certificates] Generated apiserver certificate and key.</span><br><span class="line">[certificates] apiserver serving cert is signed for DNS names [voltorb kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.230.56.118]</span><br><span class="line">[certificates] Generated apiserver-kubelet-client certificate and key.</span><br><span class="line">[certificates] Generated sa key and public key.</span><br><span class="line">[certificates] Generated front-proxy-ca certificate and key.</span><br><span class="line">[certificates] Generated front-proxy-client certificate and key.</span><br><span class="line">[certificates] Generated etcd/ca certificate and key.</span><br><span class="line">[certificates] Generated etcd/server certificate and key.</span><br><span class="line">[certificates] etcd/server serving cert is signed for DNS names [voltorb localhost] and IPs [127.0.0.1 ::1]</span><br><span class="line">[certificates] Generated etcd/peer certificate and key.</span><br><span class="line">[certificates] etcd/peer serving cert is signed for DNS names [voltorb localhost] and IPs [10.230.56.118 127.0.0.1 ::1]</span><br><span class="line">[certificates] Generated etcd/healthcheck-client certificate and key.</span><br><span class="line">[certificates] Generated apiserver-etcd-client certificate and key.</span><br><span class="line">[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;</span><br><span class="line">[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;</span><br><span class="line">[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[init] this might take a minute or longer if the control plane images have to be pulled</span><br><span class="line">[apiclient] All control plane components are healthy after 89.502565 seconds</span><br><span class="line">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.11&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[markmaster] Marking the node voltorb as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[markmaster] Marking the node voltorb as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;voltorb&quot; as an annotation</span><br><span class="line">[bootstraptoken] using token: 1yz24f.1hv4qn59rjxgj7cb</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of machines by running the following on each node</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 10.230.56.118:6443 --token 1yz24f.1hv4qn59rjxgj7cb --discovery-token-ca-cert-hash sha256:12dde7a18134d6d2effd66b17ad4e9b6b008ddfaa2c2d82232164e296d98ff0f</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br></pre></td><td class="code"><pre><span class="line">root@vps:~# ps -ef |grep kube</span><br><span class="line">root       704     1 99 06:48 ?        02:10:08 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --cgroup-driver=cgroupfs --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni --resolv-conf=/run/systemd/resolve/resolv.conf --fail-swap-on=false</span><br><span class="line">root      1169  1146  4 06:49 ?        00:01:51 etcd --advertise-client-urls=https://127.0.0.1:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --initial-advertise-peer-urls=https://127.0.0.1:2380 --initial-cluster=vps=https://127.0.0.1:2380 --key-file=/etc/kubernetes/pki/etcd/server.key --listen-client-urls=https://127.0.0.1:2379 --listen-peer-urls=https://127.0.0.1:2380 --name=vps --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/etc/kubernetes/pki/etcd/peer.key --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt --snapshot-count=10000 --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">root      1207  1190 10 06:49 ?        00:04:11 kube-apiserver --authorization-mode=Node,RBAC --advertise-address=10.230.56.118 --allow-privileged=true --client-ca-file=/etc/kubernetes/pki/ca.crt --disable-admission-plugins=PersistentVolumeLabel --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key</span><br><span class="line">root      1339  1320 14 06:49 ?        00:05:28 kube-controller-manager --address=127.0.0.1 --allocate-node-cidrs=true --cluster-cidr=10.244.0.0/16 --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt --cluster-signing-key-file=/etc/kubernetes/pki/ca.key --controllers=*,bootstrapsigner,tokencleaner --kubeconfig=/etc/kubernetes/controller-manager.conf --leader-elect=true --node-cidr-mask-size=24 --root-ca-file=/etc/kubernetes/pki/ca.crt --service-account-private-key-file=/etc/kubernetes/pki/sa.key --use-service-account-credentials=true</span><br><span class="line">root      1394  1365  2 06:49 ?        00:01:05 kube-scheduler --address=127.0.0.1 --kubeconfig=/etc/kubernetes/scheduler.conf --leader-elect=true</span><br><span class="line">root      1858  1840  0 06:49 ?        00:00:20 /usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/config.conf</span><br><span class="line">root     11432 11394  0 07:10 ?        00:00:01 /usr/bin/kube-controllers</span><br><span class="line">root     20581 19399  0 07:28 pts/1    00:00:00 grep --color=auto kube</span><br><span class="line"></span><br><span class="line">root@vps:~# cat /var/lib/kubelet/kubeadm-flags.env</span><br><span class="line">KUBELET_KUBEADM_ARGS=--cgroup-driver=cgroupfs --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni --resolv-conf=/run/systemd/resolve/resolv.conf</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /var/lib/kubelet/config.yaml</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.crt</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line">cgroupDriver: cgroupfs</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 100Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 5%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line">failSwapOn: true</span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line">maxPods: 110</span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line">port: 10250</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/admin.conf</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: xxx=</span><br><span class="line">    server: https://10.230.56.118:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: kubernetes-admin</span><br><span class="line">  name: kubernetes-admin@kubernetes</span><br><span class="line">current-context: kubernetes-admin@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: kubernetes-admin</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: xxx=</span><br><span class="line">    client-key-data: xxx=</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/kubelet.conf</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: xxx=</span><br><span class="line">    server: https://10.230.56.118:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: system:node:vps</span><br><span class="line">  name: system:node:vps@kubernetes</span><br><span class="line">current-context: system:node:vps@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: system:node:vps</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: xxx=</span><br><span class="line">    client-key-data: xxx==</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/controller-manager.conf</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: xxx=</span><br><span class="line">    server: https://10.230.56.118:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: system:kube-controller-manager</span><br><span class="line">  name: system:kube-controller-manager@kubernetes</span><br><span class="line">current-context: system:kube-controller-manager@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: system:kube-controller-manager</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: xxx==</span><br><span class="line">    client-key-data: xxx=</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/scheduler.conf</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: xxx=</span><br><span class="line">    server: https://10.230.56.118:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: system:kube-scheduler</span><br><span class="line">  name: system:kube-scheduler@kubernetes</span><br><span class="line">current-context: system:kube-scheduler@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: system:kube-scheduler</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: xxx==</span><br><span class="line">    client-key-data: xxx==</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/manifests/kube-apiserver.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    component: kube-apiserver</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: kube-apiserver</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-apiserver</span><br><span class="line">    - --authorization-mode=Node,RBAC</span><br><span class="line">    - --advertise-address=10.230.56.118</span><br><span class="line">    - --allow-privileged=true</span><br><span class="line">    - --client-ca-file=/etc/kubernetes/pki/ca.crt</span><br><span class="line">    - --disable-admission-plugins=PersistentVolumeLabel</span><br><span class="line">    - --enable-admission-plugins=NodeRestriction</span><br><span class="line">    - --enable-bootstrap-token-auth=true</span><br><span class="line">    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt</span><br><span class="line">    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key</span><br><span class="line">    - --etcd-servers=https://127.0.0.1:2379</span><br><span class="line">    - --insecure-port=0</span><br><span class="line">    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt</span><br><span class="line">    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key</span><br><span class="line">    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span><br><span class="line">    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt</span><br><span class="line">    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key</span><br><span class="line">    - --requestheader-allowed-names=front-proxy-client</span><br><span class="line">    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt</span><br><span class="line">    - --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">    - --requestheader-group-headers=X-Remote-Group</span><br><span class="line">    - --requestheader-username-headers=X-Remote-User</span><br><span class="line">    - --secure-port=6443</span><br><span class="line">    - --service-account-key-file=/etc/kubernetes/pki/sa.pub</span><br><span class="line">    - --service-cluster-ip-range=10.96.0.0/12</span><br><span class="line">    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt</span><br><span class="line">    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key</span><br><span class="line">    image: k8s.gcr.io/kube-apiserver-amd64:v1.11.0</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    livenessProbe:</span><br><span class="line">      failureThreshold: 8</span><br><span class="line">      httpGet:</span><br><span class="line">        host: 10.230.56.118</span><br><span class="line">        path: /healthz</span><br><span class="line">        port: 6443</span><br><span class="line">        scheme: HTTPS</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    name: kube-apiserver</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 250m</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /etc/kubernetes/pki</span><br><span class="line">      name: k8s-certs</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/ssl/certs</span><br><span class="line">      name: ca-certs</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /usr/share/ca-certificates</span><br><span class="line">      name: usr-share-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /usr/local/share/ca-certificates</span><br><span class="line">      name: usr-local-share-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/ca-certificates</span><br><span class="line">      name: etc-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  priorityClassName: system-cluster-critical</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/pki</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: k8s-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/ssl/certs</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: ca-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /usr/share/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: usr-share-ca-certificates</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /usr/local/share/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: usr-local-share-ca-certificates</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etc-ca-certificates</span><br><span class="line">status: &#123;&#125;</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/manifests/kube-controller-manager.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    component: kube-controller-manager</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: kube-controller-manager</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-controller-manager</span><br><span class="line">    - --address=127.0.0.1</span><br><span class="line">    - --allocate-node-cidrs=true</span><br><span class="line">    - --cluster-cidr=10.244.0.0/16</span><br><span class="line">    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt</span><br><span class="line">    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key</span><br><span class="line">    - --controllers=*,bootstrapsigner,tokencleaner</span><br><span class="line">    - --kubeconfig=/etc/kubernetes/controller-manager.conf</span><br><span class="line">    - --leader-elect=true</span><br><span class="line">    - --node-cidr-mask-size=24</span><br><span class="line">    - --root-ca-file=/etc/kubernetes/pki/ca.crt</span><br><span class="line">    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key</span><br><span class="line">    - --use-service-account-credentials=true</span><br><span class="line">    image: k8s.gcr.io/kube-controller-manager-amd64:v1.11.0</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    livenessProbe:</span><br><span class="line">      failureThreshold: 8</span><br><span class="line">      httpGet:</span><br><span class="line">        host: 127.0.0.1</span><br><span class="line">        path: /healthz</span><br><span class="line">        port: 10252</span><br><span class="line">        scheme: HTTP</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    name: kube-controller-manager</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 200m</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /usr/share/ca-certificates</span><br><span class="line">      name: usr-share-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /usr/local/share/ca-certificates</span><br><span class="line">      name: usr-local-share-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/ca-certificates</span><br><span class="line">      name: etc-ca-certificates</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/kubernetes/pki</span><br><span class="line">      name: k8s-certs</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/ssl/certs</span><br><span class="line">      name: ca-certs</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /etc/kubernetes/controller-manager.conf</span><br><span class="line">      name: kubeconfig</span><br><span class="line">      readOnly: true</span><br><span class="line">    - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec</span><br><span class="line">      name: flexvolume-dir</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  priorityClassName: system-cluster-critical</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/pki</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: k8s-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/ssl/certs</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: ca-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/controller-manager.conf</span><br><span class="line">      type: FileOrCreate</span><br><span class="line">    name: kubeconfig</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: flexvolume-dir</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /usr/share/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: usr-share-ca-certificates</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /usr/local/share/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: usr-local-share-ca-certificates</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/ca-certificates</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etc-ca-certificates</span><br><span class="line">status: &#123;&#125;</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/manifests/kube-scheduler.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    component: kube-scheduler</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: kube-scheduler</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-scheduler</span><br><span class="line">    - --address=127.0.0.1</span><br><span class="line">    - --kubeconfig=/etc/kubernetes/scheduler.conf</span><br><span class="line">    - --leader-elect=true</span><br><span class="line">    image: k8s.gcr.io/kube-scheduler-amd64:v1.11.0</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    livenessProbe:</span><br><span class="line">      failureThreshold: 8</span><br><span class="line">      httpGet:</span><br><span class="line">        host: 127.0.0.1</span><br><span class="line">        path: /healthz</span><br><span class="line">        port: 10251</span><br><span class="line">        scheme: HTTP</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    name: kube-scheduler</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 100m</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /etc/kubernetes/scheduler.conf</span><br><span class="line">      name: kubeconfig</span><br><span class="line">      readOnly: true</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  priorityClassName: system-cluster-critical</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/scheduler.conf</span><br><span class="line">      type: FileOrCreate</span><br><span class="line">    name: kubeconfig</span><br><span class="line">status: &#123;&#125;</span><br><span class="line">root@vps:~#</span><br><span class="line">root@vps:~# cat /etc/kubernetes/manifests/etcd.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    component: etcd</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: etcd</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - etcd</span><br><span class="line">    - --advertise-client-urls=https://127.0.0.1:2379</span><br><span class="line">    - --cert-file=/etc/kubernetes/pki/etcd/server.crt</span><br><span class="line">    - --client-cert-auth=true</span><br><span class="line">    - --data-dir=/var/lib/etcd</span><br><span class="line">    - --initial-advertise-peer-urls=https://127.0.0.1:2380</span><br><span class="line">    - --initial-cluster=vps=https://127.0.0.1:2380</span><br><span class="line">    - --key-file=/etc/kubernetes/pki/etcd/server.key</span><br><span class="line">    - --listen-client-urls=https://127.0.0.1:2379</span><br><span class="line">    - --listen-peer-urls=https://127.0.0.1:2380</span><br><span class="line">    - --name=vps</span><br><span class="line">    - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt</span><br><span class="line">    - --peer-client-cert-auth=true</span><br><span class="line">    - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key</span><br><span class="line">    - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">    - --snapshot-count=10000</span><br><span class="line">    - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">    image: k8s.gcr.io/etcd-amd64:3.2.18</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    livenessProbe:</span><br><span class="line">      exec:</span><br><span class="line">        command:</span><br><span class="line">        - /bin/sh</span><br><span class="line">        - -ec</span><br><span class="line">        - ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">          --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt --key=/etc/kubernetes/pki/etcd/healthcheck-client.key</span><br><span class="line">          get foo</span><br><span class="line">      failureThreshold: 8</span><br><span class="line">      initialDelaySeconds: 15</span><br><span class="line">      timeoutSeconds: 15</span><br><span class="line">    name: etcd</span><br><span class="line">    resources: &#123;&#125;</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /var/lib/etcd</span><br><span class="line">      name: etcd-data</span><br><span class="line">    - mountPath: /etc/kubernetes/pki/etcd</span><br><span class="line">      name: etcd-certs</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  priorityClassName: system-cluster-critical</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/pki/etcd</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etcd-certs</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /var/lib/etcd</span><br><span class="line">      type: DirectoryOrCreate</span><br><span class="line">    name: etcd-data</span><br><span class="line">status: &#123;&#125;</span><br><span class="line">root@vps:~#</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/13/Using-kubeadm-to-deploy-k8s/" data-id="cjm8trj68000fbobpzssf26rr" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-用OpenSSL做自签名的证书" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/13/用OpenSSL做自签名的证书/" class="article-date">
  <time datetime="2018-07-13T05:10:13.000Z" itemprop="datePublished">2018-07-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/13/用OpenSSL做自签名的证书/">用OpenSSL做自签名的证书</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>作者：张华  发表于：2014-04-18<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</p>
<p>(<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</p>
<p>加密技术回顾<br>非对称加密算法如RSA的特点如下:<br>1, 公钥加密私钥解密, 大家都可以用我的公钥给我发加密的数据了, 因为只有我有私钥才能解密.<br>2, 私钥加密公钥解密叫数字签名(例如所谓的UEFI secure boot就是在主板硬件里集成一些操作系统的公钥，由主板硬件去校验操作系统是法合法，但关键是微软把持了公钥的申请，主板硬件厂商没有提供界面让用法自定义公钥，尤其在移动领域很多win8的硬件根本不提供关闭secure boot的选项这样就造成只能安装win8一种系统）, 大家收到我用私钥加密后的数据, 看用公钥能不能打得开, 能打开说明这数据确实是由我所发的, 因为别人没有我的私钥不可能伪造这些数据.<br>非对称加密去处很费时间, 我们一般采用对称密钥算法如DES来加密, 但对称密钥的保存是一个问题.<br>所以我们可以采用非对称加密算法来加密先协商交换对称密钥, 这就叫SSL. 假设客户端A的公私钥对是(P1,V1), 服务端B的公私钥对是(P2,V2), A需要确认和它通信的是B, 那么SSL的过程是:<br>首先, A和B都持有对方的公钥.<br>step1, A-&gt;B: hello 是step2, B-&gt;A: 用V2加密过的P1（即用户证书，A就用P2解密出P1, 这种数字签名方式让A确定了和它通信的是B）<br>step3, A-&gt;B: ok<br>step4, B-&gt;A: 用V1加密的一段信息<br>step5, A-&gt;B: 用P1加密一个自动生成的对称密钥K（用之前的P1解密成功这段信息则认为B是可信的了）<br>step6, B-&gt;A: 用K加密的数据（之后两对密钥功能结束，由K来加解密数据）<br>总结一下, 这里(P2,V2)就是certificate authority (CA)用来给客户签名用的公私钥。<br>(P1,V1)是客户自己的公私钥，提交给CA，CA所做的事情就是上述step2用(P2,V2)来给客户的(P1,V1)签名，简单吧？<br>V2是CA公司要保密的，而P2就是公用CA证书要安装到客户端</p>
<p>用V2加密过（签名过）的P1，称为用户证书，和用户私钥V1连起一个文件后, 一般被安装在服务器端。</p>
<p>X.509证书是一些标准字段的集合, 是包含有关用户或设备及其相应公钥信息的一种非常通用的证书格式, 目前版本是3. 必要字段包括:<br>1, 版本号<br>2, 由CA给每一个证书分配的序列号;<br>3, 证书使用的签名算法<br>4, 证书的认证机构<br>5, 证书的有效日期<br>6, 证书的所有人的唯一标识<br>7, 认证机构使用私钥的数字签名<br>8, 公钥信息<br>不同于PGP证书任何人都可以扮演认证者的角色, X.509证书的认证者只能是CA或由CA指定的人.要获得一份X.509证书，必须请求CA发给你证书。用户提供自己的公钥，证明自己拥有相应的私钥，并提供有关自己的某些特定信息。然后在这些信息上数字签名，并将整个数据包(称为证书请求)发给CA。CA做一些努力来验证用户提供的信息是正确的，然后就生成证书并返回给用户。<br>OpenSSL对X.509的支持如下:<br>(1) 证书请求管理<br>(2) 证书生成<br>(3) 证书吊销及CRL管理<br>(4) X509名字管理<br>(5) 属性管理<br>(6) 扩展管理<br>(7) 验证及信任管理</p>
<p>用OpenSSL做自签名的证书(pem格式)步骤:<br>1, 先生成CA的公私钥<br>   mkdir CA &amp; cd CA<br>   mkdir newcerts private<br>   echo ‘01’ &gt; serial #会生成以为个数字为名字的pem文件, 且每个数字自增1<br>   touch index.txt #生成记录数据库<br>   使用配置文件, 由于openssl命令行参数太多, 为避免写太多, 就使用一个配置文件代替, 如<a href="https://github.com/openstack/nova/blob/master/nova/CA/openssl.cnf.tmpl" target="_blank" rel="external">https://github.com/openstack/nova/blob/master/nova/CA/openssl.cnf.tmpl</a><br>   生成(P2,V2), 这时候P2=cacert.pem, V2=private/cakey.pem<br>   openssl req -new -x509 -extensions v3_ca -keyout private/cakey.pem -out cacert.pem -days 365 -config ./openssl.cnf -batch -nodes<br>   查看证书信息, openssl x509 -in cacert.pem -noout -text<br>2, 生成<p1,v1>,即Certificate signing Reqeust(CSR), P1=req.pem, V1=key.pem<br>   openssl req -new -nodes -out req.pem -config ./openssl.cnf<br>3, 用CA的私钥V2为P1签名, 即在newcerts目录生成用户证书cert.pem, 并更新数据库文件index.txt及serail文件<br>   openssl ca -out cert.pem -config ./openssl.cnf -infiles req.pem<br>   查看证书信息, openssl x509 -in cert.pem -noout -text<br>4, 安装证书<br>   用户私钥key.pem(V1)和用V2加密过的用户公钥(cert.pem)安装到服务端(有的服务器碉要把这两个文件连成一个,可以执行: cat key.pem cert.pem &gt; key-cert.pem), 如:<br>   /home/httpd/ssl/cert.pem Site certificate<br>   /home/httpd/ssl/key.pem Site private key<br>   最后将CA的公钥P2=cacert.pem安装到客户端</p1,v1></p>
<p>在OpenStack PKI认证中：<br>1, Keystone产生了CA公私钥: CA.pem, CA.key<br>2, Keystone产生了用户公私钥: keystone.pub, keystone.key<br>3, Keystone产生了用户证书: keystone.pem (即使用CA.key对keystone.pub进行了签名)<br>假如nova要使用PKI认证的话：<br>1, CA端，即keystone端，安装有: CA.pem, CA.key, keystone.key, keystone.pem<br>2, 用户端，即nova端，安装有：keystone.pem<br>过程：<br>1, 用户拿用户名和密码去keystone认证，keystone将用户信息通过keystone.key进行签名后作为token返回用户<br>2, 用户用这一token去访问nova, nova拿到token后，使用keystone.pem解密。（而原来的UUID方式nova还得再拿token去keystone那边验证一下是否有效，所以使用PKI方式能减轻keystone的压力。</p>
<p>再举个例子，如在安装openconnect时生成证书：</p>
<p>sudo apt-get -y install build-essential pkg-config libgnutls28-dev libreadline-dev libseccomp-dev libwrap0-dev libnl-nf-3-dev liblz4-dev gnutls-bin</p>
<p>#Create CA certificate<br>mkdir -p /tmp/cert &amp;&amp; cd /tmp/cert<br>cat &gt; /tmp/cert/ca.tmpl &lt;&lt; EOF<br>cn = “sts CA”<br>organization = “sts CA”<br>serial = 1<br>expiration_days = 3650<br>ca<br>signing_key<br>cert_signing_key<br>crl_signing_key<br>EOF</p>
<p>#Generate CA secret KEY: V2<br>certtool –generate-privkey –outfile CA.key</p>
<p>#Generate CA certifice: P2 signed by V2<br>certtool –generate-self-signed –load-privkey CA.key –template ca.tmpl –outfile CA.pem</p>
<p>#Create User certificate (here is for VPN server)<br>cat &gt; /tmp/cert/vpnserver.tmpl &lt;&lt; EOF<br>cn = “sts vpn server”<br>organization = “sts”<br>expiration_days = 3650<br>signing_key<br>encryption_key<br>tls_www_server<br>EOF</p>
<p>#Generate User secret KEY: V1<br>certtool –generate-privkey –outfile vpnserver.key</p>
<p>#Generate User certificate: <p1 signed="" by="" v2=""><br>certtool –generate-certificate –load-privkey vpnserver.key –load-ca-certificate CA.pem –load-ca-privkey CA.key –template vpnserver.tmpl –outfile vpnserver.pem</p1></p>
<p>#CA.pem,vpnserver,pem,vpnserver.key need to be installed in vpnserver<br>sudo cp CA.pem /etc/ssl/certs/CA.pem<br>sudo cp vpnserver.pem /etc/ssl/private/vpnserver.pem<br>sudo cp vpnserver.key /etc/ssl/private/vpnserver.key<br>OpenStack创建CA的方法：</p>
<p>openssl genrsa -out /etc/keystone/ssl/private/cakey.pem 1024<br>openssl req -new -x509 -extensions v3_ca -key /etc/keystone/ssl/private/cakey.pem -out /etc/keystone/ssl/certs/ca.pem -days 3650 -config /etc/keystone/ssl/certs/openssl.conf -subj /C=US/ST=Unset/L=Unset/O=Unset/CN=localhost<br>openssl genrsa -out /etc/keystone/ssl/private/keystonekey.pem 1024<br>openssl req -key /etc/keystone/ssl/private/keystonekey.pem -new -out /etc/keystone/ssl/certs/req.pem -config /etc/keystone/ssl/certs/openssl.conf -subj /C=US/ST=Unset/L=Unset/O=Unset/CN=localhost<br>openssl ca -batch -out /etc/keystone/ssl/certs/keystone.pem -config /etc/keystone/ssl/certs/openssl.conf -days 3650d -cert /etc/keystone/ssl/certs/ca.pem -keyfile /etc/keystone/ssl/private/cakey.pem -infiles /etc/keystone/ssl/certs/req.pem</p>
<p>再看一个使用easy-rsa为openvpn生成证书的实例：</p>
<p>sudo apt-get install easy-rsa openssl<br>sudo cp -r /usr/share/easy-rsa/ /etc/openvpn<br>cd /etc/openvpn/easy-rsa<br>sudo chown -R <code>whoami</code>:root /etc/openvpn<br>mkdir /etc/openvpn/easy-rsa/keys<br>source ./vars<br>export KEY_COUNTRY=CN<br>export KEY_PROVINCE=BJ<br>export KEY_CITY=BJ<br>export KEY_ORG=sts<br>export KEY_OU=sts<br>export KEY_NAME=sts<br>export KEY_EMAIL=root@sts<br>export KEY_NAME=”server”<br>./clean-all<br>./build-ca<br>$ ls keys/<br>ca.crt  ca.key  index.txt  serial<br>./build-key-server server<br>$ ls keys/<br>01.pem  ca.key     index.txt.attr  serial      server.crt  server.key<br>ca.crt  index.txt  index.txt.old   serial.old  server.csr<br>cp /etc/openvpn/easy-rsa/keys/{server.crt,server.key,ca.crt} /etc/openvpn</p>
<p>#It’s ideal for each client connecting to the VPN to have its own unique certificate and key.</p>
<p>#This is preferable to generating one general certificate and key to use among all client devices.<br>./build-key client1<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/client1.crt /etc/openvpn/<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/client1.key /etc/openvpn/<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/client.ovpn /etc/openvpn/<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/ca.crt /etc/openvpn/</server></server></server></server></p>
<p>常见证书格式及转换</p>
<p>PKCS(Public-Key Cryptography Standards), 是由RSA实验室与其他安全系统开发商共同制定的一个公钥密码标准<br>X.509是常用的通用的证书格式, 所有的证书都符合PKI(Public Key Infrastructure)制定的的ITU-T X509国际标准<br>.cer/.crt是用于存储证书, 以二进制形式存储, 不含私钥<br>.pem跟.cer/.crt的区别是它以ascii来表示<br>pfx/p12用于存放个人证书/私钥, 他通常包含保护密码, 二进制存储, 转换如:openssl pkcs12 -export -clcerts -in server-cert.cer -inkey server-key.key -out server.p12<br>JKS和JCEKS是Java密钥库(KeyStore)的两种比较常见类型, 可以使用java提供的证书工具keytool(openssl和keytool都是可以用来管理证书的工具而已)进行转换(如:keytool -import -v -trustcacerts -storepass 123456 -alias server -file cacert.pem -keystore server.jks)</p>
<p>例如： k8s中的dashboard若不在浏览器里导入p12证书在采用RBAC授权时就会什么也看不到：</p>
<h1 id="generate-client-certificate-data"><a href="#generate-client-certificate-data" class="headerlink" title="generate client-certificate-data"></a>generate client-certificate-data</h1><p>grep ‘client-certificate-data’ /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk ‘{print $2}’ | base64 -d &gt;&gt; kubecfg.crt</p>
<h1 id="generate-client-key-data"><a href="#generate-client-key-data" class="headerlink" title="generate client-key-data"></a>generate client-key-data</h1><p>grep ‘client-key-data’ /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk ‘{print $2}’ | base64 -d &gt;&gt; kubecfg.key</p>
<h1 id="generate-p12"><a href="#generate-p12" class="headerlink" title="generate p12"></a>generate p12</h1><p>openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name “kubernetes-client”</p>
<p>非对称算法可以使用开源的GPG工具，可参考文档： <a href="http://wenku.baidu.com/link?url=d5fWoN46-y7581212dDUEt7dkUfFkriW0bKy_gwUjps4zpKH64jytimWDm-yfuKIwAtu0jFoWW_ocVTJhSeRb2_QQLUz8oIBQulU6jSI133" target="_blank" rel="external">http://wenku.baidu.com/link?url=d5fWoN46-y7581212dDUEt7dkUfFkriW0bKy_gwUjps4zpKH64jytimWDm-yfuKIwAtu0jFoWW_ocVTJhSeRb2_QQLUz8oIBQulU6jSI133</a></p>
<p>及：<br><a href="https://help.ubuntu.com/community/GnuPrivacyGuardHowto" target="_blank" rel="external">https://help.ubuntu.com/community/GnuPrivacyGuardHowto</a></p>
<p>sudo apt-get install rng-tools<br>sudo rngd -r /dev/urandom</p>
<p>sudo apt-get install gnupg-agent<br>killall -q gpg-agent<br>eval $(gpg-agent –daemon)</p>
<p>创建密钥对：gpg –gen-key， 如创建了：”Zhang Hua (zhhuabj) <a href="&#109;&#97;&#x69;&#108;&#x74;&#x6f;&#58;&#118;&#x65;&#114;&#x79;&#x68;&#117;&#97;&#50;&#x30;&#48;&#54;&#64;&#103;&#109;&#x61;&#x69;&#x6c;&#x2e;&#99;&#111;&#109;">&#118;&#x65;&#114;&#x79;&#x68;&#117;&#97;&#50;&#x30;&#48;&#54;&#64;&#103;&#109;&#x61;&#x69;&#x6c;&#x2e;&#99;&#111;&#109;</a>“</p>
<pre><code>export GPGKEY=A24B36AE
</code></pre><p>查看公钥：gpg –list-public<br>查看私钥：gpg –list-secret-key<br>查看签名：gpg –list-sig<br>查看公钥指纹：gpg –fingerprint $GPGKEY<br>提取公钥：gpg –armor –output public.key –export $GPGKEY  或者： gpg –export -a $GPGKEY &gt; public.key</p>
<p>提取私钥：gpg -a –export-secret-keys $KEYID &gt; customer-mirror.key<br>生成公钥回收证书，当私钥出问题时可将它上传密钥服务器声明公钥作废:<br>  gpg –output revoke.asc –gen-revoke $GPGKEY<br>  声明作废：gpg –keyserver Server Address –send-keys $GPGKEY</p>
<p>迁移KEY</p>
<p>gpg –output mygpgkey_pub.gpg –armor –export  $GPGKEY<br>gpg –output mygpgkey_sec.gpg –armor –export-secret-key $GPGKEY</p>
<p>gpg –import mygpgkey_pub.gpg<br>gpg –allow-secret-key-import –import mygpgkey_sec.gpg</p>
<p>上传公钥到密钥服务器，如：gpg –send-keys –keyserver keyserver.ubuntu.com $GPGKEY 或把公钥导成文本之后直接在<a href="http://keyserver.ubuntu.com/这里提交公钥。" target="_blank" rel="external">http://keyserver.ubuntu.com/这里提交公钥。</a></p>
<p>交互命令窗口：gpg –cert-digest-algo=SHA256 –edit-key $GPGKEY</p>
<p>给自己加密文件，加密是用公钥，gpg –encrypt -r veryhua2006@gmail.com test.txt, 会生成名为test.txt.gpg的加密文件<br>给自己解决文件，gpg –decrypt test.txt.gpg &gt; test.txt</p>
<p>给别人加密文件当然要先导入别人的公钥：gpg –import otherpublic.key<br>核对对方的公钥指纹：gpg –fingerprint other@gmail.com<br>为别人加密文件: gpg –encrypt –recipient other@gmail.com test.txt<br>对别人的公钥进行签名，这样别人知道是你发的： gpg –sign-key other@gmail.com</p>
<p>对文件进行签名： gpg –clearsign file<br>验证签名是否完整： gpg –verity file.asc</p>
<p>OpenPGP能用于加密邮件，将GPG指纹注册到launchpad中(<a href="https://launchpad.net/~zhhuabj)，这样launchpad将给你发签名或加密过的邮件，然后再用openPGP" target="_blank" rel="external">https://launchpad.net/~zhhuabj)，这样launchpad将给你发签名或加密过的邮件，然后再用openPGP</a> enabled的邮件客户端如thunderbird来接收解密邮件和验证签名。<br>thunderbird通过enigmail插件来支持OpenPGP, Configure OpenPGP support in Thunderbird under Enigmail-&gt;Preferences and add under GnuPG executable path. The path for GnuPG is /usr/bin/gpg.<br>如果不想用邮件客户端，直接用firefox来访问如gmail等webmail的话，安装firegpg插件即可。chrome不需要装插件直接支持pgp解密。</p>
<p>将GPG指纹（gpg –fingerprint)注册到launchpad中(<a href="https://launchpad.net/~zhhuabj)后会收到一封邮件，内容类似如下，将其存成一个文件，再解密(gpg" target="_blank" rel="external">https://launchpad.net/~zhhuabj)后会收到一封邮件，内容类似如下，将其存成一个文件，再解密(gpg</a> –decrypt file.txt)后就生成了一个验证链接如<a href="https://launchpad.net/token/Hc7J9x7kF55CHTZJs，点击验证即可。" target="_blank" rel="external">https://launchpad.net/token/Hc7J9x7kF55CHTZJs，点击验证即可。</a><br>—–BEGIN PGP MESSAGE—–<br>Version: GnuPG v1.4.11 (GNU/Linux)<br>…….<br>52gY/bZADAl0xhScHvvuYquGS3oApfgtNM3UJWXa<br>=ZgnD<br>—–END PGP MESSAGE—–</p>
<p>Signed Ubuntu Code of Conduct in <a href="https://launchpad.net/~zhhuabj，" target="_blank" rel="external">https://launchpad.net/~zhhuabj，</a><br>1, 先下载UbuntuCodeofConduct-2.0.txt, <a href="https://launchpad.net/codeofconduct/2.0/+download" target="_blank" rel="external">https://launchpad.net/codeofconduct/2.0/+download</a><br>2, gpg –clearsign UbuntuCodeofConduct-2.0.txt<br>3, 将生成的UbuntuCodeofConduct-2.0.txt.asc文件再上传至 <a href="https://launchpad.net/codeofconduct/2.0/+sign即可。" target="_blank" rel="external">https://launchpad.net/codeofconduct/2.0/+sign即可。</a></p>
<p>2014-5-23日添加，配置使用Google Authenticator服务</p>
<p>Google帐户支持密码+临时验证码的两阶段验证方式。<br>临时验证码也支持直接短信发到手机上，也可以在Android手机上安装Google Authenticator服务来接收临时验证码。<br>具体先在<a href="https://accounts.google.com/b/0/SmsAuthConfig页面配置，并先生成google服务端为安装了Google" target="_blank" rel="external">https://accounts.google.com/b/0/SmsAuthConfig页面配置，并先生成google服务端为安装了Google</a> Authenticator服务的客户端生成的密钥。然后再在Google Authenticator里输入这个密钥就可以实现一次一密了。</p>
<p>参考:<br><a href="http://www.blogjava.net/alwayscy/archive/2006/12/01/84852.html" target="_blank" rel="external">http://www.blogjava.net/alwayscy/archive/2006/12/01/84852.html</a><br><a href="http://blog.sina.com.cn/s/blog_9e9d2211010199yj.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_9e9d2211010199yj.html</a></p>
<p><a href="http://lingxiankong.github.io/blog/2014/02/06/openstack-ssl/" target="_blank" rel="external">http://lingxiankong.github.io/blog/2014/02/06/openstack-ssl/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/13/用OpenSSL做自签名的证书/" data-id="cjm8trj6h000qbobpbnheygph" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Set-up-k8s-development-env-by-quqi99" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/10/Set-up-k8s-development-env-by-quqi99/" class="article-date">
  <time datetime="2018-07-10T09:47:57.000Z" itemprop="datePublished">2018-07-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/10/Set-up-k8s-development-env-by-quqi99/">Set up k8s development env (by quqi99)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-07-10)</strong></p>
<h2 id="Sign-the-CLA"><a href="#Sign-the-CLA" class="headerlink" title="Sign the CLA"></a>Sign the CLA</h2><p>Sign via Hellosign - <a href="https://github.com/kubernetes/community/blob/master/CLA.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/CLA.md</a><br>then set email for github - <a href="https://github.com/settings/emails" target="_blank" rel="external">https://github.com/settings/emails</a><br>git config –global user.email “xxx@gmail.com”</p>
<h2 id="Run-local-k8s-via-source-code"><a href="#Run-local-k8s-via-source-code" class="headerlink" title="Run local k8s  via source code"></a>Run local k8s  via source code</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># Install some packages</span><br><span class="line">sudo apt install -y gcc make socat git build-essential</span><br><span class="line"></span><br><span class="line"># Install docker</span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line">sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt-cache policy docker-ce</span><br><span class="line">sudo apt install docker-ce</span><br><span class="line"></span><br><span class="line"># Change default location of docker image</span><br><span class="line">service docker stop</span><br><span class="line">rsync -aXS /var/lib/docker/* /bak/.docker/</span><br><span class="line">rm -rf /var/lib/docker/*</span><br><span class="line">echo /bak/.docker/ /var/lib/docker none bind 0 0 &gt;&gt; /etc/fstab</span><br><span class="line">mount –a</span><br><span class="line">service docker start</span><br><span class="line"></span><br><span class="line"># Install etcd &gt; 3.2.13</span><br><span class="line">ETCD_VER=v3.2.18</span><br><span class="line">DOWNLOAD_URL=&quot;https://github.com/coreos/etcd/releases/download&quot;</span><br><span class="line">curl -L $&#123;DOWNLOAD_URL&#125;/$&#123;ETCD_VER&#125;/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz -o /tmp/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz</span><br><span class="line">tar xzvf /tmp/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz</span><br><span class="line">sudo /bin/cp -f etcd-$&#123;ETCD_VER&#125;-linux-amd64/&#123;etcd,etcdctl&#125; /usr/bin</span><br><span class="line">rm -rf /tmp/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz etcd-$&#123;ETCD_VER&#125;-linux-amd64</span><br><span class="line"></span><br><span class="line"># Install golang &gt; 1.10.2</span><br><span class="line">wget https://dl.google.com/go/go1.10.3.linux-amd64.tar.gz</span><br><span class="line">sudo rm -rf /usr/lib/go &amp;&amp; sudo tar -C /usr/lib -xzf go1.10.3.linux-amd64.tar.gz</span><br><span class="line">export GOROOT=/usr/lib/go</span><br><span class="line">export GOPATH=/bak/golang</span><br><span class="line">export PATH=$GOROOT/bin:$GOPATH/bin:$PATH</span><br><span class="line"></span><br><span class="line"># Install and run kubernetes in local env - https://www.cnblogs.com/edisonxiang/p/6951787.html</span><br><span class="line">mkdir -p $GOPATH/src/k8s.io</span><br><span class="line">#go get -d k8s.io/kubernetes</span><br><span class="line">git clone git@github.com:zhhuabj/kubernetes.git $GOPATH/src/k8s.io/kubernetes</span><br><span class="line">#make GOGCFLAGS=&quot;-N -l&quot;  #Debug it</span><br><span class="line">sudo usermod -a -G docker $&#123;USER&#125;</span><br><span class="line">sudo systemctl restart docker.service</span><br><span class="line">sudo systemctl disable kubelet.service</span><br><span class="line">sudo systemctl stop kubelet.service</span><br><span class="line"></span><br><span class="line">#注意：一直不成功的原因是需要用小写true，它是区分大小写的</span><br><span class="line">KUBE_ENABLE_CLUSTER_DASHBOARD=true ./hack/local-up-cluster.sh</span><br><span class="line">#注意：加GO_OUT可避免再次编译</span><br><span class="line">GO_OUT=/bak/golang/src/k8s.io/kubernetes/_output/bin</span><br><span class="line">KUBE_ENABLE_CLUSTER_DASHBOARD=true ./hack/local-up-cluster.sh</span><br><span class="line"></span><br><span class="line"># Test local env</span><br><span class="line">export KUBECONFIG=/var/run/kubernetes/admin.kubeconfig</span><br><span class="line">cluster/kubectl.sh get pods --all-namespaces</span><br></pre></td></tr></table></figure>
<h2 id="github-process"><a href="#github-process" class="headerlink" title="github process"></a>github process</h2><p><a href="https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md</a><br>k8s与openstack不一样，openstack使用gerrit来review code, 但是k8s使用github的PR机制。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">kubernetes提交PR的流程可以采用pull模型（Shared Repository Model，https://gist.github.com/seshness/3943237），也可以采用fork模型（https://www.cnblogs.com/edisonxiang/p/6951787.html）。我们采用fork模型：</span><br><span class="line"></span><br><span class="line"># Click &apos;Fork&apos; button to fork your own branch - https://github.com/kubernetes/kubernetes, then we have https://github.com/zhhuabj/kubernetes</span><br><span class="line">mkdir -p $GOPATH/src/k8s.io</span><br><span class="line">git clone git@github.com:zhhuabj/kubernetes.git $GOPATH/src/k8s.io/kubernetes</span><br><span class="line">cd kubernetes</span><br><span class="line">hack/local-up-cluster.sh</span><br><span class="line"></span><br><span class="line"># set up upstream branch</span><br><span class="line">git remote add upstream https://github.com/kubernetes/kubernetes.git</span><br><span class="line">git remote set-url --push upstream no_push</span><br><span class="line">git remote -v</span><br><span class="line"></span><br><span class="line"># Update our branch</span><br><span class="line">git fetch upstream</span><br><span class="line">git checkout master</span><br><span class="line">git rebase upstream/master</span><br><span class="line">#git pull upstream master</span><br><span class="line"></span><br><span class="line"># Add new branch myfeature</span><br><span class="line">git checkout -b myfeature</span><br><span class="line">git config --global user.email &quot;veryhua2006@gmail.com&quot;</span><br><span class="line">git config --global user.name &quot;zhhuabj&quot;</span><br><span class="line"># Add or Modify files</span><br><span class="line">...</span><br><span class="line">git add .</span><br><span class="line">git commit -a -F ./msg</span><br><span class="line">git commit --amend -a -F ./message</span><br><span class="line">git commit -m &quot;update&quot;</span><br><span class="line">git push origin myfeature</span><br><span class="line">git push origin :myfeature  #delete remote branch</span><br><span class="line"></span><br><span class="line"># Rebase unmerged PR into our repo</span><br><span class="line">git fetch upstream pull/56136/head:BRANCHNAME</span><br><span class="line"></span><br><span class="line"># Merge multiple local commits into a full commit by using &apos;git squash&apos;</span><br><span class="line">git log</span><br><span class="line">git rebase -i HEAD~6 把顶部的六个版本聚到一起进入编辑页面</span><br><span class="line">　　把需要压缩的日志前面的pick都改为s（squash的缩写）</span><br><span class="line">　　注意必须保留一个pick，如果将所有的pick都改为了s那就没有合并的载体了就会报如下错误</span><br><span class="line">　　依次输入CTRL+X Y ENTER三个命令完成编辑。</span><br><span class="line">　　最后Git Push orgin branchname</span><br><span class="line"></span><br><span class="line"># Pull Request - https://github.com/zhhuabj/kubernetes, 在新上传的Branch上，点击Compare &amp; Pull Request按钮创建一个Pull Requst</span><br><span class="line"></span><br><span class="line"># 最后https://github.com/kubernetes/kubernetes/pulls就可以找到刚刚提交的Pull Request。</span><br></pre></td></tr></table></figure></p>
<h2 id="Review-process"><a href="#Review-process" class="headerlink" title="Review process"></a>Review process</h2><p><a href="https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md#the-testing-and-merge-workflow" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md#the-testing-and-merge-workflow</a><br> openstack社区更开放，使用gerrit机制，新人都能review代码，并能+1。<br>但k8s使用github的PR，相对封闭一些，新人是不能review代码的，新人的角色叫contributor，可以修改issue (在issue上回复/assign)并提交代码。<br>只有每个子模块下OWNERS文件定义的reviewer, approver角色的人员(<a href="https://github.com/kubernetes/community/blob/master/community-membership.md)才能review代码(reviewer可以LDTM(looks" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/community-membership.md)才能review代码(reviewer可以LDTM(looks</a> good to me, +1), approver可以+2，一个+1一个+2就可以进代码，但openstack中是只能两个+2才可以)</p>
<p>如果要为某个issue创建PR, 需要在PR的描述里填写fixes #issue_num 。这样PR在 merge后issue会“自动”关闭。PR创建后，k8s机器人会做以下几件事：<br>在相应OWNER列表里选取一个人做为reviewer<br>如果是kubernetes member，则启动CI来检查PR，例如UT, e2e test；如果不是kuberentes member ，则需要一个member帮忙启动相应ci<br>待CI没有问题后，可以ping相应的reviewers来检查代码了</p>
<p>在reviewer认为可以后，需要标lgtm (look go to me) 标签；同时需要该模块的approver标记approve标签。两个标签都有了以后，就可以等待合并了。代码的合并也是由k8s机器人完成的，可以在 <a href="http://submit-queue.k8s.io/#/queue" target="_blank" rel="external">http://submit-queue.k8s.io/#/queue</a> 看到等待合并的PR。在合并之前，k8s机器人也会自动重新跑ci以保证代码没有问题。<br>以上三步差不多就可以将typo提交到主干上。其中大部分工作都有k8s机器人自动完成，比如分配reviewer。<br>  Bot命令如下：</p>
<ul>
<li>Jenkins verification: @k8s-bot verify test this</li>
<li>GCE E2E: @k8s-bot cvm gce e2e test this</li>
<li>Test all: @k8s-bot test this please, issue #IGNORE</li>
<li>CRI test: @k8s-bot cri test this.</li>
<li>Verity test: @k8s-bot verify test this</li>
<li>LGTM (only applied if you are one of assignees):: /lgtm</li>
<li>LGTM cancel: /lgtm cancel<br>更多命令见 <a href="https://prow.k8s.io/command-help" target="_blank" rel="external">https://prow.k8s.io/command-help</a><h2 id="How-to-do-test"><a href="#How-to-do-test" class="headerlink" title="How to do test"></a>How to do test</h2><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md</a><br>make verify<br>make test<br>make test-integration<h2 id="How-to-debug-k8s"><a href="#How-to-debug-k8s" class="headerlink" title="How to debug k8s"></a>How to debug k8s</h2>local-up-cluster.sh是通过_output/local/bin/linux/amd64/hyperkube在容器里启动k8s各服务的，那样是不方便使用(dlv exec ${OUTDIR}/bin/kubelet – $kubelet_flags)来调试基于B/S的k8s服务的，那首先将k8s各服务以本地进程的形式启动，这样调试k8s服务就变得像调试openstack服务一样。</li>
</ul>
<p>1， 第一步创建systemd启动配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line">$ cat /lib/systemd/system/kube-etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-etcd Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/bin/etcd -name etcd -data-dir /var/lib/etcd \</span><br><span class="line">          -listen-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001 \</span><br><span class="line">          -advertise-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-apiserver Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-apiserver \</span><br><span class="line">            --admission-control=NamespaceAutoProvision,LimitRanger,SecurityContextDeny \</span><br><span class="line">            --apiserver-count=1 \</span><br><span class="line">            --cors-allowed-origins=.* \</span><br><span class="line">            --enable-garbage-collector=false \</span><br><span class="line">            --etcd-servers=http://127.0.0.1:2379 \</span><br><span class="line">            --insecure-bind-address=0.0.0.0 \</span><br><span class="line">            --insecure-port=8080 \</span><br><span class="line">            --log-dir=~/.kube/log/kube-apiserver \</span><br><span class="line">            --logtostderr=false \</span><br><span class="line">            --service-cluster-ip-range=10.0.0.0/16 \</span><br><span class="line">            --v=5 \</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-controller-manager Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-controller-manager \</span><br><span class="line">          --enable-garbage-collector=false \</span><br><span class="line">          --logtostderr=false \</span><br><span class="line">          --log-dir=~/.kube/log/kube-controller-manager \</span><br><span class="line">          --pod-eviction-timeout=5m0s \</span><br><span class="line">          --master=http://0.0.0.0:8080 \</span><br><span class="line">          --node-monitor-grace-period=40s \</span><br><span class="line">          --terminated-pod-gc-threshold=12500 \</span><br><span class="line">          --leader-elect=true \</span><br><span class="line">          --v=4 \</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-scheduler.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-scheduler Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-scheduler \</span><br><span class="line">            --log-dir=~/.k8s/log/kube-scheduler \</span><br><span class="line">            --logtostderr=false \</span><br><span class="line">            --master=http://0.0.0.0:8080 \</span><br><span class="line">            --leader-elect=true \</span><br><span class="line">            --v=5 \</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line"># prepare kubelet.kubeconfig and kube-proxy.kubeconfig</span><br><span class="line">export KUBE_APISERVER=&quot;http://127.0.0.1:8080&quot;</span><br><span class="line">./_output/bin/kubectl config set-cluster myk8s --server=$&#123;KUBE_APISERVER&#125; --kubeconfig=kubelet.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-credentials kubelet --kubeconfig=kubelet.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-context myk8s-context --cluster=myk8s --user=kubelet --kubeconfig=kubelet.kubeconfig</span><br><span class="line">./_output/bin/kubectl config use-context myk8s-context --kubeconfig=kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">./_output/bin/kubectl config set-cluster myk8s --server=$&#123;KUBE_APISERVER&#125; --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-credentials kube-proxy --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-context myk8s-context --cluster=myk8s --user=kube-proxy --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">./_output/bin/kubectl config use-context myk8s-context --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">cp *.kubeconfig /home/hua/.kube/</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=kubelet: The Kubernetes Node Agent</span><br><span class="line">Documentation=http://kubernetes.io/docs/</span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kubelet \</span><br><span class="line">          --address=127.0.0.1 --port=10250 --hostname-override=127.0.0.1 \</span><br><span class="line">          --pod-infra-container-image=docker.io/kubernetes/pause \</span><br><span class="line">          --fail-swap-on=false --cgroup-driver=cgroupfs \</span><br><span class="line">          --kubeconfig=/home/hua/.kube/kubelet.kubeconfig \</span><br><span class="line">          --runtime-cgroups=/systemd/system.slice \</span><br><span class="line">          --kubelet-cgroups=/systemd/system.slice \</span><br><span class="line">          --eviction-hard=&apos;nodefs.available&lt;1%&apos; \</span><br><span class="line">          --logtostderr=false --log-dir=~/.kube/log/kubelet --v=4</span><br><span class="line">Restart=always</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">RestartSec=10</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-proxy.service[Unit]</span><br><span class="line">Description=Kube-proxy Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-proxy \</span><br><span class="line">            --log-dir=~/.k8s/log/kube-proxy \</span><br><span class="line">            --logtostderr=false \</span><br><span class="line">            --master=http://0.0.0.0:8080 \</span><br><span class="line">            --kubeconfig=/home/hua/.kube/kube-proxy.kubeconfig \</span><br><span class="line">            --proxy-mode=userspace \</span><br><span class="line">            --v=5</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br></pre></td></tr></table></figure></p>
<p>2， 第二步，启动各服务:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl --system daemon-reload</span><br><span class="line">sudo systemctl start kube-etcd.service</span><br><span class="line">etcdctl -C http://localhost:4001 cluster-health</span><br><span class="line">sudo systemctl start kube-apiserver.service</span><br><span class="line">sudo systemctl start kube-controller-manager.service</span><br><span class="line">sudo systemctl start kube-scheduler.service</span><br><span class="line">sudo systemctl start kubelet.service</span><br></pre></td></tr></table></figure></p>
<p>3, 第二步，验证安装是否正确：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">$ /bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl -s http://127.0.0.1:8080 get componentstatus</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">controller-manager   Healthy   ok</span><br><span class="line">scheduler            Healthy   ok</span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br><span class="line"></span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config set-cluster myk8s --server=http://127.0.0.1:8080</span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config set-context myk8s-context --cluster=myk8s --namespace=default --user=client</span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config use-context myk8s-context</span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config set preferences.colors true</span><br><span class="line">$ cat ~/.kube/config</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    server: http://127.0.0.1:8080</span><br><span class="line">  name: myk8s</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: myk8s</span><br><span class="line">    namespace: default</span><br><span class="line">    user: client</span><br><span class="line">  name: myk8s-context</span><br><span class="line">current-context: myk8s-context</span><br><span class="line">kind: Config</span><br><span class="line">preferences:</span><br><span class="line">  colors: true</span><br><span class="line">users: []</span><br><span class="line"></span><br><span class="line">$ /bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl get componentstatus</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">controller-manager   Healthy   ok</span><br><span class="line">scheduler            Healthy   ok</span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br><span class="line">$ ./_output/bin/kubectl get nodes</span><br><span class="line">NAME        STATUS    ROLES     AGE       VERSION</span><br><span class="line">127.0.0.1   Ready     &lt;none&gt;    11m       v1.12.0-alpha.0.1999+32dc6cc08aa034-dirty</span><br><span class="line">$ ./_output/bin/kubectl get events</span><br></pre></td></tr></table></figure></p>
<p>4，第四步，例如要调试kubelet服务的话，先停止该服务(sudo systemctl stop kubelet)，然后使用(dlv exec ${OUTDIR}/bin/kubelet – $kubelet_flags)命令启动，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sudo /bak/golang/bin/dlv --headless -l 127.0.0.1:1234 exec /bak/golang/src/k8s.io/kubernetes/_output/bin/kubelet -- --fail-swap-on=False --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice  --v=4</span><br><span class="line">API server listening at: 127.0.0.1:1234</span><br><span class="line"></span><br><span class="line">$ sudo /bak/golang/bin/dlv connect 127.0.0.1:1234</span><br><span class="line">Type &apos;help&apos; for list of commands.</span><br><span class="line">(dlv) b main.main</span><br><span class="line">Breakpoint 1 set at 0x2d08348 for main.main() ./_output/local/go/src/k8s.io/kubernetes/cmd/kubelet/kubelet.go:36</span><br><span class="line">(dlv) c</span><br></pre></td></tr></table></figure></p>
<h2 id="安装dashboard"><a href="#安装dashboard" class="headerlink" title="安装dashboard"></a>安装dashboard</h2><p>该命令(KUBE_ENABLE_CLUSTER_DASHBOARD=true ./hack/local-up-cluster.sh）会自动安装dashboard。<br>注意：如果不成功原因是需要用小写true，它是区分大小写的。</p>
<p>安装成功后使用命令（cluster/kubectl.sh cluster-info）查看它的访问地址如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://localhost:6443//api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure></p>
<p>这个链接有点问题，在api处有两个斜线会造成看不到UI，改成如下的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://localhost:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure></p>
<p>也可运行命令（kubectl proxy –port=8001 –kubeconfig=/var/run/kubernetes/admin.kubeconfig –accept-hosts=’^*$’）访问：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure></p>
<p>上面的’–accept-hosts’用于在非本机外部访问，但Dashboard只允许localhost和127.0.0.1使用HTTP连接进行访问，而其它地址只允许使用HTTPS。因此，如果需要在非本机访问Dashboard的话，只能采用NodePort:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system edit service kubernetes-dashboard</span><br><span class="line">$ kubectl -n kube-system get service kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.0.0.232   &lt;none&gt;        443:31050/TCP   1h</span><br><span class="line">visit: https://192.168.99.216:31050/</span><br></pre></td></tr></table></figure></p>
<p>这时访问dashboard仍然有下列问题:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;message&quot;: &quot;services \&quot;https:kubernetes-dashboard:\&quot; is forbidden: User \&quot;system:anonymous\&quot; cannot get services/proxy in the namespace \&quot;kube-system\&quot;: no RBAC policy matched&quot;,</span><br></pre></td></tr></table></figure></p>
<p>这是因为最新版的k8s默认启用了RBAC(–authorization-mode=Node,RBAC)，并为未认证用户赋予了一个默认的身份：anonymous<br>对于API Server来说，它是使用证书进行认证的，我们需要先创建一个证书：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># generate client-certificate-data</span><br><span class="line">grep &apos;client-certificate-data&apos; /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.crt</span><br><span class="line"># generate client-key-data</span><br><span class="line">grep &apos;client-key-data&apos; /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.key</span><br><span class="line"># generate p12</span><br><span class="line">openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name &quot;kubernetes-client&quot;</span><br></pre></td></tr></table></figure></p>
<p>然后将该p12证书导入到浏览器即可。此时默认的anonymous身份的token可以这样获取:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cluster/kubectl.sh get secret -n kube-system | grep dashboard</span><br><span class="line">cluster/kubectl.sh -n kube-system  get secret kubernetes-dashboard-token-kglhd -o jsonpath=&#123;.data.token&#125;| base64 -d</span><br></pre></td></tr></table></figure></p>
<p>anonymous身份可能看不到很多东西，所以我们再在kube-system名空间下再创建一个admin用户并和cluster-admin角色关联：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /tmp/admin-user.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line">cat &gt; /tmp/admin-user-role-binding.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line">cluster/kubectl.sh create -f /tmp/admin-user.yaml</span><br><span class="line">cluster/kubectl.sh create -f /tmp/admin-user-role-binding.yaml</span><br><span class="line">cluster/kubectl.sh -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin | awk &apos;&#123;print $1&#125;&apos;)</span><br></pre></td></tr></table></figure>
<p>##直接修改local-up-cluster.sh代替hyperkube用本地进程启动 ##<br>或者直接修改脚本去掉hyperkube, 然后运行ENABLE_CLUSTER_DASHBOARD=True ./hack/local-up-cluster.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">diff --git a/hack/local-up-cluster.sh b/hack/local-up-cluster.sh</span><br><span class="line">index 3b688d3..95de0df 100755</span><br><span class="line">--- a/hack/local-up-cluster.sh</span><br><span class="line">+++ b/hack/local-up-cluster.sh</span><br><span class="line">@@ -202,7 +202,8 @@ do</span><br><span class="line"> done</span><br><span class="line"></span><br><span class="line"> if [ &quot;x$GO_OUT&quot; == &quot;x&quot; ]; then</span><br><span class="line">-    make -C &quot;$&#123;KUBE_ROOT&#125;&quot; WHAT=&quot;cmd/kubectl cmd/hyperkube&quot;</span><br><span class="line">+    #make -C &quot;$&#123;KUBE_ROOT&#125;&quot; WHAT=&quot;cmd/kubectl cmd/hyperkube&quot;</span><br><span class="line">+    make -C &quot;$&#123;KUBE_ROOT&#125;&quot; GOGCFLAGS=&quot;-N -l&quot; WHAT=&quot;cmd/kubelet cmd/kube-proxy cmd/kube-apiserver cmd/kube-controller-manager cmd/cloud-controller-manager cmd/kube-scheduler cmd/kubectl&quot;</span><br><span class="line"> else</span><br><span class="line">     echo &quot;skipped the build.&quot;</span><br><span class="line"> fi</span><br><span class="line">@@ -578,7 +579,7 @@ function start_apiserver &#123;</span><br><span class="line">     fi</span><br><span class="line"></span><br><span class="line">     APISERVER_LOG=$&#123;LOG_DIR&#125;/kube-apiserver.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/hyperkube&quot; apiserver $&#123;swagger_arg&#125; $&#123;audit_arg&#125; $&#123;authorizer_arg&#125; $&#123;priv_arg&#125; $&#123;runtime_config&#125; \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/kube-apiserver&quot; $&#123;swagger_arg&#125; $&#123;audit_arg&#125; $&#123;authorizer_arg&#125; $&#123;priv_arg&#125; $&#123;runtime_config&#125; \</span><br><span class="line">       $&#123;cloud_config_arg&#125; \</span><br><span class="line">       $&#123;advertise_address&#125; \</span><br><span class="line">       $&#123;node_port_range&#125; \</span><br><span class="line">@@ -650,7 +651,7 @@ function start_controller_manager &#123;</span><br><span class="line">     fi</span><br><span class="line"></span><br><span class="line">     CTLRMGR_LOG=$&#123;LOG_DIR&#125;/kube-controller-manager.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/hyperkube&quot; controller-manager \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/kube-controller-manager&quot; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --vmodule=&quot;$&#123;LOG_SPEC&#125;&quot; \</span><br><span class="line">       --service-account-private-key-file=&quot;$&#123;SERVICE_ACCOUNT_KEY&#125;&quot; \</span><br><span class="line">@@ -685,7 +686,7 @@ function start_cloud_controller_manager &#123;</span><br><span class="line">     fi</span><br><span class="line"></span><br><span class="line">     CLOUD_CTLRMGR_LOG=$&#123;LOG_DIR&#125;/cloud-controller-manager.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; $&#123;EXTERNAL_CLOUD_PROVIDER_BINARY:-&quot;$&#123;GO_OUT&#125;/hyperkube&quot; cloud-controller-manager&#125; \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; $&#123;EXTERNAL_CLOUD_PROVIDER_BINARY:-&quot;$&#123;GO_OUT&#125;/cloud-controller-manager&quot;&#125; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --vmodule=&quot;$&#123;LOG_SPEC&#125;&quot; \</span><br><span class="line">       $&#123;node_cidr_args&#125; \</span><br><span class="line">@@ -791,7 +792,7 @@ function start_kubelet &#123;</span><br><span class="line">     )</span><br><span class="line"></span><br><span class="line">     if [[ -z &quot;$&#123;DOCKERIZE_KUBELET&#125;&quot; ]]; then</span><br><span class="line">-      sudo -E &quot;$&#123;GO_OUT&#125;/hyperkube&quot; kubelet &quot;$&#123;all_kubelet_flags[@]&#125;&quot; &gt;&quot;$&#123;KUBELET_LOG&#125;&quot; 2&gt;&amp;1 &amp;</span><br><span class="line">+      sudo -E &quot;$&#123;GO_OUT&#125;/kubelet&quot; &quot;$&#123;all_kubelet_flags[@]&#125;&quot; &gt;&quot;$&#123;KUBELET_LOG&#125;&quot; 2&gt;&amp;1 &amp;</span><br><span class="line">       KUBELET_PID=$!</span><br><span class="line">     else</span><br><span class="line"></span><br><span class="line">@@ -889,14 +890,14 @@ EOF</span><br><span class="line">       done</span><br><span class="line">     fi &gt;&gt;/tmp/kube-proxy.yaml</span><br><span class="line"></span><br><span class="line">-    sudo &quot;$&#123;GO_OUT&#125;/hyperkube&quot; proxy \</span><br><span class="line">+    sudo &quot;$&#123;GO_OUT&#125;/kube-proxy&quot; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --config=/tmp/kube-proxy.yaml \</span><br><span class="line">       --master=&quot;https://$&#123;API_HOST&#125;:$&#123;API_SECURE_PORT&#125;&quot; &gt;&quot;$&#123;PROXY_LOG&#125;&quot; 2&gt;&amp;1 &amp;</span><br><span class="line">     PROXY_PID=$!</span><br><span class="line"></span><br><span class="line">     SCHEDULER_LOG=$&#123;LOG_DIR&#125;/kube-scheduler.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/hyperkube&quot; scheduler \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/kube-scheduler&quot; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --kubeconfig &quot;$CERT_DIR&quot;/scheduler.kubeconfig \</span><br><span class="line">       --feature-gates=&quot;$&#123;FEATURE_GATES&#125;&quot; \</span><br></pre></td></tr></table></figure></p>
<h2 id="How-to-read-source-code"><a href="#How-to-read-source-code" class="headerlink" title="How to read source code"></a>How to read source code</h2><p><a href="http://dockone.io/article/895" target="_blank" rel="external">http://dockone.io/article/895</a></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://kubernetes.io/docs/imported/community/devel/" target="_blank" rel="external">https://kubernetes.io/docs/imported/community/devel/</a><br>[2] <a href="https://github.com/kubernetes/community/tree/master/contributors/devel" target="_blank" rel="external">https://github.com/kubernetes/community/tree/master/contributors/devel</a><br>[3] Bug - <a href="https://github.com/kubernetes/community/issues" target="_blank" rel="external">https://github.com/kubernetes/community/issues</a><br>[4] Submit code review - <a href="https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md</a><br>[5] Membership - <a href="https://github.com/kubernetes/community/blob/master/community-membership.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/community-membership.md</a><br>[6] CONTRIBUTING - <a href="https://github.com/kubernetes/community/blob/master/CONTRIBUTING.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/CONTRIBUTING.md</a><br>[7] Code format - <a href="https://github.com/golang/go/wiki/CodeReviewComments" target="_blank" rel="external">https://github.com/golang/go/wiki/CodeReviewComments</a><br>[8] Slack - <a href="https://kubernetes.slack.com/messages" target="_blank" rel="external">https://kubernetes.slack.com/messages</a><br>[9] Mail-list - <a href="https://groups.google.com/forum/#!forum/kubernetes-dev" target="_blank" rel="external">https://groups.google.com/forum/#!forum/kubernetes-dev</a><br>[10] SIG-list (Special Interest Groups) - <a href="https://github.com/kubernetes/community/blob/master/sig-list.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/sig-list.md</a><br>[11] open-bug - <a href="https://github.com/kubernetes/community/blob/master/contributors/guide/issue-triage.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/issue-triage.md</a><br>[12] BP - <a href="https://github.com/kubernetes/community/tree/master/contributors/design-proposals" target="_blank" rel="external">https://github.com/kubernetes/community/tree/master/contributors/design-proposals</a><br>[13] <a href="https://github.com/kubernetes/community/blob/master/community-membership.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/community-membership.md</a><br>[14] test - <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md</a><br>[15] <a href="https://ress.infoq.com/minibooks/Kubernetes-handbook/zh/pdf/kubernetes.pdf" target="_blank" rel="external">https://ress.infoq.com/minibooks/Kubernetes-handbook/zh/pdf/kubernetes.pdf</a><br>[16] <a href="https://kubernetes.io/docs/home/" target="_blank" rel="external">https://kubernetes.io/docs/home/</a><br>[17] <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way" target="_blank" rel="external">https://github.com/kelseyhightower/kubernetes-the-hard-way</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/10/Set-up-k8s-development-env-by-quqi99/" data-id="cjm8trj63000bbobpoucmq5ti" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-温故OpenStack中的测试-by-Joshua" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/10/温故OpenStack中的测试-by-Joshua/" class="article-date">
  <time datetime="2018-07-10T08:28:15.000Z" itemprop="datePublished">2018-07-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/10/温故OpenStack中的测试-by-Joshua/">温故OpenStack中的测试(by Joshua)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-03-15)</strong></p>
<ol>
<li><p>沿用tox调用virtualenv自动创建的虚拟环境(virtualenv -p python3.5 .tox/py35)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source .tox/py35/bin/activate</span><br><span class="line">sudo pip install --upgrade -r requirements.txt</span><br><span class="line">sudo pip install --upgrade -r test-requirements.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用unittest和nose运行测试。nose是对unittest的扩展，使得python的测试更加简单，nose自动发现测试代码并执行，nose提供了大量的插件，比如覆盖报表等。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python -m unittest -v unit_tests.test_neutron_utils.TestNeutronUtils.test_get_packages_ovs_newton</span><br><span class="line">.tox/py35/bin/python nosetests -v unit_tests/test_neutron_utils.py:TestNeutronUtils.test_get_packages_ovs_newton</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>注意：上面采用nosetests运行时会报错，因为我们的测试采用了python3, 所以需要在安装了python3-nose之后（sudo apt-get install python3-nose python3-mock）再采用下列三种方式之一运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nosetests3 -v unit_tests/test_neutron_utils.py:TestNeutronUtils.test_restart_map_ovs_odl</span><br><span class="line">/bak/work/charms/neutron-gateway/.tox/py35/bin/python /usr/local/bin/nosetests -v unit_tests/test_neutron_utils.py:TestNeutronUtils.test_get_packages_ovs_newton</span><br><span class="line">python -m nose unit_tests/test_neutron_utils.py:TestNeutronUtils.test_restart_map_ovs_odl</span><br></pre></td></tr></table></figure></p>
<p>但实际上仍然找不找nose模块，那是因为nose与virtualenv结合地不大好，在这个网页找着了答案(<a href="https://stackoverflow.com/questions/864956/problems-using-nose-in-a-virtualenv" target="_blank" rel="external">https://stackoverflow.com/questions/864956/problems-using-nose-in-a-virtualenv</a>) - You need to have a copy of nose installed in the virtual environment. In order to force installation of nose into the virtualenv, even though it is already installed in the global site-packages, run pip install with the -I flag: pip install nose -I</p>
<ol>
<li><p>上面使用unittest与nose运行测试的方式只是将结果输出到stdout，不便于分析。所以可以使用python-subunit模块来运行测试，并将测试结果通过subunit协议输出到文件中便于日后分析。因为subunit是基于二进制的不便于人眼看，所以可使用subunit2pyunit工具将其人类可读化。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python -m subunit.run discover |subunit2pyunit</span><br><span class="line">python -m subunit.run discover -t ./ ./unit_tests |subunit2pyunit</span><br><span class="line">python -m subunit.run unit_tests.test_neutron_utils.TestNeutronUtils. |subunit2pyunit</span><br></pre></td></tr></table></figure>
</li>
<li><p>在大型应用中分析测试结果很重要，testrepository可以调用subunit来用python-subunit模块来运行测试，并将测试结果通过subunit协议输出到文件中，然后testrepository在些基础上有更多的分析，如分析哪些用例运行的时间最长，如显示失败的用例，如仅运行上次运行失败的用例。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">testr init</span><br><span class="line">testr run</span><br><span class="line">testr run --parallel</span><br><span class="line">$ cat .testr.conf</span><br><span class="line">[DEFAULT]</span><br><span class="line">test_command=OS_STDOUT_CAPTURE=$&#123;OS_STDOUT_CAPTURE:-1&#125; \</span><br><span class="line">             OS_STDERR_CAPTURE=$&#123;OS_STDERR_CAPTURE:-1&#125; \</span><br><span class="line">             OS_TEST_TIMEOUT=$&#123;OS_TEST_TIMEOUT:-60&#125; \</span><br><span class="line">             $&#123;PYTHON:-python&#125; -m subunit.run discover -t ./ ./unit_tests $LISTOPT $IDOPTION</span><br><span class="line">test_id_option=--load-list $IDFILE</span><br><span class="line">test_list_option=--list</span><br></pre></td></tr></table></figure>
</li>
<li><p>tox用于创建虚拟python环境，也可以集成上面的testrepository(commands = ostestr {posargs})</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">$ cat tox.ini</span><br><span class="line">[tox]</span><br><span class="line">envlist = pep8,py27,py35</span><br><span class="line">skipsdist = True</span><br><span class="line"></span><br><span class="line">[testenv]</span><br><span class="line">setenv = VIRTUAL_ENV=&#123;envdir&#125;</span><br><span class="line">         PYTHONHASHSEED=0</span><br><span class="line">         CHARM_DIR=&#123;envdir&#125;</span><br><span class="line">         AMULET_SETUP_TIMEOUT=5400</span><br><span class="line">install_command =</span><br><span class="line">  pip install --allow-unverified python-apt &#123;opts&#125; &#123;packages&#125;</span><br><span class="line">commands = ostestr &#123;posargs&#125;</span><br><span class="line">whitelist_externals = juju</span><br><span class="line">passenv = HOME TERM AMULET_* CS_API_*</span><br><span class="line"></span><br><span class="line">[testenv:py27]</span><br><span class="line">basepython = python2.7</span><br><span class="line">deps = -r&#123;toxinidir&#125;/requirements.txt</span><br><span class="line">       -r&#123;toxinidir&#125;/test-requirements.txt</span><br><span class="line">commands = /bin/true</span><br><span class="line"></span><br><span class="line">[testenv:py35]</span><br><span class="line">basepython = python3.5</span><br><span class="line">deps = -r&#123;toxinidir&#125;/requirements.txt</span><br><span class="line">       -r&#123;toxinidir&#125;/test-requirements.txt</span><br><span class="line"></span><br><span class="line">[testenv:pep8]</span><br><span class="line">basepython = python2.7</span><br><span class="line">deps = -r&#123;toxinidir&#125;/requirements.txt</span><br><span class="line">       -r&#123;toxinidir&#125;/test-requirements.txt</span><br><span class="line">commands = flake8 &#123;posargs&#125; hooks unit_tests tests actions lib</span><br><span class="line">           charm-proof</span><br><span class="line"></span><br><span class="line">[flake8]</span><br><span class="line">ignore = E402,E226</span><br><span class="line">exclude = */helpers</span><br></pre></td></tr></table></figure>
</li>
<li><p>pydev使用virtualenv中的py35<br>在eclipse的”Preferences -&gt; Pydev -&gt; Interpreters -&gt; Python Interpreters”菜单中定义python35=/bak/work/charms/neutron-gateway/.tox/py35/bin/python,然后在工程上点右键从”Properties -&gt; Pydev - Interpreter/Grammar”定义使用python35。注意，需要将/bak/work/charms/neutron-gateway/.tox/py35/lib/python3.5/site-packages也选到环境变量中，否则后面会报ImportError: No module named ‘mock。<br>为一个测试类定义”Python unitest”类型的”Debug Configurations”, 也在其Interpreter选项卡中定义使用python35 (结果：eclipse似乎有bug，此处选择了python35后无法保存)<br>所以无法成功，似乎是pydev与python3协作不大好。最后还是pudb好使(sudo pip install pudb, import pudb; pdb.set_trace())</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/10/温故OpenStack中的测试-by-Joshua/" data-id="cjm8trj6k000tbobpne0bbht5" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Play-with-ceph-radosgw" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/13/Play-with-ceph-radosgw/" class="article-date">
  <time datetime="2018-06-13T10:56:45.000Z" itemprop="datePublished">2018-06-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/13/Play-with-ceph-radosgw/">Play with ceph-radosgw</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-06-13)</strong></p>
<h2 id="Rapidly-install"><a href="#Rapidly-install" class="headerlink" title="Rapidly install"></a>Rapidly install</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/openstack/charm-ceph-radosgw</span><br><span class="line">juju deploy ceph-radosgw --series xenial</span><br><span class="line">juju add-relation ceph-radosgw ceph</span><br><span class="line">juju add-relation keystone ceph-radosgw</span><br><span class="line">juju expose ceph-radosgw</span><br><span class="line">curl http://juju-332891-mitaka-ceph-13</span><br><span class="line"></span><br><span class="line">juju ssh ceph/0 &apos;sudo radosgw-admin metadata list user&apos;</span><br><span class="line">sudo radosgw-admin user create --uid=&quot;admin&quot; --display-name=&quot;admin&quot;</span><br><span class="line">sudo radosgw-admin usage show --uid=admin</span><br><span class="line">sudo radosgw-admin usage show --show-log-entries=false</span><br><span class="line">sudo radosgw-admin caps add --uid=admin --caps=&quot;users=*&quot;</span><br><span class="line">sudo radosgw-admin caps add --uid=admin --caps=&quot;usage=read&quot;</span><br><span class="line">sudo radosgw-admin bucket stats</span><br><span class="line">sudo radosgw-admin bucket stats --uid=anonymous</span><br></pre></td></tr></table></figure>
<h2 id="Use-s3cmd-client-to-visit-RGW"><a href="#Use-s3cmd-client-to-visit-RGW" class="headerlink" title="Use s3cmd client to visit RGW"></a>Use s3cmd client to visit RGW</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install s3cmd</span><br><span class="line">s3cmd --configure</span><br><span class="line">check_ssl_certificate = False</span><br><span class="line">check_ssl_hostname = False</span><br><span class="line">access_key = EJECCFLCB0K53EMVM3DL</span><br><span class="line">secret_key = C281KRmdFFWxzOHyjZ3OsvQorCgf1mxdML7kYJ1t</span><br><span class="line">cloudfront_host = juju-332891-mitaka-ceph-13</span><br><span class="line">host_base = juju-332891-mitaka-ceph-13:80</span><br><span class="line">host_bucket = %(bucket)s.juju-332891-mitaka-ceph-13</span><br><span class="line"></span><br><span class="line">s3cmd mb s3://my_test1</span><br><span class="line">s3cmd ls  # qeury bucket</span><br><span class="line">s3cmd put testfile s3://my_test1</span><br><span class="line">s3cmd ls s3://my_test1</span><br><span class="line">s3cmd get s3://my_test1/diff</span><br></pre></td></tr></table></figure>
<h2 id="Enable-usage-log"><a href="#Enable-usage-log" class="headerlink" title="Enable usage.log"></a>Enable usage.log</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">http://www.yangguanjun.com/2016/08/30/rgw-user-statistics/</span><br><span class="line">Add the following configurations into ceph-radosgw/0 node</span><br><span class="line">[client.radosgw.gateway]</span><br><span class="line">rgw enable usage log = true</span><br><span class="line">rgw usage log tick interval = 30</span><br><span class="line">rgw usage log flush threshold = 1024</span><br><span class="line">rgw usage max shards = 32</span><br><span class="line">rgw usage max user shards = 1</span><br><span class="line"></span><br><span class="line">sudo ceph osd pool create .usage 64   # create a pool for usage, run in &apos;ceph/0&apos;</span><br><span class="line">sudo ceph osd pool create .rgw 128 128</span><br><span class="line">sudo ceph osd pool create .rgw.root 128 128</span><br><span class="line">sudo ceph osd pool create .rgw.control 128 128</span><br><span class="line">sudo ceph osd pool create .rgw.gc 128 128</span><br><span class="line">sudo ceph osd pool create .rgw.buckets 128 128</span><br><span class="line">sudo ceph osd pool create .rgw.buckets.index 128 128</span><br><span class="line">sudo ceph osd pool create .log 128 128</span><br><span class="line">sudo ceph osd pool create .intent-log 128 128</span><br><span class="line">sudo ceph osd pool create .usage 128 128</span><br><span class="line">sudo ceph osd pool create .users 128 128</span><br><span class="line">sudo ceph osd pool create .users.email 128 128</span><br><span class="line">sudo ceph osd pool create .users.swift 128 128</span><br><span class="line">sudo ceph osd pool create .users.uid 128 128</span><br><span class="line"></span><br><span class="line">sudo /etc/init.d/radosgw restart</span><br><span class="line">ceph daemon /var/run/ceph/ceph-client.radosgw.gateway.asok config show # verify config, run in radosgw node</span><br><span class="line">sudo radosgw-admin usage show --show-log-entries=false  # after 1 hour, use radosgw-admin to see usage data, run in ceph/0</span><br></pre></td></tr></table></figure>
<h2 id="REST-API"><a href="#REST-API" class="headerlink" title="REST API"></a>REST API</h2><p>用REST API调用时遇到一个问题(radosgw-admin usage show无此问题), 就是看到anonymous用户有很多空bucket<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">$ sudo radosgw-admin usage show --uid=anonymous</span><br><span class="line">user.init failed: (13) Permission denied</span><br><span class="line"></span><br><span class="line">$./get_anonymous.py</span><br><span class="line">DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): juju-332891-mitaka-ceph-13</span><br><span class="line">DEBUG:urllib3.connectionpool:http://juju-332891-mitaka-ceph-13:80 &quot;GET /admin/usage?format=json&amp;show-summary=False&amp;uid=anonymous HTTP/1.1&quot; 200 242</span><br><span class="line">&lt;Response [200]&gt;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;entries&quot;:[</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;buckets&quot;:[</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;bucket&quot;:&quot;&quot;,</span><br><span class="line">                    &quot;categories&quot;:[</span><br><span class="line">                        &#123;</span><br><span class="line">                            &quot;bytes_received&quot;:0,</span><br><span class="line">                            &quot;bytes_sent&quot;:940,</span><br><span class="line">                            &quot;category&quot;:&quot;list_buckets&quot;,</span><br><span class="line">                            &quot;ops&quot;:4,</span><br><span class="line">                            &quot;successful_ops&quot;:4</span><br><span class="line">                        &#125;</span><br><span class="line">                    ],</span><br><span class="line">                    &quot;epoch&quot;:1528275600,</span><br><span class="line">                    &quot;owner&quot;:&quot;anonymous&quot;,</span><br><span class="line">                    &quot;time&quot;:&quot;2018-06-06 09:00:00.000000Z&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            &quot;user&quot;:&quot;anonymous&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ cat get_anonymous.py</span><br><span class="line">#!/usr/bin/python</span><br><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">import logging</span><br><span class="line">import argparse</span><br><span class="line">from awsauth import S3Auth</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.DEBUG)</span><br><span class="line">server = &apos;juju-332891-mitaka-ceph-13&apos;</span><br><span class="line">aws_key = &apos;EJECCFLCB0K53EMVM3DL&apos;</span><br><span class="line">secret = &apos;C281KRmdFFWxzOHyjZ3OsvQorCgf1mxdML7kYJ1t&apos;</span><br><span class="line">url = &apos;http://%s/admin/usage?format=json&amp;show-summary=False&amp;uid=anonymous&apos; % server</span><br><span class="line">response = requests.get(url, auth=S3Auth(aws_key, secret, server))</span><br><span class="line">print response</span><br><span class="line">print json.dumps(response.json(), sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;:&apos;))</span><br></pre></td></tr></table></figure></p>
<h2 id="Set-up-ceph-debug-env-in-boinic"><a href="#Set-up-ceph-debug-env-in-boinic" class="headerlink" title="Set up ceph debug env in boinic"></a>Set up ceph debug env in boinic</h2><p>gdb can also debug python by using prefix py- in gdb comand - <a href="http://linux-debug.blogspot.com/2015/01/ceph-debugging-python-code-in-gdb.html" target="_blank" rel="external">http://linux-debug.blogspot.com/2015/01/ceph-debugging-python-code-in-gdb.html</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/ceph/ceph</span><br><span class="line">git submodule update --force --init --recursive</span><br><span class="line">git checkout master</span><br><span class="line">./install-deps.sh</span><br><span class="line">sudo apt install libatomic-ops-dev libboost-dev libboost-iostreams-dev libboost-thread-dev libboost-random-dev libboost-program-options-dev libcurl4-openssl-dev libcunit1 libcunit1-dev liblz4-dev liboath-dev liblttng-ust-dev libcrypto++ libcrypto++-dev libgoogle-perftools4 libtool cython libsnappy-dev libleveldb-dev libblkid-dev libudev-dev libkeyutils-dev libcrypto++-dev libcrypto++-doc libcrypto++-utils libfuse-dev libcurl4-openssl-dev libxml++2.6-dev libssl-dev libgoogle-perftools-dev libgoogle-perftools4 libatomic-ops-dev libaio-dev  xfslibs-dev libboost-iostreams-dev libfcgi-dev</span><br><span class="line">sudo apt install gcr libblockdev-crypto2 libhcrypto4-heimdal libhogweed4 libk5crypto3 libnettle6 libsodium23 openssl python-m2crypto python3-crypto python3-cryptography</span><br><span class="line">#./autogen.sh &amp;&amp; ./configure  #old way, need to modifty makefile to &apos;-O0-Wall -g&apos; for debug</span><br><span class="line">./do_cmake.sh -DCMAKE_BUILD_TYPE=Debug</span><br><span class="line">cd build</span><br><span class="line">make -j56</span><br><span class="line">make ceph-osd -j56</span><br><span class="line"></span><br><span class="line">MON=1 OSD=3 MDS=1 MGR=1 RGW=1 ../src/vstart.sh -n -d --without-dashboard</span><br><span class="line">../src/stop.sh</span><br><span class="line">./bin/ceph -s</span><br><span class="line">./bin/ceph osd pool stats</span><br><span class="line">ps aux|grep ceph</span><br><span class="line">pstree -p</span><br><span class="line"></span><br><span class="line">./bin/radosgw-admin user create --uid=admin --display-name=admin --access-key=admin --secret=password</span><br><span class="line">./bin/radosgw-admin usage show --uid=admin</span><br><span class="line">./bin/radosgw-admin bucket stats --uid=anonymous</span><br><span class="line"></span><br><span class="line">sudo gdb attach $(pidof radosgw)</span><br><span class="line">(gdb) set solib-search-path /bak/linux/ceph/src/.libs/</span><br><span class="line">(gdb) set pagination off</span><br><span class="line">(gdb) b rgw/rgw_process.cc:38</span><br><span class="line">(gdb) b process_request</span><br><span class="line">(gdb) c</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/06/13/Play-with-ceph-radosgw/" data-id="cjm8trj63000abobpq7b5drna" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Play-with-LDAP-Keystone-by-quqi99" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/08/Play-with-LDAP-Keystone-by-quqi99/" class="article-date">
  <time datetime="2018-06-08T10:09:28.000Z" itemprop="datePublished">2018-06-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/08/Play-with-LDAP-Keystone-by-quqi99/">Play with LDAP + Keystone (by quqi99)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-05-29)</strong></p>
<h2 id="Install-OpenLDAP"><a href="#Install-OpenLDAP" class="headerlink" title="Install OpenLDAP"></a>Install OpenLDAP</h2><p>OpenLDAP Server可以使用这个charm安装 - <a href="https://jujucharms.com/u/openstack-charmers/ldap-test-fixture/3" target="_blank" rel="external">https://jujucharms.com/u/openstack-charmers/ldap-test-fixture/3</a>, 最终要添加的yaml如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keystone-ldap:</span><br><span class="line">  charm: cs:keystone-ldap-10</span><br><span class="line">ldap-test-fixture:</span><br><span class="line">  charm: cs:~openstack-charmers/ldap-test-fixture</span><br><span class="line"></span><br><span class="line">- [ keystone-ldap, keystone ]</span><br></pre></td></tr></table></figure></p>
<p>也可以根据这个链接分步安装 - <a href="https://api.jujucharms.com/charmstore/v5/~openstack-charmers/ldap-test-fixture-3/archive/hooks/install" target="_blank" rel="external">https://api.jujucharms.com/charmstore/v5/~openstack-charmers/ldap-test-fixture-3/archive/hooks/install</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">export DEBIAN_FRONTEND=noninteractive</span><br><span class="line">echo -e &quot; \</span><br><span class="line">slapd slapd/internal/generated_adminpw password password</span><br><span class="line">slapd slapd/password2 password password</span><br><span class="line">slapd slapd/internal/adminpw password password</span><br><span class="line">slapd slapd/password1 password password</span><br><span class="line">&quot; | sudo debconf-set-selections</span><br><span class="line">sudo apt install slapd ldap-utils phpldapadmin</span><br><span class="line">sed -i &quot;s/dc=example/dc=test/g&quot; /etc/phpldapadmin/config.php</span><br><span class="line">service apache2 restart</span><br><span class="line">sudo service slapd restart</span><br><span class="line">#sudo dpkg-reconfigure slapd  #configure domain=test.com</span><br><span class="line">#slappasswd -h &#123;SSHA&#125; -s password</span><br><span class="line">#sudo apt-get install jxplorer  #GUI</span><br><span class="line"></span><br><span class="line"># How to test it</span><br><span class="line">sudo ldapsearch -h 10.5.0.72 -x -w password -D&quot;cn=admin,dc=test,dc=com&quot; -b dc=test,dc=com -s sub &apos;(objectclass=*)&apos; cn sn</span><br><span class="line">sudo ldapsearch -h 10.5.0.72 -x -w password -D&quot;cn=admin,dc=test,dc=com&quot; -b ou=users,dc=test,dc=com  &apos;(objectclass=*)&apos;  cn sn</span><br><span class="line">sudo ldapsearch -h 10.5.0.72 -x -w password -D&quot;cn=admin,dc=test,dc=com&quot; -b dc=test,dc=com</span><br></pre></td></tr></table></figure></p>
<h2 id="Modify-default-schema-to-support-OpenStack"><a href="#Modify-default-schema-to-support-OpenStack" class="headerlink" title="Modify default schema to support OpenStack"></a>Modify default schema to support OpenStack</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://api.jujucharms.com/charmstore/v5/~openstack-charmers/ldap-test-fixture-3/archive/files/backup.ldif</span><br><span class="line">slapadd -v -c -l .backup.ldif</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ldapsearch -h 10.5.0.72 -x -w password -D&quot;cn=admin,dc=test,dc=com&quot; -b dc=test,dc=com</span><br><span class="line"># extended LDIF</span><br><span class="line">#</span><br><span class="line"># LDAPv3</span><br><span class="line"># base &lt;dc=test,dc=com&gt; with scope subtree</span><br><span class="line"># filter: (objectclass=*)</span><br><span class="line"># requesting: ALL</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># test.com</span><br><span class="line">dn: dc=test,dc=com</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: dcObject</span><br><span class="line">objectClass: organization</span><br><span class="line">o: test</span><br><span class="line">dc: test</span><br><span class="line"></span><br><span class="line"># admin, test.com</span><br><span class="line">dn: cn=admin,dc=test,dc=com</span><br><span class="line">objectClass: simpleSecurityObject</span><br><span class="line">objectClass: organizationalRole</span><br><span class="line">cn: admin</span><br><span class="line">description: LDAP administrator</span><br><span class="line">userPassword:: e1NTSEF9Q1RxNU1nNHA5blhlL25WVjBqenZSYTZ2VkxQQnVJZjc=</span><br><span class="line"></span><br><span class="line"># groups, test.com</span><br><span class="line">dn: ou=groups,dc=test,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">objectClass: top</span><br><span class="line">ou: groups</span><br><span class="line"></span><br><span class="line"># admin, groups, test.com</span><br><span class="line">dn: cn=admin,ou=groups,dc=test,dc=com</span><br><span class="line">cn: admin</span><br><span class="line">gidNumber: 500</span><br><span class="line">memberUid: johndoe</span><br><span class="line">objectClass: posixGroup</span><br><span class="line">objectClass: top</span><br><span class="line"></span><br><span class="line"># openstack, groups, test.com</span><br><span class="line">dn: cn=openstack,ou=groups,dc=test,dc=com</span><br><span class="line">cn: openstack</span><br><span class="line">gidNumber: 501</span><br><span class="line">memberUid: johndoe</span><br><span class="line">objectClass: posixGroup</span><br><span class="line">objectClass: top</span><br><span class="line"></span><br><span class="line"># users, test.com</span><br><span class="line">dn: ou=users,dc=test,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">objectClass: top</span><br><span class="line">ou: users</span><br><span class="line"></span><br><span class="line"># janedoe, users, test.com</span><br><span class="line">dn: cn=janedoe,ou=users,dc=test,dc=com</span><br><span class="line">cn: janedoe</span><br><span class="line">gidNumber: 500</span><br><span class="line">givenName: Jane</span><br><span class="line">homeDirectory: /home/users/janedoe</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">objectClass: top</span><br><span class="line">sn: Jane Doe</span><br><span class="line">uid: janedoe</span><br><span class="line">uidNumber: 1001</span><br><span class="line">userPassword:: e01ENX1IT01SNHBNMTV0M2dZZDhXVXhNRzhnPT0=</span><br><span class="line"></span><br><span class="line"># johndoe, users, test.com</span><br><span class="line">dn: cn=johndoe,ou=users,dc=test,dc=com</span><br><span class="line">cn: johndoe</span><br><span class="line">gidNumber: 501</span><br><span class="line">givenName: John</span><br><span class="line">homeDirectory: /home/users/jdoe</span><br><span class="line">loginShell: /bin/sh</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">objectClass: top</span><br><span class="line">sn: John Doe</span><br><span class="line">uid: johndoe</span><br><span class="line">uidNumber: 1000</span><br><span class="line">userPassword:: e01ENX1IT01SNHBNMTV0M2dZZDhXVXhNRzhnPT0=</span><br><span class="line"></span><br><span class="line"># search result</span><br><span class="line">search: 2</span><br><span class="line">result: 0 Success</span><br><span class="line"></span><br><span class="line"># numResponses: 9</span><br><span class="line"># numEntries: 8</span><br></pre></td></tr></table></figure>
<h2 id="Configure-Keystone"><a href="#Configure-Keystone" class="headerlink" title="Configure Keystone"></a>Configure Keystone</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">juju config keystone preferred-api-version=3</span><br><span class="line">juju deploy keystone-ldap --series xenial</span><br><span class="line">juju add-relation keystone-ldap keystone</span><br><span class="line"></span><br><span class="line">juju config keystone-ldap ldap-server=&quot;ldap://10.5.0.72&quot; ldap-user=&quot;cn=admin,dc=test,dc=com&quot; ldap-password=&quot;crapper&quot; ldap-suffix=&quot;dc=test,dc=com&quot;</span><br><span class="line">juju config keystone-ldap domain-name=&quot;aaa_domain&quot;</span><br><span class="line">juju config keystone-ldap ldap-config-flags=&quot;&#123; user_tree_dn: &apos;dc=test,dc=com&apos;, query_scope: &apos;sub&apos;, user_objectclass: posixAccount, user_id_attribute: uid, user_name_attribute: uid, group_tree_dn: &apos;ou=groups,dc=test,dc=com&apos;, group_objectclass: posixGroup, group_id_attribute: gidNumber, group_name_attribute: cn, group_member_attribute: memberUid, group_members_are_ids: True&#125;&quot;</span><br><span class="line"></span><br><span class="line">root@juju-67d093-xenial-queens-ldap-2:~# cat /etc/keystone/domains/keystone.aaa_domain.conf</span><br><span class="line">[ldap]</span><br><span class="line">url = ldap://10.5.0.72</span><br><span class="line">user = cn=admin,dc=test,dc=com</span><br><span class="line">password = password</span><br><span class="line">suffix = dc=test,dc=com</span><br><span class="line"></span><br><span class="line">user_allow_create = False</span><br><span class="line">user_allow_update = False</span><br><span class="line">user_allow_delete = False</span><br><span class="line"></span><br><span class="line">group_allow_create = False</span><br><span class="line">group_allow_update = False</span><br><span class="line">group_allow_delete = False</span><br><span class="line"></span><br><span class="line"># User supplied configuration flags</span><br><span class="line">group_id_attribute = gidNumber</span><br><span class="line">group_member_attribute = memberUid</span><br><span class="line">group_members_are_ids = True</span><br><span class="line">group_name_attribute = cn</span><br><span class="line">group_objectclass = posixGroup</span><br><span class="line">group_tree_dn = ou=groups,dc=test,dc=com</span><br><span class="line">query_scope = sub</span><br><span class="line">#user_id_attribute = uidNumber</span><br><span class="line">user_id_attribute = uid</span><br><span class="line">user_name_attribute = uid</span><br><span class="line">user_objectclass = posixAccount</span><br><span class="line">user_tree_dn = dc=test,dc=com</span><br><span class="line">[identity]</span><br><span class="line">driver = ldap</span><br></pre></td></tr></table></figure>
<p>注意， 上面有几个重要参数，注意是group_members_are_ids = True，下面将要着重讲解。<br>query_scope = sub<br>user_tree_dn = dc=test,dc=com<br>user_id_attribute = uid<br>group_members_are_ids = True<br>下面配置也可以work:<br>query_scope = base<br>user_tree_dn = dc=users,test,dc=com<br>user_id_attribute = uid<br>group_members_are_ids = True</p>
<h2 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">source ~/stsstack-bundles/novarcv3_domain</span><br><span class="line">export OS_REGION_NAME=RegionOne</span><br><span class="line">export OS_USER_DOMAIN_NAME=admin_domain</span><br><span class="line">export OS_AUTH_VERSION=3</span><br><span class="line">export OS_IDENTITY_API_VERSION=3</span><br><span class="line">export OS_PASSWORD=openstack</span><br><span class="line">export OS_DOMAIN_NAME=admin_domain</span><br><span class="line">export OS_AUTH_URL=http://10.5.0.53:5000/v3</span><br><span class="line">export OS_USERNAME=admin</span><br><span class="line"></span><br><span class="line">openstack domain create --description &quot;aaa_domain&quot; aaa_domain</span><br><span class="line">openstack domain list</span><br><span class="line">openstack project create myproject --domain aaa_domain</span><br><span class="line">openstack project list --domain aaa_domain</span><br><span class="line">#The token used to make the request was project scoped but the policy requires [&apos;system&apos;] scope</span><br><span class="line">#so it should be &apos;openstack  group create aaa_group&apos;</span><br><span class="line">#openstack group create aaa_group --domain aaa_domain</span><br><span class="line">#openstack group create aaa_group        #we use the default openstack instead</span><br><span class="line">openstack group list --domain aaa_domain</span><br><span class="line">openstack role list</span><br><span class="line">openstack user list --domain aaa_domain</span><br><span class="line">openstack user list --group openstack --domain aaa_domain</span><br><span class="line"></span><br><span class="line">#Assign Role to a user in a Domain, it used --domain</span><br><span class="line">#openstack role add --user johndoe --domain aaa_domain Member</span><br><span class="line">#Assign Role to a group in a project, it used --group-domain</span><br><span class="line">openstack role add --group openstack --group-domain aaa_domain --project myproject Member</span><br><span class="line">openstack role add --group openstack --group-domain aaa_domain --project myproject Admin</span><br><span class="line">openstack role list --group openstack --group-domain aaa_domain --project myproject</span><br><span class="line"></span><br><span class="line">$ openstack user list --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| 5d15ad6474b1f212d159d974eba4d6b402636e67a7253bf7acb64403ff8c2c53 | janedoe |</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line"></span><br><span class="line">$ openstack group contains user --group-domain aaa_domain --user-domain aaa_domain openstack johndoe</span><br><span class="line">johndoe in group openstack</span><br><span class="line"></span><br><span class="line">source ~/stsstack-bundles/novarcv3_project</span><br><span class="line">export OS_USER_DOMAIN_NAME=aaa_domain</span><br><span class="line">export OS_PROJECT_DOMAIN_NAME=aaa_domain</span><br><span class="line">export OS_PROJECT_NAME=myproject</span><br><span class="line">export OS_USERNAME=johndoe</span><br><span class="line">export OS_PASSWORD=crapper</span><br><span class="line">export OS_AUTH_URL=http://10.5.0.72:5000/v3</span><br><span class="line">export OS_AUTH_VERSION=3</span><br><span class="line">export OS_IDENTITY_API_VERSION=3</span><br><span class="line">export OS_REGION_NAME=RegionOne</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user show johndoe</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line">| Field               | Value                                                            |</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line">| domain_id           | ae678292805a4db7917137c0621fe4cc                                 |</span><br><span class="line">| id                  | dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 |</span><br><span class="line">| name                | johndoe                                                          |</span><br><span class="line">| options             | &#123;&#125;                                                               |</span><br><span class="line">| password_expires_at | None                                                             |</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list</span><br><span class="line">You are not authorized to perform the requested action: identity:list_users. (HTTP 403) (Request-ID: req-8c373161-37d7-4d33-9dda-16bdbd2cecb7)</span><br><span class="line"></span><br><span class="line">Why we are not authorized to run &apos;openstack user list&apos;, that&apos;s because the following policy rules.</span><br><span class="line"></span><br><span class="line">&quot;admin_required&quot;: &quot;role:Admin&quot;,</span><br><span class="line">&quot;cloud_admin&quot;: &quot;rule:admin_required and (is_admin_project:True or domain_id:59d6b9c88f654dba9d06772ec1b197f0 or project_id:bbbb856f30b042a9a64d6646273a9ae2)&quot;,</span><br><span class="line">&quot;owner&quot; : &quot;user_id:%(user_id)s or user_id:%(target.token.user_id)s&quot;,</span><br><span class="line">&quot;admin_and_matching_group_domain_id&quot;: &quot;rule:admin_required and domain_id:%(group.domain_id)s&quot;,</span><br><span class="line">&quot;admin_and_matching_domain_id&quot;: &quot;rule:admin_required and domain_id:%(domain_id)s&quot;,</span><br><span class="line"></span><br><span class="line">&quot;identity:get_user&quot;: &quot;rule:cloud_admin or rule:admin_and_matching_target_user_domain_id or rule:owner&quot;,</span><br><span class="line">&quot;identity:list_users&quot;: &quot;rule:cloud_admin or rule:admin_and_matching_domain_id&quot;,</span><br></pre></td></tr></table></figure>
<h2 id="问题一，找不着用户的调试"><a href="#问题一，找不着用户的调试" class="headerlink" title="问题一，找不着用户的调试"></a>问题一，找不着用户的调试</h2><p>找不着用户时, 可查看日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(keystone.common.ldap.core): 2018-06-08 12:13:23,145 DEBUG LDAP bind: who=cn=admin,dc=cloud,dc=sts</span><br><span class="line">(keystone.common.ldap.core): 2018-06-08 12:13:23,145 DEBUG LDAP search: base=dc=cloud,dc=sts scope=2 filterstr=(&amp;(uidNumber=10002)(objectClass=inetOrgPerson)) attrs=[&apos;description&apos;, &apos;uidNumber&apos;, &apos;userPassword&apos;, &apos;enabled&apos;, &apos;mail&apos;, &apos;uid&apos;] attrsonly=0</span><br></pre></td></tr></table></figure></p>
<p>转换成下列命令看是否能运行:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ldapsearch -h 10.5.0.53 -x -b &apos;dc=cloud,dc=sts&apos; -s sub &quot;(&amp;(uidNumber=10002)(objectClass=inetOrgPerson))&quot; description uidNumber userPassword enabled mail uid attrsonly=0</span><br></pre></td></tr></table></figure></p>
<h2 id="问题二，group-members-are-ids-True"><a href="#问题二，group-members-are-ids-True" class="headerlink" title="问题二，group_members_are_ids = True"></a>问题二，group_members_are_ids = True</h2><p>例如本例数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># Entry 5: cn=openstack,ou=groups,dc=test,dc=com</span><br><span class="line">dn: cn=openstack,ou=groups,dc=test,dc=com</span><br><span class="line">cn: openstack</span><br><span class="line">gidnumber: 501</span><br><span class="line">memberuid: johndoe</span><br><span class="line">objectclass: posixGroup</span><br><span class="line">objectclass: top</span><br><span class="line"></span><br><span class="line"># Entry 8: cn=johndoe,ou=users,dc=test,dc=com</span><br><span class="line">dn: cn=johndoe,ou=users,dc=test,dc=com</span><br><span class="line">cn: johndoe</span><br><span class="line">gidnumber: 501</span><br><span class="line">givenname: John</span><br><span class="line">homedirectory: /home/users/jdoe</span><br><span class="line">loginshell: /bin/sh</span><br><span class="line">objectclass: inetOrgPerson</span><br><span class="line">objectclass: posixAccount</span><br><span class="line">objectclass: top</span><br><span class="line">sn: John Doe</span><br><span class="line">uid: johndoe</span><br><span class="line">uidnumber: 1000</span><br><span class="line">userpassword: &#123;MD5&#125;HOMR4pM15t3gYd8WUxMG8g==</span><br><span class="line"># password is crapper</span><br></pre></td></tr></table></figure></p>
<p>根据这个bug描述 - <a href="https://bugs.launchpad.net/keystone/+bug/1526462" target="_blank" rel="external">https://bugs.launchpad.net/keystone/+bug/1526462</a><br>我们得知在posixGroup类型的group下可以有很多memberuid属性，如本例中为id的形式：<br>memberuid: johndoe<br>也可能为下列dn的形式：<br>memberuid: johndoe,ou=users,dc=test,dc=com<br>在使用rpdb (import rpdb;rpdb.set_trace())对代码调试(nc 127.0.0.1 4444)时会发现， 当group_members_are_ids=true时，list_group_users就不会再根据dn找id了。<br>同时下面的一个if语句(if group_member_id == user_id)决定配置中得是：user_id_attribute = uid<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">(Pdb) p group_member_id</span><br><span class="line">u&apos;johndoe&apos;</span><br><span class="line">(Pdb) p user_id</span><br><span class="line">u&apos;johndoe&apos;</span><br><span class="line">(Pdb) l</span><br><span class="line">142             # work.</span><br><span class="line">143             self.get_user(user_id)</span><br><span class="line">144             import rpdb;rpdb.set_trace()</span><br><span class="line">145             member_list = self.group.list_group_users(group_id)</span><br><span class="line">146             for group_member_id in self._transform_group_member_ids(member_list):</span><br><span class="line">147  -&gt;             if group_member_id == user_id:</span><br><span class="line">148                     break</span><br><span class="line">149             else:</span><br><span class="line">150                 raise exception.NotFound(_(&quot;User &apos;%(user_id)s&apos; not found in&quot;</span><br><span class="line">151                                            &quot; group &apos;%(group_id)s&apos;&quot;) %</span><br><span class="line">152                                          &#123;&apos;user_id&apos;: user_id,</span><br></pre></td></tr></table></figure></p>
<h2 id="问题三，怎么用LDAP里的用户"><a href="#问题三，怎么用LDAP里的用户" class="headerlink" title="问题三，怎么用LDAP里的用户"></a>问题三，怎么用LDAP里的用户</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line">1, Confirm the user johndoe is in the domain aaa_domain</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| 5d15ad6474b1f212d159d974eba4d6b402636e67a7253bf7acb64403ff8c2c53 | janedoe |</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line"></span><br><span class="line">2, Create a project myproject</span><br><span class="line"></span><br><span class="line">openstack project create myproject --domain aaa_domain</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack project list --domain aaa_domain</span><br><span class="line">+----------------------------------+-----------+</span><br><span class="line">| ID                               | Name      |</span><br><span class="line">+----------------------------------+-----------+</span><br><span class="line">| f239a9aebc974664b3fb7823d7d873fa | myproject |</span><br><span class="line">+----------------------------------+-----------+</span><br><span class="line"></span><br><span class="line">3, LDAP has two groups, one is admin, one is openstack, see https://api.jujucharms.com/charmstore/v5/~openstack-charmers/ldap-test-fixture-3/archive/files/backup.ldif</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack group list --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+-----------+</span><br><span class="line">| ID                                                               | Name      |</span><br><span class="line">+------------------------------------------------------------------+-----------+</span><br><span class="line">| a202723c28709cef142842b452fc93caf45d6b661e5d636a96cd10b9379fe0d2 | admin     |</span><br><span class="line">| c94536ce5d46380996999782dacf490b640385cd9b75450782cb279501238eac | openstack |</span><br><span class="line">+------------------------------------------------------------------+-----------+</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --group openstack --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --group admin --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line"></span><br><span class="line">3, Assign Role to a group in a project</span><br><span class="line"></span><br><span class="line">openstack role add --group openstack --project myproject --group-domain aaa_domain Member</span><br><span class="line">openstack role add --group openstack --project myproject --group-domain aaa_domain Admin</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack role list --group openstack --project myproject --group-domain aaa_domain</span><br><span class="line">Listing assignments using role list is deprecated. Use role assignment list --group &lt;group-name&gt; --project &lt;project-name&gt; --names instead.</span><br><span class="line">+----------------------------------+--------+-----------+-----------+</span><br><span class="line">| ID                               | Name   | Project   | Group     |</span><br><span class="line">+----------------------------------+--------+-----------+-----------+</span><br><span class="line">| 578a7eca0d184945b57ed0b718e59ae0 | Member | myproject | openstack |</span><br><span class="line">| 64c64c90886d4f3cb13d3c599748086b | Admin  | myproject | openstack |</span><br><span class="line">+----------------------------------+--------+-----------+-----------+</span><br><span class="line"></span><br><span class="line">4, Confirm the user johndoe in the the domain aaa_domain and group openstack</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --group openstack --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line"></span><br><span class="line">5, Switch to use the user johndoe</span><br><span class="line"></span><br><span class="line">source ~/stsstack-bundles/novarcv3_project</span><br><span class="line">export OS_USER_DOMAIN_NAME=aaa_domain</span><br><span class="line">export OS_PROJECT_DOMAIN_NAME=aaa_domain</span><br><span class="line">export OS_PROJECT_NAME=myproject</span><br><span class="line">export OS_USERNAME=johndoe</span><br><span class="line">export OS_PASSWORD=crapper</span><br><span class="line">export OS_AUTH_URL=http://10.5.0.72:5000/v3</span><br><span class="line">export OS_AUTH_VERSION=3</span><br><span class="line">export OS_IDENTITY_API_VERSION=3</span><br><span class="line">export OS_REGION_NAME=RegionOne</span><br><span class="line"></span><br><span class="line">6, Test the user johndoe</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user show johndoe</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line">| Field               | Value                                                            |</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line">| domain_id           | ae678292805a4db7917137c0621fe4cc                                 |</span><br><span class="line">| id                  | dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 |</span><br><span class="line">| name                | johndoe                                                          |</span><br><span class="line">| options             | &#123;&#125;                                                               |</span><br><span class="line">| password_expires_at | None                                                             |</span><br><span class="line">+---------------------+------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list</span><br><span class="line">You are not authorized to perform the requested action: identity:list_users. (HTTP 403) (Request-ID: req-8c373161-37d7-4d33-9dda-16bdbd2cecb7)</span><br><span class="line"></span><br><span class="line">Why we are not authorized to run &apos;openstack user list&apos;, that&apos;s because the following policy rules.</span><br><span class="line"></span><br><span class="line">&quot;admin_required&quot;: &quot;role:Admin&quot;,</span><br><span class="line">&quot;cloud_admin&quot;: &quot;rule:admin_required and (is_admin_project:True or domain_id:59d6b9c88f654dba9d06772ec1b197f0 or project_id:bbbb856f30b042a9a64d6646273a9ae2)&quot;,</span><br><span class="line">&quot;owner&quot; : &quot;user_id:%(user_id)s or user_id:%(target.token.user_id)s&quot;,</span><br><span class="line">&quot;admin_and_matching_group_domain_id&quot;: &quot;rule:admin_required and domain_id:%(group.domain_id)s&quot;,</span><br><span class="line">&quot;admin_and_matching_domain_id&quot;: &quot;rule:admin_required and domain_id:%(domain_id)s&quot;,</span><br><span class="line"></span><br><span class="line">&quot;identity:get_user&quot;: &quot;rule:cloud_admin or rule:admin_and_matching_target_user_domain_id or rule:owner&quot;,</span><br><span class="line">&quot;identity:list_users&quot;: &quot;rule:cloud_admin or rule:admin_and_matching_domain_id&quot;,</span><br><span class="line"></span><br><span class="line">怎么才能让openstack user list生效呢？</span><br><span class="line">1, LDAP中的两个组openstack与admin, johndoe都在这两个组下。</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --group openstack --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list --group admin --domain aaa_domain</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| ID                                                               | Name    |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">| dcb455d78a9cc380d615fa79c56569b3e9947d9af7a2f83813b53fca198b61a5 | johndoe |</span><br><span class="line">+------------------------------------------------------------------+---------+</span><br><span class="line">2, policy rules中在用project_id:bbbb856f30b042a9a64d6646273a9ae2</span><br><span class="line">所以首先得用admin权限为bbbb856f30b042a9a64d6646273a9ae2这个project添加Admin role：</span><br><span class="line">openstack role add --group admin --project bbbb856f30b042a9a64d6646273a9ae2 --group-domain aaa_domain Admin</span><br><span class="line">其将环境变量得使用这个group：</span><br><span class="line">unset OS_PROJECT_NAME</span><br><span class="line">export OS_PROJECT_ID=bbbb856f30b042a9a64d6646273a9ae2</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ openstack user list</span><br><span class="line">+----------------------------------+-------------------+</span><br><span class="line">| ID                               | Name              |</span><br><span class="line">+----------------------------------+-------------------+</span><br><span class="line">| 12507a988b8a438e85ee36617302fd34 | neutron           |</span><br><span class="line">| 1b8ad6f6fc4c479a90b7a34c8187cd3b | cinderv2_cinderv3 |</span><br><span class="line">| 2c6d8f3b156c45b5bb7998cca056edc4 | nova_placement    |</span><br><span class="line">| feaaf07467f142a5a5901ab066af9dca | glance            |</span><br><span class="line">+----------------------------------+-------------------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ env |grep OS_</span><br><span class="line">OS_PROJECT_ID=bbbb856f30b042a9a64d6646273a9ae2</span><br><span class="line">OS_REGION_NAME=RegionOne</span><br><span class="line">OS_USER_DOMAIN_NAME=aaa_domain</span><br><span class="line">OS_AUTH_VERSION=3</span><br><span class="line">OS_IDENTITY_API_VERSION=3</span><br><span class="line">OS_PASSWORD=crapper</span><br><span class="line">OS_AUTH_URL=http://10.5.0.72:5000/v3</span><br><span class="line">OS_USERNAME=johndoe</span><br><span class="line">OS_PROJECT_DOMAIN_NAME=aaa_domain</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/06/08/Play-with-LDAP-Keystone-by-quqi99/" data-id="cjm8trj5z0007bobph3ceih4i" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/09/10/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2018/09/09/Win-10-UEFI-Ubuntu-18-04-UEFI-双系统/">Win 10 UEFI + Ubuntu 18.04 UEFI 双系统</a>
          </li>
        
          <li>
            <a href="/2018/09/03/也谈wifi断流问题/">也谈wifi断流问题</a>
          </li>
        
          <li>
            <a href="/2018/08/03/IPv6来啦/">IPv6来啦</a>
          </li>
        
          <li>
            <a href="/2018/07/13/Using-kubeadm-to-deploy-k8s/">Using kubeadm to deploy k8s</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 张华<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>