<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="blog.csdn.net/quqi99">
<meta property="og:type" content="website">
<meta property="og:title" content="技术并艺术着">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="blog.csdn.net/quqi99">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="技术并艺术着">
<meta name="twitter:description" content="blog.csdn.net/quqi99">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>技术并艺术着</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">技术并艺术着</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">张华的技术博客 - blog.csdn.net/quqi99</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/03/08/ZFS-Cow-and-Ceph-CoW-and-CSI/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/08/ZFS-Cow-and-Ceph-CoW-and-CSI/" itemprop="url">ZFS Cow and Ceph CoW and CSI</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-03-08T12:03:48+08:00">
                2021-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华 发表于：2021-03-01<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</strong></p>
<h2 id="ZFS-Usage"><a href="#ZFS-Usage" class="headerlink" title="ZFS Usage"></a>ZFS Usage</h2><p>sudo apt install zfsutils-linux</p>
<p>#sudo zpool create new-pool /dev/sdb /dev/sdc         #striped pool, raid-0</p>
<p>#sudo zpool create new-pool mirror /dev/sdb /dev/sdc  #mirrored pool, raid-1<br>sudo zpool create -m /usr/share/pool new-pool mirror /dev/sdb /dev/sdc #-m is mount point<br>sudo zpool add new-pool /dev/sdx<br>sudo zpool status<br>zfs list<br>sudo zpool destroy new-pool<br>sudo zfs snapshot <pool-id><br>sudo zfs rollback <pool-id></pool-id></pool-id></p>
<h2 id="ZFS-CoW-Test"><a href="#ZFS-CoW-Test" class="headerlink" title="ZFS CoW Test"></a>ZFS CoW Test</h2><p>使用vim或rsync修改ZFS上的文件会导制整个文件重新写入，以CoW写入 (ZFS是文件系统级别CoW, Ceph是块级别Cow)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install zfs -y &amp;&amp; sudo /sbin/modprobe zfs</span><br><span class="line">dd if=/dev/zero of=/tmp/disk0  bs=1M  count=100</span><br><span class="line">sudo zpool create testpool /tmp/disk0</span><br><span class="line">sudo zfs create testpool/sdc</span><br><span class="line">sudo zfs get recordsize testpool/sdc</span><br><span class="line">sudo cp ~/.vimrc /testpool/sdc/vimrc</span><br><span class="line">$ ls -i /testpool/sdc/</span><br><span class="line">256 vimrc</span><br><span class="line">$ zdb -ddddd testpool/sdc 256</span><br><span class="line">...</span><br><span class="line">Indirect blocks:</span><br><span class="line">               0 L0 0:4ae00:3800 3800L/3800P F=1 B=152/152 cksum=52e2222c06f:25cf8696e8501d:b54096cb07913e1f:d6eba6a36d42e991</span><br><span class="line"></span><br><span class="line">zdb -R testpool 0:4ae00:3800:r &gt; /tmp/file</span><br><span class="line">$ diff /tmp/file /testpool/sdc/vimrc</span><br><span class="line">459d458</span><br><span class="line">&lt;</span><br><span class="line">\ No newline at end of file</span><br><span class="line"></span><br><span class="line">echo &apos;modify vimrc&apos; |sudo tee -a /testpool/sdc/vimrc</span><br><span class="line">$ ls -i /testpool/sdc/vimrc</span><br><span class="line">256 /testpool/sdc/vimrc</span><br><span class="line">$ zdb -ddddd testpool/sdc 256</span><br><span class="line">0 L0 0:69e00:3800 3800L/3800P F=1 B=189/189 cksum=52f651a16b5:25cf8cebaf016b:b54096de7b2dc560:d6eba6d2669c6ef3</span><br><span class="line"></span><br><span class="line">zdb -R testpool 0:4ae00:3800:r &gt; /tmp/file_old</span><br><span class="line">zdb -R testpool 0:69e00:3800:r　&gt; /tmp/file_new</span><br><span class="line">#vimdiff /tmp/file_old /tmp/file2</span><br><span class="line">$ diff /tmp/file_old /tmp/file_new</span><br><span class="line">459c459,462</span><br><span class="line">&lt;</span><br><span class="line">\ No newline at end of file</span><br><span class="line">---</span><br><span class="line">&gt; modify vimrc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sudo cp /testpool/sdc/vimrc /tmp/vimrc</span><br><span class="line">echo &apos;xxxxxxxxx&apos; |sudo tee -a /tmp/vimrc</span><br><span class="line">$ sudo rsync -av --inplace --no-whole-file /tmp/vimrc /testpool/sdc/vimrc</span><br><span class="line">sending incremental file list</span><br><span class="line">vimrc</span><br><span class="line">sent 506 bytes  received 161 bytes  1,334.00 bytes/sec</span><br><span class="line">total size is 14,335  speedup is 21.49</span><br><span class="line">$ zdb -ddddd testpool/sdc 256</span><br><span class="line">...</span><br><span class="line">0 L0 0:84e00:3800 3800L/3800P F=1 B=318/318 cksum=53056157fa5:25cf8f4613d2d3:b54096e2b7747740:d6eba6d8fd3d794b</span><br><span class="line">zdb -R testpool 0:84e00:3800:r &gt; /tmp/file_after_rsync_replace</span><br></pre></td></tr></table></figure></p>
<h2 id="Ceph-CoW-Test"><a href="#Ceph-CoW-Test" class="headerlink" title="Ceph CoW Test"></a>Ceph CoW Test</h2><p>ceph snapshot是把源volume基于CoW做一个只读副本，以后用于恢复。<br>ceph clone可以基于snapshot来做clone, 也是基于CoW。即基于snapshot的clone只创建了映射到源(这里是快照)的逻辑，没有给clone分配真实的物理空间。虽然快照是只读的，但是基于快照创建的克隆是可读可写的。当我们给clone的镜像写操作时系统才会真正的给clone的镜像分配物理空间。明白了上面的道理所以我们知道从快照克隆的镜像时依赖于快照的，一旦快照被删除则这个克隆镜像也就毁了，所以我们要保护好这个快照。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">./generate-bundle.sh --ceph --name k8s --create-model --run</span><br><span class="line">juju scp kubernetes-master/0:config ~/.kube/config</span><br><span class="line">juju ssh ceph-mon/0 -- sudo -s</span><br><span class="line">ceph -s</span><br><span class="line">ceph df</span><br><span class="line">ceph osd tree</span><br><span class="line">ceph osd lspools  #rados lspools</span><br><span class="line">rbd ls &lt;pool&gt;</span><br><span class="line"></span><br><span class="line">sudo modprobe rbd</span><br><span class="line">#pg_num=128(&lt;5 OSDs), pg_num=512(5~10 OSDs), pg_num=4096(10~50 OSDs)</span><br><span class="line"># pg_num(https://ceph.com/pgcalc/) (&gt; 50 OSDs)</span><br><span class="line">ceph osd pool create testpool 128</span><br><span class="line">sudo rbd create --size 1 -p testpool test1</span><br><span class="line">sudo rbd ls testpool</span><br><span class="line">sudo rbd info testpool/test1</span><br><span class="line"></span><br><span class="line">#create snap</span><br><span class="line">sudo rbd snap create testpool/test1@test1-snap</span><br><span class="line"># sudo rbd snap list testpool/test1</span><br><span class="line">SNAPID  NAME        SIZE   PROTECTED  TIMESTAMP</span><br><span class="line">     4  test1-snap  1 MiB             Mon Mar  8 02:57:24 2021</span><br><span class="line"></span><br><span class="line"># create clone</span><br><span class="line">sudo rbd snap protect testpool/test1@test1-snap</span><br><span class="line">sudo rbd clone testpool/test1@test1-snap testpool/test1-snap-clone</span><br><span class="line">sudo rbd snap unprotect testpool/test1@test1-snap</span><br><span class="line">#sudo rbd snap rm testpool/test1@test1-snap</span><br><span class="line"># sudo rbd ls testpool</span><br><span class="line">test1</span><br><span class="line">test1-snap-clone</span><br><span class="line"># sudo rbd info testpool/test1-snap-clone |grep parent</span><br><span class="line">        parent: testpool/test1@test1-snap</span><br><span class="line"></span><br><span class="line">#如果不想被依赖于快照，需要对克隆和快照做一个合并</span><br><span class="line">sudo rbd flatten testpool/test1-snap-clone</span><br><span class="line"># sudo rbd info testpool/test1-snap-clone |grep parent</span><br><span class="line">#</span><br></pre></td></tr></table></figure>
<h2 id="k8s使用ceph-csi消费RBD作为持久化存储"><a href="#k8s使用ceph-csi消费RBD作为持久化存储" class="headerlink" title="k8s使用ceph-csi消费RBD作为持久化存储"></a>k8s使用ceph-csi消费RBD作为持久化存储</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#set up ceph k8s env</span><br><span class="line">./generate-bundle.sh --ceph --name k8s --create-model --run</span><br><span class="line">juju scp kubernetes-master/0:config ~/.kube/config</span><br><span class="line"></span><br><span class="line">charm yaml已经帮助部署了ceph-csi(git clone https://github.com/ceph/ceph-csi.git), 如果重头开始搭建见：</span><br><span class="line">K8S使用ceph-csi持久化存储之RBD - https://mp.weixin.qq.com/s?__biz=MzAxMjk0MTYzNw==&amp;mid=2247484067&amp;idx=1&amp;sn=43bdeb61540c088035d798ee42bbd076</span><br></pre></td></tr></table></figure>
<h2 id="k8s使用ceph-csi持久化存储之CephFS"><a href="#k8s使用ceph-csi持久化存储之CephFS" class="headerlink" title="k8s使用ceph-csi持久化存储之CephFS"></a>k8s使用ceph-csi持久化存储之CephFS</h2><p>k8s也可以在块的基础上来使用FS, 见 - <a href="https://www.cnblogs.com/wsjhk/p/13710577.html" target="_blank" rel="external">https://www.cnblogs.com/wsjhk/p/13710577.html</a></p>
<h2 id="k8s-CSI插件开发"><a href="#k8s-CSI插件开发" class="headerlink" title="k8s CSI插件开发"></a>k8s CSI插件开发</h2><p>k8s CSI插件开发导读见  - <a href="https://www.jianshu.com/p/88ec8cba7507" target="_blank" rel="external">https://www.jianshu.com/p/88ec8cba7507</a></p>
<p>ZFS CSI Driver - <a href="https://github.com/openebs/zfs-localpv" target="_blank" rel="external">https://github.com/openebs/zfs-localpv</a><br>Ceph CSI Driver - <a href="https://github.com/ceph/ceph-csi" target="_blank" rel="external">https://github.com/ceph/ceph-csi</a></p>
<p>控制器 （<a href="https://github.com/openebs/zfs-localpv/blob/master/pkg/driver/controller.go）实现了Volume" target="_blank" rel="external">https://github.com/openebs/zfs-localpv/blob/master/pkg/driver/controller.go）实现了Volume</a>, Snap等生命周期管理的方法。</p>
<ul>
<li>CreateZFSVolume</li>
<li>CreateSnapClone</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://ubuntu.com/tutorials/setup-zfs-storage-pool#2-installing-zfs" target="_blank" rel="external">https://ubuntu.com/tutorials/setup-zfs-storage-pool#2-installing-zfs</a><br>[2] <a href="http://tim-tang.github.io/blog/2016/06/05/zfs-cow-deepin" target="_blank" rel="external">http://tim-tang.github.io/blog/2016/06/05/zfs-cow-deepin</a><br>[3] <a href="https://my.oschina.net/wangzilong/blog/1595081" target="_blank" rel="external">https://my.oschina.net/wangzilong/blog/1595081</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/03/08/Ubuntu-14-04下单节点Ceph安装/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/08/Ubuntu-14-04下单节点Ceph安装/" itemprop="url">Ubuntu 14.04下单节点Ceph安装</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-03-08T10:34:38+08:00">
                2021-03-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2014-06-23<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>(<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )<br>Ceph理论<br>    见我的博客：<a href="http://blog.csdn.net/quqi99/article/details/32939509" target="_blank" rel="external">http://blog.csdn.net/quqi99/article/details/32939509</a></p>
<pre><code>注意点：

 a, 一个ceph cluster至少需要1个mon节点和2个osd节点才能达到active + clean状态(故osd pool default size得&gt;=2, 注意：如果不想复制的话，弄一个osd节点也是可以的，只需要将复制的备份数由默认3改为1即可，即sudo ceph osd pool set data min_size 1)，meta节点只有运行ceph文件系统时才需要。

    所以如果只有一个单节点的话，需要在ceph deploy new命令之后紧接着执行下列命令修改ceph.conf配置：

    echo &quot;osd crush chooseleaf type = 0&quot; &gt;&gt; ceph.conf
    echo &quot;osd pool default size = 1&quot; &gt;&gt; ceph.conf

    osd crush chooseleaf type参数很重要，解释见：https://ceph.com/docs/master/rados/configuration/ceph-conf/

 b, 多个网卡的话，可在ceph.conf的[global]段中添加public network = {cidr}参数

 c, 一个osd块设备最好大于5G，不然创建日志系统时会空间太小, 或修改：

    echo &quot;osd journal size = 100&quot; &gt;&gt; ceph.conf

 d, 测试时不想那么涉及权限那么麻烦，可以

   echo &quot;auth cluster required = none&quot; &gt;&gt; ceph.conf
   echo &quot;auth service required = none&quot; &gt;&gt; ceph.conf
   echo &quot;auth client required = none&quot; &gt;&gt; ceph.conf

 e, 想使用权限的话，步骤如下：
</code></pre><p>一旦 cephx 启用， ceph 会在默认的搜索路径寻找 keyring ， 像 /etc/ceph/ceph.$name.keyring 。可以的 ceph 配置文件的 [global] 段，加入 keyring 配置指定这个路径。但不推荐这样做。<br>创建 client.admin key ， 并在你的 client host 上保存一份<br>$ ceph auth get-or-create client.admin mon ‘allow <em>‘ mds ‘allow </em>‘ osd ‘allow *’ -o /etc/ceph/ceph.client.admin.keyring<br>注意 ： 此命令会毁坏己有的 /etc/ceph/ceph.client.admin.keyring 。</p>
<p>为你的 cluster 创建一个 keyring ，创建一个 monitor 安全 key<br>$ ceph-authtool –create-keyring /tmp/ceph.mon.keyring –gen-key -n mon. –cap mon ‘allow *’<br>复制上面创建的 monitor keyring 到所有 monitor 的 mon data 目录，并命名为 ceph.mon.keyring 。例如，复制它到 cluster ceph 的 mon.a monitor<br>$ cp /tmp/ceph.mon.keyring /var/lib/ceph/mon/ceph-$(hostname)/keyring<br>为所有 OSD 生成安全 key ， {$id} 指 OSD number</p>
<p>$ ceph auth get-or-create osd.{$id} mon ‘allow rwx’ osd ‘allow *’ -o /var/lib/ceph/osd/ceph-{$id}/keyring<br>为所有 MDS 生成安全 key , {$id} 指 MDS letter</p>
<p>$ ceph auth get-or-create mds.{$id} mon ‘allow rwx’ osd ‘allow <em>‘ mds ‘allow </em>‘ -o /var/lib/ceph/mds/ceph-{$id}/keyring<br>为 0.51 版本以上的 ceph 启动 cephx 认证，在配置文件的 [global] 段加入</p>
<p>auth cluster required = cephx<br>auth service required = cephx<br>auth client required = cephx</p>
<p> 环境准备<br>    单节点node1上同时安装osd(一块块设备/dev/ceph-volumes/lv-ceph0），mds, mon, client与admin。<br>    1, 确保/etc/hosts, 例: 本例中的hostname叫node1, 如果不是node1请换成别的</p>
<p>local_host=”<code>hostname --fqdn</code>“<br>local_ip=<code>host $local_host 2&gt;/dev/null | awk &#39;{print $NF}&#39; |head -n 1</code><br>sudo bash -c ‘cat &gt;&gt; /etc/hosts’ &lt;&lt; EOF<br><code>echo $local_ip</code>   <code>echo $local_host</code><br>EOF<br>sudo sed -i “/$local_host/“d /etc/hosts<br>ssh-copy-id -i ~/.ssh/id_rsa.pub $local_ip #run multiple times if there are mutliple nodes<br>ping -c 1 $local_ip</p>
<pre><code>2, 确保安装ceph-deply的机器和其它所有节点的ssh免密码访问(ssh-keygen &amp;&amp; ssh-copy-id othernode)
</code></pre><p>安装步骤(注意，下面所有的操作均在admin节点进行）<br>1, 准备两块块设备（块设备可以是硬盘，也可以是LVM卷），我们这里使用文件裸设备模拟. 若想直接使用裸设备的话，直接用losetup加载即可： sudo losetup –show -f /images/ceph-volumes.img</p>
<p>sudo mkdir -p /images &amp;&amp; sudo chown $(whoami) /images<br>dd if=/dev/zero of=/images/ceph-volumes.img bs=1M count=8192 oflag=direct<br>sudo losetup -d /dev/loop0 &gt; /dev/null 2&gt;&amp;1<br>sudo vgremove -y ceph-volumes &gt; /dev/null 2&gt;&amp;1<br>sudo vgcreate ceph-volumes $(sudo losetup –show -f /images/ceph-volumes.img)<br>sudo lvcreate -L2G -nceph0 ceph-volumes<br>sudo lvcreate -L2G -nceph1 ceph-volumes<br>sudo mkfs.xfs -f /dev/ceph-volumes/ceph0<br>sudo mkfs.xfs -f /dev/ceph-volumes/ceph1<br>sudo mkdir -p /srv/ceph/{osd0,osd1,mon0,mds0} &amp;&amp; sudo chown -R $(whoami) /srv<br>sudo mount /dev/ceph-volumes/ceph0 /srv/ceph/osd0<br>sudo mount /dev/ceph-volumes/ceph1 /srv/ceph/osd1</p>
<p>2, 找一个工作目录创建集群, ceph-deploy new {ceph-node} {ceph-other-node}，它将部署新的monitor节点</p>
<p>   sudo apt-get -y install ceph ceph-deploy<br>   mkdir ceph-cluster &amp;&amp; cd ceph-cluster<br>   ceph-deploy new node1 #如果是多节点，就将节点都列在后面</p>
<p>   hua@node1:/bak/work/ceph-cluster$ ls .<br>     ceph.conf  ceph-deploy-ceph.log  ceph.mon.keyring</p>
<p>   它将在当前目录生成ceph.conf及ceph.mon.keyring (这个相当于人工执行： ceph-authtool –create-keyring ceph.mon.keyring –gen-key -n mon. –cap mon “allow *’ )</p>
<pre><code> 如果只有一个节点，还需要执行：

    echo &quot;osd crush chooseleaf type = 0&quot; &gt;&gt; ceph.conf
    echo &quot;osd pool default size = 1&quot; &gt;&gt; ceph.conf

    echo &quot;osd journal size = 100&quot; &gt;&gt; ceph.conf

    echo &quot;rbd_default_features = 1&quot; &gt;&gt; ceph.conf

最终ceph.conf的内容如下：
</code></pre><p>[global]<br>fsid = f1245211-c764-49d3-81cd-b289ca82a96d<br>mon_initial_members = node1<br>mon_host = 192.168.99.124<br>auth_cluster_required = cephx<br>auth_service_required = cephx<br>auth_client_required = cephx<br>filestore_xattr_use_omap = true<br>osd crush chooseleaf type = 0<br>osd pool default size = 1<br>osd journal size = 100</p>
<p>rbd_default_features = 1</p>
<p>也可继续为ceph指定网络，下面两个参数可配置在每个段之中：</p>
<p>cluster network = 10.0.0.0/8<br>public network = 192.168.5.0/24</p>
<p>3, 安装Ceph基本库到各节点(ceph, ceph-common, ceph-fs-common, ceph-mds, gdisk)， ceph-deploy install {ceph-node}[{ceph-node} …]</p>
<p>   ceph-deploy purgedata node1</p>
<p>   ceph-deploy forgetkeys<br>   ceph-deploy install node1  #如果是多节点，就将节点都列在后面</p>
<p>   它会执行，sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get -q -o Dpkg::Options::=–force-confnew –no-install-recommends –assume-yes install – ceph ceph-mds ceph-common ceph-fs-common gdisk</p>
<p>4, 增加一个集群监视器, ceph-deploy mon create {ceph-node}</p>
<p>   sudo chown -R hua:root /var/run/ceph/<br>   sudo chown -R hua:root /var/lib/ceph/<br>   ceph-deploy –overwrite-conf mon create node1   #如果是多节点就将节点都列在后面</p>
<pre><code>相当于：

sudo ceph-authtool /var/lib/ceph/tmp/keyring.mon.$(hostname) --create-keyring --name=mon. --add-
</code></pre><p>key=$(ceph-authtool –gen-print-key) –cap mon ‘allow *’</p>
<pre><code>sudo ceph-mon -c /etc/ceph/ceph.conf --mkfs -i $(hostname) --keyring /var/lib/ceph/tmp/keyring.mon
</code></pre><p>.$(hostname)</p>
<p>   sudo initctl emit ceph-mon id=$(hostname)</p>
<p>5, 获取密钥，会在my-cluster目录下生成几个key</p>
<p>   ceph-deploy mon create-initial</p>
<p>hua@node1:/bak/work/ceph-cluster$ ls<br>ceph.bootstrap-mds.keyring  ceph.bootstrap-rgw.keyring  ceph.conf             ceph.mon.keyring<br>ceph.bootstrap-osd.keyring  ceph.client.admin.keyring   ceph-deploy-ceph.log</p>
<p>6, 增加osd, ceph-deploy osd prepare {ceph-node}:/path/to/directory<br>   ceph-deploy osd prepare node1:/srv/ceph/osd0<br>   ceph-deploy osd prepare node1:/srv/ceph/osd1</p>
<pre><code>若使用了cephx权限的话，可以：
</code></pre><p>   OSD_ID=$(sudo ceph -c /etc/ceph/ceph.conf osd create)<br>   sudo ceph -c /etc/ceph/ceph.conf auth get-or-create osd.${OSD_ID} mon ‘allow profile osd ‘ osd<br> ‘allow *’ | sudo tee ${CEPH_DATA_DIR}/osd/ceph-${OSD_ID}/keyring</p>
<p>7, 激活OSD, ceph-deploy osd activate {ceph-node}:/path/to/directory</p>
<p>   sudo chmod 777 /srv/ceph/osd0<br>   sudo chmod 777 /srv/ceph/osd1<br>   sudo ceph-deploy osd activate node1:/srv/ceph/osd0</p>
<p>   sudo ceph-deploy osd activate node1:/srv/ceph/osd1<br>   若出现错误ceph-disk: Error: No cluster conf found，那是需要清空/src/ceph/osd0</p>
<p>8, 复制 admin 密钥到其他节点, 复制 ceph.conf, ceph.client.admin.keyring 到 ceph{1,2,3}:/etc/ceph<br>   ceph-deploy admin node1</p>
<p>   ssh node1 ls /etc/ceph/ceph.conf</p>
<p>9, 验证<br>   sudo ceph -s<br>   sudo ceph osd tree </p>
<p>hua@node1:/bak/work/ceph-cluster$ sudo ceph -s<br>    cluster 333a8495-601f-4237-9b60-c07e13b80b5b<br>     health HEALTH_OK<br>     monmap e1: 1 mons at {node1=192.168.99.124:6789/0}<br>            election epoch 3, quorum 0 node1<br>     osdmap e9: 2 osds: 2 up, 2 in<br>            flags sortbitwise,require_jewel_osds<br>      pgmap v27: 64 pgs, 1 pools, 0 bytes data, 0 objects<br>            269 MB used, 3806 MB / 4076 MB avail<br>                  64 active+clean</p>
<p>hua@node1:/bak/work/ceph-cluster$ sudo ceph osd tree<br>ID WEIGHT  TYPE NAME      UP/DOWN REWEIGHT PRIMARY-AFFINITY<br>-1 0.00378 root default<br>-2 0.00378     host node1<br> 0 0.00189         osd.0       up  1.00000          1.00000<br> 1 0.00189         osd.1       up  1.00000          1.00000 </p>
<p>10, 添加新的mon<br>   多个mon可以高可用，<br>   1）修改/etc/ceph/ceph.conf文件，如修改：mon_initial_members = node1 node2<br>   2) 同步配置到其它节点，ceph-deploy –overwrite-conf config push node1 node2<br>   3) 创建mon, ceph-deploy node1 node2<br>11, 添加新mds, 只有文件系统只需要mds,目前官方只推荐在生产环境中使用一个 mds。<br>12, 作为文件系统使用直接mount即可，mount -t ceph node1:6789:/ /mnt -o name=admin,secret=<keyring><br>13, 作为块设备使用：<br>    sudo modprobe rbd</keyring></p>
<pre><code>sudo rados mkpool data
sudo ceph osd pool set data min_size 1  
sudo rbd create --size 1 -p data test1 
sudo rbd map test1 --pool data

rbd list -p data

rbd info test1 -p data
</code></pre><p>hua@node1:/bak/work/ceph-cluster$ sudo rados -p data ls<br>rbd_object_map.102174b0dc51<br>rbd_id.test1<br>rbd_directory<br>rbd_header.102174b0dc51</p>
<p>hua@node1:/bak/work/ceph-cluster$ rbd list -p data<br>test1</p>
<p>hua@node1:/bak/work/ceph-cluster$ rbd info test1 -p data<br>rbd image ‘test1’:<br>size 1024 kB in 1 objects<br>order 22 (4096 kB objects)<br>block_name_prefix: rbd_data.102174b0dc51<br>format: 2<br>features: layering, exclusive-lock, object-map, fast-diff, deep-flatten<br>flags:</p>
<p>接着要map设设备到操作系统，但却报如下的错：</p>
<p>hua@node1:/bak/work/ceph-cluster$ sudo rbd map test1 -p data<br>rbd: sysfs write failed<br>RBD image feature set mismatch. You can disable features unsupported by the kernel with “rbd feature disable”.<br>In some cases useful info is found in syslog - try “dmesg | tail” or so.<br>rbd: map failed: (6) No such device or address</p>
<p>这是因为rbd镜像的一些特性，kernel并不支持，所以映射失败，需要disable掉不支持的特性。可在ceph.conf中添加“rbd_default_features = 1”解决。</p>
<p>hua@node1:/bak/work/ceph-cluster$ rbd info test1 -p data |grep feature<br>features: layering, exclusive-lock, object-map, fast-diff, deep-flatten</p>
<p>hua@node1:/bak/work/ceph-cluster$ sudo rbd map test1 -p data<br>/dev/rbd0</p>
<p>hua@node1:/bak/work/ceph-cluster$ rbd showmapped<br>id pool image snap device<br>0  data test2 -    /dev/rbd0</p>
<p>接着格式化并使用它:</p>
<p>sudo mkfs.ext4 /dev/rbd0</p>
<p>mkdir test &amp;&amp; sudo mount /dev/rbd0 test</p>
<p>hua@node1:/bak/work/ceph-cluster$ mount |grep test<br>/dev/rbd0 on /bak/work/ceph-cluster/test type ext4 (rw,relatime,block_validity,delalloc,barrier,user_xattr,acl,stripe=4096)</p>
<p>14, 命令操作<br>   1)默认有3个池<br>     $ sudo rados lspools<br>      data<br>      metadata<br>      rbd<br>      创建池：$ sudo rados mkpool nova<br>   2)将data池的文件副本数设为2, 此值是副本数（总共有2个osd, 如果只有一个osd的话就设置为1),如果不设置这个就命令一直不返回<br>     $ sudo ceph osd pool set data min_size 2<br>       set pool 0 min_size to 1<br>   3)上传一个文件，$ sudo rados put test.txt ./test.txt –pool=data<br>   4)查看文件，<br>     $ sudo rados -p data ls<br>       test.txt<br>   5)查看对象位置<br>     $ sudo ceph osd map data test.txt<br>       osdmap e9 pool ‘data’ (0) object ‘test.txt’ -&gt; pg 0.8b0b6108 (0.8) -&gt; up ([0], p0) acting ([0], p0)<br>     $ cat /srv/ceph/osd0/current/0.8_head/test.txt<strong>head_8B0B6108</strong>0<br>       test<br>   6)添加一个新osd后，可以用“sudo ceph -w”命令看到对象在群体内迁移<br>16, Ceph与Cinder集成, 见：<a href="http://ceph.com/docs/master/rbd/rbd-openstack/" target="_blank" rel="external">http://ceph.com/docs/master/rbd/rbd-openstack/</a><br>   1) 集建池<br>      sudo ceph osd pool create volumes 8<br>      sudo ceph osd pool create images 8<br>      sudo ceph osd pool set volumes min_size 2<br>      sudo ceph osd pool set images min_size 2<br>   2) 配置glance-api, cinder-volume, nova-compute的节点作为ceph client，因为我的全部是一台机器就不需要执行下列步骤<br>      a, 都需要ceph.conf, ssh {openstack-server} sudo tee /etc/ceph/ceph.conf &lt; /etc/ceph/ceph.conf<br>      b, 都需要安装ceph client, sudo apt-get install python-ceph ceph-common<br>      c, 为images池创建cinder用户，为images创建glance用户，并给用户赋予权限<br>         sudo ceph auth get-or-create client.cinder mon ‘allow r’ osd ‘allow class-read object_prefixrbd_children,allow rwx pool=volumes,allow rx pool=images’<br>         sudo ceph auth get-or-create client.glance mon ‘allow r’ osd ‘allow class-read object_prefixrbd_children,allow rwx pool=images’\</p>
<pre><code>     如果涉及了权限的话，命令看起来像这样：

     ceph --name mon. --keyring /var/lib/ceph/mon/ceph-p01-storage-a1-e1c7g8/keyring auth get-or-create client.nova-compute mon allow rw osd allow rwx
  d, 为cinder和glance生成密钥（ceph.client.cinder.keyring与ceph.client.glance.keyring）

     sudo chown -R hua:root /etc/ceph
     ceph auth get-or-create client.glance | ssh {glance-api-server} sudo tee /etc/ceph/ceph.client.glance.keyring
     ssh {glance-api-server} sudo chown hua:root /etc/ceph/ceph.client.glance.keyring
     ceph auth get-or-create client.cinder | ssh {volume-server} sudo tee /etc/ceph/ceph.client.cinder.keyring
    ssh {cinder-volume-server} sudo chown hua:root /etc/ceph/ceph.client.cinder.keyring

  e, 配置glance, /etc/glance/glance-api.conf，注意，是追加，放在后面

  default_store=rbd
 rbd_store_user=glance
 rbd_store_pool=images
 show_image_direct_url=True
  f, 为nova-compute的libvirt进程也生成它所需要的ceph密钥client.cinder.key
    sudo ceph auth get-key client.cinder | ssh {compute-node} tee /etc/ceph/client.cinder.key
    $ sudo ceph auth get-key client.cinder | ssh node1 tee /etc/ceph/client.cinder.key
      AQAXe6dTsCEkBRAA7MbJdRruSmW9XEYy/3WgQA==
    $ uuidgen
      e896efb2-1602-42cc-8a0c-c032831eef17
$ cat &gt; secret.xml &lt;&lt;EOF
&lt;secret ephemeral=&apos;no&apos; private=&apos;no&apos;&gt;
  &lt;uuid&gt;e896efb2-1602-42cc-8a0c-c032831eef17&lt;/uuid&gt;
  &lt;usage type=&apos;ceph&apos;&gt;
    &lt;name&gt;client.cinder secret&lt;/name&gt;
  &lt;/usage&gt;
&lt;/secret&gt;
EOF
   $ sudo virsh secret-define --file secret.xml
     Secret e896efb2-1602-42cc-8a0c-c032831eef17 created
   $ sudo virsh secret-set-value --secret e896efb2-1602-42cc-8a0c-c032831eef17 --base64 $(cat /etc/ceph/client.cinder.key)
   $ rm client.cinder.key secret.xml
</code></pre><p>vi /etc/nova/nova.conf</p>
<p>libvirt_images_type=rbd<br>libvirt_images_rbd_pool=volumes<br>libvirt_images_rbd_ceph_conf=/etc/ceph/ceph.conf<br>rbd_user=cinder<br>rbd_secret_uuid=e896efb2-1602-42cc-8a0c-c032831eef17<br>libvirt_inject_password=false<br>libvirt_inject_key=false<br>libvirt_inject_partition=-2</p>
<p>并重启nova-compute服务后在计算节点可以执行：</p>
<p>sudo rbd –keyring /etc/ceph/client.cinder.key –id nova-compute -p cinder ls </p>
<pre><code>f,配置cinder.conf并重启cinder-volume,
</code></pre><p>sudo apt-get install librados-dev librados2 librbd-dev python-ceph radosgw radosgw-agent</p>
<p>cinder-volume –config-file /etc/cinder/cinder.conf<br>    volume_driver =cinder.volume.drivers.rbd.RBDDriver<br>    rbd_pool=volumes<br>    glance_api_version= 2<br>    rbd_user = cinder<br>    rbd_secret_uuid = e896efb2-1602-42cc-8a0c-c032831eef17<br>    rbd_ceph_conf=/etc/ceph/ceph.conf</p>
<p>17, 运行一个实例</p>
<p>wget <a href="http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-disk.img" target="_blank" rel="external">http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-disk.img</a></p>
<p>qemu-img convert -f qcow2 -O raw cirros-0.3.2-x86_64-disk.img cirros-0.3.2-x86_64-disk.raw</p>
<p>glance image-create –name cirros –disk-format raw –container-format ovf –file cirros-0.3.2-x86_64-disk.raw –is-public True</p>
<p>$ glance index<br>ID                                   Name                           Disk Format          Container Format     Size          </p>
<hr>
<p>dbc2b04d-7bf7-4f78-bdc0-859a8a588122 cirros                        raw                  ovf                        41126400</p>
<p>$ rados -p images ls<br>rbd_id.dbc2b04d-7bf7-4f78-bdc0-859a8a588122</p>
<p>cinder create –image-id dbc2b04d-7bf7-4f78-bdc0-859a8a588122 –display-name storage1 1</p>
<p>cinder list</p>
<p>18, Destroying a cluster</p>
<pre><code>cd /bak/work/ceph/ceph-cluster/

ceph-deploy purge node1

 ceph-deploy purgedata node1
 rm -rf /bak/work/ceph/ceph-cluster/*
 sudo umount /srv/ceph/osd0

 sudo umount /srv/ceph/osd1
 mkdir -p /srv/ceph/{osd0,mon0,mds0}
</code></pre><p>devstack对ceph的支持见：<a href="https://review.openstack.org/#/c/65113/" target="_blank" rel="external">https://review.openstack.org/#/c/65113/</a></p>
<p>一些调试经验：</p>
<p>收集数据<br>ceph status –format=json-pretty, 提供健康状态，monitors, osds和placement groups的状态，当前的epoch<br>ceph health detail –format=json-pretty, 提供像monitors，placement groups的错误和警告信息等<br>ceph osd tree –format=json-pretty, 提供了osd的状态，以及osd在哪个cluster上</p>
<p>问诊Placement Groups<br>ceph health detail<br>ceph pg dump_stuck –format=json-pretty<br>ceph pg map <pgnum><br>ceph pg <pgnum><br>ceph -w<br>例如：pg 4.63 is stuck unclean for 2303.828665, current state active+degraded, last acting [2,1]<br>它说明4.63这个placement groups位于pool 4, stuck了2303.828665秒，这个pg里的[2, 1]这些osd受到了影响<br>a, inactive状态，一般是osd是down状态的，’ceph pg <pgnum>‘<br>b, unclean状态，意味着object没有复制到期望的备份数量，这一般是recovery有问题<br>c, Degraded状态，复制数量多于osd数量时可能出现这种情况，’ceph -w’可查看复制过程<br>d, Undersized状态，意味着placement groups和pgnum不匹配，一般是配置错误，像池的pgnum配置的太多, cluster’s crush map, 或者osd没空间了。总之，是有什么情况阻止了crush算法为pg选择osd<br>e, Stale状态，pg内没有osd报告状态时是这样的，可能osd离线了，重启osd去重建PG</pgnum></pgnum></pgnum></p>
<p>替换出错的osd或磁盘<br>见：<a href="http://ceph.com/docs/master/rados/operations/add-or-rm-osds/" target="_blank" rel="external">http://ceph.com/docs/master/rados/operations/add-or-rm-osds/</a><br>总得来说：<br>Remove the OSD<br>1, Mark the OSD as out of the cluster<br>2, Wait for the data migration throughout the cluster (ceph -w)<br>3, Stop the OSD<br>4, Remove the OSD from the crushmap (ceph osd crush remove <osd.name>)<br>5, Delete the OSD’s authentication (ceph auth del <osd.num>)<br>6, Remove the OSD entry from any of the ceph.conf files.<br>Adding the OSD<br>1, Create the new OSD (ceph osd create <cluster-uuid> [osd_num]<br>2, Create a filesystem on the OSD<br>3, Mount the disk to the OSD directory<br>4, Initialize the OSD directory &amp; create auth key<br>5, Allow the auth key to have access to the cluster<br>6, Add the OSD to the crushmap<br>7, Start the OSD</cluster-uuid></osd.num></osd.name></p>
<p>磁盘Hung了无法unmount<br>echo offline &gt; /sys/block/$DISK/device/state<br>echo 1 &gt; /sys/block/$DISK/device/delete</p>
<p>恢复incomplete PGs<br>在ceph集群中，如果有的节点没有空间的话容易造成incomplete PGs，恢复起来很困难，可以采用osd_find_best_info_ignore_history_les这招(在ceph.conf中设置osd_find_best_info_ignore_history_les选项后， PG peering进程将忽略last epoch，从头在历史日志中找到和此PG相关的信息回放）。可以采用reweight-by-utilization参数控制不要发生一个节点空间不够的情况。</p>
<p>贴一些输出数据帮助感性理解</p>
<p>Pool和Rule关联决定如何复制，Rule再和CRUSH结构关联决定在物理设备中的复制策略</p>
<p>#Create a pool, and associate pool and rule<br>ceph osd pool create SSD 128 128<br>ceph osd pool set SSD crush_ruleset <rule_id></rule_id></p>
<p>ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph osd tree<br>ID WEIGHT  TYPE NAME                                 UP/DOWN REWEIGHT PRIMARY-AFFINITY<br>-1 0.08487 root default<br>-2 0.02829     host juju-864213-xenial-mitaka-ceph-0<br> 0 0.02829         osd.0                                  up  1.00000          1.00000<br>-3 0.02829     host juju-864213-xenial-mitaka-ceph-1<br> 1 0.02829         osd.1                                  up  1.00000          1.00000<br>-4 0.02829     host juju-864213-xenial-mitaka-ceph-2<br> 2 0.02829         osd.2                                  up  1.00000          1.00000</p>
<p>ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph osd getcrushmap -o mycrushmap<br>got crush map from osdmap epoch 23<br>ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ crushtool -d mycrushmap &gt; mycrushmap.txt</p>
<p>ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ cat mycrushmap.txt</p>
<h1 id="begin-crush-map"><a href="#begin-crush-map" class="headerlink" title="begin crush map"></a>begin crush map</h1><p>tunable choose_local_tries 0<br>tunable choose_local_fallback_tries 0<br>tunable choose_total_tries 50<br>tunable chooseleaf_descend_once 1<br>tunable chooseleaf_vary_r 1<br>tunable straw_calc_version 1</p>
<h1 id="devices"><a href="#devices" class="headerlink" title="devices"></a>devices</h1><p>device 0 osd.0<br>device 1 osd.1<br>device 2 osd.2</p>
<h1 id="types"><a href="#types" class="headerlink" title="types"></a>types</h1><p>type 0 osd<br>type 1 host<br>type 2 chassis<br>type 3 rack<br>type 4 row<br>type 5 pdu<br>type 6 pod<br>type 7 room<br>type 8 datacenter<br>type 9 region<br>type 10 root</p>
<h1 id="buckets"><a href="#buckets" class="headerlink" title="buckets"></a>buckets</h1><p>host juju-864213-xenial-mitaka-ceph-0 {<br>        id -2           # do not change unnecessarily</p>
<pre><code># weight 0.028
alg straw
hash 0  # rjenkins1
item osd.0 weight 0.028
</code></pre><p>}<br>host juju-864213-xenial-mitaka-ceph-1 {<br>        id -3           # do not change unnecessarily</p>
<pre><code># weight 0.028
alg straw
hash 0  # rjenkins1
item osd.1 weight 0.028
</code></pre><p>}<br>host juju-864213-xenial-mitaka-ceph-2 {<br>        id -4           # do not change unnecessarily</p>
<pre><code># weight 0.028
alg straw
hash 0  # rjenkins1
item osd.2 weight 0.028
</code></pre><p>}<br>root default {<br>        id -1           # do not change unnecessarily</p>
<pre><code># weight 0.085
alg straw
hash 0  # rjenkins1
item juju-864213-xenial-mitaka-ceph-0 weight 0.028
item juju-864213-xenial-mitaka-ceph-1 weight 0.028
item juju-864213-xenial-mitaka-ceph-2 weight 0.028
</code></pre><p>}</p>
<h1 id="rules"><a href="#rules" class="headerlink" title="rules"></a>rules</h1><p>rule replicated_ruleset {<br>        ruleset 0<br>        type replicated<br>        min_size 1<br>        max_size 10<br>        step take default<br>        step chooseleaf firstn 0 type host<br>        step emit<br>}</p>
<h1 id="end-crush-map"><a href="#end-crush-map" class="headerlink" title="end crush map"></a>end crush map</h1><p>ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph osd crush rule dump<br>[<br>    {<br>        “rule_id”: 0,<br>        “rule_name”: “replicated_ruleset”,<br>        “ruleset”: 0,<br>        “type”: 1,<br>        “min_size”: 1,<br>        “max_size”: 10,<br>        “steps”: [<br>            {<br>                “op”: “take”,<br>                “item”: -1,<br>                “item_name”: “default”<br>            },<br>            {<br>                “op”: “chooseleaf_firstn”,<br>                “num”: 0,<br>                “type”: “host”<br>            },<br>            {<br>                “op”: “emit”<br>            }<br>        ]<br>    }<br>]</p>
<p>恢复元数据的实例</p>
<p>root@juju-864213-xenial-mitaka-ceph-3:~# rados -p cinder-ceph ls<br>rbd_id.volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74<br>rbd_directory<br>rbd_header.47d0caaedb0<br>rbd_object_map.47d0caaedb0</p>
<p>root@juju-864213-xenial-mitaka-ceph-3:~# rados -p cinder-ceph get rbd_id.volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74 -|strings<br>47d0caaedb0</p>
<p>root@juju-864213-xenial-mitaka-ceph-3:~# rados -p cinder-ceph listomapvals rbd_header.47d0caaedb0<br>features<br>value (8 bytes) :<br>00000000  3d 00 00 00 00 00 00 00                           |=…….|<br>00000008</p>
<p>object_prefix<br>value (24 bytes) :<br>00000000  14 00 00 00 72 62 64 5f  64 61 74 61 2e 34 37 64  |….rbd_data.47d|<br>00000010  30 63 61 61 65 64 62 30                           |0caaedb0|<br>00000018</p>
<p>order<br>value (1 bytes) :<br>00000000  16                                                |.|<br>00000001</p>
<p>size<br>value (8 bytes) :<br>00000000  00 00 00 40 00 00 00 00                           |…@….|<br>00000008</p>
<p>snap_seq<br>value (8 bytes) :<br>00000000  00 00 00 00 00 00 00 00                           |……..|<br>00000008</p>
<p>root@juju-864213-xenial-mitaka-ceph-3:~# rbd -p cinder-ceph info volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74<br>rbd image ‘volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74’:<br>        size 1024 MB in 256 objects<br>        order 22 (4096 kB objects)<br>        block_name_prefix: rbd_data.47d0caaedb0<br>        format: 2<br>        features: layering, exclusive-lock, object-map, fast-diff, deep-flatten<br>        flags:</p>
<p>root@juju-864213-xenial-mitaka-ceph-3:~# rados -p cinder-ceph rm rbd_header.47d0caaedb0<br>root@juju-864213-xenial-mitaka-ceph-3:~# rados -p cinder-ceph listomapvals rbd_header.47d0caaedb0<br>error getting omap keys cinder-ceph/rbd_header.47d0caaedb0: (2) No such file or directory<br>root@juju-864213-xenial-mitaka-ceph-3:~# rbd -p cinder-ceph info volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74<br>2017-12-01 08:22:28.725851 7f80c55fd700 -1 librbd::image::OpenRequest: failed to retreive immutable metadata: (2) No such file or directory<br>rbd: error opening image volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74: (2) No such file or directory</p>
<p>echo -en \x3d\x00\x00\x00\x00\x00\x00\x00 | sudo rados -p cinder-ceph setomapval rbd_header.47d0caaedb0 features<br>echo -en \x14\x00\x00\x00rbd_data.47d0caaedb0 | sudo rados -p cinder-ceph setomapval rbd_header.47d0caaedb0 object_prefix<br>echo -en \x16 | sudo rados -p cinder-ceph setomapval rbd_header.47d0caaedb0 order<br>echo -en \x00\x00\x00\x40\x00\x00\x00\x00 | sudo rados -p cinder-ceph setomapval rbd_header.47d0caaedb0 size<br>echo -en \x00\x00\x00\x00\x00\x00\x00\x00 | sudo rados -p cinder-ceph setomapval rbd_header.47d0caaedb0 snap_seq<br>root@juju-864213-xenial-mitaka-ceph-3:~# rados -p cinder-ceph listomapvals rbd_header.47d0caaedb0<br>features<br>value (8 bytes) :<br>00000000  3d 00 00 00 00 00 00 00                           |=…….|<br>00000008<br>object_prefix<br>value (24 bytes) :<br>00000000  14 00 00 00 72 62 64 5f  64 61 74 61 2e 34 37 64  |….rbd_data.47d|<br>00000010  30 63 61 61 65 64 62 30                           |0caaedb0|<br>00000018<br>order<br>value (1 bytes) :<br>00000000  16                                                |.|<br>00000001<br>size<br>value (8 bytes) :<br>00000000  00 00 00 40 00 00 00 00                           |…@….|<br>00000008<br>snap_seq<br>value (8 bytes) :<br>00000000  00 00 00 00 00 00 00 00                           |……..|<br>00000008<br>root@juju-864213-xenial-mitaka-ceph-3:~# rbd -p cinder-ceph info volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74<br>rbd image ‘volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74’:<br>        size 1024 MB in 256 objects<br>        order 22 (4096 kB objects)<br>        block_name_prefix: rbd_data.47d0caaedb0<br>        format: 2<br>        features: layering, exclusive-lock, object-map, fast-diff, deep-flatten<br>        flags:</p>
<p>基他数据<br><a href="http://paste.ubuntu.com/26213468/" target="_blank" rel="external">http://paste.ubuntu.com/26213468/</a><br>基他数据<br><a href="http://paste.ubuntu.com/26213468/" target="_blank" rel="external">http://paste.ubuntu.com/26213468/</a><br>1, ceph status ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph -s cluster 6547bd3e-1397-11e2-82e5-53567c8d32dc health HEALTH_OK monmap e2: 3 mons at {juju-864213-xenial-mitaka-ceph-0=10.5.0.26:6789/0,juju-864213-xenial-mitaka-ceph-1=10.5.0.20:6789/0,juju-864213-xenial-mitaka-ceph-2=10.5.0.23:6789/0} election epoch 10, quorum 0,1,2 juju-864213-xenial-mitaka-ceph-1,juju-864213-xenial-mitaka-ceph-2,juju-864213-xenial-mitaka-ceph-0 osdmap e25: 3 osds: 3 up, 3 in flags sortbitwise,require_jewel_osds pgmap v31559: 132 pgs, 4 pools, 277 MB data, 48 objects 948 MB used, 88093 MB / 89041 MB avail 132 active+clean 2, mon status ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph mon_status | python -mjson.tool { “election_epoch”: 10, “extra_probe_peers”: [], “monmap”: { “created”: “2017-11-07 09:00:10.987037”, “epoch”: 2, “fsid”: “6547bd3e-1397-11e2-82e5-53567c8d32dc”, “modified”: “2017-11-07 09:00:32.839271”, “mons”: [ { “addr”: “10.5.0.20:6789/0”, “name”: “juju-864213-xenial-mitaka-ceph-1”, “rank”: 0 }, { “addr”: “10.5.0.23:6789/0”, “name”: “juju-864213-xenial-mitaka-ceph-2”, “rank”: 1 }, { “addr”: “10.5.0.26:6789/0”, “name”: “juju-864213-xenial-mitaka-ceph-0”, “rank”: 2 } ] }, “name”: “juju-864213-xenial-mitaka-ceph-0”, “outside_quorum”: [], “quorum”: [ 0, 1, 2 ], “rank”: 2, “state”: “peon”, “sync_provider”: [] } 3, osd status/dump ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph osd stat osdmap e25: 3 osds: 3 up, 3 in flags sortbitwise,require_jewel_osds ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph osd dump epoch 25 fsid 6547bd3e-1397-11e2-82e5-53567c8d32dc created 2017-11-07 09:00:25.412066 modified 2017-12-01 07:51:02.498448 flags sortbitwise,require_jewel_osds pool 0 ‘rbd’ replicated size 3 min_size 2 crush_ruleset 0 object_hash rjenkins pg_num 64 pgp_num 64 last_change 25 flags hashpspool stripe_width 0 removed_snaps [1~3] pool 1 ‘cinder-ceph’ replicated size 3 min_size 2 crush_ruleset 0 object_hash rjenkins pg_num 32 pgp_num 32 last_change 21 flags hashpspool stripe_width 0 removed_snaps [1~3] pool 2 ‘glance’ replicated size 3 min_size 2 crush_ruleset 0 object_hash rjenkins pg_num 4 pgp_num 4 last_change 19 flags hashpspool stripe_width 0 removed_snaps [1~3] pool 3 ‘nova’ replicated size 3 min_size 2 crush_ruleset 0 object_hash rjenkins pg_num 32 pgp_num 32 last_change 23 flags hashpspool stripe_width 0 max_osd 3 osd.0 up in weight 1 up_from 4 up_thru 22 down_at 0 last_clean_interval [0,0) 10.5.0.26:6800/27459 10.5.0.26:6801/27459 10.5.0.26:6802/27459 10.5.0.26:6803/27459 exists,up 33594674-62e3-4502-9247-5108f6feef7c osd.1 up in weight 1 up_from 9 up_thru 22 down_at 0 last_clean_interval [0,0) 10.5.0.20:6800/27653 10.5.0.20:6801/27653 10.5.0.20:6802/27653 10.5.0.20:6803/27653 exists,up 0a2d39e3-89da-4272-bcb8-b4b6e60137df osd.2 up in weight 1 up_from 10 up_thru 22 down_at 0 last_clean_interval [0,0) 10.5.0.23:6800/27260 10.5.0.23:6801/27260 10.5.0.23:6802/27260 10.5.0.23:6803/27260 exists,up 204e8baa-8aa7-4e90-beaf-d129276501ec 4, pd status/dump ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph pg stat v31561: 132 pgs: 132 active+clean; 277 MB data, 948 MB used, 88093 MB / 89041 MB avail ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph pg dump dumped all in format plain version 31561 stamp 2017-12-19 06:45:57.860391 last_osdmap_epoch 25 last_pg_scan 25 full_ratio 0.95 nearfull_ratio 0.85 pg_stat objects mip degr misp unf bytes log disklog state state_stamp v reported up up_primary acting acting_primary last_scrub scrub_stamp last_deep_scrub deep_scrub_stamp 0.39 1 0 0 0 0 17 2 2 active+clean 2017-12-19 01:40:23.607006 25’2 25:86 [1,0,2]1 [1,0,2] 1 25’2 2017-12-19 01:40:23.606906 25’2 2017-12-15 16:16:44.422399 0.38 0 0 0 0 0 0 0 0 active+clean 2017-12-19 05:14:05.701416 0’0 25:79 [1,0,2]1 [1,0,2] 1 0’0 2017-12-19 05:14:05.701274 0’0 2017-12-15 15:48:31.555886 0.37 0 0 0 0 0 0 0 0 active+clean 2017-12-19 02:15:10.894036 0’0 25:83 [1,0,2]1 [1,0,2] 1 0’0 2017-12-19 02:15:10.893913 0’0 2017-12-16 07:33:06.968661 0.36 0 0 0 0 0 0 0 0 active+clean 2017-12-18 09:22:34.899211 0’0 25:83 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 09:22:34.899099 0’0 2017-12-16 04:57:08.214820 0.35 0 0 0 0 0 0 0 0 active+clean 2017-12-18 04:07:32.312624 0’0 25:81 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 04:07:32.312208 0’0 2017-12-16 21:17:29.353034 0.34 0 0 0 0 0 0 0 0 active+clean 2017-12-18 02:05:08.439211 0’0 25:81 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 02:05:08.438806 0’0 2017-12-15 12:38:34.056387 0.33 0 0 0 0 0 0 0 0 active+clean 2017-12-18 08:53:52.040008 0’0 25:81 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 08:53:52.039899 0’0 2017-12-16 21:17:37.364792 0.32 0 0 0 0 0 0 0 0 active+clean 2017-12-18 01:16:11.175607 0’0 25:88 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 01:16:11.175475 0’0 2017-12-11 09:32:40.466977 3.0 0 0 0 0 0 0 0 0 active+clean 2017-12-17 23:42:20.803783 0’0 25:70 [1,2,0]1 [1,2,0] 1 0’0 2017-12-17 23:42:20.803362 0’0 2017-12-15 14:20:48.927411 2.1 11 0 0 0 0 72482875 12 12 active+clean 2017-12-19 05:44:09.159924 19’12 25:88 [0,1,2] 0 [0,1,2] 0 19’12 2017-12-19 05:44:09.159809 19’12 2017-12-18 04:35:02.140422 0.3 0 0 0 0 0 0 0 0 active+clean 2017-12-18 07:13:26.367448 0’0 25:81 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 07:13:26.367279 0’0 2017-12-18 07:13:26.367279 1.2 1 0 0 0 0 15 2 2 active+clean 2017-12-19 02:44:20.841572 21’2 25:94 [1,2,0]1 [1,2,0] 1 21’2 2017-12-19 02:44:20.841455 21’2 2017-12-13 15:07:02.013739 0.2e 0 0 0 0 0 0 0 0 active+clean 2017-12-18 14:16:04.153210 0’0 25:86 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 14:16:04.153113 0’0 2017-12-17 05:53:35.522242 0.2d 1 0 0 0 0 0 2 2 active+clean 2017-12-18 14:11:03.439214 25’2 25:89 [1,2,0]1 [1,2,0] 1 25’2 2017-12-18 14:11:03.438830 25’2 2017-12-14 21:14:36.695147 0.2c 0 0 0 0 0 0 0 0 active+clean 2017-12-19 05:59:07.652903 0’0 25:77 [2,0,1]2 [2,0,1] 2 0’0 2017-12-19 05:59:07.652803 0’0 2017-12-16 13:41:53.858535 0.2b 0 0 0 0 0 0 0 0 active+clean 2017-12-19 06:00:03.866870 0’0 25:81 [1,2,0]1 [1,2,0] 1 0’0 2017-12-19 06:00:03.866730 0’0 2017-12-16 15:46:25.399077 0.2a 0 0 0 0 0 0 0 0 active+clean 2017-12-18 18:19:23.627293 0’0 25:75 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 18:19:23.627185 0’0 2017-12-16 09:54:17.956801 0.29 0 0 0 0 0 0 0 0 active+clean 2017-12-19 05:53:48.331532 0’0 25:75 [2,0,1]2 [2,0,1] 2 0’0 2017-12-19 05:53:48.331444 0’0 2017-12-19 05:53:48.331444 0.28 0 0 0 0 0 0 0 0 active+clean 2017-12-18 10:50:27.843478 0’0 25:86 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 10:50:27.843327 0’0 2017-12-15 18:59:45.769231 0.27 0 0 0 0 0 0 0 0 active+clean 2017-12-18 04:11:19.718171 0’0 25:86 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 04:11:19.717407 0’0 2017-12-12 11:23:47.089204 0.26 0 0 0 0 0 0 0 0 active+clean 2017-12-18 23:10:29.139623 0’0 25:84 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 23:10:29.139497 0’0 2017-12-16 06:54:22.131937 0.25 0 0 0 0 0 0 0 0 active+clean 2017-12-18 10:45:29.725866 0’0 25:81 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 10:45:29.725674 0’0 2017-12-18 10:45:29.725674 0.24 0 0 0 0 0 0 0 0 active+clean 2017-12-18 09:39:27.366211 0’0 25:75 [2,0,1]2 [2,0,1] 2 0’0 2017-12-18 09:39:27.366081 0’0 2017-12-14 07:46:16.059058 0.23 0 0 0 0 0 0 0 0 active+clean 2017-12-19 04:00:18.727236 0’0 25:81 [1,2,0]1 [1,2,0] 1 0’0 2017-12-19 04:00:18.727071 0’0 2017-12-12 20:55:22.902938 3.16 0 0 0 0 0 0 0 0 active+clean 2017-12-19 03:24:44.373066 0’0 25:72 [0,1,2]0 [0,1,2] 0 0’0 2017-12-19 03:24:44.372735 0’0 2017-12-17 20:29:01.002908 0.15 0 0 0 0 0 0 0 0 active+clean 2017-12-19 03:55:52.394801 0’0 25:86 [0,2,1]0 [0,2,1] 0 0’0 2017-12-19 03:55:52.394684 0’0 2017-12-16 19:48:46.609011 1.14 0 0 0 0 0 0 0 0 active+clean 2017-12-19 05:05:52.126333 0’0 25:79 [1,2,0]1 [1,2,0] 1 0’0 2017-12-19 05:05:52.126215 0’0 2017-12-12 18:49:33.002680 3.17 0 0 0 0 0 0 0 0 active+clean 2017-12-18 15:26:57.831069 0’0 25:70 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 15:26:57.830869 0’0 2017-12-14 19:08:54.589399 0.14 0 0 0 0 0 0 0 0 active+clean 2017-12-18 02:47:24.423329 0’0 25:86 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 02:47:24.423223 0’0 2017-12-11 09:58:48.889005 1.15 0 0 0 0 0 0 0 0 active+clean 2017-12-18 20:11:49.580004 0’0 25:77 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 20:11:49.579500 0’0 2017-12-16 06:06:43.052406 3.10 0 0 0 0 0 0 0 0 active+clean 2017-12-18 15:30:16.983013 0’0 25:68 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 15:30:16.982742 0’0 2017-12-14 10:55:39.640017 0.13 0 0 0 0 0 0 0 0 active+clean 2017-12-17 23:33:50.282655 0’0 25:81 [1,2,0]1 [1,2,0] 1 0’0 2017-12-17 23:33:50.282458 0’0 2017-12-11 09:27:00.573991 1.12 1 0 0 0 0 0 6 6 active+clean 2017-12-18 10:04:00.709872 25’6 25:81 [0,1,2]0 [0,1,2] 0 25’6 2017-12-18 10:04:00.709750 25’6 2017-12-18 10:04:00.709750 3.11 0 0 0 0 0 0 0 0 active+clean 2017-12-19 04:39:13.688279 0’0 25:72 [2,1,0]2 [2,1,0] 2 0’0 2017-12-19 04:39:13.688192 0’0 2017-12-15 04:23:45.933640 0.12 0 0 0 0 0 0 0 0 active+clean 2017-12-19 05:28:15.717046 0’0 25:83 [1,2,0]1 [1,2,0] 1 0’0 2017-12-19 05:28:15.716921 0’0 2017-12-19 05:28:15.716921 1.13 0 0 0 0 0 0 0 0 active+clean 2017-12-18 13:45:45.848497 0’0 25:75 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 13:45:45.848358 0’0 2017-12-18 13:45:45.848358 3.15 0 0 0 0 0 0 0 0 active+clean 2017-12-17 23:15:20.318545 0’0 25:68 [2,1,0]2 [2,1,0] 2 0’0 2017-12-17 23:15:20.318459 0’0 2017-12-16 11:58:09.469155 0.16 0 0 0 0 0 0 0 0 active+clean 2017-12-17 23:55:35.756278 0’0 25:73 [2,1,0]2 [2,1,0] 2 0’0 2017-12-17 23:55:35.756099 0’0 2017-12-14 00:05:46.725428 1.17 0 0 0 0 0 0 0 0 active+clean 2017-12-18 21:53:40.119153 0’0 25:75 [2,0,1]2 [2,0,1] 2 0’0 2017-12-18 21:53:40.118945 0’0 2017-12-18 21:53:40.118945 0.2f 0 0 0 0 0 0 0 0 active+clean 2017-12-18 01:16:44.889379 0’0 25:73 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 01:16:44.888999 0’0 2017-12-18 01:16:44.888999 3.3 0 0 0 0 0 0 0 0 active+clean 2017-12-18 05:13:59.611677 0’0 25:70 [2,0,1]2 [2,0,1] 2 0’0 2017-12-18 05:13:59.611555 0’0 2017-12-18 05:13:59.611555 2.2 10 0 0 0 0 75497515 83 83 active+clean 2017-12-18 05:16:35.846337 19’83 25:159[0,1,2] 0 [0,1,2] 0 19’83 2017-12-18 05:16:35.846000 19’83 2017-12-15 18:21:04.972135 0.0 0 0 0 0 0 0 0 0 active+clean 2017-12-18 14:25:22.788930 0’0 25:86 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 14:25:22.785405 0’0 2017-12-17 04:55:51.913445 1.1 0 0 0 0 0 0 0 0 active+clean 2017-12-18 17:30:09.530773 0’0 25:75 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 17:30:09.530603 0’0 2017-12-13 05:43:09.146223 3.14 0 0 0 0 0 0 0 0 active+clean 2017-12-19 02:26:04.397183 0’0 25:70 [2,0,1]2 [2,0,1] 2 0’0 2017-12-19 02:26:04.397023 0’0 2017-12-16 14:50:42.319029 0.17 0 0 0 0 0 0 0 0 active+clean 2017-12-18 15:38:01.467210 0’0 25:86 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 15:38:01.467081 0’0 2017-12-16 00:12:41.509078 1.16 0 0 0 0 0 0 0 0 active+clean 2017-12-18 12:28:23.822722 0’0 25:75 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 12:28:23.822620 0’0 2017-12-18 12:28:23.822620 0.30 0 0 0 0 0 0 0 0 active+clean 2017-12-18 21:58:47.472513 0’0 25:75 [2,0,1]2 [2,0,1] 2 0’0 2017-12-18 21:58:47.472404 0’0 2017-12-12 12:42:04.016321 3.2 0 0 0 0 0 0 0 0 active+clean 2017-12-18 08:00:22.561183 0’0 25:70 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 08:00:22.561066 0’0 2017-12-13 02:14:03.411923 2.3 5 0 0 0 0 33554432 51 51 active+clean 2017-12-18 07:26:08.230120 23’51 25:126[2,0,1] 2 [2,0,1] 2 23’51 2017-12-18 07:26:08.230026 23’51 2017-12-18 07:26:08.230026 0.1 0 0 0 0 0 0 0 0 active+clean 2017-12-18 20:09:27.994306 0’0 25:79 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 20:09:27.994195 0’0 2017-12-17 15:59:37.177068 1.0 0 0 0 0 0 0 0 0 active+clean 2017-12-18 07:10:50.151193 0’0 25:75 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 07:10:50.150984 0’0 2017-12-11 16:41:13.834816 3.1b 0 0 0 0 0 0 0 0 active+clean 2017-12-18 01:00:21.188763 0’0 25:68 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 01:00:21.188504 0’0 2017-12-12 07:30:14.931021 0.18 0 0 0 0 0 0 0 0 active+clean 2017-12-18 04:19:25.218443 0’0 25:71 [2,0,1]2 [2,0,1] 2 0’0 2017-12-18 04:19:25.218285 0’0 2017-12-15 12:35:08.459074 1.19 0 0 0 0 0 0 0 0 active+clean 2017-12-18 15:55:29.382654 0’0 25:75 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 15:55:29.378857 0’0 2017-12-17 05:24:36.296344 3.13 0 0 0 0 0 0 0 0 active+clean 2017-12-18 07:46:40.623587 0’0 25:70 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 07:46:40.623502 0’0 2017-12-13 07:08:04.935165 0.10 0 0 0 0 0 0 0 0 active+clean 2017-12-18 18:55:28.237924 0’0 25:84 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 18:55:28.232992 0’0 2017-12-17 14:34:08.085013 1.11 0 0 0 0 0 0 0 0 active+clean 2017-12-18 14:08:13.234638 0’0 25:77 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 14:08:13.234525 0’0 2017-12-13 20:05:09.727370 3.12 0 0 0 0 0 0 0 0 active+clean 2017-12-17 20:00:56.145750 0’0 25:68 [1,2,0]1 [1,2,0] 1 0’0 2017-12-17 20:00:56.145614 0’0 2017-12-16 14:17:21.742100 0.11 0 0 0 0 0 0 0 0 active+clean 2017-12-18 01:59:54.111143 0’0 25:81 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 01:59:54.111031 0’0 2017-12-14 04:19:15.303528 1.10 0 0 0 0 0 0 0 0 active+clean 2017-12-18 03:36:39.368684 0’0 25:77 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 03:36:39.368509 0’0 2017-12-16 23:46:49.778409 3.1a 0 0 0 0 0 0 0 0 active+clean 2017-12-18 21:26:58.470656 0’0 25:70 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 21:26:58.470494 0’0 2017-12-18 21:26:58.470494 0.19 0 0 0 0 0 0 0 0 active+clean 2017-12-18 04:11:16.743839 0’0 25:86 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 04:11:16.743689 0’0 2017-12-18 04:11:16.743689 1.18 0 0 0 0 0 0 0 0 active+clean 2017-12-19 03:13:26.304029 0’0 25:77 [2,0,1]2 [2,0,1] 2 0’0 2017-12-19 03:13:26.303836 0’0 2017-12-14 02:16:50.494347 0.31 0 0 0 0 0 0 0 0 active+clean 2017-12-18 09:07:46.905181 0’0 25:86 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 09:07:46.905081 0’0 2017-12-12 07:17:27.453352 3.1 0 0 0 0 0 0 0 0 active+clean 2017-12-17 21:38:44.661316 0’0 25:68 [1,0,2]1 [1,0,2] 1 0’0 2017-12-17 21:38:44.661151 0’0 2017-12-16 17:14:23.983676 2.0 14 0 0 0 0 109051904 15 15 active+clean 2017-12-18 23:16:24.507965 23’15 25:91 [0,2,1] 0 [0,2,1] 0 23’15 2017-12-18 23:16:24.507629 23’15 2017-12-13 00:41:58.376080 0.2 0 0 0 0 0 0 0 0 active+clean 2017-12-18 19:18:56.808939 0’0 25:79 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 19:18:56.808785 0’0 2017-12-18 19:18:56.808785 1.3 0 0 0 0 0 0 0 0 active+clean 2017-12-18 21:39:32.910285 0’0 25:75 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 21:39:32.910107 0’0 2017-12-16 10:24:36.847816 3.19 0 0 0 0 0 0 0 0 active+clean 2017-12-18 05:09:03.314289 0’0 25:70 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 05:09:03.313978 0’0 2017-12-12 19:06:29.077744 0.1a 0 0 0 0 0 0 2 2 active+clean 2017-12-18 15:08:12.270866 25’2 25:82 [1,0,2]1 [1,0,2] 1 25’2 2017-12-18 15:08:12.270382 25’2 2017-12-13 15:44:52.423465 1.1b 0 0 0 0 0 0 0 0 active+clean 2017-12-18 18:52:10.695149 0’0 25:75 [2,0,1]2 [2,0,1] 2 0’0 2017-12-18 18:52:10.695014 0’0 2017-12-15 02:09:58.688027 3.18 0 0 0 0 0 0 0 0 active+clean 2017-12-18 07:03:06.646577 0’0 25:68 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 07:03:06.646450 0’0 2017-12-18 07:03:06.646450 0.1b 0 0 0 0 0 0 0 0 active+clean 2017-12-18 10:53:40.332204 0’0 25:81 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 10:53:40.332044 0’0 2017-12-16 23:10:30.422172 1.1a 0 0 0 0 0 0 0 0 active+clean 2017-12-18 14:32:00.826929 0’0 25:75 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 14:32:00.826804 0’0 2017-12-13 06:56:44.934621 3.1f 0 0 0 0 0 0 0 0 active+clean 2017-12-19 00:55:10.694973 0’0 25:72 [2,0,1]2 [2,0,1] 2 0’0 2017-12-19 00:55:10.694812 0’0 2017-12-17 17:11:03.530971 0.1c 1 0 0 0 0 0 2 2 active+clean 2017-12-17 23:07:09.564023 25’2 25:83 [1,2,0]1 [1,2,0] 1 25’2 2017-12-17 23:07:09.563939 25’2 2017-12-15 03:03:48.357577 1.1d 0 0 0 0 0 0 0 0 active+clean 2017-12-18 06:21:56.896449 0’0 25:75 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 06:21:56.896362 0’0 2017-12-17 04:38:29.625922 3.1e 0 0 0 0 0 0 0 0 active+clean 2017-12-18 02:43:01.868155 0’0 25:70 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 02:43:01.868013 0’0 2017-12-13 02:25:10.797527 0.1d 0 0 0 0 0 0 0 0 active+clean 2017-12-18 00:42:05.953583 0’0 25:79 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 00:42:05.953424 0’0 2017-12-15 09:19:26.023068 1.1c 1 0 0 0 0 0 2 2 active+clean 2017-12-18 09:59:51.673737 23’2 25:81 [2,1,0]2 [2,1,0] 2 23’2 2017-12-18 09:59:51.673609 23’2 2017-12-13 04:32:32.734026 3.1d 0 0 0 0 0 0 0 0 active+clean 2017-12-18 12:55:27.110427 0’0 25:70 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 12:55:27.110061 0’0 2017-12-14 12:30:31.232459 0.1e 0 0 0 0 0 0 0 0 active+clean 2017-12-18 20:05:19.738426 0’0 25:81 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 20:05:19.738328 0’0 2017-12-16 11:00:48.200157 1.1f 1 0 0 0 0 98 1 1 active+clean 2017-12-18 18:53:35.770168 21’1 25:76 [2,1,0]2 [2,1,0] 2 21’1 2017-12-18 18:53:35.770077 21’1 2017-12-13 19:03:13.642323 3.1c 0 0 0 0 0 0 0 0 active+clean 2017-12-18 19:54:28.057688 0’0 25:70 [1,0,2]1 [1,0,2] 1 0’0 2017-12-18 19:54:28.057521 0’0 2017-12-18 19:54:28.057521 0.1f 0 0 0 0 0 0 0 0 active+clean 2017-12-19 05:01:46.031689 0’0 25:75 [2,0,1]2 [2,0,1] 2 0’0 2017-12-19 05:01:46.031556 0’0 2017-12-19 05:01:46.031556 1.1e 1 0 0 0 0 0 10 10 active+clean 2017-12-18 07:42:29.235179 25’10 25:5201 [1,2,0]1 [1,2,0] 1 25’10 2017-12-18 07:42:29.235077 25’10 2017-12-14 11:33:55.725980 0.20 0 0 0 0 0 0 0 0 active+clean 2017-12-19 00:09:28.879241 0’0 25:81 [1,0,2]1 [1,0,2] 1 0’0 2017-12-19 00:09:28.879090 0’0 2017-12-12 10:02:45.990082 0.21 0 0 0 0 0 0 0 0 active+clean 2017-12-18 10:26:23.348959 0’0 25:83 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 10:26:23.348810 0’0 2017-12-13 21:42:36.788814 0.22 0 0 0 0 0 0 0 0 active+clean 2017-12-18 09:13:58.759944 0’0 25:75 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 09:13:58.759790 0’0 2017-12-15 22:25:25.959063 0.3a 0 0 0 0 0 0 0 0 active+clean 2017-12-18 05:15:47.811645 0’0 25:84 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 05:15:47.810786 0’0 2017-12-15 16:57:15.632503 0.3b 0 0 0 0 0 0 0 0 active+clean 2017-12-18 13:38:48.856584 0’0 25:86 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 13:38:48.856434 0’0 2017-12-16 01:56:39.239797 0.3c 0 0 0 0 0 0 0 0 active+clean 2017-12-19 00:12:25.076586 0’0 25:81 [1,0,2]1 [1,0,2] 1 0’0 2017-12-19 00:12:25.075865 0’0 2017-12-17 13:13:19.705717 0.3d 0 0 0 0 0 0 0 0 active+clean 2017-12-18 08:42:10.275657 0’0 25:84 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 08:42:10.275546 0’0 2017-12-13 01:40:35.739284 0.3e 0 0 0 0 0 0 0 0 active+clean 2017-12-19 06:36:42.943023 0’0 25:77 [2,0,1]2 [2,0,1] 2 0’0 2017-12-19 06:36:42.942896 0’0 2017-12-13 11:52:09.318495 0.3f 0 0 0 0 0 0 0 0 active+clean 2017-12-18 21:20:26.177081 0’0 25:86 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 21:20:26.176839 0’0 2017-12-16 14:13:47.056217 3.7 0 0 0 0 0 0 0 0 active+clean 2017-12-18 06:54:01.846660 0’0 25:70 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 06:54:01.846563 0’0 2017-12-15 22:17:39.553949 0.4 0 0 0 0 0 0 0 0 active+clean 2017-12-19 00:15:57.308559 0’0 25:81 [1,2,0]1 [1,2,0] 1 0’0 2017-12-19 00:15:57.303061 0’0 2017-12-19 00:15:57.303061 1.5 0 0 0 0 0 0 0 0 active+clean 2017-12-18 16:05:28.050259 0’0 25:75 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 16:05:28.049939 0’0 2017-12-13 08:44:47.095183 3.6 0 0 0 0 0 0 0 0 active+clean 2017-12-18 08:09:41.132762 0’0 25:68 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 08:09:41.132619 0’0 2017-12-18 08:09:41.132619 0.5 0 0 0 0 0 0 0 0 active+clean 2017-12-19 02:38:20.126701 0’0 25:75 [2,0,1]2 [2,0,1] 2 0’0 2017-12-19 02:38:20.126592 0’0 2017-12-13 14:45:05.054828 1.4 0 0 0 0 0 0 0 0 active+clean 2017-12-18 13:39:33.879784 0’0 25:75 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 13:39:33.879663 0’0 2017-12-16 06:42:32.387889 3.5 0 0 0 0 0 0 0 0 active+clean 2017-12-18 19:28:24.970257 0’0 25:70 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 19:28:24.970108 0’0 2017-12-11 20:46:56.439037 0.6 0 0 0 0 0 0 0 0 active+clean 2017-12-18 20:50:34.289462 0’0 25:86 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 20:50:34.289316 0’0 2017-12-16 09:32:54.146238 1.7 0 0 0 0 0 0 0 0 active+clean 2017-12-18 11:33:39.585225 0’0 25:75 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 11:33:39.585106 0’0 2017-12-14 08:53:30.456251 3.4 0 0 0 0 0 0 0 0 active+clean 2017-12-19 00:10:24.930916 0’0 25:70 [1,2,0]1 [1,2,0] 1 0’0 2017-12-19 00:10:24.930800 0’0 2017-12-16 12:01:45.111268 0.7 0 0 0 0 0 0 0 0 active+clean 2017-12-18 21:11:57.668625 0’0 25:88 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 21:11:57.668438 0’0 2017-12-13 15:41:44.444720 1.6 0 0 0 0 0 0 0 0 active+clean 2017-12-18 21:08:32.302123 0’0 25:75 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 21:08:32.302011 0’0 2017-12-18 21:08:32.302011 3.b 0 0 0 0 0 0 0 0 active+clean 2017-12-18 04:49:13.034736 0’0 25:68 [2,0,1]2 [2,0,1] 2 0’0 2017-12-18 04:49:13.034626 0’0 2017-12-13 06:44:54.008291 0.8 0 0 0 0 0 0 0 0 active+clean 2017-12-18 23:01:43.406282 0’0 25:83 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 23:01:43.406157 0’0 2017-12-16 14:29:48.534565 1.9 0 0 0 0 0 0 0 0 active+clean 2017-12-18 15:58:35.767965 0’0 25:75 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 15:58:35.767763 0’0 2017-12-17 13:01:45.054352 3.a 0 0 0 0 0 0 0 0 active+clean 2017-12-18 16:35:26.143666 0’0 25:70 [2,0,1]2 [2,0,1] 2 0’0 2017-12-18 16:35:26.143413 0’0 2017-12-13 06:56:03.706565 0.9 0 0 0 0 0 0 0 0 active+clean 2017-12-18 03:19:11.400996 0’0 25:86 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 03:19:11.400629 0’0 2017-12-18 03:19:11.400629 1.8 0 0 0 0 0 0 0 0 active+clean 2017-12-19 02:31:13.671306 0’0 25:75 [2,0,1]2 [2,0,1] 2 0’0 2017-12-19 02:31:13.670967 0’0 2017-12-17 20:02:31.243782 3.9 0 0 0 0 0 0 0 0 active+clean 2017-12-18 06:42:12.627425 0’0 25:70 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 06:42:12.627221 0’0 2017-12-18 06:42:12.627221 0.a 0 0 0 0 0 0 0 0 active+clean 2017-12-18 16:04:29.144733 0’0 25:75 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 16:04:29.144543 0’0 2017-12-12 05:03:07.503116 1.b 0 0 0 0 0 0 0 0 active+clean 2017-12-18 14:48:40.371345 0’0 25:75 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 14:48:40.371194 0’0 2017-12-16 02:40:42.962114 3.8 0 0 0 0 0 0 0 0 active+clean 2017-12-19 00:31:31.237095 0’0 25:72 [2,1,0]2 [2,1,0] 2 0’0 2017-12-19 00:31:31.236939 0’0 2017-12-16 06:51:33.686165 0.b 0 0 0 0 0 0 0 0 active+clean 2017-12-18 15:10:42.820528 0’0 25:86 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 15:10:42.820244 0’0 2017-12-14 03:21:43.959388 1.a 0 0 0 0 0 0 0 0 active+clean 2017-12-18 06:13:53.677627 0’0 25:75 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 06:13:53.677460 0’0 2017-12-15 20:30:07.455919 3.f 0 0 0 0 0 0 0 0 active+clean 2017-12-18 02:39:39.997741 0’0 25:70 [2,0,1]2 [2,0,1] 2 0’0 2017-12-18 02:39:39.997575 0’0 2017-12-18 02:39:39.997575 0.c 0 0 0 0 0 0 0 0 active+clean 2017-12-18 20:42:57.126892 0’0 25:81 [1,2,0]1 [1,2,0] 1 0’0 2017-12-18 20:42:57.123346 0’0 2017-12-13 19:54:34.094834 1.d 0 0 0 0 0 0 0 0 active+clean 2017-12-17 22:54:11.005970 0’0 25:75 [2,1,0]2 [2,1,0] 2 0’0 2017-12-17 22:54:11.005860 0’0 2017-12-16 17:27:50.758077 3.e 0 0 0 0 0 0 0 0 active+clean 2017-12-18 16:33:25.064795 0’0 25:70 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 16:33:25.064689 0’0 2017-12-14 13:43:48.430894 0.d 0 0 0 0 0 0 0 0 active+clean 2017-12-19 04:34:53.481599 0’0 25:75 [2,1,0]2 [2,1,0] 2 0’0 2017-12-19 04:34:53.481437 0’0 2017-12-12 13:45:11.646604 1.c 0 0 0 0 0 0 0 0 active+clean 2017-12-18 04:57:39.570521 0’0 25:73 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 04:57:39.570297 0’0 2017-12-17 04:43:58.906482 3.d 0 0 0 0 0 0 0 0 active+clean 2017-12-18 11:33:46.608958 0’0 25:70 [0,1,2]0 [0,1,2] 0 0’0 2017-12-18 11:33:46.608846 0’0 2017-12-14 11:33:07.764667 0.e 0 0 0 0 0 0 0 0 active+clean 2017-12-17 21:50:58.197440 0’0 25:86 [0,1,2]0 [0,1,2] 0 0’0 2017-12-17 21:50:58.197298 0’0 2017-12-16 19:27:05.193424 1.f 0 0 0 0 0 0 0 0 active+clean 2017-12-18 19:05:21.513225 0’0 25:75 [2,1,0]2 [2,1,0] 2 0’0 2017-12-18 19:05:21.513127 0’0 2017-12-16 06:59:47.193849 3.c 0 0 0 0 0 0 0 0 active+clean 2017-12-19 02:58:16.330075 0’0 25:72 [2,1,0]2 [2,1,0] 2 0’0 2017-12-19 02:58:16.329948 0’0 2017-12-16 15:37:38.187042 0.f 0 0 0 0 0 0 0 0 active+clean 2017-12-18 09:37:12.908961 0’0 25:84 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 09:37:12.908852 0’0 2017-12-15 18:48:43.037117 1.e 0 0 0 0 0 0 0 0 active+clean 2017-12-18 02:58:11.041477 0’0 25:73 [0,2,1]0 [0,2,1] 0 0’0 2017-12-18 02:58:11.041386 0’0 2017-12-13 21:34:26.514865 pool 3 0 0 0 0 0 0 0 0 pool 2 40 0 0 0 0 290586726 161 161 pool 1 5 0 0 0 0 113 21 21 pool 0 3 0 0 0 0 17 8 8 sum 48 0 0 0 0 290586856 190 190 osdstat kbused kbavail kb hb in hb out 2 323496 30069320 30392816 [0,1] [] 1 323596 30069220 30392816 [0,2] [] 0 323928 30068888 30392816 [1,2] [] sum 971020 90207428 91178448 5, mds stat/dump ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph mds stat e1: ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo ceph mds dump dumped fsmap epoch 1 fs_name cephfs epoch 1 flags 0 created 0.000000 modified 0.000000 tableserver 0 root 0 session_timeout 0 session_autoclose 0 max_file_size 0 last_failure 0 last_failure_osd_epoch 0 compat compat={},rocompat={},incompat={} max_mds 0 in up {} failed damaged stopped data_pools metadata_pool 0 inline_data disabled 6, object ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo rados lspools rbd cinder-ceph glance nova ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo rbd -p cinder-ceph list volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74 ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo rbd -p cinder-ceph info volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74 rbd image ‘volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74’: size 1024 MB in 256 objects order 22 (4096 kB objects) block_name_prefix: rbd_data.47d0caaedb0 format: 2 features: layering, exclusive-lock, object-map, fast-diff, deep-flatten flags: ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo rbd info -p cinder-ceph volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74 rbd image ‘volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74’: size 1024 MB in 256 objects order 22 (4096 kB objects) block_name_prefix: rbd_data.47d0caaedb0 format: 2 features: layering, exclusive-lock, object-map, fast-diff, deep-flatten flags: ubuntu@juju-864213-xenial-mitaka-ceph-3:~$ sudo rbd info -p cinder-ceph volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74 –debug-rbd=20 –debug-ms=5 2017-12-19 06:45:57.694357 7fb21f07a100 1 – :/0 messenger.start 2017-12-19 06:45:57.695076 7fb21f07a100 1 – :/973500521 –&gt; 10.5.0.20:6789/0 – auth(proto 0 36 bytes epoch 0) v1 – ?+0 0x564f49a68920 con 0x564f49a679a0 2017-12-19 06:45:57.697651 7fb21f06d700 1 – 10.5.0.27:0/973500521 learned my addr 10.5.0.27:0/973500521 2017-12-19 06:45:57.699831 7fb201b21700 2 – 10.5.0.27:0/973500521 &gt;&gt; 10.5.0.20:6789/0 pipe(0x564f49a666c0 sd=3 :54264 s=2 pgs=59511 cs=1 l=1 c=0x564f49a679a0).reader got KEEPALIVE_ACK 2017-12-19 06:45:57.700204 7fb204326700 1 – 10.5.0.27:0/973500521 &lt;== mon.0 10.5.0.20:6789/0 1 ==== mon_map magic: 0 v1 ==== 566+0+0 (156923887 0 0) 0x7fb1f8000d30 con 0x564f49a679a0 2017-12-19 06:45:57.703912 7fb204326700 1 – 10.5.0.27:0/973500521 &lt;== mon.0 10.5.0.20:6789/0 2 ==== auth_reply(proto 2 0 (0) Success) v1 ==== 33+0+0 (1990328902 0 0) 0x7fb1f8000a20 con 0x564f49a679a0 2017-12-19 06:45:57.704081 7fb204326700 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6789/0 – auth(proto 2 32 bytes epoch 0) v1 – ?+0 0x7fb1ec0019f0 con 0x564f49a679a0 2017-12-19 06:45:57.705277 7fb204326700 1 – 10.5.0.27:0/973500521 &lt;== mon.0 10.5.0.20:6789/0 3 ==== auth_reply(proto 2 0 (0) Success) v1 ==== 222+0+0 (1622389239 0 0) 0x7fb1f8000a20 con 0x564f49a679a0 2017-12-19 06:45:57.705502 7fb204326700 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6789/0 – auth(proto 2 181 bytes epoch 0) v1 – ?+0 0x7fb1ec003560 con 0x564f49a679a0 2017-12-19 06:45:57.706542 7fb204326700 1 – 10.5.0.27:0/973500521 &lt;== mon.0 10.5.0.20:6789/0 4 ==== auth_reply(proto 2 0 (0) Success) v1 ==== 425+0+0 (2988836998 0 0) 0x7fb1f8001120 con 0x564f49a679a0 2017-12-19 06:45:57.706636 7fb204326700 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6789/0 – mon_subscribe({monmap=0+}) v2 – ?+0 0x564f49a6c970 con 0x564f49a679a0 2017-12-19 06:45:57.706875 7fb21f07a100 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6789/0 – mon_subscribe({osdmap=0}) v2 – ?+0 0x564f49a68920 con 0x564f49a679a0 2017-12-19 06:45:57.707991 7fb204326700 1 – 10.5.0.27:0/973500521 &lt;== mon.0 10.5.0.20:6789/0 5 ==== mon_map magic: 0 v1 ==== 566+0+0 (156923887 0 0) 0x7fb1f80012b0 con 0x564f49a679a0 2017-12-19 06:45:57.708216 7fb204326700 1 – 10.5.0.27:0/973500521 &lt;== mon.0 10.5.0.20:6789/0 6 ==== osd_map(25..25 src has 1..25) v3 ==== 3778+0+0 (1591735250 0 0) 0x7fb1f8001f40 con 0x564f49a679a0 2017-12-19 06:45:57.708540 7fb21f07a100 5 librbd::AioImageRequestWQ: 0x564f49a6dac0 : ictx=0x564f49a6cc80 2017-12-19 06:45:57.708549 7fb21f07a100 20 librbd::ImageState: 0x564f49a68e00 open 2017-12-19 06:45:57.708556 7fb21f07a100 10 librbd::ImageState: 0x564f49a68e00 0x564f49a68e00 send_open_unlock 2017-12-19 06:45:57.708562 7fb21f07a100 10 librbd::image::OpenRequest: 0x564f49a6e1a0 send_v2_detect_header 2017-12-19 06:45:57.708686 7fb21f07a100 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6800/27653 – osd_op(client.192363.0:1 1.58bd2a22 rbd_id.volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74 [stat] snapc 0=[] ack+read+known_if_redirected e25) v7 – ?+0 0x564f49a719f0 con 0x564f49a70610 2017-12-19 06:45:57.716215 7fb20011c700 1 – 10.5.0.27:0/973500521 &lt;== osd.1 10.5.0.20:6800/27653 1 ==== osd_op_reply(1 rbd_id.volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74 [stat] v0’0 uv2 ondisk = 0) v7 ==== 170+0+16 (226874884 0 1116245864) 0x7fb1e8000b70 con 0x564f49a70610 2017-12-19 06:45:57.716420 7fb20121f700 10 librbd::image::OpenRequest: handle_v2_detect_header: r=0 2017-12-19 06:45:57.716432 7fb20121f700 10 librbd::image::OpenRequest: 0x564f49a6e1a0 send_v2_get_id 2017-12-19 06:45:57.716480 7fb20121f700 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6800/27653 – osd_op(client.192363.0:2 1.58bd2a22 rbd_id.volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74 [call rbd.get_id] snapc 0=[] ack+read+known_if_redirected e25) v7 – ?+0 0x7fb1dc002390 con 0x564f49a70610 2017-12-19 06:45:57.717316 7fb20011c700 1 – 10.5.0.27:0/973500521 &lt;== osd.1 10.5.0.20:6800/27653 2 ==== osd_op_reply(2 rbd_id.volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74 [call] v0’0 uv2 ondisk = 0) v7 ==== 170+0+15 (1931867352 0 3569059384) 0x7fb1e8000b70 con 0x564f49a70610 2017-12-19 06:45:57.717466 7fb20121f700 10 librbd::image::OpenRequest: handle_v2_get_id: r=0 2017-12-19 06:45:57.717474 7fb20121f700 10 librbd::image::OpenRequest: 0x564f49a6e1a0 send_v2_get_immutable_metadata 2017-12-19 06:45:57.717518 7fb20121f700 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6800/27653 – osd_op(client.192363.0:3 1.b3d94e1e rbd_header.47d0caaedb0 [call rbd.get_size,call rbd.get_object_prefix] snapc 0=[] ack+read+known_if_redirected e25) v7 – ?+0 0x7fb1dc004da0 con 0x564f49a70610 2017-12-19 06:45:57.718771 7fb20011c700 1 – 10.5.0.27:0/973500521 &lt;== osd.1 10.5.0.20:6800/27653 3 ==== osd_op_reply(3 rbd_header.47d0caaedb0 [call,call] v0’0 uv9 ondisk = 0) v7 ==== 184+0+33 (1658043623 0 3400148178) 0x7fb1e8000b70 con 0x564f49a70610 2017-12-19 06:45:57.719104 7fb20121f700 10 librbd::image::OpenRequest: handle_v2_get_immutable_metadata: r=0 2017-12-19 06:45:57.719114 7fb20121f700 10 librbd::image::OpenRequest: 0x564f49a6e1a0 send_v2_get_stripe_unit_count 2017-12-19 06:45:57.719138 7fb20121f700 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6800/27653 – osd_op(client.192363.0:4 1.b3d94e1e rbd_header.47d0caaedb0 [call rbd.get_stripe_unit_count] snapc 0=[] ack+read+known_if_redirected e25) v7 – ?+0 0x7fb1dc002f10 con 0x564f49a70610 2017-12-19 06:45:57.720014 7fb20011c700 1 – 10.5.0.27:0/973500521 &lt;== osd.1 10.5.0.20:6800/27653 4 ==== osd_op_reply(4 rbd_header.47d0caaedb0 [call] v0’0 uv0 ondisk = -8 ((8) Exec format error)) v7 ==== 142+0+0 (779763376 0 0) 0x7fb1e8000b70 con 0x564f49a70610 2017-12-19 06:45:57.720197 7fb20121f700 10 librbd::image::OpenRequest: handle_v2_get_stripe_unit_count: r=-8 2017-12-19 06:45:57.720210 7fb20121f700 10 librbd::ImageCtx: init_layout stripe_unit 4194304 stripe_count 1 object_size 4194304 prefix rbd_data.47d0caaedb0 format rbd_data.47d0caaedb0.%016llx 2017-12-19 06:45:57.720213 7fb20121f700 10 librbd::image::OpenRequest: 0x564f49a6e1a0 send_v2_apply_metadata: start<em>key=conf</em> 2017-12-19 06:45:57.720250 7fb20121f700 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6800/27653 – osd_op(client.192363.0:5 1.b3d94e1e rbd_header.47d0caaedb0 [call rbd.metadata_list] snapc 0=[] ack+read+known_if_redirected e25) v7 – ?+0 0x7fb1dc004500 con 0x564f49a70610 2017-12-19 06:45:57.721015 7fb20011c700 1 – 10.5.0.27:0/973500521 &lt;== osd.1 10.5.0.20:6800/27653 5 ==== osd_op_reply(5 rbd_header.47d0caaedb0 [call] v0’0 uv9 ondisk = 0) v7 ==== 142+0+4 (1982410784 0 0) 0x7fb1e8000b70 con 0x564f49a70610 2017-12-19 06:45:57.721153 7fb20121f700 10 librbd::image::OpenRequest: 0x564f49a6e1a0 handle_v2_apply_metadata: r=0 2017-12-19 06:45:57.721205 7fb20121f700 20 librbd::ImageCtx: apply_metadata 2017-12-19 06:45:57.721413 7fb20121f700 20 librbd::ImageCtx: enabling caching… 2017-12-19 06:45:57.721414 7fb20121f700 20 librbd::ImageCtx: Initial cache settings: size=33554432 num_objects=10 max_dirty=25165824 target_dirty=16777216 max_dirty_age=1 2017-12-19 06:45:57.722163 7fb20121f700 10 librbd::ImageCtx: cache bytes 33554432 -&gt; about 855 objects 2017-12-19 06:45:57.722200 7fb20121f700 10 librbd::image::OpenRequest: 0x564f49a6e1a0 send_refresh 2017-12-19 06:45:57.722204 7fb20121f700 10 librbd::image::RefreshRequest: 0x7fb1dc004ae0 send_v2_get_mutable_metadata 2017-12-19 06:45:57.722710 7fb20121f700 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6800/27653 – osd_op(client.192363.0:6 1.b3d94e1e rbd_header.47d0caaedb0 [call rbd.get_size,call rbd.get_features,call rbd.get_snapcontext,call rbd.get_parent,call lock.get_info] snapc 0=[] ack+read+known_if_redirected e25) v7 – ?+0 0x7fb1dc00ed30 con 0x564f49a70610 2017-12-19 06:45:57.728240 7fb20011c700 1 – 10.5.0.27:0/973500521 &lt;== osd.1 10.5.0.20:6800/27653 6 ==== osd_op_reply(6 rbd_header.47d0caaedb0 [call,call,call,call,call] v0’0 uv9 ondisk = 0) v7 ==== 310+0+80 (4053120443 0 4203826074) 0x7fb1e8000b70 con 0x564f49a70610 2017-12-19 06:45:57.728410 7fb20121f700 10 librbd::image::RefreshRequest: 0x7fb1dc004ae0 handle_v2_get_mutable_metadata: r=0 2017-12-19 06:45:57.728422 7fb20121f700 10 librbd::image::RefreshRequest: 0x7fb1dc004ae0 send_v2_get_flags 2017-12-19 06:45:57.728449 7fb20121f700 1 – 10.5.0.27:0/973500521 –&gt; 10.5.0.20:6800/27653 – osd_op(client.192363.0:7 1.b3d94e1e rbd_header.47d0caaedb0 [call rbd.get_flags] snapc 0=[] ack+read+known_if_redirected e25) v7 – ?+0 0x7fb1dc007400 con 0x564f49a70610 2017-12-19 06:45:57.729286 7fb20011c700 1 – 10.5.0.27:0/973500521 &lt;== osd.1 10.5.0.20:6800/27653 7 ==== osd_op_reply(7 rbd_header.47d0caaedb0 [call] v0’0 uv9 ondisk = 0) v7 ==== 142+0+8 (381355293 0 0) 0x7fb1e8000b70 con 0x564f49a70610 rbd image ‘volume-4bb84842-24fb-42ff-bfa1-a4d73fae0f74’: size 1024 MB in 256 objects order 22 (4096 kB objects) block_name_prefix: rbd_data.47d0caaedb0 format: 2 features: layering, exclusive-lock, object-map, fast-diff, deep-flatten flags: 2017-12-19 06:45:57.729432 7fb20121f700 10 librbd::image::RefreshRequest: 0x7fb1dc004ae0 handle_v2_get_flags: r=0 2017-12-19 06:45:57.729446 7fb20121f700 10 librbd::image::RefreshRequest: 0x7fb1dc004ae0 send_v2_apply 2017-12-19 06:45:57.729459 7fb200a1e700 10 librbd::image::RefreshRequest: 0x7fb1dc004ae0 handle_v2_apply 2017-12-19 06:45:57.729460 7fb200a1e700 20 librbd::image::RefreshRequest: 0x7fb1dc004ae0 apply 2017-12-19 06:45:57.729470 7fb200a1e700 10 librbd::image::OpenRequest: handle_refresh: r=0 2017-12-19 06:45:57.729474 7fb200a1e700 10 librbd::ImageState: 0x564f49a68e00 0x564f49a68e00 handle_open: r=0 2017-12-19 06:45:57.729527 7fb21f07a100 20 librbd: info 0x564f49a6cc80 2017-12-19 06:45:57.729652 7fb21f07a100 20 librbd::ImageState: 0x564f49a68e00 close 2017-12-19 06:45:57.729656 7fb21f07a100 10 librbd::ImageState: 0x564f49a68e00 0x564f49a68e00 send_close_unlock 2017-12-19 06:45:57.729658 7fb21f07a100 10 librbd::image::CloseRequest: 0x564f49a71c60 send_shut_down_update_watchers 2017-12-19 06:45:57.729660 7fb21f07a100 20 librbd::ImageState: 0x564f49a68e00 shut_down_update_watchers 2017-12-19 06:45:57.729661 7fb21f07a100 20 librbd::ImageState: 0x564f49a6c9f0 ImageUpdateWatchers::shut_down 2017-12-19 06:45:57.729663 7fb21f07a100 20 librbd::ImageState: 0x564f49a6c9f0 ImageUpdateWatchers::shut_down: completing shut down 2017-12-19 06:45:57.729686 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 handle_shut_down_update_watchers: r=0 2017-12-19 06:45:57.729709 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 send_shut_down_aio_queue 2017-12-19 06:45:57.729711 7fb200a1e700 5 librbd::AioImageRequestWQ: shut_down: in_flight=0 2017-12-19 06:45:57.729717 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 handle_shut_down_aio_queue: r=0 2017-12-19 06:45:57.729720 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 send_flush 2017-12-19 06:45:57.729723 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 handle_flush: r=0 2017-12-19 06:45:57.729724 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 send_flush_readahead 2017-12-19 06:45:57.729727 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 handle_flush_readahead: r=0 2017-12-19 06:45:57.729728 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 send_shut_down_cache 2017-12-19 06:45:57.730112 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 handle_shut_down_cache: r=0 2017-12-19 06:45:57.730121 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 send_flush_op_work_queue 2017-12-19 06:45:57.730125 7fb200a1e700 10 librbd::image::CloseRequest: 0x564f49a71c60 handle_flush_op_work_queue: r=0 2017-12-19 06:45:57.730149 7fb200a1e700 10 librbd::ImageState: 0x564f49a68e00 0x564f49a68e00 handle_close: r=0 2017-12-19 06:45:57.730761 7fb21f07a100 1 – 10.5.0.27:0/973500521 mark_down 0x564f49a70610 – 0x564f49a6f330 2017-12-19 06:45:57.730831 7fb21f07a100 1 – 10.5.0.27:0/973500521 mark_down 0x564f49a679a0 – 0x564f49a666c0 2017-12-19 06:45:57.730882 7fb201b21700 2 – 10.5.0.27:0/973500521 &gt;&gt; 10.5.0.20:6789/0 pipe(0x564f49a666c0 sd=3 :54264 s=4 pgs=59511 cs=1 l=1 c=0x564f49a679a0).reader couldn’t read tag, (0) Success 2017-12-19 06:45:57.730901 7fb201b21700 2 – 10.5.0.27:0/973500521 &gt;&gt; 10.5.0.20:6789/0 pipe(0x564f49a666c0 sd=3 :54264 s=4 pgs=59511 cs=1 l=1 c=0x564f49a679a0).fault (0) Success 2017-12-19 06:45:57.731141 7fb21f07a100 1 – 10.5.0.27:0/973500521 mark_down_all 2017-12-19 06:45:57.731376 7fb20011c700 2 – 10.5.0.27:0/973500521 &gt;&gt; 10.5.0.20:6800/27653 pipe(0x564f49a6f330 sd=4 :53226 s=4 pgs=1847 cs=1 l=1 c=0x564f49a70610).reader couldn’t read tag, (0) Success 2017-12-19 06:45:57.731491 7fb20011c700 2 – 10.5.0.27:0/973500521 &gt;&gt; 10.5.0.20:6800/27653 pipe(0x564f49a6f330 sd=4 :53226 s=4 pgs=1847 cs=1 l=1 c=0x564f49a70610).fault (0) Success 2017-12-19 06:45:57.731618 7fb21f07a100 1 – 10.5.0.27:0/973500521 shutdown complete.<br>换硬盘后backfill不停止的实例</p>
<p>1, ./sos_commands/ceph/ceph_osd_tree<br>osd.12 weight -0</p>
<p>2,./sos_commands/ceph/ceph_health_detail, two inactive PGs can stop backfill<br>pg 88.9 is stuck inactive for 53999.758365, current state creating, last acting []<br>pg 20.ae3 is stuck unclean for 419743.607751, current state stale+active+undersized+degraded+remapped, last acting [68]<br>osd.160 is near full at 87%</p>
<p>ceph pg 88.9 query - stuck without output</p>
<p>pg 19.ff7 is stuck unclean for 234078.474055, current state active+undersized+degraded, last acting [105,126]<br>ceph pg 19.ff7 query</p>
<p>3, ./sos_commands/ceph/ceph_osd_tree<br>four host-cap without pgs mapped to them, all osds inside them are almost empty.<br>host-cap zag0t1a-sto199cz3543kpf1-hr<br>host-cap zag0t1b-sto200cz3543kpf3-hr<br>host-cap zag0t1b-sto200cz3543kpf3-hr<br>host-cap zag0t1a-sto199cz3543kpf1-hr</p>
<p>./sos_commands/ceph/ceph_osd_df_tree<br>-10 36.37000 - 37241G 448G 36792G 1.21 0.02 0 host-cap zag0t1a-sto199cz3543kpf1-hr<br>116 3.63699 1.00000 3724G 27055M 3697G 0.71 0.01 0 osd.116<br>167 3.63699 1.00000 3724G 27055M 3697G 0.71 0.01 0 osd.167<br>170 3.63699 1.00000 3724G 27055M 3697G 0.71 0.01 0 osd.170<br>168 3.63699 1.00000 3724G 27237M 3697G 0.71 0.01 0 osd.168<br>169 3.63699 1.00000 3724G 27055M 3697G 0.71 0.01 0 osd.169<br>131 3.63699 1.00000 3724G 27055M 3697G 0.71 0.01 0 osd.131<br>111 3.63699 1.00000 3724G 27055M 3697G 0.71 0.01 0 osd.111<br>117 3.63699 1.00000 3724G 27055M 3697G 0.71 0.01 0 osd.117<br>121 3.63699 1.00000 3724G 210G 3513G 5.66 0.11 0 osd.121<br>171 3.63699 1.00000 3724G 27055M 3697G 0.71 0.01 0 osd.171</p>
<p>4, This two hosts was moved from host-cap to host-std in crush rule 1<br>host-cap zag0t1b-sto200cz3543kpf3-hr<br>host-cap zag0t1a-sto199cz3543kpf1-hr</p>
<p>“rule_id”: 1,<br>       “steps”: [{ “op”: “take”, “item”: -48, “item_name”: “root-std-g”},<br>                 {“op”: “choose_firstn”, “num”: -1, “type”: “rack-std”},</p>
<p>the failure domain is supposed to be rack-std ? so one rack should have one replica. but you only have 2 rack with type “host-std” which are rack199-std and rack200-std. were you supposed to have 3 rack ? or am i missing somthing here.</p>
<p>they added two host to the rack-std, but didn’t change those two host’s type to host-std from rack-std</p>
<p>They are currently trying to fix their crush map, and once this is fixed, those backfill too full osds should be able to continue to do the backfill.</p>
<p>get the pgs mapped to those two machines. so that your backfill_toofull issue and nearfull issue can be solved.<br>附件 - juju</p>
<p>bash -c ‘cat &gt; cephtest.yaml’ &lt;&lt; EOF<br>series: bionic<br>machines:<br>  “0”: {}<br>  “1”: {}<br>  “2”: {}<br>applications:<br>  ceph-osd:<br>    charm: cs:ceph-osd-275<br>    num_units: 3<br>    options:<br>      aa-profile-mode: complain<br>    storage:<br>      osd-devices: “cinder,10G”<br>    to:</p>
<pre><code>- &apos;0&apos;
- &apos;1&apos;
- &apos;2&apos;
</code></pre><p>  ceph-mon:<br>    charm: cs:ceph-mon<br>    num_units: 3<br>    to:</p>
<pre><code>- lxd:0
- lxd:1
- lxd:2
</code></pre><p>relations:</p>
<ul>
<li>[ ceph-osd, ceph-mon ]<br>EOF<br>juju deploy ./cephtest.yaml<br>juju scp  ~/.local/share/juju/ssh/juju_id_rsa* ceph-osd/0:/home/ubuntu/<br>juju ssh ceph-osd/0 – ssh -i ./juju_id_rsa ubuntu@252.0.16.231</li>
</ul>
<p>参考：<br>1, <a href="http://blog.scsorlando.com/post/2013/11/21/Ceph-Install-and-Deployment-in-a-production-environment.aspx" target="_blank" rel="external">http://blog.scsorlando.com/post/2013/11/21/Ceph-Install-and-Deployment-in-a-production-environment.aspx</a><br>2, <a href="http://mathslinux.org/?p=441" target="_blank" rel="external">http://mathslinux.org/?p=441</a><br>3, <a href="http://blog.zhaw.ch/icclab/deploy-ceph-and-start-using-it-end-to-end-tutorial-installation-part-13/" target="_blank" rel="external">http://blog.zhaw.ch/icclab/deploy-ceph-and-start-using-it-end-to-end-tutorial-installation-part-13/</a><br>4, <a href="http://dachary.org/?p=1971" target="_blank" rel="external">http://dachary.org/?p=1971</a><br>5, <a href="http://blog.csdn.net/EricGogh/article/details/24348127" target="_blank" rel="external">http://blog.csdn.net/EricGogh/article/details/24348127</a><br>6, <a href="https://wiki.debian.org/OpenStackCephHowto" target="_blank" rel="external">https://wiki.debian.org/OpenStackCephHowto</a><br>7, <a href="http://ceph.com/docs/master/rbd/rbd-openstack/#configure-openstack-to-use-ceph" target="_blank" rel="external">http://ceph.com/docs/master/rbd/rbd-openstack/#configure-openstack-to-use-ceph</a><br>8, <a href="http://openstack.redhat.com/Using_Ceph_for_Cinder_with_RDO_Havana" target="_blank" rel="external">http://openstack.redhat.com/Using_Ceph_for_Cinder_with_RDO_Havana</a></p>
<p>9, <a href="http://dachary.org/?p=2374" target="_blank" rel="external">http://dachary.org/?p=2374</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/03/06/docker-host-net-mtu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/06/docker-host-net-mtu/" itemprop="url">docker host net mtu</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-03-06T11:48:55+08:00">
                2021-03-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华 发表于：2021-03-06<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</strong></p>
<p>在一个gre虚机上创建一个docker container，显然网络不通是由mtu造成的。但是如果host=net创建的网络为什么也是不行呢？<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run --rm --net=host --privileged --name=nginx -v /sys/fs/cgroup:/sys/fs/cgroup -d -ti nginx</span><br><span class="line">sudo docker exec -ti nginx bash</span><br></pre></td></tr></table></figure></p>
<p>测试了UDP与TCP都是时而可以时而不可以。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#TCP</span><br><span class="line">nc -tlp 8888</span><br><span class="line">nc -vtz 10.5.0.178 8888</span><br><span class="line"></span><br><span class="line">#UDP</span><br><span class="line">nc -ulp 8888</span><br><span class="line">nc -vuz 10.5.0.178 8888</span><br></pre></td></tr></table></figure>
<h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><ul>
<li>使用tcp时，tcp server每测试一遍会自动断，重新运行’nc -tlp 8888’每次均没有问题</li>
<li><p>使用udp时，udp server每测试一遍不会自动断，每次重新运行”nc -ulp 8888”不会有问题，但不重新运行server时就报refused错误了</p>
<p>上面其实都是正常的，但客户那里报的错如下，这也是正常的，至于“inverse host lookup failed: Unknown host”是查不到host, nc上添加”-n”参数即可解决。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> # nc -uvz xxx 5093</span><br><span class="line">xxx: inverse host lookup failed: Unknown host</span><br><span class="line">(UNKNOWN) [xxx] 5093 (?) open</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>但客户tcpdump抓到了如下mtu问题，这才是真正的错误所在</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">07:19:55.096224 IP 10.30.50.189.33473 &gt; xxx.5093: UDP, bad length 1432 &gt; 1408</span><br></pre></td></tr></table></figure>
<p>所以用nc测试能看到“5093 (?) open”说明网络是通的，但存在mtu问题。</p>
<h2 id="tcp可以时的抓包"><a href="#tcp可以时的抓包" class="headerlink" title="tcp可以时的抓包"></a>tcp可以时的抓包</h2><p>在虚机上的抓包数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@i1:~$ sudo tcpdump -ei ens2 -s 0 port 8888</span><br><span class="line">02:06:28.513860 fa:16:3e:54:36:ad (oui Unknown) &gt; fa:16:3e:22:d6:67 (oui Unknown), ethertype IPv4 (0x0800), length 74: i1.38146 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: Flags [S], seq 3310591319, win 65340, options [mss 1452,sackOK,TS val 2788776170 ecr 0,nop,wscale 7], length 0</span><br><span class="line">02:06:28.515634 fa:16:3e:22:d6:67 (oui Unknown) &gt; fa:16:3e:54:36:ad (oui Unknown), ethertype IPv4 (0x0800), length 74: juju-c40d4b-ovn-6.cloud.sts.8888 &gt; i1.38146: Flags [S.], seq 432497099, ack 3310591320, win 62342, options [mss 8918,sackOK,TS val 3043405881 ecr 2788776170,nop,wscale 7], length 0</span><br><span class="line">02:06:28.515689 fa:16:3e:54:36:ad (oui Unknown) &gt; fa:16:3e:22:d6:67 (oui Unknown), ethertype IPv4 (0x0800), length 66: i1.38146 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: Flags [.], ack 1, win 511, options [nop,nop,TS val 2788776172 ecr 3043405881], length 0</span><br><span class="line">02:06:28.515907 fa:16:3e:54:36:ad (oui Unknown) &gt; fa:16:3e:22:d6:67 (oui Unknown), ethertype IPv4 (0x0800), length 66: i1.38146 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: Flags [F.], seq 1, ack 1, win 511, options [nop,nop,TS val 2788776172 ecr 3043405881], length 0</span><br><span class="line">02:06:28.517663 fa:16:3e:22:d6:67 (oui Unknown) &gt; fa:16:3e:54:36:ad (oui Unknown), ethertype IPv4 (0x0800), length 68: juju-c40d4b-ovn-6.cloud.sts.8888 &gt; i1.38146: Flags [P.], seq 1:3, ack 2, win 488, options [nop,nop,TS val 3043405882 ecr 2788776172], length 2</span><br><span class="line">02:06:28.517723 fa:16:3e:54:36:ad (oui Unknown) &gt; fa:16:3e:22:d6:67 (oui Unknown), ethertype IPv4 (0x0800), length 54: i1.38146 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: Flags [R], seq 3310591321, win 0, length 0</span><br><span class="line">02:06:28.517860 fa:16:3e:22:d6:67 (oui Unknown) &gt; fa:16:3e:54:36:ad (oui Unknown), ethertype IPv4 (0x0800), length 66: juju-c40d4b-ovn-6.cloud.sts.8888 &gt; i1.38146: Flags [F.], seq 3, ack 2, win 488, options [nop,nop,TS val 3043405882 ecr 2788776172], length 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ubuntu@i1:~$ ip addr show ens2</span><br><span class="line">2: ens2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1492 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:54:36:ad brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.21.161/24 brd 192.168.21.255 scope global dynamic ens2</span><br></pre></td></tr></table></figure>
<p>在物理机上的抓包数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">02:06:28.514218 fa:16:3e:50:aa:2a (oui Unknown) &gt; fa:16:3e:64:80:50 (oui Unknown), ethertype IPv4 (0x0800), length 74: 10.5.150.115.38146 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: Flags [S], seq 3310591319, win 65340, options [mss 1452,sackOK,TS val 2788776170 ecr 0,nop,wscale 7], length 0</span><br><span class="line">02:06:28.514272 fa:16:3e:64:80:50 (oui Unknown) &gt; fa:16:3e:50:aa:2a (oui Unknown), ethertype IPv4 (0x0800), length 74: juju-c40d4b-ovn-6.cloud.sts.8888 &gt; 10.5.150.115.38146: Flags [S.], seq 432497099, ack 3310591320, win 62342, options [mss 8918,sackOK,TS val 3043405881 ecr 2788776170,nop,wscale 7], length 0</span><br><span class="line">02:06:28.515805 fa:16:3e:50:aa:2a (oui Unknown) &gt; fa:16:3e:64:80:50 (oui Unknown), ethertype IPv4 (0x0800), length 66: 10.5.150.115.38146 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: Flags [.], ack 1, win 511, options [nop,nop,TS val 2788776172 ecr 3043405881], length 0</span><br><span class="line">02:06:28.515848 fa:16:3e:50:aa:2a (oui Unknown) &gt; fa:16:3e:64:80:50 (oui Unknown), ethertype IPv4 (0x0800), length 66: 10.5.150.115.38146 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: Flags [F.], seq 1, ack 1, win 511, options [nop,nop,TS val 2788776172 ecr 3043405881], length 0</span><br><span class="line">02:06:28.516053 fa:16:3e:64:80:50 (oui Unknown) &gt; fa:16:3e:50:aa:2a (oui Unknown), ethertype IPv4 (0x0800), length 68: juju-c40d4b-ovn-6.cloud.sts.8888 &gt; 10.5.150.115.38146: Flags [P.], seq 1:3, ack 2, win 488, options [nop,nop,TS val 3043405882 ecr 2788776172], length 2</span><br><span class="line">02:06:28.516071 fa:16:3e:64:80:50 (oui Unknown) &gt; fa:16:3e:50:aa:2a (oui Unknown), ethertype IPv4 (0x0800), length 66: juju-c40d4b-ovn-6.cloud.sts.8888 &gt; 10.5.150.115.38146: Flags [F.], seq 3, ack 2, win 488, options [nop,nop,TS val 3043405882 ecr 2788776172], length 0</span><br><span class="line">02:06:28.517335 fa:16:3e:50:aa:2a (oui Unknown) &gt; fa:16:3e:64:80:50 (oui Unknown), ethertype IPv4 (0x0800), length 54: 10.5.150.115.38146 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: Flags [R], seq 3310591321, win 0, length 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@juju-c40d4b-ovn-6:~# ip addr show ens3</span><br><span class="line">2: ens3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8958 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:64:80:50 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.5.0.178/16 brd 10.5.255.255 scope global dynamic ens3</span><br></pre></td></tr></table></figure>
<h2 id="udp可以时的抓包"><a href="#udp可以时的抓包" class="headerlink" title="udp可以时的抓包"></a>udp可以时的抓包</h2><p>虚机</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">02:15:12.943389 fa:16:3e:54:36:ad (oui Unknown) &gt; fa:16:3e:22:d6:67 (oui Unknown), ethertype IPv4 (0x0800), length 43: i1.39709 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: UDP, length 1</span><br><span class="line">02:15:12.946069 fa:16:3e:54:36:ad (oui Unknown) &gt; fa:16:3e:22:d6:67 (oui Unknown), ethertype IPv4 (0x0800), length 43: i1.39709 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: UDP, length 1</span><br><span class="line"></span><br><span class="line">ubuntu@i1:~$ sudo tcpdump -i ens2 udp port 8888 -A -nn</span><br><span class="line">02:46:17.724481 IP 192.168.21.161.50757 &gt; 10.5.0.178.8888: UDP, length 1</span><br><span class="line">E...#.@.@.6.....</span><br><span class="line">....E&quot;..        ...</span><br><span class="line">02:46:17.728605 IP 192.168.21.161.50757 &gt; 10.5.0.178.8888: UDP, length 1</span><br><span class="line">E...#.@.@.6.....</span><br><span class="line">....E&quot;..        ...</span><br></pre></td></tr></table></figure>
<p>物理机</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">02:15:12.942802 fa:16:3e:50:aa:2a (oui Unknown) &gt; fa:16:3e:64:80:50 (oui Unknown), ethertype IPv4 (0x0800), length 43: 10.5.150.115.39709 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: UDP, length 1</span><br><span class="line">02:15:12.944746 fa:16:3e:50:aa:2a (oui Unknown) &gt; fa:16:3e:64:80:50 (oui Unknown), ethertype IPv4 (0x0800), length 43: 10.5.150.115.39709 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: UDP, length 1</span><br></pre></td></tr></table></figure>
<h2 id="udp不可以时的抓包数据-这也是正常的，server要重启"><a href="#udp不可以时的抓包数据-这也是正常的，server要重启" class="headerlink" title="udp不可以时的抓包数据(这也是正常的，server要重启)"></a>udp不可以时的抓包数据(这也是正常的，server要重启)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@10:/# nc -vuz 10.5.0.178 8888</span><br><span class="line">juju-c40d4b-ovn-6.cloud.sts [10.5.0.178] 8888 (?) : Connection refused</span><br></pre></td></tr></table></figure>
<p>虚机</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">02:16:28.016397 fa:16:3e:54:36:ad (oui Unknown) &gt; fa:16:3e:22:d6:67 (oui Unknown), ethertype IPv4 (0x0800), length 43: i1.55573 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: UDP, length 1</span><br></pre></td></tr></table></figure>
<p>物理机<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">02:16:28.014916 fa:16:3e:50:aa:2a (oui Unknown) &gt; fa:16:3e:64:80:50 (oui Unknown), ethertype IPv4 (0x0800), length 43: 10.5.150.115.55573 &gt; juju-c40d4b-ovn-6.cloud.sts.8888: UDP, length 1</span><br></pre></td></tr></table></figure></p>
<h2 id="UDP-bad-length-1432-gt-1408"><a href="#UDP-bad-length-1432-gt-1408" class="headerlink" title="UDP, bad length 1432 &gt; 1408"></a>UDP, bad length 1432 &gt; 1408</h2><p>错误”UDP, bad length 1432 &gt; 1408”意为UDP包长度大于UDP有效负载长度(The tcpdump error message you get is due to IP fragmentation which happens because the multicast datagram length &gt; MTU - <a href="https://github.com/the-tcpdump-group/tcpdump/blob/tcpdump-4.7.4/print-udp.c#L694)，客户的ens3的mtu是1442" target="_blank" rel="external">https://github.com/the-tcpdump-group/tcpdump/blob/tcpdump-4.7.4/print-udp.c#L694)，客户的ens3的mtu是1442</a>, 这个1442是怎么来的。</p>
<p>以太网帧为46到1500节字之间，IPv4的IP包头是20，IP报文体是1480字节。UDP头(源端口，目标端口，UDP长度，UDP校验和）是8字节，所以UDP包长度是1472字节。还有GRE头也是8字节。<br>所以 1442 - 20(IP头) - 8 (UDP头) - 8 (ICMP头）　＝　1408<br>GRE/Vxlan的包头大小见　－　<a href="https://tonydeng.github.io/sdn-handbook/basic/overlay.html" target="_blank" rel="external">https://tonydeng.github.io/sdn-handbook/basic/overlay.html</a></p>
<p>可用下列命令测试mtu (1442 - 28 = 1414)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ping -c 2 -s 1414 -M do 10.5.0.178</span><br><span class="line"></span><br><span class="line">root@10:/# traceroute --mtu 10.5.0.178</span><br><span class="line">traceroute to 10.5.0.178 (10.5.0.178), 30 hops max, 65000 byte packets</span><br><span class="line"> 1  * F=1492 * *</span><br><span class="line"> 2  juju-c40d4b-ovn-6.cloud.sts (10.5.0.178)  2.859 ms  2.169 ms  0.671 ms</span><br></pre></td></tr></table></figure></p>
<p>对于udp, 因为无连接, 所以无法协商mss<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/sys/net/ipv4/ip_no_pmtu_disc</span><br><span class="line">0</span><br></pre></td></tr></table></figure></p>
<p>见 - <a href="https://zhhuabj.blog.csdn.net/article/details/82346840" target="_blank" rel="external">https://zhhuabj.blog.csdn.net/article/details/82346840</a><br>根据这篇文章（<a href="https://blog.csdn.net/sinat_20184565/article/details/80326262），对于udp，在udp" target="_blank" rel="external">https://blog.csdn.net/sinat_20184565/article/details/80326262），对于udp，在udp</a> server处设置ip_no_pmtu_disc=1(docker中如何设置-<a href="https://github.com/hwdsl2/docker-ipsec-vpn-server)后，udp" target="_blank" rel="external">https://github.com/hwdsl2/docker-ipsec-vpn-server)后，udp</a> server发出来的包会带有禁止分片DF=1, 这样当udp client收到这种DF=1且udp包大小&gt;mtu时（也见－<a href="https://zhhuabj.blog.csdn.net/article/details/114434188）就会向server返回实际的mtu大小，然后server端将包先按mtu分好。因为一般udp分片都是关的，所以需要在server端的应用层先分好。" target="_blank" rel="external">https://zhhuabj.blog.csdn.net/article/details/114434188）就会向server返回实际的mtu大小，然后server端将包先按mtu分好。因为一般udp分片都是关的，所以需要在server端的应用层先分好。</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@i1:~$ ethtool -k ens2 |grep udp-fragmentation-offload</span><br><span class="line">udp-fragmentation-offload: off</span><br></pre></td></tr></table></figure></p>
<p>另一种办法可以是提高虚机与容器的mtu到(1432+ 28=1460), 为什么现在是1442这么低。</p>
<h2 id="重现问题"><a href="#重现问题" class="headerlink" title="重现问题"></a>重现问题</h2><p>perf相比nc有一个-l参数，可以指定udp包大小(在服务端不指定大小，在客户端指定大小1432, 这样得出1432是发包，所以可以很容易重现问题。<br>在容器里运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf -c 10.5.0.178 -u -l 1432</span><br></pre></td></tr></table></figure></p>
<p>在物理机上运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf -s -u</span><br></pre></td></tr></table></figure></p>
<p>容器里抓包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@i1:~$ sudo tcpdump -ei ens2 -s 0 port 5001</span><br><span class="line">04:06:53.401372 fa:16:3e:54:36:ad (oui Unknown) &gt; fa:16:3e:22:d6:67 (oui Unknown), ethertype IPv4 (0x0800), length 1450: i1.54000 &gt; juju-c40d4b-ovn-6.cloud.sts.5001: UDP, bad length 1432 &gt; 1408</span><br></pre></td></tr></table></figure></p>
<p>换成下列UDP代码无问题, 但将里面的server与client的行（msgFromServer       = “Hello UDP Client”）改成（msgFromServer       = “Hello UDP Client” * 100 )就重现问题了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt; EOF | sudo tee -a udp_server.py</span><br><span class="line">import socket</span><br><span class="line">localIP     = &quot;0.0.0.0&quot;</span><br><span class="line">localPort   = 5001</span><br><span class="line">bufferSize  = 1024</span><br><span class="line">msgFromServer       = &quot;Hello UDP Client&quot;</span><br><span class="line">bytesToSend         = str.encode(msgFromServer)</span><br><span class="line"># Create a datagram socket</span><br><span class="line">UDPServerSocket = socket.socket(family=socket.AF_INET, type=socket.SOCK_DGRAM)</span><br><span class="line"># Bind to address and ip</span><br><span class="line">UDPServerSocket.bind((localIP, localPort))</span><br><span class="line">print(&quot;UDP server up and listening&quot;)</span><br><span class="line"># Listen for incoming datagrams</span><br><span class="line">while(True):</span><br><span class="line">    bytesAddressPair = UDPServerSocket.recvfrom(bufferSize)</span><br><span class="line">    message = bytesAddressPair[0]</span><br><span class="line">    address = bytesAddressPair[1]</span><br><span class="line">    clientMsg = &quot;Message from Client:&#123;&#125;&quot;.format(message)</span><br><span class="line">    clientIP  = &quot;Client IP Address:&#123;&#125;&quot;.format(address)</span><br><span class="line">    print(clientMsg)</span><br><span class="line">    print(clientIP)</span><br><span class="line">    # Sending a reply to client</span><br><span class="line">    UDPServerSocket.sendto(bytesToSend, address)</span><br><span class="line">EOF</span><br><span class="line">python3 udp_server.py</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF | sudo tee -a udp_client.py</span><br><span class="line">import socket</span><br><span class="line">msgFromClient       = &quot;Hello UDP Server&quot;</span><br><span class="line">bytesToSend         = str.encode(msgFromClient)</span><br><span class="line">serverAddressPort   = (&quot;192.168.2.139&quot;, 5001)</span><br><span class="line">bufferSize          = 1024</span><br><span class="line"># Create a UDP socket at client side</span><br><span class="line">UDPClientSocket = socket.socket(family=socket.AF_INET, type=socket.SOCK_DGRAM)</span><br><span class="line"># Send to server using created UDP socket</span><br><span class="line">UDPClientSocket.sendto(bytesToSend, serverAddressPort)</span><br><span class="line">msgFromServer = UDPClientSocket.recvfrom(bufferSize)</span><br><span class="line">msg = &quot;Message from Server &#123;&#125;&quot;.format(msgFromServer[0])</span><br><span class="line">print(msg)</span><br><span class="line">EOF</span><br><span class="line">python3 udp_client.py</span><br></pre></td></tr></table></figure></p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>这个udp包的大小是由udp应用自己指定的。</p>
<ul>
<li>iperf遇到这种udp包比mss还大的情况（<a href="https://github.com/esnet/iperf/issues/604）就提醒人们注意了" target="_blank" rel="external">https://github.com/esnet/iperf/issues/604）就提醒人们注意了</a> - <a href="https://github.com/esnet/iperf/commit/6663be4144873b2751e7ae48b0161663ecf78d00" target="_blank" rel="external">https://github.com/esnet/iperf/commit/6663be4144873b2751e7ae48b0161663ecf78d00</a></li>
<li>有一些软件会在udp发送端(server与client都有可能成为发送端设置“echo 1 &gt;/proc/sys/net/ipv4/ip_no_pmtu_disc”，这样不再充许pmtu协商 (这当然也会破坏tcp的mss协商)，这相当于是 disable the Don’t Fragment (DF) ( DF置位时才能pmtu协商），这样这种软件自己实现了IP分片。见: <a href="https://www.zeitgeist.se/2013/11/26/mtu-woes-in-ipsec-tunnels-how-to-fix/" target="_blank" rel="external">https://www.zeitgeist.se/2013/11/26/mtu-woes-in-ipsec-tunnels-how-to-fix/</a></li>
</ul>
<p>所以对于这个问题的解决：</p>
<ul>
<li>要么udp软件中自己改小udp包大小。</li>
<li>要求提高虚机的mtu (这也得改底层openstack的mtu)</li>
</ul>
<p>也这是为什么一些网站如京东用到了udp不好使的原因　－　见：　<a href="https://blog.csdn.net/quqi99/article/details/82346840" target="_blank" rel="external">https://blog.csdn.net/quqi99/article/details/82346840</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/03/04/Win10-UEFI-Ubuntu-18-04-UEFI双系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/04/Win10-UEFI-Ubuntu-18-04-UEFI双系统/" itemprop="url">Win10 UEFI + Ubuntu 18.04 UEFI双系统</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-03-04T20:31:51+08:00">
                2021-03-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本人昨天买了一块SSD, 结果后来发现原来这块SSD存在硬件质量问题, 造成了软件上的种种诡异问题, 如U盘时而识别时而不识别, 如触摸屏左键时而抽风, 如ghost安装win10时几乎到100%的进度时忽然来一个无响应, 重启系统后出现了”To interrupt normal start up, press the blue ThinkVantage button.”, 此时键盘无反应, 既进不了系统, 也进不了BIOS. 拨CMOS电源也无效. 最后发现是这块SSD有质量问题. 估计是SSD有控制器主要是软件吧, 控制器软件有bug导致运行ghost这种软件时也能导致硬件挂住.<br>也正是因为这个问题吧, 七搞八搞, 一不小心在重试的过程中将之前的一块linux分区误删了, 于是之前打算的迁移双系统的想法泡汤(当然, 那些通过分区助手或者ghost来迁移分区的网上文章照着做没一个是成功的).<br>这样, 有机会事隔多年再一次重装双系统的机会, 但是发现世道变了, 之前百试不爽的方法现在行不通了. 后经查证, 主要原因是ubuntu 18.04开始默认采用UEFI, 而win10默认仍然是MBR. 这样会导致一系列的问题, 如报错: grub-efi-amd64-signed failed to install 18.04, 统一采用UEFI安装.</p>
<h2 id="BIOS设置"><a href="#BIOS设置" class="headerlink" title="BIOS设置"></a>BIOS设置</h2><p>在BIOS中将Boot Mode设置为UEFI Only, 如果有Secure Boot选项还要disable它(不做这一步可能会造成按F12键之后无法找到U盘)<br>注: 改成UEFI only之后, 运行双系统, 四系统都没问题, 但后来进不了U盘的livecd, 报: couldn’t get UEFI db list, 所以只得改回Both, 但UEFI优先.</p>
<h2 id="安装win10"><a href="#安装win10" class="headerlink" title="安装win10"></a>安装win10</h2><ul>
<li>下载大白菜UEFI专版 - <a href="http://www.bigbaicai.com/download.html?down2" target="_blank" rel="external">http://www.bigbaicai.com/download.html?down2</a></li>
<li>下载win10 ghost - axel -n 10 <a href="http://xz.win10cjb.com/18.5/win10_64/DEEP_Win10x64_201805.rar" target="_blank" rel="external">http://xz.win10cjb.com/18.5/win10_64/DEEP_Win10x64_201805.rar</a></li>
<li>制作大白菜启动U盘, 如果界面上有UEFI字眼就点上(不记得了, 有就点上), 还要注意一点, 记得点里面的格式转换, 将FAT32格式(HDD-FAT32)转换成NTFS(HDD-NTFS)转换, 否则HDD-FAT32格式不能拷贝大于4G的ghost文件哦,</li>
<li>按F12选U盘启动进入大白菜后, 用DiskGenius工具重新分区, 必须将BIOS+MBR格式转UEFI+GPT格式. 分区表格式为GUID而不是MBR, window上管EFI分区叫ESP/MSR分区</li>
<li><p>注意, 不要修改推荐的卷标, 这个卷就是指向的ESP/MSR分区.</p>
<h2 id="安装win10后"><a href="#安装win10后" class="headerlink" title="安装win10后"></a>安装win10后</h2><p>安装win10后需要将禁用掉快速启动, 否则会造成按F12无法选择U盘启动. 菜单路径为: “设置 -&gt; 系统 -&gt; 电源与睡眠 -&gt; 其他电源设置 -&gt; 选择电源按钮的功能 -&gt; 更改当前不可用的设置 -&gt; 启动快速启动”</p>
<h2 id="安装ubuntu-18-04"><a href="#安装ubuntu-18-04" class="headerlink" title="安装ubuntu 18.04"></a>安装ubuntu 18.04</h2><p>像安装win10一样, 一样要注意重要一点, 需创建大概300M左右的UEF分区, 另外, 还可以创建一个根分区和一个备份文件用的bak分区.<br>注意, windows非常霸道, 它是总修改bios里的启动顺序, 将它的”Windows boot Manager”放在”ubuntu grub”的前面, 可以在bios里锁定启动顺序</p>
<h2 id="安装win7"><a href="#安装win7" class="headerlink" title="安装win7"></a>安装win7</h2><p>win7若没有sata的驱动, 所以得先改回IDE, 装完win7之后再改回AHCI, 否则也容易挂在启动界面不动了.<br>注: 我未遇到以上问题, 可能因为我装的win7并不是原版的, 已经带了sata驱动</p>
<h2 id="加装SSD"><a href="#加装SSD" class="headerlink" title="加装SSD"></a>加装SSD</h2><p>如果加装了SSD之后呢? 那得注意:</p>
</li>
<li><p>装win10时同样需要进大白菜或老毛桃后用DiskGenius在SSD上划分ESP/MSR分区</p>
</li>
<li>装ubuntu时, 分区处也要创建EFI分区, 同时grub设置安装在SSD上, 相当于: grub-install /dev/sdX.</li>
<li>bios里选择哪块硬盘启动. 其实在SSD上安装grub后, 这个grub会连HDD上原先的win10与ubuntu一起放在启动列表里. 注意, windows非常霸道, 它是总修改bios里的启动顺序, 将它的”Windows boot Manager”放在”ubuntu grub”的前面, 可以在bios里锁定启动顺序</li>
<li><p>有时候需要对ssd优化, 例如不要将swap分区放在ssd以延长寿命, 如更改i/o调度策略为noop, 如使用bcache</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>装完之后进入win10发现thinkpad小红点左键失灵, 再切换进ubuntu发现小红点左键正常(实际上, 5次大概有一次有问题, 只是登录界面左键与右键似乎混乱了, 登录之后就正常了. 再换PE进系统发现小红点左键依然有问题. 所以基本断定和硬件没有关系, 应该是win10上的小红点驱动有问题.<br>但搜索了很多帖子, 没一个能解决问题的, 联想的小红点win10驱动做得太烂了. 所以决定回到win7, 回到win7之后该问题解决. 另外, PE回到win7的过程中不会伤害之前SSD上安装的ubuntu系统, 也不会伤害原HDD里的双系统.</p>
<h2 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h2><p>现在在笔记本x220t上装了win10, 也装了ubuntu 18.04, 但是如何将工作机t440p的根分区迁移到x220t的根分区呢? 因为我们已经在x220t上安装了ubuntu 18.04, 这样省去了采用命令划分EFI分区, 以及最后填充EFI分区的步骤. 现在将精力集中在如何快速迁移根分区上.</p>
</li>
<li><p>目的机x220t因为有写操作, 故要以livecd启动, 启动ssh server, 并将根分区加载到/mnt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sudo -i</span><br><span class="line">apt install openssh-server</span><br><span class="line">passwd</span><br><span class="line">echo &apos;PermitRootLogin yes&apos; &gt;&gt; /etc/ssh/sshd_config</span><br><span class="line">service ssh restart</span><br><span class="line">fdisk -l</span><br><span class="line">mount /dev/sdb4 /mnt</span><br><span class="line"></span><br><span class="line"># backup 3 files</span><br><span class="line">/mnt/boot/grub/grub.cfg</span><br><span class="line">/mnt/etc/hostname</span><br><span class="line">/mnt/etc/fstab</span><br></pre></td></tr></table></figure>
</li>
<li><p>源机t440p只有读操作故不需要以livecd启动. 但如果以livecd启动的话, 未加载根分区所依赖的分区如/bak分区, 此时如果又没挂载/bak分区的话, rsync命令迁移一些指向/bak分区的软链时会报错退出. 人工删除该软链重新运行即可.  且需要注意 rsync命令中的/mnt/后应该有/, 否则会将mnt目录迁移到根分区的mnt目录下.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sudo -i</span><br><span class="line">fdisk -l</span><br><span class="line">mount /dev/sda9 /mnt</span><br><span class="line"></span><br><span class="line"># rsync will now copy all files, directories, permissions and owners over to the destination machine.</span><br><span class="line"># It also skips all files and directories that are not on the root filesystem, like /dev/, /sys/, /proc/.</span><br><span class="line"># If there are filesystems that are mounted separately on the source machine and your want those copied too, use rsync again on those mountpoints too.</span><br><span class="line"># NOT USE livecd</span><br><span class="line">rsync -xavP --numeric-ids --exclude=&apos;tmp&apos; --exclude=&apos;/nas&apos; /mnt/ root@192.168.99.128:/mnt/</span><br><span class="line"># USE livecd</span><br><span class="line">rsync -xavP --numeric-ids --exclude=&apos;tmp&apos; / root@192.168.99.128:/mnt/</span><br><span class="line"></span><br><span class="line"># then restore above 3 files</span><br><span class="line">/mnt/boot/grub/grub.cfg</span><br><span class="line">/mnt/etc/hostname</span><br><span class="line">/mnt/etc/fstab</span><br></pre></td></tr></table></figure>
</li>
<li><p>可选, 如果之前没有备份/mnt/boot/grub/grub.cfg, 这时也可以重新生成. 更新grub, 此时会报”canot find EFI directory”, 这样会导致这时生成grub时无法找到原HDD中的双系统, 不要紧, 只要找到目前SSD中的双系统即可. 呆会下一步再运行一下grub命令即可解决</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/sdb8 /mnts</span><br><span class="line">for d in dev sys proc; do mount --bind /$d /mnt/$d; done</span><br><span class="line">chroot /mnt/ grub-install /dev/sdb   # canot find EFI directory</span><br><span class="line">chroot /mnt/ update-grub</span><br></pre></td></tr></table></figure>
</li>
<li><p>可选, 如果之前没有备份/mnt/etc/fstab, 这时也可以重新生成. 修复fstab, 之前运行上述迁移命令前忘了备份x220t上的fstab系统, 导致它被覆盖, OK, 我们修复它.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">blkid</span><br><span class="line">e2label /dev/sdb8 &quot;ROOT_SSD&quot;</span><br><span class="line">tee &quot;/mnt/etc/fstab&quot; &lt;&lt;EOF</span><br><span class="line">#UUID can be found via blkid command</span><br><span class="line">#LABEL=boot /boot ext2 sync 0 2</span><br><span class="line">#UUID=735b3be3-779c-4d21-a944-b033225f3ab4 none   swap    sw      0       0</span><br><span class="line">#LABEL=SWAP none swap sw 0 0</span><br><span class="line">UUID=9401-D2EA /boot/efi vfat defaults 0 2</span><br><span class="line">LABEL=ROOT_SSD / ext4 errors=remount-ro 0 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
<li><p>这时重启系统, 就可以以grub选择启动SSD上的双系统了, 如果还想把HDD的原有的双系统也加到grub的话, 那进ubuntu系统后再执行一次update-grub命令即可.</p>
</li>
<li>这种迁移方式效果非常好, 一个rsync命令搞定, 各种工作软件不需要再重装了. 呵呵<h2 id="bcache"><a href="#bcache" class="headerlink" title="bcache"></a>bcache</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install bcache-tools</span><br><span class="line"># sdb is ssd, sda is hdd</span><br><span class="line"># bcache will refuse to instantiate if it looks like a filesystem already exists on the device</span><br><span class="line">sudo umount /data</span><br><span class="line">sudo umount /bak</span><br><span class="line">sudo wipefs -a /dev/sdb5</span><br><span class="line">sudo wipefs -a /dev/sda5</span><br><span class="line"># creating the bcache, --discard flag is for TRIM</span><br><span class="line">sudo make-bcache -C /dev/sdb5 -B /dev/sda5 --block 4k --discard --writeback</span><br><span class="line"># creae and mount the filesystem</span><br><span class="line">sudo mkfs.ext4 /dev/bcache0</span><br><span class="line">sudo mkdir -p /bak</span><br><span class="line"></span><br><span class="line"># remember to comment /bak and /data as well, or it will throw: Welcome to emergency mode</span><br><span class="line">vi /etc/fstab</span><br><span class="line">#UUID=85d5095b-4288-4cc3-8ac7-aae3ed8e872c /bak            ext4    defaults        0       2</span><br><span class="line">#UUID=e246b3d0-6905-4602-a3ae-2f2162f9871f /data           ext4    defaults        0       2</span><br><span class="line">/dev/bcache0 /bak           ext4    defaults        0       2</span><br><span class="line"></span><br><span class="line"># other commands</span><br><span class="line">ls -la /sys/fs/bcache/</span><br><span class="line">umount /bak</span><br><span class="line">echo 1 /sys/block/bcache0/bcache/stop</span><br><span class="line">echo f3e2ac40-5dc4-4e28-880c-4bbb6cd415e3 /sys/block/bcache0/bcache/detach</span><br><span class="line">lsblk</span><br><span class="line">cat /sys/block/bcache0/bcache/state</span><br><span class="line">cat /sys/block/bcache0/bcache/cache_mode</span><br><span class="line">cat /sys/block/bcache0/bcache/dirty_data</span><br><span class="line">bcache-super-show /dev/sda5</span><br><span class="line">bcache-super-show /dev/sdb5</span><br><span class="line">lsblk</span><br><span class="line"></span><br><span class="line">#其他, 测试虚机中ceph盘的性能</span><br><span class="line">The IO path is:</span><br><span class="line">VM -&gt; RBD -&gt; compute node -&gt; network -&gt; OSD(primary + 2 replicas) -&gt; bcache (nvme + hdd)</span><br><span class="line"></span><br><span class="line">Stage 1, exclude VM, check IO performance on RBD directly</span><br><span class="line">Create a RBD in cinder-ceph pool and run rbd bench to check IOPS</span><br><span class="line">rbd create cinder-ceph/canonical-test-rbd --size 20G</span><br><span class="line">rbd bench cinder-ceph/canonical-test-rbd --io-size=4K --io-threads=1 --io-total=10G --io-pattern=rand --io-type=write</span><br><span class="line">rbd bench cinder-ceph/canonical-test-rbd --io-size=4K --io-threads=1 --io-total=10G --io-pattern=rand --io-type=read</span><br><span class="line">rbd bench cinder-ceph/canonical-test-rbd --io-size=4M --io-threads=1 --io-total=10G --io-pattern=rand --io-type=write</span><br><span class="line">rbd bench cinder-ceph/canonical-test-rbd --io-size=4M --io-threads=1 --io-total=10G --io-pattern=rand --io-type=read</span><br><span class="line">rbd rm cinder-ceph/canonical-test-rbd</span><br><span class="line"></span><br><span class="line">Stage 2, check network between compute node and the nodes which store test RBD’s primary or replicas</span><br><span class="line">This can be done by iperf</span><br><span class="line"></span><br><span class="line">Stage 3, IO performance on OSD nodes hold the RBD’s primary and 2 replicas</span><br><span class="line">We can not test IO performance on OSD devices directly, so need to find a way to test bcache performance on OSD node, we can use /var/lib/virt/image as test</span><br><span class="line">We can possibly use this folder /var/lib/virt/images to verify IO performance, but there is ext4 built on this bcache, so file system cache could affect a bit, but we should be able to roughly see the overall performance</span><br><span class="line">dd if=/dev/zero of=/var/lib/virt/images/fiotest-image bs=1M count=10240</span><br><span class="line">fio --name=fiotest --rw=randwrite --bs=4k --runtime=30 --ioengine=libaio --iodepth=128 --numjobs=1 --filename=/var/lib/virt/images/canonical-fiotest-image --direct=1 --sync=1 --group_reporting --time_based=1 --eta-newline 1</span><br><span class="line">fio --name=fiotest --rw=randread --bs=4k --runtime=30 --ioengine=libaio --iodepth=128 --numjobs=1 --filename=/var/lib/virt/images/canonical-fiotest-image --direct=1 --sync=1 --group_reporting --time_based=1 --eta-newline 1</span><br><span class="line">fio --name=fiotest --rw=randwrite --bs=4m --runtime=30 --ioengine=libaio --iodepth=128 --numjobs=1 --filename=/var/lib/virt/images/canonical-fiotest-image --direct=1 --sync=1 --group_reporting --time_based=1 --eta-newline 1</span><br><span class="line">fio --name=fiotest --rw=randread --bs=4m --runtime=30 --ioengine=libaio --iodepth=128 --numjobs=1 --filename=/var/lib/virt/images/canonical-fiotest-image --direct=1 --sync=1 --group_reporting --time_based=1 --eta-newline 1</span><br><span class="line">rm -f /var/lib/virt/images/fiotest-image</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>两个参数：</p>
<ul>
<li>sequential_cutoff默认为4k, 就是大于4k的就是绕开NVME直接往HDD写, 为0就是disable这个特性。所以这个要设置为0, 不然IO性能会很差。</li>
<li>另外bcache的cache_available_percent(/sys/block/bcache0/bcache/cache/cache_available_percent)来看bacache的ssd/cache是不是被写满了，被写满了IO(没写时是100,降到30就差不多快满了)会直接写backing HDD，这样IO会很慢。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">while true; do echo `date`; cat /sys/block/bcache0/bcache/cache/cache_available_percent; cat /sys/block/bcache0/bcache/dirty_data; cat /sys/block/bcache0/bcache/writeback_rate; sleep 5; done;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line"># comes dongdong&apos;s patch - https://lkml.org/lkml/2021/1/8/110</span><br><span class="line">while true; do echo &quot;`date +%s`, `cat</span><br><span class="line">/sys/block/bcache0/bcache/dirty_data`, `cat</span><br><span class="line">/sys/block/bcache0/bcache/cache/cache_available_percent`, `cat</span><br><span class="line">/sys/block/bcache0/bcache/writeback_rate`&quot; &gt;&gt; $1; sleep 5; done;</span><br></pre></td></tr></table></figure>
<h2 id="恢复bak分区"><a href="#恢复bak分区" class="headerlink" title="恢复bak分区"></a>恢复bak分区</h2><p>bak分区存放数据, 由bcache加速<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -xavP --numeric-ids --exclude=&apos;images&apos; /bak/ root@192.168.99.128:/bak/</span><br></pre></td></tr></table></figure></p>
<h2 id="调整分区"><a href="#调整分区" class="headerlink" title="调整分区"></a>调整分区</h2><p>一个分区不够用时, 可以使用gpartd合并相邻的空闲分区.注意一点, 要合并的分区必须是umount状态时才能合并.</p>
<h2 id="SSD优化"><a href="#SSD优化" class="headerlink" title="SSD优化"></a>SSD优化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"># disable scanning for btrfs filesystems when boot</span><br><span class="line">sudo apt-get purge btrfs-tools</span><br><span class="line">sudo update-initramfs -ukall</span><br><span class="line"></span><br><span class="line"># enable TRIM feature by adding discard option</span><br><span class="line"># what&apos;s TRIM - https://blog.csdn.net/quqi99/article/details/50963308</span><br><span class="line"># the option noatime is used to disable access time for a file</span><br><span class="line">sudo hdparm -I /dev/sdb |grep TRIM</span><br><span class="line">vi /etc/fstab</span><br><span class="line">LABEL=ROOT_SSD /               ext4    noatime,discard,errors=remount-ro 0       1</span><br><span class="line">sudo mount -o remount /dev/sdb8</span><br><span class="line">sudo mount |grep sdb8 |grep discard</span><br><span class="line"></span><br><span class="line"># Try not to use swap space unless it&apos;s running out of memory.</span><br><span class="line">echo 1 &gt; /proc/sys/vm/swappiness</span><br><span class="line"></span><br><span class="line"># avoid visiting ssd by using ramdisk for /tmp instead of tmpfs</span><br><span class="line">vim /etc/fstab</span><br><span class="line">tmpfs /tmp tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">tmpfs /var/tmp tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">tmpfs /var/log tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">sudo mount -o remount /</span><br><span class="line"></span><br><span class="line"># Set chrome to use ramdisk cache</span><br><span class="line">cd ~/.cache/google-chrome/Default</span><br><span class="line">rm -rf Cache</span><br><span class="line">sudo ln -s /tmp Cache</span><br><span class="line">rm -rf Media\ Cache/</span><br><span class="line">sudo ln -s /tmp Media\ Cache</span><br><span class="line"></span><br><span class="line"># Use noop for I/O elevator</span><br><span class="line">cat /sys/block/sda/queue/scheduler</span><br><span class="line">sudo vi /etc/default/grub</span><br><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=&quot;elevator=noop&quot;</span><br><span class="line">sudo update-grub</span><br><span class="line"></span><br><span class="line"># Test SSD speed</span><br><span class="line">$ sudo hdparm -Tt /dev/sdb</span><br><span class="line">/dev/sdb:</span><br><span class="line"> Timing cached reads:   9128 MB in  2.00 seconds = 4569.28 MB/sec</span><br><span class="line"> Timing buffered disk reads: 818 MB in  3.01 seconds = 272.07 MB/sec</span><br><span class="line"></span><br><span class="line"># Make sure 4K align</span><br><span class="line">$ sudo fdisk -lu |grep sdb |grep sectors</span><br><span class="line">Disk /dev/sdb: 232.9 GiB, 250059350016 bytes, 488397168 sectors</span><br><span class="line"></span><br><span class="line"># Health check</span><br><span class="line">$ sudo smartctl -s on -a /dev/sdb |grep PASSED</span><br><span class="line">SMART overall-health self-assessment test result: PASSED</span><br></pre></td></tr></table></figure>
<h2 id="20200808更新"><a href="#20200808更新" class="headerlink" title="20200808更新"></a>20200808更新</h2><p>为什么新电脑think x1 yoga这次又要安装双系统，那是因为win10上的cmder似乎丢失键盘按键, 见：<a href="https://github.com/cmderdev/cmder/issues/258" target="_blank" rel="external">https://github.com/cmderdev/cmder/issues/258</a><br>与：　<a href="https://blog.csdn.net/quqi99/article/details/105598417" target="_blank" rel="external">https://blog.csdn.net/quqi99/article/details/105598417</a><br>需关闭win10上的硬盘加密功能：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">manage-bde -status</span><br><span class="line">manage-bde -?</span><br><span class="line">manage-bde -off c:</span><br><span class="line">manage-bde -off d:</span><br></pre></td></tr></table></figure></p>
<p>另外，用ubuntu上的Startup Disk Creation创建u盘启动盘时总不好使，后来证明是U盘质量问题．<br>目前ubuntu 20.4还遇到一个尚未解决的问题，锁屏时敲密码hang在那儿，日志似乎是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Aug  8 18:34:03 x1 gsd-power[2533]: Error setting property &apos;PowerSaveMode&apos; on interface org.gnome.Mutter.DisplayConfig: Timeout was reached (g-io-error-quark, 24)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/03/04/dive-into-openstack-ovn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/04/dive-into-openstack-ovn/" itemprop="url">dive into openstack ovn</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-03-04T20:08:53+08:00">
                2021-03-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华 发表于：2021-03-04<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</strong></p>
<p>前一篇基础是：Play with OVN - <a href="https://blog.csdn.net/quqi99/article/details/103194137" target="_blank" rel="external">https://blog.csdn.net/quqi99/article/details/103194137</a><br>这一篇将主要讲openstack如何来使用ovn的。<br><img src="https://img-blog.csdnimg.cn/20210304190448273.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h2><p>下面将搭建一下类似的测试环境。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">./generate-bundle.sh --name ovn --series bionic --release ussuri --ovn --vault --create-model --run</span><br><span class="line">juju add-unit nova-compute</span><br><span class="line">./configure</span><br><span class="line">source novarc</span><br><span class="line"></span><br><span class="line">neutron net-create private2 --provider:network_type geneve --provider:segmentation_id 1012</span><br><span class="line">neutron subnet-create --gateway 192.168.22.1 private2 192.168.22.0/24 --enable_dhcp=True --name private_subnet2</span><br><span class="line">ROUTER_ID=$(neutron router-list |grep &apos; provider-router &apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">SUBNET_ID=$(neutron subnet-list |grep &apos;192.168.22.0/24&apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">neutron router-interface-add $ROUTER_ID $SUBNET_ID</span><br><span class="line">nova hypervisor-list</span><br><span class="line">openstack server create --wait --image bionic --flavor m1.small --key-name testkey --nic net-id=$(openstack net show private -f value -c id) --availability-zone=nova:juju-c40d4b-ovn-13.cloud.sts i1</span><br><span class="line">./tools/float_all.sh</span><br><span class="line">./tools/sec_groups.sh</span><br><span class="line">openstack server create --wait --image cirros2 --flavor m1.small --key-name testkey --nic net-id=$(openstack net show private -f value -c id) --availability-zone=nova:juju-c40d4b-ovn-6.cloud.sts i2</span><br><span class="line">openstack server create --wait --image cirros2 --flavor m1.small --key-name testkey --nic net-id=$(openstack net show private2 -f value -c id) --availability-zone=nova:juju-c40d4b-ovn-6.cloud.sts i3</span><br><span class="line"></span><br><span class="line">$ nova list</span><br><span class="line">+--------------------------------------+------+--------+------------+-------------+--------------------------------------+</span><br><span class="line">| ID                                   | Name | Status | Task State | Power State | Networks                             |</span><br><span class="line">+--------------------------------------+------+--------+------------+-------------+--------------------------------------+</span><br><span class="line">| 82c89129-0335-4e33-b117-be940a7020d4 | i1   | ACTIVE | -          | Running     | private=192.168.21.161, 10.5.150.115 |</span><br><span class="line">| 74641e74-3401-44f9-8d7d-bef3ea0fdb92 | i2   | ACTIVE | -          | Running     | private=192.168.21.3                 |</span><br><span class="line">| 37f7c5c0-844c-4d8d-ad95-aa29b7418dc0 | i3   | ACTIVE | -          | Running     | private2=192.168.22.47               |</span><br><span class="line">+--------------------------------------+------+--------+------------+-------------+--------------------------------------+</span><br></pre></td></tr></table></figure></p>
<h2 id="OVN-Northbound-DB与Neutron的概念映射"><a href="#OVN-Northbound-DB与Neutron的概念映射" class="headerlink" title="OVN Northbound DB与Neutron的概念映射"></a>OVN Northbound DB与Neutron的概念映射</h2><p>Neutron中有Network, Subnet, Router, Port的概念，OVN Northbound DB中也有对应的逻辑概念: Switch=Neutron Subnet, Port=Neutron Port, Distributed Router=Neutron DVR Router, Gateway Router=Neutron Centralized L3, Port=Neutron Port</p>
<h2 id="举例查看OVN-Northbound-DB中和L3-NAT相关的数据"><a href="#举例查看OVN-Northbound-DB中和L3-NAT相关的数据" class="headerlink" title="举例查看OVN Northbound DB中和L3 NAT相关的数据"></a>举例查看OVN Northbound DB中和L3 NAT相关的数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">#run in compute node</span><br><span class="line"># ovs-vsctl get open . external_ids</span><br><span class="line">&#123;hostname=juju-c40d4b-ovn-6.cloud.sts, ovn-bridge-mappings=&quot;physnet1:br-data&quot;, ovn-cms-options=enable-chassis-as-gw, ovn-encap-ip=&quot;10.5.0.178&quot;, ovn-encap-type=geneve, ovn-remote=&quot;ssl:10.5.2.178:6642,ssl:10.5.1.220:6642,ssl:10.5.1.157:6642&quot;, rundir=&quot;/var/run/openvswitch&quot;, system-id=juju-c40d4b-ovn-6.cloud.sts&#125;</span><br><span class="line">export SB=$(sudo ovs-vsctl get open . external_ids:ovn-remote | sed -e &apos;s/\&quot;//g&apos;)</span><br><span class="line">export NB=$(sudo ovs-vsctl get open . external_ids:ovn-remote | sed -e &apos;s/\&quot;//g&apos; | sed -e &apos;s/6642/6641/g&apos;)</span><br><span class="line"></span><br><span class="line">#从所有计算节点上的ovn-controller中所出用于中心化l3的那个(搜索enable-chassis-as-gw得知是juju-c40d4b-ovn-6.cloud.sts(uuid=f8004279-14d2-48fd-8b6a-f025706fa8a8)</span><br><span class="line">#run in ovnnb_db master and ovnsb_db master</span><br><span class="line">juju ssh ovn-central/1 -- sudo -s</span><br><span class="line">root@juju-c40d4b-ovn-8:~# ovn-sbctl list chassis</span><br><span class="line">_uuid               : add1028c-e19c-4f23-8795-a0c64f16fdcd</span><br><span class="line">encaps              : [7417dd02-d2d5-45bb-88b9-3dafe07c92c6]</span><br><span class="line">external_ids        : &#123;datapath-type=system, iface-types=&quot;erspan,geneve,gre,internal,ip6erspan,ip6gre,lisp,patch,stt,system,tap,vxlan&quot;, is-interconn=&quot;false&quot;, neutron-metadata-proxy-networks=&quot;d0382b73-eb07-4314-a803-b957662f618c&quot;, &quot;neutron:liveness_check_at&quot;=&quot;2021-03-04T10:34:37.869388+00:00&quot;, &quot;neutron:metadata_liveness_check_at&quot;=&quot;2021-03-04T10:34:38.163481+00:00&quot;, &quot;neutron:ovn-metadata-id&quot;=&quot;4849b5a6-3134-4ca2-9fea-38c24aef6121&quot;, &quot;neutron:ovn-metadata-sb-cfg&quot;=&quot;578&quot;, ovn-bridge-mappings=&quot;&quot;, ovn-chassis-mac-mappings=&quot;&quot;, ovn-cms-options=&quot;&quot;&#125;</span><br><span class="line">hostname            : juju-c40d4b-ovn-13.cloud.sts</span><br><span class="line">name                : juju-c40d4b-ovn-13.cloud.sts</span><br><span class="line">nb_cfg              : 578</span><br><span class="line">transport_zones     : []</span><br><span class="line">vtep_logical_switches: []</span><br><span class="line">_uuid               : f8004279-14d2-48fd-8b6a-f025706fa8a8</span><br><span class="line">encaps              : [50fde256-2d20-4e4d-aa6e-c7838edee407]</span><br><span class="line">external_ids        : &#123;datapath-type=system, iface-types=&quot;erspan,geneve,gre,internal,ip6erspan,ip6gre,lisp,patch,stt,system,tap,vxlan&quot;, is-interconn=&quot;false&quot;, neutron-metadata-proxy-networks=&quot;d0382b73-eb07-4314-a803-b957662f618c,f1b85533-3f78-4f44-9785-996e725bb3bf&quot;, &quot;neutron:liveness_check_at&quot;=&quot;2021-03-04T10:34:37.322922+00:00&quot;, &quot;neutron:metadata_liveness_check_at&quot;=&quot;2021-03-04T10:34:37.602977+00:00&quot;, &quot;neutron:ovn-metadata-id&quot;=&quot;9dd62f6d-c41b-42e2-b424-7d0bbf0902ea&quot;, &quot;neutron:ovn-metadata-sb-cfg&quot;=&quot;578&quot;, ovn-bridge-mappings=&quot;physnet1:br-data&quot;, ovn-chassis-mac-mappings=&quot;&quot;, ovn-cms-options=enable-chassis-as-gw&#125;</span><br><span class="line">hostname            : juju-c40d4b-ovn-6.cloud.sts</span><br><span class="line">name                : juju-c40d4b-ovn-6.cloud.sts</span><br><span class="line">nb_cfg              : 578</span><br><span class="line">transport_zones     : []</span><br><span class="line">vtep_logical_switches: []</span><br><span class="line"></span><br><span class="line">#或者直接找到它l3 ovn-controller</span><br><span class="line">root@juju-c40d4b-ovn-8:~# ovn-nbctl list Gateway_Chassis</span><br><span class="line">_uuid               : 5de561d4-77e5-467d-8b69-ec064e949d8c</span><br><span class="line">chassis_name        : juju-c40d4b-ovn-6.cloud.sts</span><br><span class="line">external_ids        : &#123;&#125;</span><br><span class="line">name                : lrp-304cfe5a-d25c-41aa-bfbe-9ba60c7248c2_juju-c40d4b-ovn-6.cloud.sts</span><br><span class="line">options             : &#123;&#125;</span><br><span class="line">priority            : 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#找到neutron router的external_gateway_info和routerid=1a4bf8d2-c885-4af8-8b9c-061c7b27fa69</span><br><span class="line">$ openstack router show provider-router --fit-width |grep external_gateway_info</span><br><span class="line">| external_gateway_info   | &#123;&quot;network_id&quot;: &quot;1d7749fd-90c9-4f31-ada4-50f1845ca32e&quot;, &quot;external_fixed_ips&quot;: [&#123;&quot;subnet_id&quot;: &quot;4009f18b-eb09-4b74-a0ac-ce29537838a3&quot;, &quot;ip_address&quot;: &quot;10.5.152.46&quot;&#125;], &quot;enable_snat&quot;: true&#125;</span><br><span class="line"></span><br><span class="line">#找到与此neutron router对应的ovn router</span><br><span class="line">root@juju-c40d4b-ovn-8:~# ovn-nbctl find Logical_Router name=neutron-1a4bf8d2-c885-4af8-8b9c-061c7b27fa69</span><br><span class="line">_uuid               : 89a12d3b-28ad-466b-97d6-971c669aee44</span><br><span class="line">enabled             : true</span><br><span class="line">external_ids        : &#123;&quot;neutron:availability_zone_hints&quot;=&quot;&quot;, &quot;neutron:gw_port_id&quot;=&quot;304cfe5a-d25c-41aa-bfbe-9ba60c7248c2&quot;, &quot;neutron:revision_number&quot;=&quot;5&quot;, &quot;neutron:router_name&quot;=provider-router&#125;</span><br><span class="line">load_balancer       : []</span><br><span class="line">name                : neutron-1a4bf8d2-c885-4af8-8b9c-061c7b27fa69</span><br><span class="line">nat                 : [6196ba5f-568b-486e-b7d6-add825d2f8f9, b1e5878e-95f0-45f7-b3a2-232b550be281, cb82abf5-55b5-4731-aa24-b993ac4621d9]</span><br><span class="line">options             : &#123;&#125;</span><br><span class="line">policies            : []</span><br><span class="line">ports               : [3aa3c7ce-ec0f-4d3e-9a3b-15ae7f750622, f964314d-ac73-4dda-a940-9c6910850b34, fb90ec4c-ac5e-4415-96e8-28ea18e53205]</span><br><span class="line">static_routes       : [cd814869-e8a0-4dde-9730-362d5d83a1d0]</span><br><span class="line"></span><br><span class="line">#从OVN NAT northbound表中验证SNAT</span><br><span class="line">root@juju-c40d4b-ovn-8:~# ovn-nbctl find NAT type=snat</span><br><span class="line">_uuid               : b1e5878e-95f0-45f7-b3a2-232b550be281</span><br><span class="line">external_ids        : &#123;&#125;</span><br><span class="line">external_ip         : &quot;10.5.152.46&quot;</span><br><span class="line">external_mac        : []</span><br><span class="line">logical_ip          : &quot;192.168.22.0/24&quot;</span><br><span class="line">logical_port        : []</span><br><span class="line">options             : &#123;&#125;</span><br><span class="line">type                : snat</span><br><span class="line">_uuid               : 6196ba5f-568b-486e-b7d6-add825d2f8f9</span><br><span class="line">external_ids        : &#123;&#125;</span><br><span class="line">external_ip         : &quot;10.5.152.46&quot;</span><br><span class="line">external_mac        : []</span><br><span class="line">logical_ip          : &quot;192.168.21.0/24&quot;</span><br><span class="line">logical_port        : []</span><br><span class="line">options             : &#123;&#125;</span><br><span class="line">type                : snat</span><br><span class="line"></span><br><span class="line">root@juju-c40d4b-ovn-8:~# ovn-nbctl find NAT type=dnat_and_snat</span><br><span class="line">_uuid               : cb82abf5-55b5-4731-aa24-b993ac4621d9</span><br><span class="line">external_ids        : &#123;&quot;neutron:fip_external_mac&quot;=&quot;fa:16:3e:b6:11:c5&quot;, &quot;neutron:fip_id&quot;=&quot;9bf3a29c-e7fe-4dca-8c59-a8809ae87db9&quot;, &quot;neutron:fip_port_id&quot;=&quot;13d0a59c-e25d-48f5-af68-ca18dbbf139d&quot;, &quot;neutron:revision_number&quot;=&quot;2&quot;, &quot;neutron:router_name&quot;=neutron-1a4bf8d2-c885-4af8-8b9c-061c7b27fa69&#125;</span><br><span class="line">external_ip         : &quot;10.5.150.115&quot;</span><br><span class="line">external_mac        : []</span><br><span class="line">logical_ip          : &quot;192.168.21.161&quot;</span><br><span class="line">logical_port        : &quot;13d0a59c-e25d-48f5-af68-ca18dbbf139d&quot;</span><br><span class="line">options             : &#123;&#125;</span><br><span class="line">type                : dnat_and_snat</span><br><span class="line"></span><br><span class="line">root@juju-c40d4b-ovn-8:~# ovn-nbctl lr-nat-list neutron-1a4bf8d2-c885-4af8-8b9c-061c7b27fa69</span><br><span class="line">TYPE             EXTERNAL_IP        LOGICAL_IP            EXTERNAL_MAC         LOGICAL_PORT</span><br><span class="line">dnat_and_snat    10.5.150.115       192.168.21.161</span><br><span class="line">snat             10.5.152.46        192.168.21.0/24</span><br><span class="line">snat             10.5.152.46        192.168.22.0/24</span><br></pre></td></tr></table></figure>
<h2 id="OVN-Southbound-DB-L2-Logical-Flow-同网段大二层"><a href="#OVN-Southbound-DB-L2-Logical-Flow-同网段大二层" class="headerlink" title="OVN Southbound DB - L2 Logical Flow (同网段大二层)"></a>OVN Southbound DB - L2 Logical Flow (同网段大二层)</h2><p><img src="https://img-blog.csdnimg.cn/20210304190524530.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ openstack port list</span><br><span class="line">+--------------------------------------+------+-------------------+-------------------------------------------------------------------------------+--------+</span><br><span class="line">| ID                                   | Name | MAC Address       | Fixed IP Addresses                                                            | Status |</span><br><span class="line">+--------------------------------------+------+-------------------+-------------------------------------------------------------------------------+--------+</span><br><span class="line">| 0a2c4125-791c-4824-837a-1a940e78673a |      | fa:16:3e:2d:ce:27 | ip_address=&apos;192.168.21.2&apos;, subnet_id=&apos;a1607cfe-3fa8-40a1-891e-776801f90342&apos;   | DOWN   |</span><br><span class="line">| 13d0a59c-e25d-48f5-af68-ca18dbbf139d |      | fa:16:3e:54:36:ad | ip_address=&apos;192.168.21.161&apos;, subnet_id=&apos;a1607cfe-3fa8-40a1-891e-776801f90342&apos; | ACTIVE |</span><br><span class="line">| 1ba6b6f4-140b-4bb7-a0fd-6d880cda47ff |      | fa:16:3e:d2:1d:ec | ip_address=&apos;192.168.22.47&apos;, subnet_id=&apos;450d6660-b862-4908-b501-4c8533211b23&apos;  | ACTIVE |</span><br><span class="line">| 304cfe5a-d25c-41aa-bfbe-9ba60c7248c2 |      | fa:16:3e:50:aa:2a | ip_address=&apos;10.5.152.46&apos;, subnet_id=&apos;4009f18b-eb09-4b74-a0ac-ce29537838a3&apos;    | ACTIVE |</span><br><span class="line">| 3999ba6e-7f80-499b-8dd8-fa87d0f4a63e |      | fa:16:3e:76:aa:1e | ip_address=&apos;192.168.22.2&apos;, subnet_id=&apos;450d6660-b862-4908-b501-4c8533211b23&apos;   | DOWN   |</span><br><span class="line">| 7a9ae9c2-3dd5-498b-9c4d-09a101fc3120 |      | fa:16:3e:b0:67:15 |                                                                               | DOWN   |</span><br><span class="line">| abe38147-7909-4708-ad02-d478e62e7ff1 |      | fa:16:3e:22:d6:67 | ip_address=&apos;192.168.21.1&apos;, subnet_id=&apos;a1607cfe-3fa8-40a1-891e-776801f90342&apos;   | ACTIVE |</span><br><span class="line">| b236113a-86e2-4d69-8de8-f1086cc17a7b |      | fa:16:3e:93:b1:62 | ip_address=&apos;192.168.22.1&apos;, subnet_id=&apos;450d6660-b862-4908-b501-4c8533211b23&apos;   | ACTIVE |</span><br><span class="line">| cd9fefdb-00f0-4efd-950b-84ba32788571 |      | fa:16:3e:78:2f:34 | ip_address=&apos;192.168.21.3&apos;, subnet_id=&apos;a1607cfe-3fa8-40a1-891e-776801f90342&apos;   | ACTIVE |</span><br><span class="line">| eb40953f-28f3-46f4-a28a-50786d1090b5 |      | fa:16:3e:b6:11:c5 | ip_address=&apos;10.5.150.115&apos;, subnet_id=&apos;4009f18b-eb09-4b74-a0ac-ce29537838a3&apos;   | N/A    |</span><br><span class="line">+--------------------------------------+------+-------------------+-------------------------------------------------------------------------------+--------+</span><br></pre></td></tr></table></figure>
<p>对于vm1=i1(192.168.21.161)访问vm3=i3(192.168.21.3)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ openstack port list |grep -E &apos;192.168.21.3|192.168.21.161&apos;</span><br><span class="line">| 13d0a59c-e25d-48f5-af68-ca18dbbf139d |      | fa:16:3e:54:36:ad | ip_address=&apos;192.168.21.161&apos;, subnet_id=&apos;a1607cfe-3fa8-40a1-891e-776801f90342&apos; | ACTIVE |</span><br><span class="line">| cd9fefdb-00f0-4efd-950b-84ba32788571 |      | fa:16:3e:78:2f:34 | ip_address=&apos;192.168.21.3&apos;, subnet_id=&apos;a1607cfe-3fa8-40a1-891e-776801f90342&apos;   | ACTIVE |</span><br></pre></td></tr></table></figure></p>
<p>1, port security只是对从虚机进来的包检查它的IP与MAC是否对应<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@juju-c40d4b-ovn-8:~# ovn-sbctl lflow-list |grep inport |grep 13d0a59c-e25d-48f5-af68-ca18dbbf139d |grep -E &apos;table=0&apos;</span><br><span class="line">  table=0 (ls_in_port_sec_l2  ), priority=50   , match=(inport == &quot;13d0a59c-e25d-48f5-af68-ca18dbbf139d&quot; &amp;&amp; eth.src == &#123;fa:16:3e:54:36:ad&#125;), action=(next;)</span><br></pre></td></tr></table></figure></p>
<p>2,</p>
<p>接下来的看这篇文章 -<br>OpenStack SDN With OVN (Part 2) - Network Engineering Analysis<br> <a href="https://networkop.co.uk/blog/2016/12/10/ovn-part2/" target="_blank" rel="external">https://networkop.co.uk/blog/2016/12/10/ovn-part2/</a></p>
<h2 id="OVN-Southbound-DB-L3-Logical-Flow-南北"><a href="#OVN-Southbound-DB-L3-Logical-Flow-南北" class="headerlink" title="OVN Southbound DB - L3 Logical Flow(南北)"></a>OVN Southbound DB - L3 Logical Flow(南北)</h2><p><img src="https://img-blog.csdnimg.cn/2021030419364960.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>见　－　 <a href="https://networkop.co.uk/blog/2016/12/10/ovn-part2/" target="_blank" rel="external">https://networkop.co.uk/blog/2016/12/10/ovn-part2/</a></p>
<h2 id="OVN-Southbound-DB-ovn-controller-Logical-Flow-不同网段东西"><a href="#OVN-Southbound-DB-ovn-controller-Logical-Flow-不同网段东西" class="headerlink" title="OVN Southbound DB - ovn controller Logical Flow (不同网段东西)"></a>OVN Southbound DB - ovn controller Logical Flow (不同网段东西)</h2><h2 id="通过ovn-trace调试OVN-Sourthbound-DB逻辑流"><a href="#通过ovn-trace调试OVN-Sourthbound-DB逻辑流" class="headerlink" title="通过ovn-trace调试OVN Sourthbound DB逻辑流"></a>通过ovn-trace调试OVN Sourthbound DB逻辑流</h2><p>ovn-trace能用来帮助调试或者理解上面的ovn南向逻辑流<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@juju-c40d4b-ovn-8:~# ovn-sbctl lflow-list |grep -i datapath</span><br><span class="line">Datapath: &quot;neutron-1a4bf8d2-c885-4af8-8b9c-061c7b27fa69&quot; aka &quot;provider-router&quot; (587cfb5a-2797-405f-83f0-385211e2ad78)  Pipeline: ingress</span><br><span class="line">Datapath: &quot;neutron-1a4bf8d2-c885-4af8-8b9c-061c7b27fa69&quot; aka &quot;provider-router&quot; (587cfb5a-2797-405f-83f0-385211e2ad78)  Pipeline: egress</span><br><span class="line">Datapath: &quot;neutron-1d7749fd-90c9-4f31-ada4-50f1845ca32e&quot; aka &quot;ext_net&quot; (74359f20-4009-4c7e-afd8-3f3dd2423b77)  Pipeline: ingress</span><br><span class="line">Datapath: &quot;neutron-1d7749fd-90c9-4f31-ada4-50f1845ca32e&quot; aka &quot;ext_net&quot; (74359f20-4009-4c7e-afd8-3f3dd2423b77)  Pipeline: egress</span><br><span class="line">Datapath: &quot;neutron-b2f023b1-4a05-4443-b334-cf47e90a1567&quot; aka &quot;private&quot; (d0382b73-eb07-4314-a803-b957662f618c)  Pipeline: ingress</span><br><span class="line">Datapath: &quot;neutron-b2f023b1-4a05-4443-b334-cf47e90a1567&quot; aka &quot;private&quot; (d0382b73-eb07-4314-a803-b957662f618c)  Pipeline: egress</span><br><span class="line">Datapath: &quot;neutron-1c537bdd-5633-4263-a364-b14cecd4e92d&quot; aka &quot;private2&quot; (f1b85533-3f78-4f44-9785-996e725bb3bf)  Pipeline: ingress</span><br><span class="line">Datapath: &quot;neutron-1c537bdd-5633-4263-a364-b14cecd4e92d&quot; aka &quot;private2&quot; (f1b85533-3f78-4f44-9785-996e725bb3bf)  Pipeline: egress</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">root@juju-c40d4b-ovn-8:~# ovn-nbctl show c6cc6d66-91af-4613-87aa-cbd770d8040d</span><br><span class="line">switch c6cc6d66-91af-4613-87aa-cbd770d8040d (neutron-b2f023b1-4a05-4443-b334-cf47e90a1567) (aka private)</span><br><span class="line">    port abe38147-7909-4708-ad02-d478e62e7ff1</span><br><span class="line">        type: router</span><br><span class="line">        router-port: lrp-abe38147-7909-4708-ad02-d478e62e7ff1</span><br><span class="line">    port 13d0a59c-e25d-48f5-af68-ca18dbbf139d</span><br><span class="line">        addresses: [&quot;fa:16:3e:54:36:ad 192.168.21.161&quot;]</span><br><span class="line">    port 0a2c4125-791c-4824-837a-1a940e78673a</span><br><span class="line">        type: localport</span><br><span class="line">        addresses: [&quot;fa:16:3e:2d:ce:27 192.168.21.2&quot;]</span><br><span class="line">    port cd9fefdb-00f0-4efd-950b-84ba32788571</span><br><span class="line">        addresses: [&quot;fa:16:3e:78:2f:34 192.168.21.3&quot;]</span><br></pre></td></tr></table></figure>
<p>例如上面的192.168.21.161如何访问192.168.21.3的.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">root@juju-c40d4b-ovn-8:~# ovn-trace --minimal neutron-b2f023b1-4a05-4443-b334-cf47e90a1567 &apos;inport == &quot;13d0a59c-e25d-48f5-af68-ca18dbbf139d&quot; &amp;&amp; eth.src == fa:16:3e:54:36:ad &amp;&amp; eth.dst == fa:16:3e:78:2f:34&apos;</span><br><span class="line"># reg14=0x3,vlan_tci=0x0000,dl_src=fa:16:3e:54:36:ad,dl_dst=fa:16:3e:78:2f:34,dl_type=0x0000</span><br><span class="line">output(&quot;cd9fef&quot;);</span><br><span class="line"></span><br><span class="line">root@juju-c40d4b-ovn-8:~# ovn-trace  neutron-b2f023b1-4a05-4443-b334-cf47e90a1567 &apos;inport == &quot;13d0a59c-e25d-48f5-af68-ca18dbbf139d&quot; &amp;&amp; eth.src == fa:16:3e:54:36:ad &amp;&amp; eth.dst == fa:16:3e:78:2f:34&apos;</span><br><span class="line"># reg14=0x3,vlan_tci=0x0000,dl_src=fa:16:3e:54:36:ad,dl_dst=fa:16:3e:78:2f:34,dl_type=0x0000</span><br><span class="line"></span><br><span class="line">ingress(dp=&quot;private&quot;, inport=&quot;13d0a5&quot;)</span><br><span class="line">--------------------------------------</span><br><span class="line"> 0. ls_in_port_sec_l2 (ovn-northd.c:4516): inport == &quot;13d0a5&quot; &amp;&amp; eth.src == &#123;fa:16:3e:54:36:ad&#125;, priority 50, uuid 620c23f4</span><br><span class="line">    next;</span><br><span class="line">19. ls_in_l2_lkup (ovn-northd.c:6779): eth.dst == fa:16:3e:78:2f:34, priority 50, uuid cdf396b9</span><br><span class="line">    outport = &quot;cd9fef&quot;;</span><br><span class="line">    output;</span><br><span class="line"></span><br><span class="line">egress(dp=&quot;private&quot;, inport=&quot;13d0a5&quot;, outport=&quot;cd9fef&quot;)</span><br><span class="line">-------------------------------------------------------</span><br><span class="line"> 9. ls_out_port_sec_l2 (ovn-northd.c:4582): outport == &quot;cd9fef&quot; &amp;&amp; eth.dst == &#123;fa:16:3e:78:2f:34&#125;, priority 50, uuid b48eb374</span><br><span class="line">    output;</span><br><span class="line">    /* output to &quot;cd9fef&quot;, type &quot;&quot; */</span><br><span class="line">root@juju-c40d4b-ovn-8:~# ovn-trace --summary neutron-b2f023b1-4a05-4443-b334-cf47e90a1567 &apos;inport == &quot;13d0a59c-e25d-48f5-af68-ca18dbbf139d&quot; &amp;&amp; eth.src == fa:16:3e:54:36:ad &amp;&amp; eth.dst == fa:16:3e:78:2f:34&apos;</span><br><span class="line"># reg14=0x3,vlan_tci=0x0000,dl_src=fa:16:3e:54:36:ad,dl_dst=fa:16:3e:78:2f:34,dl_type=0x0000</span><br><span class="line">ingress(dp=&quot;private&quot;, inport=&quot;13d0a5&quot;) &#123;</span><br><span class="line">    next;</span><br><span class="line">    outport = &quot;cd9fef&quot;;</span><br><span class="line">    output;</span><br><span class="line">    egress(dp=&quot;private&quot;, inport=&quot;13d0a5&quot;, outport=&quot;cd9fef&quot;) &#123;</span><br><span class="line">        output;</span><br><span class="line">        /* output to &quot;cd9fef&quot;, type &quot;&quot; */;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>再例如如何访问8.8.8.8</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@juju-c40d4b-ovn-8:~# ovn-trace --detail neutron-b2f023b1-4a05-4443-b334-cf47e90a1567 &apos;inport == &quot;13d0a59c-e25d-48f5-af68-ca18dbbf139d&quot; &amp;&amp; eth.src == fa:16:3e:54:36:ad &amp;&amp; ip4.dst == 8.8.8.8&apos;</span><br><span class="line"># ip,reg14=0x3,vlan_tci=0x0000,dl_src=fa:16:3e:54:36:ad,dl_dst=00:00:00:00:00:00,nw_src=0.0.0.0,nw_dst=8.8.8.8,nw_proto=0,nw_tos=0,nw_ecn=0,nw_ttl=0</span><br><span class="line"></span><br><span class="line">ingress(dp=&quot;private&quot;, inport=&quot;13d0a5&quot;)</span><br><span class="line">--------------------------------------</span><br><span class="line"> 0. ls_in_port_sec_l2 (ovn-northd.c:4516): inport == &quot;13d0a5&quot; &amp;&amp; eth.src == &#123;fa:16:3e:54:36:ad&#125;, priority 50, uuid 620c23f4</span><br><span class="line">    next;</span><br><span class="line"> 1. ls_in_port_sec_ip (ovn-northd.c:4225): inport == &quot;13d0a5&quot; &amp;&amp; eth.src == fa:16:3e:54:36:ad &amp;&amp; ip, priority 80, uuid 47d5e0e8</span><br><span class="line">    drop;</span><br></pre></td></tr></table></figure>
<h2 id="计算节点上的openflow-flow"><a href="#计算节点上的openflow-flow" class="headerlink" title="计算节点上的openflow flow"></a>计算节点上的openflow flow</h2><p>上面的都是OVN南向DB的逻辑流，直接到计算节点上的openflow通过“ovs-ofctl dump-flows br-int”查看，可通过“ovs-appctl ofproto/trace”来调试(ovn Logical Flow流过ovn-trace调试)，见：<a href="https://blog.russellbryant.net/2016/11/11/ovn-logical-flows-and-ovn-trace/" target="_blank" rel="external">https://blog.russellbryant.net/2016/11/11/ovn-logical-flows-and-ovn-trace/</a></p>
<p>如：<br>sudo ovs-appctl ofproto/trace br-int in_port=6,arp,arp_spa=192.168.21.7,dl_src=fa:16:3e:c4:58:9c<br>可使用ovs-stat snap工具来方便生成ovs-appctl辅助命令，见：　<a href="https://blog.csdn.net/quqi99/article/details/111831695" target="_blank" rel="external">https://blog.csdn.net/quqi99/article/details/111831695</a></p>
<h2 id="实操-虚机访问外部UDP服务调试流表"><a href="#实操-虚机访问外部UDP服务调试流表" class="headerlink" title="实操 - 虚机访问外部UDP服务调试流表"></a>实操 - 虚机访问外部UDP服务调试流表</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line">找到了centralized l3为juju-c40d4b-ovn-6.cloud.sts，　</span><br><span class="line">root@juju-c40d4b-ovn-6:~# sudo ovs-appctl dpif/show</span><br><span class="line">system@ovs-system: hit:243081 missed:5389</span><br><span class="line">  br-data:</span><br><span class="line">    br-data 65534/2: (internal)</span><br><span class="line">    ens8 1/3: (system)</span><br><span class="line">    patch-provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7-to-br-int 2/none: (patch: peer=patch-br-int-to-provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7)</span><br><span class="line">  br-int:</span><br><span class="line">    br-int 65534/1: (internal)</span><br><span class="line">    ovn-juju-c-0 2/4: (geneve: csum=true, key=flow, remote_ip=10.5.0.191)</span><br><span class="line">    patch-br-int-to-provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7 1/none: (patch: peer=patch-provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7-to-br-int)</span><br><span class="line">    tap1ba6b6f4-14 5/7: (system)</span><br><span class="line">    tapcd9fefdb-00 3/5: (system)</span><br><span class="line">    tapd0382b73-e0 4/6: (system)</span><br><span class="line">    tapf1b85533-30 6/8: (system)</span><br><span class="line"></span><br><span class="line">root@juju-c40d4b-ovn-6:~# ovs-vsctl show</span><br><span class="line">2849984e-7c3c-4390-b6f0-2cb47c757ca0</span><br><span class="line">    Manager &quot;ptcp:6640:127.0.0.1&quot;</span><br><span class="line">        is_connected: true</span><br><span class="line">    Bridge br-int</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        datapath_type: system</span><br><span class="line">        Port tapcd9fefdb-00</span><br><span class="line">            Interface tapcd9fefdb-00</span><br><span class="line">        Port tap1ba6b6f4-14</span><br><span class="line">            Interface tap1ba6b6f4-14</span><br><span class="line">        Port tapd0382b73-e0</span><br><span class="line">            Interface tapd0382b73-e0</span><br><span class="line">        Port tapf1b85533-30</span><br><span class="line">            Interface tapf1b85533-30</span><br><span class="line">        Port br-int</span><br><span class="line">            Interface br-int</span><br><span class="line">                type: internal</span><br><span class="line">        Port ovn-juju-c-0</span><br><span class="line">            Interface ovn-juju-c-0</span><br><span class="line">                type: geneve</span><br><span class="line">                options: &#123;csum=&quot;true&quot;, key=flow, remote_ip=&quot;10.5.0.191&quot;&#125;</span><br><span class="line">        Port patch-br-int-to-provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7</span><br><span class="line">            Interface patch-br-int-to-provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7-to-br-int&#125;</span><br><span class="line">    Bridge br-data</span><br><span class="line">        fail_mode: standalone</span><br><span class="line">        datapath_type: system</span><br><span class="line">        Port patch-provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7-to-br-int</span><br><span class="line">            Interface patch-provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7-to-br-int</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-br-int-to-provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7&#125;</span><br><span class="line">        Port br-data</span><br><span class="line">            Interface br-data</span><br><span class="line">                type: internal</span><br><span class="line">        Port ens8</span><br><span class="line">            Interface ens8</span><br><span class="line">                type: system</span><br><span class="line">    ovs_version: &quot;2.13.1&quot;</span><br><span class="line"></span><br><span class="line">当ssh into i1，在l3上会看到：</span><br><span class="line">tcp      6 426771 ESTABLISHED src=10.5.0.8 dst=10.5.150.115 sport=39746 dport=22 src=192.168.21.161 dst=10.5.0.8 sport=22 dport=39746 [ASSURED] mark=0 zone=1 use=1</span><br><span class="line">tcp      6 431995 ESTABLISHED src=10.5.0.8 dst=10.5.150.115 sport=39904 dport=22 src=192.168.21.161 dst=10.5.0.8 sport=22 dport=39904 [ASSURED] mark=0 zone=1 use=1</span><br><span class="line"></span><br><span class="line">当从i1上运行&quot;nc -uvz 10.5.0.2 53&quot;, 在L3上会看到</span><br><span class="line">root@juju-c40d4b-ovn-6:~# conntrack -L |grep 192.168.21.161</span><br><span class="line">conntrack v1.4.4 (conntrack-tools): 52 flow entries have been shown.</span><br><span class="line">udp      17 25 src=192.168.21.161 dst=10.5.0.2 sport=55185 dport=53 [UNREPLIED] src=10.5.0.2 dst=10.5.150.115 sport=53 dport=55185 mark=0 zone=2 use=1</span><br><span class="line">udp      17 6 src=192.168.21.161 dst=10.5.0.2 sport=36199 dport=53 [UNREPLIED] src=10.5.0.2 dst=10.5.150.115 sport=53 dport=36199 mark=0 zone=2 use=1</span><br><span class="line"></span><br><span class="line">在SouthBound DB master上看到了ovn逻辑流是：</span><br><span class="line">ubuntu@zhhuabj-bastion:~/stsstack-bundles/openstack$ juju ssh ovn-central/2 -- sudo -s</span><br><span class="line">root@juju-c40d4b-ovn-9:~# ovn-trace --detail neutron-b2f023b1-4a05-4443-b334-cf47e90a1567 &apos;inport == &quot;13d0a59c-e25d-48f5-af68-ca18dbbf139d&quot; &amp;&amp; eth.src == fa:16:3e:54:36:ad &amp;&amp; ip4.dst == 10.5.0.2&apos;</span><br><span class="line"># ip,reg14=0x3,vlan_tci=0x0000,dl_src=fa:16:3e:54:36:ad,dl_dst=00:00:00:00:00:00,nw_src=0.0.0.0,nw_dst=10.5.0.2,nw_proto=0,nw_tos=0,nw_ecn=0,nw_ttl=0</span><br><span class="line">ingress(dp=&quot;private&quot;, inport=&quot;13d0a5&quot;)</span><br><span class="line">--------------------------------------</span><br><span class="line"> 0. ls_in_port_sec_l2 (ovn-northd.c:4516): inport == &quot;13d0a5&quot; &amp;&amp; eth.src == &#123;fa:16:3e:54:36:ad&#125;, priority 50, uuid 620c23f4</span><br><span class="line">    next;</span><br><span class="line"> 1. ls_in_port_sec_ip (ovn-northd.c:4225): inport == &quot;13d0a5&quot; &amp;&amp; eth.src == fa:16:3e:54:36:ad &amp;&amp; ip, priority 80, uuid 47d5e0e8</span><br><span class="line"></span><br><span class="line">在L3上调试openflow</span><br><span class="line">sudo snap install ovs-stat</span><br><span class="line">sudo snap connect ovs-stat:openvswitch</span><br><span class="line">sudo snap connect ovs-stat:network-control</span><br><span class="line">#sudo snap connect ovs-stat:removable-media</span><br><span class="line">#ovs-stat -p /tmp/results --tree ./sosreport-015 --openstack  #don&apos;t use sudo</span><br><span class="line">ovs-stat -p /tmp/results --tree --openstack</span><br><span class="line">sudo ls /tmp/snap.ovs-stat/tmp/results</span><br><span class="line">ovs-stat -p /tmp/results --host juju-c40d4b-ovn-6 --query &quot;&quot;</span><br><span class="line">root@juju-c40d4b-ovn-6:~# ovs-stat -p /tmp/results --host juju-c40d4b-ovn-6 --query &quot;ofproto-trace.port tapf1b85533-30&quot;</span><br><span class="line">[arp]</span><br><span class="line">no source ips found - skipping</span><br><span class="line">[icmp]</span><br><span class="line">no source ips found - skipping</span><br><span class="line">[dhcp]</span><br><span class="line">sudo ovs-appctl ofproto/trace br-int udp,in_port=6,dl_src=12:6b:c5:a6:f5:47,dl_dst=ff:ff:ff:ff:ff:ff,nw_src=0.0.0.0,nw_dst=255.255.255.255,udp_src=68,udp_dst=67</span><br><span class="line">[vm-to-vm]</span><br><span class="line">sudo ovs-appctl ofproto/trace br-int in_port=6,tcp,dl_src=12:6b:c5:a6:f5:47,dl_dst=MAC_OF_REMOTE_INSTANCE</span><br><span class="line">sudo ovs-appctl ofproto/trace br-int in_port=6,dl_vlan=,dl_src=12:6b:c5:a6:f5:47,dl_dst=MAC_OF_REMOTE_INSTANCE</span><br><span class="line"></span><br><span class="line">在L3节点上看到的openflow flow是：</span><br><span class="line">root@juju-c40d4b-ovn-6:~# ovs-ofctl dump-flows br-int |grep 192.168.21.161</span><br><span class="line"> cookie=0xe51693a7, duration=86438.109s, table=14, n_packets=22223, n_bytes=1532774, idle_age=33, hard_age=65534, priority=100,ip,reg14=0x1,metadata=0x2,nw_dst=10.5.150.115 actions=ct(commit,table=15,zone=NXM_NX_REG11[0..15],nat(dst=192.168.21.161))</span><br><span class="line"> cookie=0x1043afc5, duration=86542.428s, table=21, n_packets=1, n_bytes=42, idle_age=65534, hard_age=65534, priority=50,arp,metadata=0x3,arp_tpa=192.168.21.161,arp_op=1 actions=move:NXM_OF_ETH_SRC[]-&gt;NXM_OF_ETH_DST[],mod_dl_src:fa:16:3e:54:36:ad,load:0x2-&gt;NXM_OF_ARP_OP[],move:NXM_NX_ARP_SHA[]-&gt;NXM_NX_ARP_THA[],load:0xfa163e5436ad-&gt;NXM_NX_ARP_SHA[],move:NXM_OF_ARP_SPA[]-&gt;NXM_OF_ARP_TPA[],load:0xc0a815a1-&gt;NXM_OF_ARP_SPA[],move:NXM_NX_REG14[]-&gt;NXM_NX_REG15[],load:0x1-&gt;NXM_NX_REG10[0],resubmit(,32)</span><br><span class="line"> cookie=0xd56bfbc4, duration=86438.109s, table=40, n_packets=53762, n_bytes=13079808, idle_age=33, hard_age=65534, priority=100,ip,reg15=0x1,metadata=0x2,nw_src=192.168.21.161 actions=ct(table=41,zone=NXM_NX_REG11[0..15],nat)</span><br><span class="line"> cookie=0xf8bdd8ec, duration=86438.109s, table=41, n_packets=16596, n_bytes=1295012, idle_age=34, hard_age=65534, priority=161,ip,reg15=0x1,metadata=0x2,nw_src=192.168.21.161 actions=ct(commit,table=42,zone=NXM_NX_REG12[0..15],nat(src=10.5.150.115))</span><br><span class="line"> cookie=0x0, duration=85847.305s, table=44, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=2002,ct_state=-new+est-rpl+trk,ct_label=0/0x1,ip,metadata=0x3,nw_src=192.168.21.161 actions=conjunction(9,1/2)</span><br><span class="line"> cookie=0x0, duration=85847.305s, table=44, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=2002,ct_state=-new+est-rpl+trk,ct_label=0x1/0x1,ip,metadata=0x4,nw_src=192.168.21.161 actions=conjunction(3,1/2)</span><br><span class="line"> cookie=0x0, duration=85847.306s, table=44, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=2002,ct_state=-new+est-rpl+trk,ct_label=0x1/0x1,ip,metadata=0x3,nw_src=192.168.21.161 actions=conjunction(7,1/2)</span><br><span class="line"> cookie=0x0, duration=85847.305s, table=44, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=2002,ct_state=-new+est-rpl+trk,ct_label=0/0x1,ip,metadata=0x4,nw_src=192.168.21.161 actions=conjunction(5,1/2)</span><br><span class="line"> cookie=0x0, duration=85847.306s, table=44, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=2002,ct_state=+new-est+trk,ip,metadata=0x3,nw_src=192.168.21.161 actions=conjunction(6,1/2)</span><br><span class="line"> cookie=0x0, duration=85847.305s, table=44, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=2002,ct_state=+new-est+trk,ip,metadata=0x4,nw_src=192.168.21.161 actions=conjunction(2,1/2)</span><br><span class="line"> cookie=0x0, duration=85847.305s, table=44, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=2002,ct_state=-trk,ip,metadata=0x4,nw_src=192.168.21.161 actions=conjunction(4,1/2)</span><br><span class="line"> cookie=0x0, duration=85847.305s, table=44, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=2002,ct_state=-trk,ip,metadata=0x3,nw_src=192.168.21.161 actions=conjunction(8,1/2)</span><br></pre></td></tr></table></figure>
<h2 id="附录-NB与SB表"><a href="#附录-NB与SB表" class="headerlink" title="附录 - NB与SB表"></a>附录 - NB与SB表</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">root@juju-c40d4b-ovn-8:~# ovn-nbctl show</span><br><span class="line">switch 38364b40-19f0-473f-8878-da50b652cc67 (neutron-1d7749fd-90c9-4f31-ada4-50f1845ca32e) (aka ext_net)</span><br><span class="line">    port 7a9ae9c2-3dd5-498b-9c4d-09a101fc3120</span><br><span class="line">        type: localport</span><br><span class="line">        addresses: [&quot;fa:16:3e:b0:67:15&quot;]</span><br><span class="line">    port 304cfe5a-d25c-41aa-bfbe-9ba60c7248c2</span><br><span class="line">        type: router</span><br><span class="line">        router-port: lrp-304cfe5a-d25c-41aa-bfbe-9ba60c7248c2</span><br><span class="line">    port provnet-5a77e708-5c1f-48dc-acdf-21e66d8e3be7</span><br><span class="line">        type: localnet</span><br><span class="line">        addresses: [&quot;unknown&quot;]</span><br><span class="line">switch c6cc6d66-91af-4613-87aa-cbd770d8040d (neutron-b2f023b1-4a05-4443-b334-cf47e90a1567) (aka private)</span><br><span class="line">    port abe38147-7909-4708-ad02-d478e62e7ff1</span><br><span class="line">        type: router</span><br><span class="line">        router-port: lrp-abe38147-7909-4708-ad02-d478e62e7ff1</span><br><span class="line">    port 13d0a59c-e25d-48f5-af68-ca18dbbf139d</span><br><span class="line">        addresses: [&quot;fa:16:3e:54:36:ad 192.168.21.161&quot;]</span><br><span class="line">    port 0a2c4125-791c-4824-837a-1a940e78673a</span><br><span class="line">        type: localport</span><br><span class="line">        addresses: [&quot;fa:16:3e:2d:ce:27 192.168.21.2&quot;]</span><br><span class="line">    port cd9fefdb-00f0-4efd-950b-84ba32788571</span><br><span class="line">        addresses: [&quot;fa:16:3e:78:2f:34 192.168.21.3&quot;]</span><br><span class="line">switch c53d2b6f-6721-4b97-bb8e-c62df9bd952b (neutron-1c537bdd-5633-4263-a364-b14cecd4e92d) (aka private2)</span><br><span class="line">    port 1ba6b6f4-140b-4bb7-a0fd-6d880cda47ff</span><br><span class="line">        addresses: [&quot;fa:16:3e:d2:1d:ec 192.168.22.47&quot;]</span><br><span class="line">    port b236113a-86e2-4d69-8de8-f1086cc17a7b</span><br><span class="line">        type: router</span><br><span class="line">        router-port: lrp-b236113a-86e2-4d69-8de8-f1086cc17a7b</span><br><span class="line">    port 3999ba6e-7f80-499b-8dd8-fa87d0f4a63e</span><br><span class="line">        type: localport</span><br><span class="line">        addresses: [&quot;fa:16:3e:76:aa:1e 192.168.22.2&quot;]</span><br><span class="line">router 89a12d3b-28ad-466b-97d6-971c669aee44 (neutron-1a4bf8d2-c885-4af8-8b9c-061c7b27fa69) (aka provider-router)</span><br><span class="line">    port lrp-abe38147-7909-4708-ad02-d478e62e7ff1</span><br><span class="line">        mac: &quot;fa:16:3e:22:d6:67&quot;</span><br><span class="line">        networks: [&quot;192.168.21.1/24&quot;]</span><br><span class="line">    port lrp-b236113a-86e2-4d69-8de8-f1086cc17a7b</span><br><span class="line">        mac: &quot;fa:16:3e:93:b1:62&quot;</span><br><span class="line">        networks: [&quot;192.168.22.1/24&quot;]</span><br><span class="line">    port lrp-304cfe5a-d25c-41aa-bfbe-9ba60c7248c2</span><br><span class="line">        mac: &quot;fa:16:3e:50:aa:2a&quot;</span><br><span class="line">        networks: [&quot;10.5.152.46/16&quot;]</span><br><span class="line">        gateway chassis: [juju-c40d4b-ovn-6.cloud.sts]</span><br><span class="line">    nat 6196ba5f-568b-486e-b7d6-add825d2f8f9</span><br><span class="line">        external ip: &quot;10.5.152.46&quot;</span><br><span class="line">        logical ip: &quot;192.168.21.0/24&quot;</span><br><span class="line">        type: &quot;snat&quot;</span><br><span class="line">    nat b1e5878e-95f0-45f7-b3a2-232b550be281</span><br><span class="line">        external ip: &quot;10.5.152.46&quot;</span><br><span class="line">        logical ip: &quot;192.168.22.0/24&quot;</span><br><span class="line">    nat cb82abf5-55b5-4731-aa24-b993ac4621d9</span><br><span class="line">        external ip: &quot;10.5.150.115&quot;</span><br><span class="line">        logical ip: &quot;192.168.21.161&quot;</span><br><span class="line">        type: &quot;dnat_and_snat&quot;</span><br><span class="line"></span><br><span class="line">root@juju-c40d4b-ovn-8:~# ovn-sbctl show</span><br><span class="line">Chassis juju-c40d4b-ovn-13.cloud.sts</span><br><span class="line">    hostname: juju-c40d4b-ovn-13.cloud.sts</span><br><span class="line">    Encap geneve</span><br><span class="line">        ip: &quot;10.5.0.191&quot;</span><br><span class="line">        options: &#123;csum=&quot;true&quot;&#125;</span><br><span class="line">    Port_Binding &quot;13d0a59c-e25d-48f5-af68-ca18dbbf139d&quot;</span><br><span class="line">Chassis juju-c40d4b-ovn-6.cloud.sts</span><br><span class="line">    hostname: juju-c40d4b-ovn-6.cloud.sts</span><br><span class="line">    Encap geneve</span><br><span class="line">        ip: &quot;10.5.0.178&quot;</span><br><span class="line">        options: &#123;csum=&quot;true&quot;&#125;</span><br><span class="line">    Port_Binding cr-lrp-304cfe5a-d25c-41aa-bfbe-9ba60c7248c2</span><br><span class="line">    Port_Binding &quot;cd9fefdb-00f0-4efd-950b-84ba32788571&quot;</span><br><span class="line">    Port_Binding &quot;1ba6b6f4-140b-4bb7-a0fd-6d880cda47ff&quot;</span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://networkop.co.uk/blog/2016/12/10/ovn-part2/" target="_blank" rel="external">https://networkop.co.uk/blog/2016/12/10/ovn-part2/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/02/Fixing-thinkpad-bluetooth-keyboard/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/02/Fixing-thinkpad-bluetooth-keyboard/" itemprop="url">Fixing thinkpad bluetooth keyboard</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-02-02T15:59:12+08:00">
                2021-02-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2019-03-30)</strong></p>
<p>为了保护颈椎, 已经习惯不用鼠标, 但是高度依赖于Thinkpad的小红点鼠标. 但是蓝牙经常性一个月会断一次, 断了之后很难连接上. 这次更奇葩了, 蓝牙灯也不灭, 键盘上也没有重置的键, 只好等到今天蓝牙键盘电池耗尽之后再试, 但是还是连不上, 错误为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Mar 30 07:46:42 t440p bluetoothd[10079]: Can&apos;t get HIDP connection info</span><br><span class="line">Mar 30 07:46:43 t440p bluetoothd[10079]: connect error: Invalid exchange (52)</span><br><span class="line">Mar 30 07:46:50 t440p kernel: [240741.397564] Bluetooth: hci0: last event is not cmd complete (0x0f)</span><br></pre></td></tr></table></figure></p>
<p>在设置GUI里先删除这个蓝牙, 也报错:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mar 30 07:58:28 t440p gnome-control-c[9696]: Failed to remove device &apos;/org/bluez/hci1/dev_90_7F_61_00_23_C3&apos;: GDBus.Error:org.freedesktop.DBus.Error.ServiceUnknown: The name :1.505 was not provided by any .service files</span><br></pre></td></tr></table></figure></p>
<p>好吧, 通过下列命令删除, 再连接, 这次终于算成功了. 本博客将继续记录蓝牙今后遇到的所有连接问题.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">hua@t440p:$ bluetoothctl</span><br><span class="line">[NEW] Controller 00:15:00:CB:B0:FF t440p #2 [default]</span><br><span class="line">[NEW] Device 90:7F:61:00:23:C3 ThinkPad Compact Bluetooth Keyboard with TrackPoint</span><br><span class="line">[NEW] Device 04:F1:28:31:D2:10 Nokia 7</span><br><span class="line">[NEW] Controller 00:1A:7D:DA:71:13 t440p #1</span><br><span class="line">[NEW] Device 00:15:00:CB:B0:FF t440p</span><br><span class="line">[NEW] Device 90:7F:61:00:23:C3 ThinkPad Compact Bluetooth Keyboard with TrackPoint</span><br><span class="line">Agent registered</span><br><span class="line">[bluetooth]# list</span><br><span class="line">Controller 00:15:00:CB:B0:FF t440p #2 [default]</span><br><span class="line">Controller 00:1A:7D:DA:71:13 t440p #1</span><br><span class="line">[bluetooth]# devices</span><br><span class="line">Device 90:7F:61:00:23:C3 ThinkPad Compact Bluetooth Keyboard with TrackPoint</span><br><span class="line">Device 04:F1:28:31:D2:10 Nokia 7</span><br><span class="line">[bluetooth]# info 90:7F:61:00:23:C3</span><br><span class="line">Device 90:7F:61:00:23:C3 (public)</span><br><span class="line">	Name: ThinkPad Compact Bluetooth Keyboard with TrackPoint</span><br><span class="line">	Alias: ThinkPad Compact Bluetooth Keyboard with TrackPoint</span><br><span class="line">	Class: 0x00000540</span><br><span class="line">	Icon: input-keyboard</span><br><span class="line">	Paired: yes</span><br><span class="line">	Trusted: no</span><br><span class="line">	Blocked: no</span><br><span class="line">	Connected: no</span><br><span class="line">	LegacyPairing: no</span><br><span class="line">[bluetooth]# remove 90:7F:61:00:23:C3</span><br><span class="line">[DEL] Device 90:7F:61:00:23:C3 ThinkPad Compact Bluetooth Keyboard with TrackPoint</span><br><span class="line">Device has been removed</span><br><span class="line">[bluetooth]# power on</span><br><span class="line">Changing power on succeeded</span><br></pre></td></tr></table></figure></p>
<p>一行命令搞定：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#bt-device  -l |grep -i keyboard</span><br><span class="line">DEVICE_MAC=&apos;90:7F:61:00:23:C3&apos;</span><br><span class="line">&lt;&lt;&lt;&quot;connect $DEVICE_MAC&quot; bluetoothctl</span><br><span class="line">&lt;&lt;&lt;&quot;connect $DEVICE_MAC&quot; bluetoothctl &amp;&gt; /dev/null</span><br></pre></td></tr></table></figure>
<p>然后升级bluez到5.5版本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dpkg --status bluez | grep &apos;^Version:&apos;</span><br><span class="line">sudo add-apt-repository ppa:bluetooth/bluez</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br></pre></td></tr></table></figure></p>
<h2 id="解决suspend唤醒之后的usb问题"><a href="#解决suspend唤醒之后的usb问题" class="headerlink" title="解决suspend唤醒之后的usb问题"></a>解决suspend唤醒之后的usb问题</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">#重启USB</span><br><span class="line">#!/bin/bash</span><br><span class="line">for I in $(ls /sys/bus/pci/drivers/xhci_hcd/|grep : ) ; do</span><br><span class="line">echo $I</span><br><span class="line">sudo echo $I &gt; /sys/bus/pci/drivers/xhci_hcd/unbind</span><br><span class="line">sudo echo $I &gt; /sys/bus/pci/drivers/xhci_hcd/bind</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">#https://itectec.com/ubuntu/ubuntu-wakes-from-suspend-immediately-when-bluetooth-device-disconnected/</span><br><span class="line">#通过重启USB让系统进入suspend之后马上又唤醒</span><br><span class="line">chmod a+x /lib/systemd/system-sleep/custom-xhci_hcd</span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line"># Original script was using /bin/sh but shellcheck reporting warnings.</span><br><span class="line"></span><br><span class="line"># NAME: custom-xhci_hcd</span><br><span class="line"># PATH: /lib/systemd/system-sleep</span><br><span class="line"># CALL: Called from SystemD automatically</span><br><span class="line"># DESC: Suspend broken for USB3.0 as of Oct 25/2018 various kernels all at once</span><br><span class="line"></span><br><span class="line"># DATE: Oct 28 2018.</span><br><span class="line"></span><br><span class="line"># NOTE: From comment #61 at: https://bugs.launchpad.net/ubuntu/+source/linux/+bug/522998</span><br><span class="line"></span><br><span class="line">TMPLIST=/tmp/xhci-dev-list</span><br><span class="line"></span><br><span class="line"># Original script was: case &quot;$&#123;1&#125;&quot; in hibernate|suspend)</span><br><span class="line"></span><br><span class="line">case $1/$2 in</span><br><span class="line">  pre/*)</span><br><span class="line">    echo &quot;$0: Going to $2...&quot;</span><br><span class="line">    echo -n &apos;&apos; &gt; $TMPLIST</span><br><span class="line">          for i in `ls /sys/bus/pci/drivers/xhci_hcd/ | egrep &apos;[0-9a-z]+\:[0-9a-z]+\:.*$&apos;`; do</span><br><span class="line">              # Unbind xhci_hcd for first device XXXX:XX:XX.X:</span><br><span class="line">               echo -n &quot;$i&quot; | tee /sys/bus/pci/drivers/xhci_hcd/unbind</span><br><span class="line">           echo &quot;$i&quot; &gt;&gt; $TMPLIST</span><br><span class="line">          done</span><br><span class="line">        ;;</span><br><span class="line">  post/*)</span><br><span class="line">    echo &quot;$0: Waking up from $2...&quot;</span><br><span class="line">    for i in `cat $TMPLIST`; do</span><br><span class="line">              # Bind xhci_hcd for first device XXXX:XX:XX.X:</span><br><span class="line">              echo -n &quot;$i&quot; | tee /sys/bus/pci/drivers/xhci_hcd/bind</span><br><span class="line">    done</span><br><span class="line">    rm $TMPLIST</span><br><span class="line">        ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>
<p>如果想在系统在suspend时usb不suspend 还能继续供电的话可以修改/etc/tlp.conf添加:　USB_AUTOSUSPEND=0 即可</p>
<h2 id="让蓝牙不autosuspend或者通过蓝牙唤醒suspend系统-not-work"><a href="#让蓝牙不autosuspend或者通过蓝牙唤醒suspend系统-not-work" class="headerlink" title="让蓝牙不autosuspend或者通过蓝牙唤醒suspend系统(not work)"></a>让蓝牙不autosuspend或者通过蓝牙唤醒suspend系统(not work)</h2><p>现在的问题是不是唤醒之后蓝牙有问题，而是蓝牙无法唤醒suspend系统。我的问题如同的描述　－　<a href="https://unix.stackexchange.com/questions/609438/how-can-i-use-a-usb-keyboard-or-mouse-to-wake-from-suspend" target="_blank" rel="external">https://unix.stackexchange.com/questions/609438/how-can-i-use-a-usb-keyboard-or-mouse-to-wake-from-suspend</a><br>将下面语句添加到rc.local中去，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo enabled &gt; /sys/bus/usb/devices/3-11/power/wakeup</span><br></pre></td></tr></table></figure>
<p>或者使用udev，但都不work<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#lsusb -tv |grep btusb -A1</span><br><span class="line">vim /etc/udev/rules.d/80-persistent-usb.rules</span><br><span class="line">ACTION==&quot;add&quot;, SUBSYSTEM==&quot;usb&quot;, ATTRS&#123;idVendor&#125;==&quot;8087&quot;, ATTRS&#123;idProduct&#125;==&quot;07dc&quot; RUN+=&quot;/bin/sh -c &apos;echo enabled &gt; /sys/bus/usb/devices/3-11/power/wakeup&apos;&quot;</span><br><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure></p>
<p>下面是不让蓝牙进入autosuspend的方法，但也不work<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lsusb -tv</span><br><span class="line">grep . /sys/bus/usb/devices/*/product</span><br><span class="line"></span><br><span class="line">root@t440p:~# grep -r &apos;auto&apos; /etc/rc.local</span><br><span class="line"># disable bluetooth&apos;s autosuspend - dmesg |grep blue</span><br><span class="line">echo -1 &gt;/sys/bus/usb/devices/3-11/power/autosuspend_delay_ms</span><br><span class="line"></span><br><span class="line">root@t440p:~# grep -r &apos;IdleTimeout&apos; /etc/bluetooth/input.conf</span><br><span class="line">IdleTimeout=0</span><br><span class="line">root@t440p:~# grep -r &apos;FastConnectable&apos; /etc/bluetooth/main.conf</span><br><span class="line">FastConnectable = true</span><br><span class="line"></span><br><span class="line">sudo systemctl restart bluetooth</span><br><span class="line">sudo systemctl suspend  #or sudo pm-suspend</span><br><span class="line"></span><br><span class="line">#https://blog.csdn.net/weixin_43971560/article/details/100591034</span><br><span class="line">sudo apt-get install --reinstall xserver-xorg-input-all</span><br></pre></td></tr></table></figure></p>
<p>下面的也不work<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># chmod a+x /usr/lib/pm-utils/sleep.d/45fixbluetoothwakeup</span><br><span class="line">#!/bin/bash</span><br><span class="line">case $1 in</span><br><span class="line">    hibernate)</span><br><span class="line">            echo &quot;Going to suspend to disk!&quot;</span><br><span class="line">            ;;</span><br><span class="line">    suspend)</span><br><span class="line">            /etc/init.d/bluetooth start</span><br><span class="line">            echo enabled &gt; /sys/bus/usb/devices/3-11/power/wakeup</span><br><span class="line">            /sbin/modprobe btusb</span><br><span class="line">            echo &quot;Suspending to RAM.&quot;</span><br><span class="line">            ;;</span><br><span class="line">    thaw)</span><br><span class="line">            echo &quot;Suspend to disk is now over!&quot;</span><br><span class="line">            ;;</span><br><span class="line">    resume)</span><br><span class="line">            /etc/init.d/bluetooth start</span><br><span class="line">            echo &quot;We are now resuming.&quot;</span><br><span class="line">            ;;</span><br><span class="line">    *)</span><br><span class="line">            echo &quot;Somebody is callin me totally wrong.&quot;</span><br><span class="line">            ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure></p>
<p>这个网页的方法（<a href="http://www.thedreaming.org/2020/11/13/ubuntu-mac-bluetooth-wake/）也不work" target="_blank" rel="external">http://www.thedreaming.org/2020/11/13/ubuntu-mac-bluetooth-wake/）也不work</a>, 它会交/sys/devices/pci0000:00/0000:00:14.0/usb3/3-11/power/wakeup设置成enabled, 它会让它一进入suspend马上就又唤醒了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">root@t440p:~# lsusb -tv |grep btusb -A1</span><br><span class="line">    |__ Port 11: Dev 5, If 0, Class=Wireless, Driver=btusb, 12M</span><br><span class="line">        ID 8087:07dc Intel Corp.</span><br><span class="line">    |__ Port 11: Dev 5, If 1, Class=Wireless, Driver=btusb, 12M</span><br><span class="line">        ID 8087:07dc Intel Corp.</span><br><span class="line">root@t440p:~# lsusb |grep 8087:07dc</span><br><span class="line">Bus 003 Device 005: ID 8087:07dc Intel Corp.</span><br><span class="line"></span><br><span class="line">root@t440p:~# lsusb -v -s 003:005 |grep &apos;id&apos;</span><br><span class="line">  idVendor           0x8087 Intel Corp.</span><br><span class="line">  idProduct          0x07dc</span><br><span class="line">root@t440p:~# lsusb -v -d 8087:07dc |grep -i bus</span><br><span class="line">Bus 003 Device 005: ID 8087:07dc Intel Corp.</span><br><span class="line"></span><br><span class="line">#DEVPATH is /devices/pci0000:00/0000:00:14.0/usb3/3-11</span><br><span class="line">root@t440p:~# udevadm info -q path -n /dev/bus/usb/003/005</span><br><span class="line">/devices/pci0000:00/0000:00:14.0/usb3/3-11</span><br><span class="line">root@t440p:~# udevadm info -a -p $(udevadm info -q path -n /dev/bus/usb/003/005)</span><br><span class="line">   ...</span><br><span class="line"></span><br><span class="line">root@t440p:~# cat /sys/devices/pci0000:00/0000:00:14.0/usb3/3-11/power/wakeup</span><br><span class="line">enabled</span><br><span class="line"></span><br><span class="line">https://blog.csdn.net/quqi99/article/details/78729252</span><br><span class="line">#  /usr/local/sbin/enable-wakeup /sys/devices/pci0000:00/0000:00:14.0/usb3/3-11/power/wakeup</span><br><span class="line">root@t440p:~# cat /etc/udev/rules.d/80-persistent-usb.rules</span><br><span class="line">SUBSYSTEM==&quot;usb&quot;, ATTRS&#123;idVendor&#125;==&quot;8087&quot;, ATTRS&#123;idProduct&#125;==&quot;07dc&quot; RUN+=&quot;/usr/local/sbin/enable-wakeup $env&#123;DEVPATH&#125;&quot;</span><br><span class="line">#don&apos;t forget to run: sudo update-initramfs -u</span><br><span class="line"># https://unix-memo.readthedocs.io/en/latest/udev.html</span><br><span class="line">#test it by: udevadm test /devices/pci0000:00/0000:00:14.0/usb3/3-11</span><br><span class="line"></span><br><span class="line">root@t440p:~# cat /usr/local/sbin/enable-wakeup</span><br><span class="line">#!/bin/bash</span><br><span class="line">#</span><br><span class="line"># Script to enable a USB devices to be used to resume computer from sleep</span><br><span class="line">#</span><br><span class="line"># Depends on udevadm package</span><br><span class="line"># 09/05/2012 - V1.0 by Nicolas Bernaerts</span><br><span class="line"></span><br><span class="line"># if device has been removed, exit</span><br><span class="line">[ &quot;$ACTION&quot; = &quot;remove&quot; ] &amp;&amp; exit 0</span><br><span class="line"></span><br><span class="line"># set PATH as it is not set for udev scripts</span><br><span class="line">PATH=&quot;/usr/sbin:/usr/bin:/sbin:/bin&quot;</span><br><span class="line"></span><br><span class="line"># set device SYSFS path</span><br><span class="line">DEVICE_SYSFS=&quot;/sys$1&quot;</span><br><span class="line">CURRENT_SYSFS=$DEVICE_SYSFS</span><br><span class="line"></span><br><span class="line"># get device product and vendor name from parent SYSFS</span><br><span class="line">DEVICE_VENDOR=`udevadm info --query=all -p &quot;$CURRENT_SYSFS/../&quot; | grep &quot;ID_VENDOR_ID=&quot; | cut -d &quot;=&quot; -f 2`</span><br><span class="line">DEVICE_PRODUCT=`udevadm info --query=all -p &quot;$CURRENT_SYSFS/../&quot; | grep &quot;ID_MODEL_ID=&quot; | cut -d &quot;=&quot; -f 2`</span><br><span class="line">DEVICE_LABEL=`lsusb | grep &quot;$&#123;DEVICE_VENDOR&#125;:$&#123;DEVICE_PRODUCT&#125;&quot; | sed &apos;s/^.*[0-9a-f]\:[0-9a-f]* \(.*\)$/\1/g&apos;`</span><br><span class="line"></span><br><span class="line"># loop thru the SYSFS path, up to PCI bus</span><br><span class="line">CARRY_ON=1</span><br><span class="line">while [ $CARRY_ON -eq 1 ]</span><br><span class="line">do</span><br><span class="line">  # get the first three letters of current SYSFS folder</span><br><span class="line">  FIRST_LETTERS=`basename $CURRENT_SYSFS | sed &apos;s/^\(...\).*$/\1/g&apos;`</span><br><span class="line"></span><br><span class="line">  # if current SYSFS is PCI bus, stop the loop</span><br><span class="line">  if [ &quot;$FIRST_LETTERS&quot; = &quot;pci&quot; ] || [ &quot;$FIRST_LETTERS&quot; = &quot;/&quot; ] ; then</span><br><span class="line">    CARRY_ON=0</span><br><span class="line"></span><br><span class="line">  # else,</span><br><span class="line">  else</span><br><span class="line">    # if possible, enable wakeup for current SYSFS</span><br><span class="line">    WAKEUP_FILE=&quot;$&#123;CURRENT_SYSFS&#125;/power/wakeup&quot;</span><br><span class="line">    if [ -f $WAKEUP_FILE ]; then</span><br><span class="line">      echo &quot;enabled&quot; &gt; $WAKEUP_FILE</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">    # go to father directory of current SYSFS</span><br><span class="line">    CURRENT_SYSFS=`dirname $CURRENT_SYSFS`</span><br><span class="line">  fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"># log the action</span><br><span class="line">LOG_HEADER=&quot;USB device $&#123;DEVICE_VENDOR&#125;:$&#123;DEVICE_PRODUCT&#125;&quot;</span><br><span class="line">logger &quot;$&#123;LOG_HEADER&#125; - Description : $&#123;DEVICE_LABEL&#125;&quot;</span><br><span class="line">logger &quot;$&#123;LOG_HEADER&#125; - SysFS path  : $&#123;DEVICE_SYSFS&#125;&quot;</span><br><span class="line">logger &quot;$&#123;LOG_HEADER&#125; - Device is enabled to handle suspend/resume&quot;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>下面两个设置了运行’systemctl suspend’后再敲蓝牙键盘不会有任何反应：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># grep . /sys/bus/usb/devices/*/power/wakeup</span><br><span class="line">echo enabled &gt; /sys/bus/usb/devices/3-11/power/wakeup</span><br><span class="line">echo enabled &gt; /sys/devices/pci0000:00/0000:00:14.0/usb3/3-11/power/wakeup</span><br></pre></td></tr></table></figure></p>
<p>下面设置了之后再suspend之后不敲蓝牙键盘也马上会wakeup无法使用:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo enabled &gt; /sys/bus/usb/devices/usb3/power/wakeup</span><br></pre></td></tr></table></figure></p>
<p>看来目前使用蓝牙键盘唤醒suspend系统是不可能的了，放弃，将suspend改为1小时这样短途休息时不用suspend，第二天要唤醒时使用电源键或者专门买一个无线鼠标来专门用于唤醒。</p>
<h2 id="Another-post"><a href="#Another-post" class="headerlink" title="Another post"></a>Another post</h2><p><a href="https://blog.csdn.net/quqi99/article/details/103754977" target="_blank" rel="external">https://blog.csdn.net/quqi99/article/details/103754977</a><br><a href="https://zhhuabj.blog.csdn.net/article/details/83109470" target="_blank" rel="external">https://zhhuabj.blog.csdn.net/article/details/83109470</a></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://askubuntu.com/questions/822249/unpair-remove-bluetooth-devices-in-16-04-1-and-other-problems" target="_blank" rel="external">https://askubuntu.com/questions/822249/unpair-remove-bluetooth-devices-in-16-04-1-and-other-problems</a><br>[2] <a href="http://events17.linuxfoundation.org/sites/events/files/slides/Bluetooth%20on%20Modern%20Linux_0.pdf" target="_blank" rel="external">http://events17.linuxfoundation.org/sites/events/files/slides/Bluetooth%20on%20Modern%20Linux_0.pdf</a><br>[3] <a href="https://medium.com/@overcode/fixing-bluetooth-in-ubuntu-pop-os-18-04-d4b8dbf7ddd6" target="_blank" rel="external">https://medium.com/@overcode/fixing-bluetooth-in-ubuntu-pop-os-18-04-d4b8dbf7ddd6</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/02/Ubuntu-18-04安装全面战争三国游戏/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/02/Ubuntu-18-04安装全面战争三国游戏/" itemprop="url">Ubuntu 18.04安装全面战争三国游戏</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-02-02T12:30:47+08:00">
                2021-02-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>作者：张华 发表于：2019-08-02<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository multiverse</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y libvulkan1 libvulkan-dev mesa-vulkan-drivers</span><br><span class="line">#sudo add-apt-repository ppa:graphics-drivers/ppa  #Use latest version</span><br><span class="line">sudo lshw -c display             #By default, the opensource nouveau driver is being used for Nvidia card.</span><br><span class="line">sudo ubuntu-drivers devices      #List available driver for your Nvidia card from the default Ubuntu repo.</span><br><span class="line">sudo ubuntu-drivers autoinstall  #Or run: sudo apt install nvidia-driver-390</span><br><span class="line">#sudo apt purge nvidia-*</span><br><span class="line">sudo shutdown -r now</span><br><span class="line">sudo lshw -c display</span><br><span class="line">prime-select query</span><br><span class="line"></span><br><span class="line">sudo prime-select intel</span><br><span class="line">sudo prime-select nvidia</span><br><span class="line">watch -n 1 nvidia-smi</span><br><span class="line"></span><br><span class="line">sudo cpupower -c all frequency-set -g performance</span><br><span class="line">echo &apos;GOVERNOR=&quot;performance&quot;&apos; | sudo tee /etc/default/cpufrequtils</span><br><span class="line">cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</span><br><span class="line">sudo systemctl restart cpufrequtils</span><br><span class="line">sudo systemctl disable ondemand</span><br><span class="line"></span><br><span class="line">sudo apt install -y steam</span><br><span class="line">mkdir -p /game/.steam &amp;&amp; rm -rf ~/.steam &amp;&amp; ln -s /game/.steam ~/.steam</span><br><span class="line">steam</span><br><span class="line"></span><br><span class="line">#optimize the performance</span><br><span class="line">sudo add-apt-repository ppa:samoilov-lex/gamemode</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt install -y gamemode</span><br><span class="line"># then open &apos;NVIDIA X Server Settings&apos; program, and set &apos;Enable FXAA&apos;</span><br><span class="line"></span><br><span class="line">https://support.feralinteractive.com/docs/zh_cn/threekingdomstw/1.0.4/linux/faqs/?access=zooevrj6xb&amp;utm_source=game_linux&amp;utm_medium=link&amp;utm_campaign=game_linux_threekingdomstw_support#i_linux_graphics_drivers</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/02/CPU-governor/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/02/CPU-governor/" itemprop="url">CPU governor</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-02-02T12:15:20+08:00">
                2021-02-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2019-04-25)</strong></p>
<h2 id="performance-and-powersave"><a href="#performance-and-powersave" class="headerlink" title="performance and powersave"></a>performance and powersave</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># we can set CPU governor in BIOS or Power Mangement Program or the following Linux commands</span><br><span class="line">sudo apt install cpufrequtils sysfsutils linux-tools-generic -y</span><br><span class="line"># all cpu info</span><br><span class="line">cpufreq-info</span><br><span class="line"># cpu info for just cpu0</span><br><span class="line">cpupower frequency-info</span><br><span class="line"># just set cpu0 to performance mode</span><br><span class="line">sudo cpufreq-set -g performance</span><br><span class="line"># set all cpu to powersave mode</span><br><span class="line">sudo cpupower -c all frequency-set -g powersave</span><br><span class="line">cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</span><br><span class="line">cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_max_freq</span><br><span class="line">cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_min_freq</span><br><span class="line">cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_cur_freq</span><br><span class="line">cat /proc/cpuinfo | grep -i &quot;cpu mhz&quot;</span><br><span class="line"></span><br><span class="line"># How to persistence these configurations</span><br><span class="line">sudo sed -i &apos;s/^GOVERNOR=.*/GOVERNOR=&quot;powersave&quot;/&apos;/etc/init.d/cpufrequtils</span><br><span class="line"># or</span><br><span class="line">echo &apos;GOVERNOR=&quot;powersave&quot;&apos; | sudo tee/etc/default/cpufrequtils</span><br><span class="line"></span><br><span class="line">sudo systemctl restart cpufrequtils</span><br><span class="line">sudo systemctl disable ondemand</span><br></pre></td></tr></table></figure>
<h2 id="userspace-and-ondemand"><a href="#userspace-and-ondemand" class="headerlink" title="userspace and ondemand"></a>userspace and ondemand</h2><p>This is because your system is using the new driver called intel_pstate. There are only two governors available when using this driver: powersave and performance.<br>The userspace governor is only available with the older acpi-cpufreq driver (which will be automatically used if you disable intel_pstate at boot time; you then set the governor/frequency with cpupower):</p>
<p>disable the current driver: add intel_pstate=disable to your kernel boot line<br>boot, then load the userspace module: modprobe cpufreq_userspace<br>set the governor: cpupower frequency-set –governor userspace<br>set the frequency: cpupower –cpu all frequency-set –freq 800MHz<br>NOTE:　还是要intel-pstate驱动吧，因为：</p>
<ul>
<li>intel_pstate驱动程序知道CPU工作方式的详细信息，并且比通用ACPI解决方案做得更好</li>
<li>intel_pstate仅提供两个调控器，powersave而performance。英特尔声称intel_pstate的“省电”速度比具有“性能”的通用acpi调速器快</li>
</ul>
<h2 id="openwrt-setting"><a href="#openwrt-setting" class="headerlink" title="openwrt setting"></a>openwrt setting</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for core in $(seq 0 &quot;$(($(getconf _NPROCESSORS_ONLN) - 1))&quot;); do</span><br><span class="line">echo &#123;performance|powersave&#125; &gt;/sys/devices/system/cpu/cpu$core/cpufreq/scaling_governor ;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/02/GSO-TSO-GRO等对VirtIO虚机的网络性能影响分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/02/GSO-TSO-GRO等对VirtIO虚机的网络性能影响分析/" itemprop="url">GSO/TSO/GRO等对VirtIO虚机的网络性能影响分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-02-02T09:57:34+08:00">
                2021-02-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2016-04-05<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</p>
<p>( <a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</p>
<p>IP层叫分片，TCP/UDP层叫分段。网卡能做的事（TCP/UDP组包校验和分段，IP添加包头校验与分片）尽量往网卡做，网卡不能做的也尽量迟后分片（发送）或提前合并片（接收）来减少在网络栈中传输和处理的包数目，从而减少数据传输和上下文切换所需要的CPU计算时间。</p>
<p>发数据<br>TSO(TCP分段，TCP Segmentation Offload)在TCP处做，UFO(UDP分片，UDP Fragmentation Offload）因为UDP不支持分段所以移到下层的IP层做分片。TSO是使得网络协议栈能够将大块buffer推送至网卡，然后网卡执行分片工作，这样减轻了CPU 的负荷，但TSO需要硬件来实现分片功能；</p>
<p>GSO(Generic Segmentation Offload)比TSO更通用，基本思想就是尽可能的推迟数据分片直至发送到网卡驱动之前，如果硬件不支持TSO分段则由dev_hard_start_xmit中的dev_gso_segment先软件分段的segs赋值给skb-&gt;next（skb-&gt;next = segs）, 如果网卡硬件支持分段则直接将GSO大帧（skb-next)传给网卡驱动(dev_hard_start_xmit中的ndo_start_xmit)（所以它传给virtio驱动的是GSO大帧），然后继续进行IP分片后再发往网卡。GSO自动检测网卡支持特性， 硬件不支持也可以使用GSO它更通用（TSO一定需要硬件支持）。当打开GSO时，GSO会在xmit那块做GSO分片时调用TCP/UDP的回调函数自动添加TCP/UDP头（不使用GSO的只有第一个分片有TCP/UDP头，后面接着的分片是没有的，这也是为什么在虚机里打开TSO/GSO时对于隧道会多出一块数据的原因），然后再调IP层回调函数为每个分片添加IP头。<br>命令(ethtool -K eth0 tso|gso off|on)可打开或关闭网卡驱动的gso/tso特性：</p>
<p>1, 物理网卡不支持GSO时, 使用TSO时TCP分段在驱动处调用硬件做，不使用TSO时TCP分段在TCP协议处软件做。<br>2, 物理网卡不支持UFO时，使用GSO时在发送给驱动前一刻做，不使用GSO在IP层软件做。<br>3, 物理网卡不支持TSO时，使用GSO时在发送给驱动前一刻做，不使用GSO在TCP层软件做。</p>
<p>TSO与GSO的重要区别</p>
<p>1, TSO只有第一个分片有TCP头和IP头，接着的分段只有IP头。意味着第一个分段丢失，所有分段得重传。<br>2, GSO在分段时会调用TCP或UDP的回调函数(udp4_ufo_fragment)为每个分段都加上IP头，由于分段是通过mss设置的（mss由发送端设置），所以长度仍然可能超过mtu值，所以在IP层还得再分片(代码位于dev_hard_start_xmit)。</p>
<p>收数据<br>LRO(Large Receive Offload），TSO是发，LRO是收。将多个TCP分段聚合成一个skb结构，以减小上层协议栈的skb的开销。skb的数据保存在skb-&gt;data中，分段的数据保存在skb_shared_info-&gt;frag_list中。<br>GRO(Generic Receive Offloading)，GSO是发，GRO是收。LRO使用发送方和目的地IP地址，IP封包ID，L4协议三者来区分段，对于从同一个SNAT域的两个机器发向同一目的IP的两个封包可能会存在相同的IP封包ID（因为不是全局分配的ID），这样会有所谓的卷绕的bug。GRO采用发送方和目的地IP地址，源/目的端口，L4协议三者来区分作为改进。所以对于后续的驱动都应该使用GRO的接口，而不是LRO。另外，GRO也支持多协议。<br>1, 物理网卡不支持GRO时, 使用LRO在驱动处合并了多个skb一次性通过网络栈，对CPU负荷的减轻是显然的。<br>2, 物理网卡不支持LRO时，使用GRO在从驱动接收数据那一刻合并了多个skb一次性通过网络栈，对CPU负荷的减轻是显然的。</p>
<p>性能影响<br>性能依次是：客户机和宿主机GSO/TSO/UFO都打开 &gt; 客户机打开宿主机关闭 &gt; 客户机宿主机都关闭。</p>
<p>对TCP来说，在CPU资源充足的情况下，TSO/GSO 能带来的效果不大，但是在CPU资源不足的情况下，其带来的改观还是很大的。<br>对UDP来说，其改进效果一般，改进效果不超过20%。所以在VxLAN环境中，其实是可以把GSO关闭，从而避免它带来的一些潜在问题。</p>
<p>Offloading 带来的潜在问题<br>分段offloading可能会带来潜在的问题，比如网络传输的延迟latency，因为packets的大小的增加，大大增加了driver queue的容量（capacity）。比如说，系统一方面在使用大的packet size传输大量的数据，同时在运行许多的交换式应用（interactive application）。因为交互式应用会定时发送许多小的packet，这时候可能会应为这些小的packets被淹没在大的packets之中，需要等待较长的时间才能被处理，这可能会带来不可接受的延迟。在网络上也能看到一些建议，在使用这些offloading技术时如果发现莫名的网络问题，建议先将这些技术关闭后再看看情况有没有改变。</p>
<h1 id="ethtool-K-interface-gso-off"><a href="#ethtool-K-interface-gso-off" class="headerlink" title="ethtool -K interface gso off"></a>ethtool -K interface gso off</h1><h1 id="ethtool-K-interface-tso-off"><a href="#ethtool-K-interface-tso-off" class="headerlink" title="ethtool -K interface tso off"></a>ethtool -K interface tso off</h1><p>VirtIO<br>在guest中有virtio前端驱动, 如针对网络的virtio-net，和其他驱动如virtio-pci等共同经过virt-queue的notify的trap中断到主机的hypervisor中执行host中面向guest前端驱动的api接口与后端驱动(virtio-backend driver)。guest内核的rx0与tx0两个队列与host的rx与tx两个队列通过socket共享内存交换数据。</p>
<p>下面是如何打开virtqueue的调试功能</p>
<p>echo -n “func virtqueue_add +flmpt” | sudo tee /sys/kernel/debug/dynamic_debug/control<br>sudo cat /sys/kernel/debug/dynamic_debug/control | grep virtio<br>这样能看到 virtqueue_add() 函数的信息：<br>drivers/virtio/virtio_ring.c:294 [virtio_ring]virtqueue_add =pmflt “Added buffer head %i to %p\012”<br>drivers/virtio/virtio_ring.c:236 [virtio_ring]virtqueue_add =pmflt “Can’t add buf len %i - avail = %i\012”</p>
<p>vxlan的实现</p>
<p>从guest出来的tcp数据到达host的vxlan driver时会调用vxlan_xmit, 它的主要逻辑是获取 vxlan dev，然后为 sk_buff 中的每一个skb调用vxlan_xmit_skb方法, vlan_xmit_skb除了计算 tos，ttl，df，src_port，dst_port，md，flags等以外，也调用skb_set_inner_protocol(skb, htons(ETH_P_TEB))设置GSO参数。最后调用udp_tunnel_xmit_skb将skb传给udp tunnel协议栈继续处理。<br>这样也就进了IP层的ip_finish_output_gso，如果硬件支持，则由硬件调用linux内核中的UDP GSO函数（当有GSO时，由 UDP协议栈提供UDP分片逻辑而不是IP分片逻辑，这使得每个分片都有完整的UDP包头，然后继续IP层的GSO分片。所以GSO本身是对UFO的优化）；如果硬件不支持，则在进入device driver queue之前由linux内核调用UDP GSO分片函数，然后再一直往下到网卡。<br>static int ip_finish_output_gso(struct net <em>net, struct sock </em>sk,<br>struct sk_buff *skb, unsigned int mtu){<br>…</p>
<p>   #调用回调函数, 对于UDP则是调用UDP的gso_segment回调函数进行UDP GSO分段<br>   segs = skb_gso_segment(skb, features &amp; ~NETIF_F_GSO_MASK);<br>   …<br>do {<br>struct sk_buff *nskb = segs-&gt;next;<br>int err;<br>segs-&gt;next = NULL;</p>
<pre><code>#有必要则IP分片，因为UDP GSO是按照MSS进行，MSS还是有可能超过IP分段所使用的host物理网卡MTU
</code></pre><p>err = ip_fragment(net, sk, segs, mtu, ip_finish_output2);<br>if (err &amp;&amp; ret == 0)<br>ret = err;<br>segs = nskb;<br>} while (segs);</p>
<p>这里是udp_offload.c中定义的回调函数：<br>static const struct net_offload udpv4_offload = {<br>.callbacks = {<br>.gso_segment = udp4_ufo_fragment,<br>                …<br>},<br>};<br>可见，在整个过程中，有客户机上TCP协议层设置的skb_shinfo(skb)-&gt;gso_size始终保持不变为MSS，因此，在网卡中最终所做的针对UDP GSO数据报的GSO分片所依据的分片的长度还是根据skb_shinfo(skb)-&gt;gso_size的值即TCP MSS，所以vxlan协议有一个问题，即host的IP分片是根据geuest中TCP连接的MSS来进行的。</p>
<p>从geust到host的包流向</p>
<p>1, netif_needs_gso先判断网卡是否支持GSO（guest里的virtio nic肯定支持），if(unlikely(foo))认为foo通常为0， 所以如果网卡支持TSO时dev_gso_segment将返回0（skb-&gt;next==NULL)，也就是说，当guest网卡的GSO特性打开时，guest会直接将没有分段的GSO大帧传递到virtio-net driver中。<br>int dev_hard_start_xmit(struct sk_buff <em>skb, struct net_device </em>dev,<br>struct netdev_queue <em>txq)<br>{<br>…<br>if (netif_needs_gso(skb, features)) {<br>if (unlikely(dev_gso_segment(skb, features)))<br>goto out_kfree_skb;<br>if (skb-&gt;next)<br>goto gso;<br>}<br>gso:<br>do {<br>struct sk_buff </em>nskb = skb-&gt;next;<br>skb-&gt;next = nskb-&gt;next;<br>…<br>rc = ops-&gt;ndo_start_xmit(nskb, dev);<br>…<br>} while (skb-&gt;next);</p>
<p>static int dev_gso_segment(struct sk_buff <em>skb, netdev_features_t features)<br>{<br>struct sk_buff </em>segs;<br>segs = skb_gso_segment(skb, features);</p>
<p>/<em> Verifying header integrity only. </em>/<br>if (!segs)<br>return 0;<br>skb-&gt;next = segs;<br>DEV_GSO_CB(skb)-&gt;destructor = skb-&gt;destructor;<br>skb-&gt;destructor = dev_gso_skb_destructor;<br>return 0;<br>}</p>
<p>2, virtio_net.c中的如下代码定义了virtio-net driver的xmit函数为start_xmit，它会直接将这个GSO大帧通过vring(&lt;=64K)传给host上的virtio backend driver.<br>static const struct net_device_ops virtnet_netdev = {<br>        …<br>.ndo_start_xmit      = start_xmit,</p>
<p>3, 然后host上的tap和bridge都会原封不动动转发这个GSO大帧(payload, inner-tcp, inner-ip, inner-ethernet)。</p>
<p>4, host上的vxlan driver在原GSO大帧上添加vxlan帧头，从(payload, inner-tcp, inner-ip, inner-ethernet)变成(payload, inner-tcp, inner-ip, inner-ethernet, vxlan)。</p>
<p>5, 如果host不支持GSO，那么在host的IP层直接对外层的UDP分片，注意：只有第1个分片有UDP头，接下来的分片没有UDP头。<br>   分片1： payload, inner-tcp, inner-ip, inner-ethernet, vxlan，outer-udp, outer-ip<br>   分片2： payload, inner-tcp, inner-ip, inner-ethernet, vxlan，outer-ip</p>
<p>6, 如果host支持GSO，在host的dev_hard_start_xmit处（代码回到第1步），如果物理网卡支持TSO直接将大帧(payload, inner-tcp, inner-ip, inner-ethernet, vxlan)将给物理网卡的TSO去硬件分片。如果物理网卡不支持TSO将调用skb_gso_segment软件执行GSO。GSO由于会调用UDP的回调函数，但vxlan没有GSO回调函数，所以这里的GSO分片应该每一个分片都有UDP头部，但是只有第一个分片有vxlan头部。<br>   分片1： payload, inner-tcp, inner-ip, inner-ethernet, vxlan，outer-udp, outer-ip<br>   分片2： payload, inner-tcp, inner-ip, inner-ethernet，outer-udp, outer-ip</p>
<p>7, 但是host的物理网卡是根据mss(由sender确定，也就是guest设定,而不是由mtu设定）发给远端的。host打开GSO增加outer-udp时可能会造成包大于mss值从而继续在添加outer-ip时做ip分片。所以redhat的最佳实践要求关闭host机上的GSO特性。</p>
<p>从host到guest的包流向<br>1, 如果host上的GRO打开的话，host上的物理网卡要先将分片重组合并成一个大的GRO包。</p>
<p>2, 包在过路由器时，conntrack需要将分段重组后使用防火墙规则检查，为防止攻击，路由器会有定时器设置一段时间没有做完分段重组就会丢弃清理相应的内存资源，下面参数可以设置分段使用的内存量和<br>hua@node1:~$ cat /proc/sys/net/ipv4/ipfrag_high_thresh  #一旦达到最高内存分配值，其它分段将被丢弃，直到达到最低内存分配值。<br>4194304<br>hua@node1:~$ cat /proc/sys/net/ipv4/ipfrag_low_thresh<br>3145728<br>hua@node1:~$ cat /proc/sys/net/ipv4/ipfrag_time<br>30<br>具体到openstack的网络节点，数据流向是：<br>eth0(pysical nic for public network) -&gt; br-ex (maybe a linux bridge) -&gt; qg-XXX -&gt; qr-XXX -&gt; br-int (ovs bridge) -&gt; ovs-patch-ports -&gt; br-tun (for stt tunnel) -&gt; eth1(pysical nic for management network)<br>如eth0, eth1的mtu是9000的话，若host的GRO打开的话，eth0收到数据会会分段重组成一个大GRO帧：<br>1, 如果br-ex是linux bridge，且net.bridge.bridge-nf-call-arptables = 1，在br-ex上就会分段重组然后使用qg-xxx的mtu=1500再进行分片。<br>2, 即使br-ex不是linux bridge，eth0在重组后做完防火墙后再使用9000再重新分片， 再传到后面1500的虚拟设备又会重组。<br>所以如果mtu设置不当，还不如将host上的TSO/GSO/GRO关闭(Redhat这是这样推荐的），这样也不会造成一个大帧反复重组和分片的问题了。</p>
<p>另外就是路由器又和NAT搅和在一起的问题，由于在路由器上可能会重组再分片，路由器为了识别一个包属于哪一个分片，会使用&lt;发送方和接收方IP、IP分段ID，L4协议&gt;五元组来区分，由于SNAT在IP分段ID相同的话会出现来自NAT路由器背后不同机器上的分段的五元组相同的情况。所以后来GRO在TSO的基础上将这个五元组改为：&lt;发送方和接收方IP、TOS/协议字段，L4协议&gt;.</p>
<p>3, 在linux bridge上，如果net.bridge.bridge-nf-call-arptables = 1 ， netfilter conntrack为了做二层的防欺骗检查也需要先分片重组, 然后重新分片（此时分片采用出口NIC的MTU进行分片, 而从geust往host出时的分片采用的是来自guest的mss值）。故不想linux bridge有防火墙功能的话应该设置：<br>net.bridge.bridge-nf-call-arptables = 0<br>net.bridge.bridge-nf-call-ip6tables = 0<br>net.bridge.bridge-nf-call-iptables = 0</p>
<p>4, 另外，包在过路由器时，</p>
<p>5, 然后virtio继续将大帧传入guest.</p>
<p>VMware STT隧道<br>如果现在不是Linux + OVS bridge (ovs bridge支持STT，Linux Bridge不支持STT) + virtio， 而是VMware STT呢？有几个问题要搞清楚：<br>1, STT是加了伪装TCP头利用网卡的TSO特性硬件分片的，所以它走的是TCP，不是UDP（因为很多网卡不支持UDP的硬件分段）。<br>2, NSX Bridge是如何实现的，是否有类似于Linux中的net.bridge.bridge-nf-call-iptables, (tap -&gt; NSX bridge -&gt; ??? -&gt; dev_queue_xmit )<br>    这个网址（<a href="http://blog.scottlowe.org/learning-nvp-nsx/）有一堆关于nsx的介绍，nsx也是用了ovs的，bridge-nf-call-iptables只是linux" target="_blank" rel="external">http://blog.scottlowe.org/learning-nvp-nsx/）有一堆关于nsx的介绍，nsx也是用了ovs的，bridge-nf-call-iptables只是linux</a> bridge的特性，ovs bridge不存在这个特性。但nsx与neutron集成时可能仍然使用tap-&gt;qbr-&gt;qvb-&gt;qvr-&gt;br-int-&gt;ovs-patch-port-&gt;phy-br-eth0，在这里面qbr与phy-br-eth0均有可能是Linux Bridge.<br>3, NSX实现了virtio吗？<br>    上面已回答，nsx仍然使用ovs。virtio是qemu的特性，与nsx无关。</p>
<p>解决办法<br>链连[10]上说：<br>1, 若用隧道guest中设置mtu</p>
<p>2, echo 0 &gt; /proc/sys/net/bridge/bridge-nf-call-iptable (可选，如果有Linux Bridge的话）</p>
<p>3, 关闭host上的GSO, TSO, GRO (如果为使用conntract特性没有关闭bridge-nf-call-iptable的话）</p>
<p>4, 重点关注host机上物理网卡与Linux bridge上的mtu，其他的虚拟网卡的mtu可以默认设置很大如65000 (可选）</p>
<p>5, 也可以试试关闭tx与rx两个offload特性，sudo ethtool –offload eth0 rx off tx off sg off tso off， 注意：在tx与rx打开时，chksum是在硬件网卡处做的，tcpdump的输出“cksum 0x0a2b (incorrect -&gt; xxx”应该是正常的。</p>
<p>juju run –application nova-compute ‘for x in <code>ip netns | cut -f1 -d&quot; &quot;</code>; do ip netns exec $x bash -c “ip link list | sed -e \”s/2: (.<em>)@if.</em>/\1/;t;d\” | while read x; do ethtool –offload \$x rx off tx off sg off tso off; done”; done’</p>
<p>参考</p>
<p>[1] <a href="http://www.pagefault.info/?p=159" target="_blank" rel="external">http://www.pagefault.info/?p=159</a><br>[2] <a href="https://kris.io/2015/10/01/kvm-network-performance-tso-and-gso-turn-it-off/" target="_blank" rel="external">https://kris.io/2015/10/01/kvm-network-performance-tso-and-gso-turn-it-off/</a><br>[3] <a href="http://www.cnblogs.com/sammyliu/p/5227121.html" target="_blank" rel="external">http://www.cnblogs.com/sammyliu/p/5227121.html</a><br>[4] <a href="https://patchwork.ozlabs.org/patch/415791/" target="_blank" rel="external">https://patchwork.ozlabs.org/patch/415791/</a><br>[5] <a href="http://www.ibm.com/developerworks/cn/linux/l-virtio/" target="_blank" rel="external">http://www.ibm.com/developerworks/cn/linux/l-virtio/</a><br>[6] <a href="http://www.cnblogs.com/sammyliu/p/5228581.html" target="_blank" rel="external">http://www.cnblogs.com/sammyliu/p/5228581.html</a><br>[7] <a href="http://royluo.org/2014/08/09/virtio-netdev-send/" target="_blank" rel="external">http://royluo.org/2014/08/09/virtio-netdev-send/</a><br>[8] <a href="https://markmc.fedorapeople.org/virtio-code-review/VirtioCodeReview.pdf" target="_blank" rel="external">https://markmc.fedorapeople.org/virtio-code-review/VirtioCodeReview.pdf</a></p>
<p>[9] <a href="http://blog.csdn.net/majieyue/article/details/7929398" target="_blank" rel="external">http://blog.csdn.net/majieyue/article/details/7929398</a></p>
<p>[10] <a href="https://ask.openstack.org/en/question/58607/poor-network-connection-issue-with-windows-instance/" target="_blank" rel="external">https://ask.openstack.org/en/question/58607/poor-network-connection-issue-with-windows-instance/</a></p>
<p>[11] <a href="https://sokratisg.net/2012/04/01/udp-tcp-checksum-errors-from-tcpdump-nic-hardware-offloading/" target="_blank" rel="external">https://sokratisg.net/2012/04/01/udp-tcp-checksum-errors-from-tcpdump-nic-hardware-offloading/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/01/Thinkpad-T440p安装Linux的种种问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/02/01/Thinkpad-T440p安装Linux的种种问题/" itemprop="url">Thinkpad T440p安装Linux的种种问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-02-01T10:27:18+08:00">
                2021-02-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作者：张华  发表于：2014-05-08<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br>(<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )<br>Thinkpad T440p里使用了一些最新的硬件，这些硬件厂商对Linux高度不兼容, 下面是安装ubuntu 14.04与win8双系统时遇到的一些问题。<br>1, 要在BIOS（F1键）里disable掉UEFI Security Boot特性, 之前按F12选usb进行安装。<br>   UEFI是下一代的BIOS，它内操置了一些操作系统的公钥，操作系统要用私钥签名，UEFI硬件用公钥检测操作系统的完整性，可信才加载系统。<br>本来是一个很好的技术，但是被微软给滥用了。微软先强制将它自己的公钥加到UEFI DB中，然后再要求厂商预安装Win8之后强制厂商将UEFI Security Boot特性打开，这样就无法安装其他没有公钥的操作系统了，然后强制其它厂商向微软申请公钥，也不允许用户自定义公钥文件。对于一些支持win8的移动硬件，微软甚至都强制不提供disable UEFI Security Boot的开关界面。<br>2, Thinkpad T440p使用了Realtek公司的rtl8192ee 10ec:818b网卡，<br>   root@laptop:/home/hua# lspci -nn |grep Wireless<br>   04:00.0 Network controller [0280]: Realtek Semiconductor Co., Ltd. RTL8192EE PCIe Wireless Network Adapter [10ec:818b]<br>   Realtek公司却没有提供相应的Linux驱动（附录一是一个极不稳定的驱动，基本没法用），也就是目前：<br>   有固件：/lib/firmware/rtlwifi/rtl8192eefw.bin<br>   但无驱动：/lib/modules/3.13.0-24-generic/kernel/drivers/net/wireless/rtlwifi/rtl8192ee/rtl8192ee.ko<br>   Realtec公司的rtl8192ee驱动将出现在linux 3.16版本的内核里，3.16内核目前还没有出，实在没办法解决，只好先又买了个TL-WN725N USB无线网卡对付着用。<br>3, Thinkpad T440p除了主板里的集成显卡以外，还有一个nvidia的显卡，默认使用的是开源的bumblebee驱动，我遇到的会造成这两种问题：<br>   一是例如执行lspci命令之后都会造成所有的usb设备都无法用，如usb网卡，如usb数标。<br>   二是由于acpi call失败造成无法正常关机，且每次造成磁盘数据损坏导致在开机时需要修复</p>
<p>   三是合上电脑再打开桌面消失</p>
<p>   四是发热厉害</p>
<p>   五是不安装它可能启动ubuntu不成功，需要在grub中临时将quiet splash改成nomodeset即可，将nvidea驱动安装后就不需要了。<br>   网上有人遇到了和我一样的问题，见：<a href="https://github.com/Bumblebee-Project/bbswitch/issues/78，但它的办法是在仍然用bumblebee驱动的前提下寻求解决（见附录二），我是直接安装nvidia" target="_blank" rel="external">https://github.com/Bumblebee-Project/bbswitch/issues/78，但它的办法是在仍然用bumblebee驱动的前提下寻求解决（见附录二），我是直接安装nvidia</a> linux驱动（值得一提的是，nvidia也是一个起初对linux极不友好的一家公司，linux之父在公开场合还曾经骂地这家公司，见：<a href="http://www.ithome.com/html/it/19249.htm，但是现在居然有nvidia" target="_blank" rel="external">http://www.ithome.com/html/it/19249.htm，但是现在居然有nvidia</a> linux驱动了，赞一个）。<br>  sudo apt-get purge bumblebee*<br>  sudo apt-get purge libvdpau-va-gl12  sudo apt-get install nvidia-319 nvidia-settings-319 nvidia-prime</p>
<p>20140709更新：</p>
<p>安装nvidia驱动后在移动电脑时桌面lightadm很容易死，可进控制台（ctrl + alt + f1)后通过apport-cli命令收集日志，或者查看/var/crash的相关日志发现是lightadm crash了，现在的做法是禁用掉nvidia的一切驱动，切换到intel的集成显卡，在/etc/default/grub中更新下列一行，然后更新grub</p>
<p>GRUB_CMDLINE_LINUX_DEFAULT=”quiet splash rdblacklist=nouveau i965.modeset=1 nouveau.modeset”</p>
<p>另外我也更新了kernel到3.14.1-031401-generic</p>
<p>附录一，目前极不稳定的一个rtl8192ee linux驱动<br>参考：<a href="http://ubuntuforums.org/showthread.php?t=2198221" target="_blank" rel="external">http://ubuntuforums.org/showthread.php?t=2198221</a><br>wget <a href="http://netbook-remix.archive.canonical.com/updates/pool/public/o/oem-wireless-rtl-92ce-92se-92de-8723ae-88ee-8723be-92ee-dkms/oem-wireless-rtl-92ce-92se-92de-8723ae-88ee-8723be-92ee-dkms_0017.1016.2013~sutton1.tar.gz" target="_blank" rel="external">http://netbook-remix.archive.canonical.com/updates/pool/public/o/oem-wireless-rtl-92ce-92se-92de-8723ae-88ee-8723be-92ee-dkms/oem-wireless-rtl-92ce-92se-92de-8723ae-88ee-8723be-92ee-dkms_0017.1016.2013~sutton1.tar.gz</a><br>sudo modprobe rtl8192ee<br>sudo modprobe -rv rtl8192ee<br>sudo modprobe -v rtl8192ee swenc=1 fwlps=0 ips=0</p>
<p>附录二，仍使用开源的nvidia驱动nouveau的前提下解决acpi问题<br>git clone <a href="https://github.com/mkottman/acpi_call" target="_blank" rel="external">https://github.com/mkottman/acpi_call</a><br>cd acpi_call<br>make<br>sudo cp acpi_call.ko /lib/modules/<code>uname -r</code>/kernel/drivers/acpi<br>sudo depmod -a<br>sudo modprobe acpi_call<br>Create a script with the following in it (e.g. at /usr/local/bin/disable_nvidia.sh, remember chmod +x it):</p>
<p>#!/bin/sh<br>echo “_SB.PCI0.PEG.VID._DSM {0xF8,0xD8,0x86,0xA4,0xDA,0x0B,0x1B,0x47,0x60,0x42,0xA6,0xB5,0xBE,0xE0} 0x100 0x1A {0x1,0x0,0x0,0x3}” &gt;/proc/acpi/call<br>echo “_SB.PCI0.PEG.VID.GPOF” &gt;/proc/acpi/call<br>exit 0<br>Call the script from /etc/rc.local<br>Add rdblacklist=nouveau i965.modeset=1 nouveau.modeset to the GRUB_CMDLINE_LINUX_DEFAULT flags in /etc/default/grub, also for full KVM support (e.g. better brightness control etc.) I’ve found adding acpi_osi=\”!Windows 2012\” helps too.<br>run sudo update-grub</p>
<p>2014-06-21更新：</p>
<p>解决办法已经出来了，见：</p>
<p><a href="https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1239578" target="_blank" rel="external">https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1239578</a></p>
<p>2014-07-29更新：</p>
<p>有些型号的机器即使像上面disable UEFI Security Boot特性也是安装不了的，那是因为遇到了一个UEFI的bug，原因如下：</p>
<p>Some EFI-based computers, including some HPs, have broken EFIs that<br>don’t accept anything but the fallback boot loader<br>(EFI/boot/bootx64.efi on the EFI System Partition) or the Windows boot<br>loader (EFI/Microsoft/boot/bootmgfw.efi on the ESP). If yours suffers<br>from this defect, you’ll need to copy EFI/ubuntu/grubx64.efi (or<br>EFI/ubuntu/shimx64.efi, if Secure Boot is active) to one or both of<br>those names. (If Secure Boot is active, also copy<br>EFI/ubuntu/grubx64.efi to the same directory where you copy GRUB, but<br>keep its filename as grubx64.efi).</p>
<p>Note that I’m assuming you’re doing an Ubuntu-only installation. If<br>you want to dual-boot with Windows, you’ve got to copy ITS boot loader<br>to another name and tweak GRUB to find Windows there. This starts to<br>get complex, so the Boot Repair tool<br>(<a href="https://help.ubuntu.com/community/Boot-Repair" target="_blank" rel="external">https://help.ubuntu.com/community/Boot-Repair</a>) may be helpful. It’s<br>got an option to do all this on its Advanced page.</p>
<p>Alternatively, you could install  rEFInd<br>(<a href="http://www.rodsbooks.com/refind" target="_blank" rel="external">http://www.rodsbooks.com/refind</a>) to one of those “magic” locations –<br>but the installation script won’t install there by default, so you’ll<br>need to do it manually or juggle filenames afterwards. (The<br>mvrefind.sh script can help with that.)</p>
<p>2014-12-01更新：</p>
<p>现在ubuntu 14.10默认的内核版本里已经有该网卡的驱动了，我已经用上了，挺好使的。见： <a href="https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1239578" target="_blank" rel="external">https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1239578</a></p>
<p>2015-03-02更新, 解决一crash问题：</p>
<p>之前一直感觉系统容易忽然死机，可能一周一次，没去管它。但今天居然邪门到一个小时内死机6次，不得不深度介入了。根据观察，感觉是Chrome的时候容易死，使用“watch sensors” （需安装sudo dpkg -l |grep sensors 软件包）查看cpu温度在打开chrome之非常容易从56度升到八十几度。于是，不启动chrome，观察两小时，ok，不死机。于是google关键字”ubuntu 14.10 chrome crash”， 非常幸运，找到一个bug （<a href="https://bugs.launchpad.net/ubuntu/+source/mesa/+bug/1377220" target="_blank" rel="external">https://bugs.launchpad.net/ubuntu/+source/mesa/+bug/1377220</a> ），原来是chrome新增加了一个根据gpu加速的新特性，针对intel gpu加速不了，退到软加速了，从而导致全局crash的问题。解决办法：修改文件/usr/share/applications/google-chrome.desktop， 将”Exec=/usr/bin/google-chrome-stable”修改成” Exec=env LIBGL_DRI3_DISABLE=1 /usr/bin/google-chrome-stable”即可。</p>
<p>2015-03-03， 像上面那样修改之后，使用htop命令还能看到chrome时不时有gpu字眼的进程蹦出来，这时候温度会上升，于是升级了内核为3.40版本，<a href="http://kernel.ubuntu.com/~kernel-ppa/mainline/daily/current/" target="_blank" rel="external">http://kernel.ubuntu.com/~kernel-ppa/mainline/daily/current/</a></p>
<p>20180216更新 - 禁用蓝牙键盘的休眠功能</p>
<p><a href="https://unix.stackexchange.com/questions/177998/bluetooth-mouse-disconnects" target="_blank" rel="external">https://unix.stackexchange.com/questions/177998/bluetooth-mouse-disconnects</a></p>
<p>sudo sed -i ‘s/#IdleTimeout=30/IdleTimeout=0/‘ /etc/bluetooth/input.conf</p>
<p>#$ cat /etc/udev/rules.d/91-local.rules</p>
<p>#ACTION==”add”, SUBSYSTEM==”bluetooth”, ATTR{product}==”Microsoft Bluetooth Mouse        “, ATTR{power/control}=”on”</p>
<p>#sudo udevadm control –reload-rules</p>
<p>sudo apt-get install pulseaudio-module-bluetooth<br>killall pulseaudio<br>rfkill list<br>rfkill unblock xx</p>
<p>20180822更新 - chrome花屏问题</p>
<p>昨晚将ubuntu 16.04升级到ubuntu 18.04之后, 今早发现使用chrome时有轻微花屏, 网上搜索了好多网页都不能解决问题, 最后发现了这个网页(<a href="https://blog.csdn.net/u010665691/article/details/44114119)解决了问题" target="_blank" rel="external">https://blog.csdn.net/u010665691/article/details/44114119)解决了问题</a>. 即在chrome的高级设置中将’Use hardware acceleration when available’前的勾去掉.</p>
<p>20181017更新 - IBM小红点TrackPoint休眠后左键失效问题</p>
<p>注: 其实下面的方法一个也不使, 真正解决问题的是这条命令: </p>
<p>gsettings set org.gnome.desktop.peripherals.touchpad click-method disabled</p>
<p>自从将Ubuntu从16.04升级到18.04之后, 在电脑休眠之后会发现小红点左键失效, 今天终于解决这个头疼的问题. 方法如下:</p>
<p><a href="https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1791427" target="_blank" rel="external">https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1791427</a><br><a href="https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1788928" target="_blank" rel="external">https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1788928</a></p>
<p>1, comment the line ‘blacklist i2c_i80’ from the file /etc/modprobe.d/blacklist.conf due to the lp bug #1786574</p>
<p>2, configure the management tool tlp not to autosuspend usb<br>$ grep -r ‘USB_AUTO’ /etc/default/tlp<br>USB_AUTOSUSPEND=0<br>USB_AUTOSUSPEND_DISABLE_ON_SHUTDOWN=1</p>
<p>3, upgrade libinput from the page <a href="https://launchpad.net/ubuntu/+source/libinput" target="_blank" rel="external">https://launchpad.net/ubuntu/+source/libinput</a><br>wget <a href="https://launchpad.net/ubuntu/+archive/primary/+files/libinput-bin_1.12.1-1_amd64.deb" target="_blank" rel="external">https://launchpad.net/ubuntu/+archive/primary/+files/libinput-bin_1.12.1-1_amd64.deb</a><br>wget <a href="https://launchpad.net/ubuntu/+archive/primary/+files/libinput10_1.12.1-1_amd64.deb" target="_blank" rel="external">https://launchpad.net/ubuntu/+archive/primary/+files/libinput10_1.12.1-1_amd64.deb</a><br>sudo dpkg -i libinput*</p>
<p>4, <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1560723" target="_blank" rel="external">https://bugzilla.redhat.com/show_bug.cgi?id=1560723</a></p>
<p>$ sudo chmod 755 /lib/systemd/system-sleep/trackpad<br>$ cat /lib/systemd/system-sleep/trackpad</p>
<p>#!/bin/sh<br>if [ “${1}” == “post” ]; then<br>  echo -n none &gt; /sys/devices/platform/i8042/serio1/drvctl<br>  sleep 1<br>  echo -n reconnect &gt; /sys/devices/platform/i8042/serio1/drvctl<br>fi</p>
<p>5, <a href="https://medium.com/@pck/ubuntu-18-04-fix-for-right-click-not-working-touchpad-issues-40037ff249e1" target="_blank" rel="external">https://medium.com/@pck/ubuntu-18-04-fix-for-right-click-not-working-touchpad-issues-40037ff249e1</a><br>sudo apt install gnome-tweak-tool<br>$ gsettings get org.gnome.desktop.peripherals.touchpad click-method<br>‘fingers’<br>gsettings set org.gnome.desktop.peripherals.touchpad click-method disabled<br>It equals run the command ‘gnome-tweaks’, navigate to the “Keyboard &amp; Mouse” sub-menu in the left menu, and select “Area” from the the touchpad’s “Click Emulation” menu in the right side panel.<br>Also configure Touchpad disable when typing - <a href="https://askubuntu.com/questions/1052665/touchpad-not-getting-disabled-while-typing-on-thinkpad-e450-with-ubuntu-18-04" target="_blank" rel="external">https://askubuntu.com/questions/1052665/touchpad-not-getting-disabled-while-typing-on-thinkpad-e450-with-ubuntu-18-04</a></p>
<p>20201107更新</p>
<p>chrome上网慢用fast.com测速在30K到18M之间不稳定，而用firefox总有69M，但重启机器后，chrome恢复到94M左右。</p>
<p>20210201更新</p>
<p>机器太慢，报：</p>
<p>Feb 1 09:36:48 t440p gnome-shell[3675]: libinput error: client bug: timer event25 debounce: scheduled expiry is in the past (-6ms), your system is too slow</p>
<p>perf data显示它和chrom有关，故设置：</p>
<p>chrome://settings/?search=hardware selects ‘Use hardware acceleration when available’<br>chrome://flags/#disable-accelerated-video-decode selects ‘Hardware-accelerated video decode’</p>
<p>但上面没解决问题，真正解决问题的是disable GPU</p>
<p><a href="https://blog.csdn.net/weixin_39726131/article/details/111653527" target="_blank" rel="external">https://blog.csdn.net/weixin_39726131/article/details/111653527</a></p>
<p>chrome://settings/?search=hardware uncheck ‘Use hardware acceleration when available’<br>chrome://flags/ search ‘gpu’ then disable ‘Accelerated 2D canvas’  and ‘GPU rasterization’</p>
<p>shift + esc to see chrome task</p>
<p>Chrome 浏览器默认开启了“GPU 渲染”的特性，当开启了硬件加速选项之后，所有的 WEB 网页内容都会使用显卡 GPU 来进行解析渲染, 当GPU性能不好时反而慢，不如直接使用CPU</p>
<p>20210202更新 - GPU问题总结<br>shift + esc打开看到GPU Process在开hangout时cpu超100%，另外风扇响个不停(cpu温度从70多升到80多），这都是gpu性能差但chrome又强制打开了gpu硬件加速造成的，关闭gpu加速即可。</p>
<p><a href="https://blog.csdn.net/weixin_39866974/article/details/111653530" target="_blank" rel="external">https://blog.csdn.net/weixin_39866974/article/details/111653530</a></p>
<p>1, 打开chrome://flags/ 搜索GPU，disable掉所有和GPU相关的设置</p>
<p>２，在/usr/share/applications/google-chrome.desktop中添加参数：–disable-gpu –disable-software-rasterizer</p>
<p>20210224改用回到旧版本83.0.4103.116-1</p>
<p>wget <a href="https://www.slimjet.com/chrome/download-chrome.php?file=files%2F83.0.4103.116%2Fgoogle-chrome-stable_current_amd64.deb" target="_blank" rel="external">https://www.slimjet.com/chrome/download-chrome.php?file=files%2F83.0.4103.116%2Fgoogle-chrome-stable_current_amd64.deb</a><br>apt-cache policy google-chrome-stable<br>chrome://flags/   #search ‘gpu’ then reset all setting<br>sudo rm -rf /etc/apt/sources.list.d/google-chrome.list*  #disable auto update</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">张华</p>
              <p class="site-description motion-element" itemprop="description">blog.csdn.net/quqi99</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">105</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张华</span>

  
</div>


  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
