<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>技术并艺术着</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="blog.csdn.net/quqi99">
<meta property="og:type" content="website">
<meta property="og:title" content="技术并艺术着">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="blog.csdn.net/quqi99">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="技术并艺术着">
<meta name="twitter:description" content="blog.csdn.net/quqi99">
  
    <link rel="alternate" href="/atom.xml" title="技术并艺术着" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">技术并艺术着</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">张华的技术博客 - blog.csdn.net/quqi99</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Set-ip-IPv6-env" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/18/Set-ip-IPv6-env/" class="article-date">
  <time datetime="2019-01-18T05:44:20.000Z" itemprop="datePublished">2019-01-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/18/Set-ip-IPv6-env/">Set ip IPv6 env</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="基础-ND协议的三个位"><a href="#基础-ND协议的三个位" class="headerlink" title="基础 - ND协议的三个位"></a>基础 - ND协议的三个位</h2><p>ND协议包中有三个位(Auto, Managed, Other)：</p>
<ul>
<li>M bit (Managed Address Configuration), M bit如果是1,表示Clients要另外再去跟DHCPv6要IPv6 Prefix</li>
<li>O bit (Other Configuration), O bit如果是1,表示Clients要去跟DHCPv6要DNS(RDNSS)等其他信息<br>这样：</li>
<li>slaas, Stateless autoconfiguration, A=1, M=0, O=0, 主机將只得到Router給的 Prefix, 无法取得DNS等资讯, 其他必须自己填写.</li>
<li>dhcpv6-stateful, A=0, M=1, O=1, 所有信息（IPv6 prefix, DNS等)都通过DHCPv6获得,客戶端主要使用UDP port 546, 而服務器端使用 UDP port 547</li>
<li>dhcpv6-stateless,A=1, M=0, O=1, 除了使用RA裡面的Prefix,其他如DNS等等信息会由DHCPv6 取得.<h2 id="基础-Neutron-IPv6"><a href="#基础-Neutron-IPv6" class="headerlink" title="基础 - Neutron IPv6"></a>基础 - Neutron IPv6</h2>Neutron中有两个重要属性来支持IPv6 (ipv6_address_mode 与 ipv6_ra_mode):</li>
<li>ipv6_ra_mode, 如果设置表示由Neutron来使用radvd来模拟软件IPv6路由器, 如果不设置表示使用外部IPv6路由器</li>
<li>ipv6_address_mode, 对应上述ND协议中的三个位(Auto, Managed, Other), 例如: 对于dhcpv6-stateless, 3比特应该是: A=1, M=0, O=1.</li>
</ul>
<p>下面是创建一个使用外部IPv6路由器并使用dhcpv6-stateless的例子:<br>neutron net-create –provider:network_type flat –provider:physical_network physnet1 –router:external=True ext_net<br>neutron subnet-create ext_net –name external-subnet-v6 –ip_version 6 –ipv6_address_mode dhcpv6-stateless –allocation-pool start=2001:db8:0:1::2,end=2001:db8:0:1:ffff:ffff:ffff:ffff 2001:db8:0:1::/64</p>
<h2 id="基础-Ubuntu中手工配置IPv6的注意点"><a href="#基础-Ubuntu中手工配置IPv6的注意点" class="headerlink" title="基础 - Ubuntu中手工配置IPv6的注意点"></a>基础 - Ubuntu中手工配置IPv6的注意点</h2><p>Ubuntu中配置IPv6可以采用network-manager, 也可采用在/etc/network/interface中手工配置, 也可以使用最新的netplan. 这里描述的是采用手工配置的方法.<br>先看一个遇到的实际问题:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">下面配置不work</span><br><span class="line">iface eth0 inet6 auto</span><br><span class="line">   # use SLAAC to get global IPv6 address from the router</span><br><span class="line">   # we may not enable ipv6 forwarding, otherwise SLAAC gets disabled</span><br><span class="line">   up sleep 5</span><br><span class="line">   dhcp 1</span><br><span class="line">   autoconf 1</span><br><span class="line">   accept_ra 2</span><br><span class="line"></span><br><span class="line">下列配置work</span><br><span class="line">iface eth0 inet6 static</span><br><span class="line">address 2001:192:168:99::135</span><br><span class="line">   gateway 2001:192:168:99::1</span><br><span class="line">   netmask 64</span><br><span class="line">且改成network-manager也work, 这是为什么呢?</span><br><span class="line"></span><br><span class="line">测试方法是:</span><br><span class="line">#it will flush link-local address as well</span><br><span class="line">#ip addr flush br-eth0</span><br><span class="line"># avoid the error: can&apos;t get a link-local address</span><br><span class="line">sudo ip link set dev eth0 down</span><br><span class="line">sudo ip link set dev eth0 up</span><br><span class="line">ifdown br-eth0</span><br><span class="line">ifup --force --verbose br-eth0</span><br></pre></td></tr></table></figure></p>
<p>采用”ifup –force –verbose br-eth0”命令看到的错误是”can’t get a link-local address”.<br>为什么static模式与network-manager模式没有这个错误呢? 原来是这两者默认执行了:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br></pre></td></tr></table></figure></p>
<p>并且之前Linux网桥br-eth0上一直没有IPv6地址的原因也是这个, 且上面”sudo ip link set dev eth0 up”这句也会自动设置disable_ipv6=0, 但不会对br-eth0作同样的设置.<br>所以添加”up echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6”后问题解决, 完整配置如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">root@node1:~# cat /etc/network/interfaces</span><br><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line">auto eth0</span><br><span class="line">iface eth0 inet manual</span><br><span class="line">auto br-eth0</span><br><span class="line">iface br-eth0 inet static</span><br><span class="line">    address 192.168.99.124/24</span><br><span class="line">    gateway 192.168.99.1</span><br><span class="line">    bridge_ports eth0</span><br><span class="line">    dns-nameservers 192.168.99.1</span><br><span class="line">    bridge_stp on</span><br><span class="line">    bridge_fd 0</span><br><span class="line">    bridge_maxwait 0</span><br><span class="line">    up echo -n 0 &gt; /sys/devices/virtual/net/$IFACE/bridge/multicast_snooping</span><br><span class="line"># for stateless it&apos;s &apos;inet6 auto&apos;, for stateful it&apos;s &apos;inet6 dhcp&apos;</span><br><span class="line">iface br-eth0 inet6 auto</span><br><span class="line">    #iface eth0 inet6 static</span><br><span class="line">    #address 2001:192:168:99::135</span><br><span class="line">    #gateway 2001:192:168:99::1</span><br><span class="line">    #netmask 64</span><br><span class="line">    # use SLAAC to get global IPv6 address from the router</span><br><span class="line">    # we may not enable ipv6 forwarding, otherwise SLAAC gets disabled</span><br><span class="line">    # sleep 5 is due a bug and &apos;dhcp 1&apos; indicates that info should be obtained from dhcpv6 server for stateless</span><br><span class="line">    up echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br><span class="line">    up sleep 5</span><br><span class="line">    autoconf 1</span><br><span class="line">    accept_ra 2</span><br><span class="line">    dhcp 1</span><br></pre></td></tr></table></figure></p>
<p>此外, 最好设置accept_ra=2, 因为经常会遇到自动配置的IPv6地址丢失或者不能获取的问题。一般情况是都是启用了IPv6转发功能(sudo sysctl -w net.ipv6.conf.all.forwarding=1)引起的。<br>为了配置IPv6 address和default gateway, client/host都会默认去listen或者solicit RA广播, 并且host作为router时会忽略RA, 这由accept_ra设置:</p>
<ul>
<li>0 Do not accept RouterAdvertisements.</li>
<li>1 Accept Router Advertisements if forwarding is disabled.</li>
<li>2 Overrule forwarding behavior. Accept Router Advertisements  even if forwarding is enabled.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv6.conf.all.forwarding=1</span><br><span class="line">sudo sysctl -w net.ipv6.conf.all.accept_ra=2</span><br><span class="line">sudo sysctl -w net.ipv6.conf.br-lan.disable_ipv6=0</span><br><span class="line">#echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="IPv6中的防火墙"><a href="#IPv6中的防火墙" class="headerlink" title="IPv6中的防火墙"></a>IPv6中的防火墙</h2><p>IPv6 Router端:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># Clear all ip6tables rules</span><br><span class="line">ip6tables -t nat -X</span><br><span class="line">ip6tables -t nat -P PREROUTING ACCEPT</span><br><span class="line">ip6tables -t nat -P POSTROUTING ACCEPT</span><br><span class="line">ip6tables -t nat -P OUTPUT ACCEPT</span><br><span class="line">ip6tables -t mangle -F</span><br><span class="line">ip6tables -t mangle -X</span><br><span class="line">ip6tables -t mangle -P PREROUTING ACCEPT</span><br><span class="line">ip6tables -t mangle -P INPUT ACCEPT</span><br><span class="line">ip6tables -t mangle -P FORWARD ACCEPT</span><br><span class="line">ip6tables -t mangle -P OUTPUT ACCEPT</span><br><span class="line">ip6tables -t mangle -P POSTROUTING ACCEPT</span><br><span class="line">ip6tables -F</span><br><span class="line">ip6tables -X</span><br><span class="line">ip6tables -P FORWARD ACCEPT</span><br><span class="line">ip6tables -P INPUT ACCEPT</span><br><span class="line">ip6tables -P OUTPUT ACCEPT</span><br><span class="line">ip6tables -t raw -F</span><br><span class="line">ip6tables -t raw -X</span><br><span class="line">ip6tables -t raw -P PREROUTING ACCEPT</span><br><span class="line">ip6tables -t raw -P OUTPUT ACCEPT</span><br><span class="line"></span><br><span class="line"># Default DROP rules</span><br><span class="line">ip6tables -P INPUT   DROP</span><br><span class="line">ip6tables -P OUTPUT  ACCEPT</span><br><span class="line">ip6tables -P FORWARD DROP</span><br><span class="line"></span><br><span class="line"># Allow established connections</span><br><span class="line">ip6tables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br><span class="line">ip6tables -A FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br><span class="line"></span><br><span class="line"># For IPv6</span><br><span class="line"># it&apos;s not required due to ipv6-icmp</span><br><span class="line"># sudo ip6tables -A INPUT -p udp --dport 547 -j ACCEPT</span><br><span class="line">#ip6tables -A INPUT -p icmpv6 --icmpv6-type echo-request -j ACCEPT</span><br><span class="line">ip6tables -A INPUT -p ipv6-icmp -j ACCEPT</span><br><span class="line">ip6tables -A FORWARD -p ipv6-icmp -j ACCEPT</span><br><span class="line"></span><br><span class="line"># Ajust MTU</span><br><span class="line">ip6tables -t mangle -A POSTROUTING -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br></pre></td></tr></table></figure></p>
<p>IPv6 Client端:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ip6tables -t filter -A INPUT -p udp -m udp --sport 547 --dport 546 -j ACCEPT</span><br><span class="line">ip6tables -t filter -A INPUT -p ipv6-icmp -j ACCEPT</span><br><span class="line"></span><br><span class="line"># or security group</span><br><span class="line">https://bugs.launchpad.net/neutron/+bug/1335984</span><br><span class="line">openstack security group rule create $secgroup --protocol udp --dst-port 546 --ethertype IPv6</span><br><span class="line">openstack security group rule create $secgroup --protocol icmpv6 --ethertype IPv6</span><br><span class="line"></span><br><span class="line"># Flow based firewall</span><br><span class="line">hard_timeout=0,idle_timeout=0,priority=4,udp,tp_dst=546/0xffff,table=32,tp_src=547/0xffff,nw_src=fe80::f816:3eff:fea3:ec40,actions=learn(table=33,priority=5,hard_timeout=120,eth_type=0x800,nw_proto=17,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],NXM_OF_IP_SRC[]=NXM_OF_IP_DST[],NXM_OF_UDP_SRC[]=NXM_OF_UDP_DST[], NXM_OF_UDP_DST[]=NXM_OF_UDP_SRC[],output:NXM_OF_IN_PORT[]),normal</span><br></pre></td></tr></table></figure></p>
<p>另外, 别忘了禁用掉ufw或者SELinux之类的.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ufw disable</span><br></pre></td></tr></table></figure></p>
<h2 id="Statefull-DHCPv6"><a href="#Statefull-DHCPv6" class="headerlink" title="Statefull DHCPv6"></a>Statefull DHCPv6</h2><p>采用isc-dhcp-server搭建DHCPv6 Server:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">https://jochen.kirstaetter.name/dhcpv6-ipv6-in-your-local-network/</span><br><span class="line">hua@t440p:~$ ip addr show eth0 |grep inet6 |grep global</span><br><span class="line">    inet6 2001:192:168:99::430/128 scope global</span><br><span class="line">echo &apos;Acquire::ForceIPv4 &quot;true&quot;;&apos; | sudo tee /etc/apt/apt.conf.d/99force-ipv4</span><br><span class="line">sudo apt install isc-dhcp-server</span><br><span class="line">grep -v ^# /etc/dhcp/dhcpd6.conf</span><br><span class="line">sudo cp /etc/dhcp/dhcpd6.conf /etc/dhcp/dhcpd6.conf_bak</span><br><span class="line">sudo bash -c &apos;cat &gt;/etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">authoritative;</span><br><span class="line">default-lease-time 14400;</span><br><span class="line">max-lease-time 86400;</span><br><span class="line">log-facility local7;</span><br><span class="line">subnet6 2001:192:168:99::/64 &#123;</span><br><span class="line">    option dhcp6.name-servers 2001:4860:4860::8888, 2001:4860:4860::8844;</span><br><span class="line">    option dhcp6.domain-search &quot;quqi.com&quot;;</span><br><span class="line">    range6 2001:192:168:99::100 2001:192:168:99::199;</span><br><span class="line">    range6 2001:192:168:99::/64 temporary;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo touch /var/lib/dhcp/dhcpd6.leases</span><br><span class="line">sudo /usr/sbin/dhcpd -6 -d -cf /etc/dhcp/dhcpd6.conf eth0</span><br><span class="line">sudo chown dhcpd:dhcpd /var/lib/dhcp/dhcpd6.leases</span><br><span class="line">sudo service isc-dhcp-server6 restart</span><br></pre></td></tr></table></figure></p>
<p>然后记得照上节说的设置DHCPv6 Server与Client上的防火墙规则. 接着在另一台机器上作client测试:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># need to use &apos;inet6 dhcp&apos; in client side for statefull DHCPv6</span><br><span class="line">iface br-eth0 inet6 dhcp</span><br><span class="line">    #iface eth0 inet6 static</span><br><span class="line">    #address 2001:192:168:99::135</span><br><span class="line">    #gateway 2001:192:168:99::1</span><br><span class="line">    #netmask 64</span><br><span class="line">    # use SLAAC to get global IPv6 address from the router</span><br><span class="line">    # we may not enable ipv6 forwarding, otherwise SLAAC gets disabled</span><br><span class="line">    # sleep 5 is due a bug and &apos;dhcp 1&apos; indicates that info should be obtained from dhcpv6 server for stateless</span><br><span class="line">    up echo 0 &gt; /proc/sys/net/ipv6/conf/$IFACE/disable_ipv6</span><br><span class="line">    up sleep 5</span><br><span class="line">    autoconf 1</span><br><span class="line">    accept_ra 2</span><br><span class="line">    dhcp 1</span><br><span class="line"></span><br><span class="line"># test command</span><br><span class="line">dhclient -6 -d br-eth0</span><br><span class="line"></span><br><span class="line"># verity</span><br><span class="line">hua@node1:~$ sudo tcpdump -ni eth0 ip6 host fe80::d5a3:10a3:6161:5b2e</span><br><span class="line">12:44:00.868609 IP6 fe80::d5a3:10a3:6161:5b2e.547 &gt; fe80::fa32:e4ff:febe:87cd.546: dhcp6 advertise</span><br><span class="line">12:44:01.946548 IP6 fe80::d5a3:10a3:6161:5b2e.547 &gt; fe80::fa32:e4ff:febe:87cd.546: dhcp6 reply</span><br><span class="line">root@node1:~# cat /etc/resolv.conf</span><br><span class="line"># Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)</span><br><span class="line">#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN</span><br><span class="line">nameserver 192.168.99.1</span><br><span class="line">#nameserver 211.136.17.107</span><br><span class="line">#nameserver 114.114.114.114</span><br><span class="line">#nameserver 223.5.5.5</span><br><span class="line">nameserver 2001:4860:4860::8888</span><br><span class="line">nameserver 2001:4860:4860::8844</span><br><span class="line">nameserver 2001:db8::1:6a1:51ff:fe8a:2ca7</span><br><span class="line">search quqi.com lan</span><br></pre></td></tr></table></figure>
<p>另外, 使用BIND9的例子可参见 - <a href="https://jochen.kirstaetter.name/enabling-dns-for-ipv6-infrastructure/" target="_blank" rel="external">https://jochen.kirstaetter.name/enabling-dns-for-ipv6-infrastructure/</a></p>
<h2 id="SLAAC-Stateless-Address-Auto-Configuration"><a href="#SLAAC-Stateless-Address-Auto-Configuration" class="headerlink" title="SLAAC (Stateless Address Auto Configuration)"></a>SLAAC (Stateless Address Auto Configuration)</h2><p>radvd来提供RA部分, SLAAC只有RA部分. RA只能设置IPv6 prefix与DNS (RDNSS).<br>Historically the software package radvd was commonly used for just the RA-part of this. But dnsmasq offers a more complete setup.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv6.conf.all.forwarding=1</span><br><span class="line">sudo ip addr add 2001:db8:0:1::1/64 dev eth0</span><br><span class="line">sudo apt-get install radvd</span><br><span class="line">$ cat /etc/radvd.conf</span><br><span class="line">    interface eth0</span><br><span class="line">    &#123;</span><br><span class="line">       AdvSendAdvert on;</span><br><span class="line">       prefix 2001:db8:0:1::/64</span><br><span class="line">       &#123;</span><br><span class="line">            AdvOnLink on;</span><br><span class="line">            AdvAutonomous on;</span><br><span class="line">       &#125;;</span><br><span class="line">       #Send DNS Server setting</span><br><span class="line">       #RDNSS fd5d:12c9:2201:1::2&#123;</span><br><span class="line">    &#125;;</span><br><span class="line">sudo /etc/init.d/radvd restart</span><br><span class="line">sudo ip6tables -F</span><br><span class="line"></span><br><span class="line">neutron subnet-create --ip-version=6 --name=ext-v6-subnet --gateway 2001:db8:0:1::1 --allocation-pool start=2001:db8:0:1::5,end=2001:db8:0:1:ffff:ffff:ffff:fffe --disable-dhcp ext_net 2001:db8:0:1::/64</span><br><span class="line">neutron net-create private</span><br><span class="line">neutron subnet-create --ip-version=6 --name=private_v6_subnet --ipv6-address-mode=slaac --ipv6-ra-mode=slaac private 2001:db8:0:2::/64</span><br><span class="line">neutron router-interface-add provider-router private_v6_subnet</span><br></pre></td></tr></table></figure></p>
<h2 id="SLAAS-with-Stateless-DHCPv6"><a href="#SLAAS-with-Stateless-DHCPv6" class="headerlink" title="SLAAS with Stateless DHCPv6"></a>SLAAS with Stateless DHCPv6</h2><p>Stateless意味着:</p>
<ul>
<li>radvd提供RA (AdvManagedFlag=off)</li>
<li>client使用radvd RA提供的IPv6 prefix配置IPv6 address</li>
<li>client的其他信息如DNS等从DHCPv6获得<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">sudo bash -c &apos;cat &gt; /etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">interface eth0</span><br><span class="line">&#123;</span><br><span class="line">    AdvSendAdvert on;</span><br><span class="line">    MinRtrAdvInterval 30;</span><br><span class="line">    MaxRtrAdvInterval 100;</span><br><span class="line">    AdvManagedFlag off;</span><br><span class="line">    AdvOtherConfigFlag on;</span><br><span class="line">    prefix 2001:192:168:99::/64</span><br><span class="line">    &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">        AdvRouterAddr off;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; /etc/radvd.conf&apos; &lt;&lt;EOF</span><br><span class="line">default-lease-time 600;</span><br><span class="line">max-lease-time 7200;</span><br><span class="line">log-facility local7;</span><br><span class="line">option dhcp6.name-servers 2001:4860:4860::8888;</span><br><span class="line">option dhcp6.domain-search &quot;&quot;;</span><br><span class="line">subnet6 2001:192:168:99::/64 &#123;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="SLAAS-with-Statefull-DHCPv6"><a href="#SLAAS-with-Statefull-DHCPv6" class="headerlink" title="SLAAS with Statefull DHCPv6"></a>SLAAS with Statefull DHCPv6</h2><p>Statefull意味着:</p>
<ul>
<li>radvd不提供RA (AdvManagedFlag=on)</li>
<li>client使用DHCPv6去配置IPv6 address</li>
<li>client的其他信息如DNS等也从DHCPv6获得<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">sudo bash -c &apos;cat &gt; /etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">interface eth0</span><br><span class="line">&#123;</span><br><span class="line">    AdvSendAdvert on;</span><br><span class="line">    MinRtrAdvInterval 30;</span><br><span class="line">    MaxRtrAdvInterval 100;</span><br><span class="line">    AdvManagedFlag on;</span><br><span class="line">    AdvOtherConfigFlag on;</span><br><span class="line">    prefix 2001:192:168:99::/64</span><br><span class="line">    &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">        AdvRouterAddr off;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt;/etc/dhcp/dhcpd6.conf&apos; &lt;&lt;EOF</span><br><span class="line">authoritative;</span><br><span class="line">default-lease-time 14400;</span><br><span class="line">max-lease-time 86400;</span><br><span class="line">log-facility local7;</span><br><span class="line">subnet6 2001:192:168:99::/64 &#123;</span><br><span class="line">    option dhcp6.name-servers 2001:4860:4860::8888, 2001:4860:4860::8844;</span><br><span class="line">    option dhcp6.domain-search &quot;quqi.com&quot;;</span><br><span class="line">    range6 2001:192:168:99::100 2001:192:168:99::199;</span><br><span class="line">    range6 2001:192:168:99::/64 temporary;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="实际问题"><a href="#实际问题" class="headerlink" title="实际问题"></a>实际问题</h2><p>例如, 使用OpenStack根据外部IPv6 stateless router定义的IPv6网络, 虚机分配了IP, 但是网卡上去没配置, 一般地, 理论上问题出在:<br>1, 既然有外部路由器, Openstack CLI中不应该定义ipv6_ra_mode, 不指定ipv6_ra_mode, neutron就不会创建radvd, 那样就会直接使用外部的IPv6路由器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">neutron net-create IPv6 (vlan1809) --shared --provider:physical_network physnet2 --provider:network_type vlan --provider:segmentation_id 1809 --router:external True</span><br><span class="line">neutron subnet-create ipv6-pd --name external-subnet-v6 --ip_version 6 --ipv6_address_mode dhcp-stateless --allocation-pool start=2001:1284:ff:18::2,end=2001:1284:ff:18:ffff:ffff:ffff:ffff --dns-nameserver 2001:1284:ff02::243 2001:1284:ff:18::/64</span><br></pre></td></tr></table></figure></p>
<p>2, 外部IPv6路由器的防火墙规则打开了没:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo ip6tables -A INPUT -p icmpv6 -j ACCEPT</span><br><span class="line">sudo ip6tables -A OUTPUT -p icmpv6 -j ACCEPT</span><br><span class="line">sudo ip6tables -A FORWARD -p icmpv6 -j ACCEPT</span><br><span class="line">sudo ufw allow proto udp from fe80::/64 to any port 547</span><br><span class="line">sudo ufw disable</span><br></pre></td></tr></table></figure></p>
<p>3, 虚机这边虚机定义security group rule将其所有的计算节点上的防火墙规则打开:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">https://bugs.launchpad.net/neutron/+bug/1335984</span><br><span class="line"></span><br><span class="line">openstack security group rule create $secgroup --protocol udp --dst-port 546 --ethertype IPv6</span><br><span class="line">openstack security group rule create $secgroup --protocol icmpv6 --ethertype IPv6</span><br><span class="line"></span><br><span class="line">For iptables driver, above equals:</span><br><span class="line">ip6tables -t filter -A INPUT -p udp -m udp --sport 547 --dport 546 -j ACCEPT</span><br><span class="line">ip6tables -t filter -A INPUT -p ipv6-icmp -j ACCEPT</span><br><span class="line"></span><br><span class="line">For ovs flow based driver, above equals:</span><br><span class="line">hard_timeout=0,idle_timeout=0,priority=4,udp,tp_dst=546/0xffff,table=32,tp_src=547/0xffff,nw_src=fe80::f816:3eff:fea3:ec40,actions=learn(table=33,priority=5,hard_timeout=120,eth_type=0x800,nw_proto=17,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],NXM_OF_IP_SRC[]=NXM_OF_IP_DST[],NXM_OF_UDP_SRC[]=NXM_OF_UDP_DST[], NXM_OF_UDP_DST[]=NXM_OF_UDP_SRC[],output:NXM_OF_IN_PORT[]),normal</span><br></pre></td></tr></table></figure></p>
<p>3, 外部路由器因为启用了forwarding应该设置accept_ra=2而不是accept_ra=1:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv6.conf.all.accept_ra=2</span><br></pre></td></tr></table></figure></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="http://asdkda.github.io/2016/02/05/ipv6/" target="_blank" rel="external">http://asdkda.github.io/2016/02/05/ipv6/</a><br>[2] <a href="http://tldp.org/HOWTO/html_single/Linux+IPv6-HOWTO/#idp57787920" target="_blank" rel="external">http://tldp.org/HOWTO/html_single/Linux+IPv6-HOWTO/#idp57787920</a><br>[3] <a href="https://jochen.kirstaetter.name/dhcpv6-ipv6-in-your-local-network/" target="_blank" rel="external">https://jochen.kirstaetter.name/dhcpv6-ipv6-in-your-local-network/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/18/Set-ip-IPv6-env/" data-id="cjr2rybt6000baxbpzznzbw4p" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Using-kubeadm-to-deploy-k8s" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/02/Using-kubeadm-to-deploy-k8s/" class="article-date">
  <time datetime="2019-01-02T03:08:22.000Z" itemprop="datePublished">2019-01-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/02/Using-kubeadm-to-deploy-k8s/">Using kubeadm to deploy k8s</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-07-13)</strong></p>
<h2 id="Bootstrapping-master-with-kubeadm"><a href="#Bootstrapping-master-with-kubeadm" class="headerlink" title="Bootstrapping master with kubeadm"></a>Bootstrapping master with kubeadm</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">https://kubernetes.io/docs/setup/independent/install-kubeadm/</span><br><span class="line">Create a VM (ubuntu 18.04) joshuazhang1c.mylabserver.com in linuxacademy.com, then run:</span><br><span class="line"></span><br><span class="line"># Reset env</span><br><span class="line">kubectl drain joshuazhang1c.mylabserver.com --delete-local-data --force --ignore-daemonsets</span><br><span class="line">kubectl get node</span><br><span class="line">kubectl delete node joshuazhang1c.mylabserver.com</span><br><span class="line">sudo kubeadm reset</span><br><span class="line"></span><br><span class="line"># Installing kubeadm, kubelet, kubectl, docker</span><br><span class="line">sudo apt update &amp;&amp; sudo apt install -y apt-transport-https curl</span><br><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</span><br><span class="line">sudo bash -c &apos;cat &gt;/etc/apt/sources.list.d/kubernetes.list&apos; &lt;&lt;EOF</span><br><span class="line">deb https://apt.kubernetes.io/ kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y kubelet kubeadm kubectl</span><br><span class="line">sudo apt-mark hold kubelet kubeadm kubectl</span><br><span class="line">cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br><span class="line">sudo apt install -y docker.io</span><br><span class="line">sudo systemctl enable docker.service</span><br><span class="line"></span><br><span class="line"># Creating a single master cluster with kubeadm</span><br><span class="line"># For flannle to work correctly, you must pass --pod-network-cidr=10.244.0.0/16</span><br><span class="line">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</span><br><span class="line">sudo kubeadm init --pod-network-cidr=10.244.0.0/16</span><br><span class="line">kubectl describe ds kube-flannel-ds-amd64 --namespace kube-system</span><br><span class="line">cat /etc/cni/net.d/10-flannel.conflist</span><br><span class="line"></span><br><span class="line"># the following commands come from the output of &apos;kubeadm init&apos;</span><br><span class="line"># export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">rm -rf ~/.kube/config &amp;&amp; sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line">kubectl cluster-info</span><br><span class="line"></span><br><span class="line"># configure kubectl completion</span><br><span class="line">kubectl completion bash | sudo tee /etc/bash_completion.d/k8s</span><br><span class="line"></span><br><span class="line"># Installing a pod network add-on</span><br><span class="line">sudo bash -c &apos;cat &gt;&gt; /etc/sysctl.conf&apos; &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">EOF</span><br><span class="line">sysctl -p</span><br><span class="line">sysctl net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml</span><br><span class="line">kubectl get daemonsets --all-namespaces</span><br><span class="line">kubectl get nodes --all-namespaces -o wide</span><br><span class="line"></span><br><span class="line"># Joining your nodes with kubeadm way, we will aslo try tls bootstrap way below</span><br><span class="line">ssh cloud_user@joshuazhang3c.mylabserver.com -v</span><br><span class="line">sudo -i</span><br><span class="line">apt install -y docker.io</span><br><span class="line">systemctl enable docker.service</span><br><span class="line">apt update &amp;&amp; apt install -y apt-transport-https curl</span><br><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">deb https://apt.kubernetes.io/ kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">apt update</span><br><span class="line">apt install -y kubeadm</span><br><span class="line"></span><br><span class="line"># kubeadm token list</span><br><span class="line"># openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &apos;s/^.* //&apos;</span><br><span class="line"># kubectl get secrets --namespace=kube-system bootstrap-token-9k9xoo -o jsonpath=&apos;&#123;.data.token-id&#125;&apos; |base64 -d</span><br><span class="line"># kubectl get secrets --namespace=kube-system bootstrap-token-9k9xoo -o jsonpath=&apos;&#123;.data.token-secret&#125;&apos; |base64 -d</span><br><span class="line">kubeadm join 172.31.19.84:6443 --token 0c4fdy.xptpmgh4eqihxh66 --discovery-token-ca-cert-hash sha256:b227cfd35c9d1ad42d8692576c0a453271741f59e5052c98674bc075b0789a17</span><br></pre></td></tr></table></figure>
<h2 id="Bootstrapping-workerwith-tls-bootstrapping"><a href="#Bootstrapping-workerwith-tls-bootstrapping" class="headerlink" title="Bootstrapping workerwith tls bootstrapping"></a>Bootstrapping workerwith tls bootstrapping</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line">https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/</span><br><span class="line">Just need to copy two files(/var/lib/kubelet/config.yaml and ca.crt) to new worker node, then use bootstrap token (temporary auth) and ca.crt to generate kubeconfig, finally restart kubelet with &apos;kubelet --bootstrap-kubeconfig=&quot;/etc/kubelet/bootstrap-kubelet.conf&quot; --kubeconfig=&quot;/etc/kubelet/kubeconfig.conf&quot; --config=&quot;/var/lib/kubelet/config.yaml&quot;&apos;, then master will create the certificate(for non-temporary auth) for worker and auto approve them.</span><br><span class="line"></span><br><span class="line">a, Principle behind. kubeadm has created bootstrap token with the auth-extra-groups &apos;system:bootstrappers:kubeadm:default-node-token&apos; for us. You can change the group name &apos;system:bootstrappers:kubeadm:default-node-token&apos; to another, eg: system:bootstrappers:myworkers</span><br><span class="line"></span><br><span class="line">$ kubectl get --namespace=kube-system secrets bootstrap-token-9k9xoo -o jsonpath=&apos;&#123;.data.auth-extra-groups&#125;&apos; |base64 -d</span><br><span class="line">system:bootstrappers:kubeadm:default-node-token</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; bootstrap-token.yaml&apos; &lt;&lt;EOF</span><br><span class="line"># https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  # Name MUST be of form &quot;bootstrap-token-&lt;token id&gt;&quot;</span><br><span class="line">  name: bootstrap-token-07401b</span><br><span class="line">  namespace: kube-system</span><br><span class="line"># Type MUST be &apos;bootstrap.kubernetes.io/token&apos;</span><br><span class="line">type: bootstrap.kubernetes.io/token</span><br><span class="line">stringData:</span><br><span class="line">  # Human readable description. Optional.</span><br><span class="line">  description: &quot;The default bootstrap token generated by &apos;kubeadm init&apos;.&quot;</span><br><span class="line">  # Token ID and secret. Required.</span><br><span class="line">  token-id: 07401b</span><br><span class="line">  token-secret: f395accd246ae52d</span><br><span class="line">  # Expiration. Optional.</span><br><span class="line">  expiration: 2019-03-10T03:22:11Z</span><br><span class="line">  # Allowed usages.</span><br><span class="line">  usage-bootstrap-authentication: &quot;true&quot;</span><br><span class="line">  usage-bootstrap-signing: &quot;true&quot;</span><br><span class="line">  # Extra groups to authenticate the token as. Must start with &quot;system:bootstrappers:&quot;</span><br><span class="line">  auth-extra-groups: system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f bootstrap-token.yaml</span><br><span class="line">kubectl describe secrets --namespace=kube-system bootstrap-token-07401b</span><br><span class="line">kubectl get secrets --namespace=kube-system bootstrap-token-07401b -o jsonpath=&#123;.data.token-id&#125; |base64 -d</span><br><span class="line">kubectl get secrets --namespace=kube-system bootstrap-token-07401b -o jsonpath=&#123;.data.token-secret&#125; |base64 -d</span><br><span class="line"></span><br><span class="line">So the following &apos;kubeadm token create&apos; will create a new token with the auth-extra-groups &apos;system:bootstrappers:kubeadm:default-node-token&apos;.</span><br><span class="line">$ kubeadm token create</span><br><span class="line">iate9c.v9qhw2dyngxfcsig</span><br><span class="line">TOKEN_ID=$(kubectl get secrets --namespace=kube-system bootstrap-token-iate9c -o jsonpath=&apos;&#123;.data.token-id&#125;&apos; |base64 -d)</span><br><span class="line">TOKEN_SECRET=$(kubectl get secrets --namespace=kube-system bootstrap-token-iate9c -o jsonpath=&apos;&#123;.data.token-secret&#125;&apos; |base64 -d)</span><br><span class="line"></span><br><span class="line">b, Principle behind. kubeadm has also create the following 3 clusterrolebindings to map the group &apos;system:bootstrappers:kubeadm:default-node-token&apos; for us. If you are using the new group &apos;system:bootstrappers:myworkers&apos;, here you need to change to &apos;system:bootstrappers:myworkers&apos; or &apos;system:bootstrappers&apos;.</span><br><span class="line"></span><br><span class="line">#Authorize kubelet to create CSR by mapping the clusterrole &apos;system:node-bootstrapper&apos; to the group &apos;system:bootstrappers&apos; or &apos;system:bootstrappers:joshuazhang2c.mylabserver.com&apos;</span><br><span class="line">kubectl create clusterrolebinding create-csrs-for-bootstrapping --group=system:bootstrappers:kubeadm:default-node-token --clusterrole=system:node-bootstrapper</span><br><span class="line"></span><br><span class="line">#Auto approve all CSRs by mapping the clusterrole &apos;selfnodeclient&apos; to the group &quot;system:bootstrappers&quot; or &apos;system:bootstrappers:joshuazhang2c.mylabserver.com&apos;</span><br><span class="line">kubectl create clusterrolebinding auto-approve-csrs-for-group --group=system:bootstrappers:kubeadm:default-node-token --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line"></span><br><span class="line">#Auto approve renewal CSRs by mapping the clusterrole &apos;selfnodeclient&apos; to the group &quot;system:nodes&quot;</span><br><span class="line">kubectl create clusterrolebinding auto-approve-renewals-csrs-for-group --group=system:nodes --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line"></span><br><span class="line">So we can use the following CertificateSigningRequest to self-test it.</span><br><span class="line"></span><br><span class="line">openssl genrsa -out joshuazhang2c.mylabserver.com.key</span><br><span class="line">openssl req -new -key joshuazhang2c.mylabserver.com.key -out joshuazhang2c.mylabserver.com.csr -subj &quot;/CN=system:node:joshuazhang2c.mylabserver.com/O=system:nodes&quot;</span><br><span class="line">openssl x509 -req -in joshuazhang2c.mylabserver.com.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out joshuazhang4c.mylabserver.com.crt -days 45</span><br><span class="line">cat &lt;&lt;EOF | kubectl apply -f -</span><br><span class="line">apiVersion: certificates.k8s.io/v1beta1</span><br><span class="line">kind: CertificateSigningRequest</span><br><span class="line">metadata:</span><br><span class="line">  name: system:node:joshuazhang2c.mylabserver.com</span><br><span class="line">spec:</span><br><span class="line">  groups:</span><br><span class="line">    - system:nodes</span><br><span class="line">  request: $(cat joshuazhang2c.mylabserver.com.csr | base64 | tr -d &apos;\n&apos;)</span><br><span class="line">  usages:</span><br><span class="line">    - key encipherment</span><br><span class="line">    - digital signature</span><br><span class="line">    - client auth</span><br><span class="line">EOF</span><br><span class="line">kubectl get csr</span><br><span class="line"></span><br><span class="line">c, Generate kubeconfig with bootstrap token and ca</span><br><span class="line">ENDPOINT=$(kubectl describe service kubernetes |grep -i endpoints |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">CLUSTER=$(kubectl config view |grep &apos;  cluster:&apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">TOKEN_ID=$(kubectl get secrets --namespace=kube-system bootstrap-token-iate9c -o jsonpath=&apos;&#123;.data.token-id&#125;&apos; |base64 -d)</span><br><span class="line">TOKEN_SECRET=$(kubectl get secrets --namespace=kube-system bootstrap-token-iate9c -o jsonpath=&apos;&#123;.data.token-secret&#125;&apos; |base64 -d)</span><br><span class="line">sudo kubectl config --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf set-cluster $&#123;CLUSTER&#125; --server=https://$&#123;ENDPOINT&#125; --certificate-authority=/etc/kubernetes/pki/ca.crt</span><br><span class="line">sudo kubectl config --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf set-credentials kubelet-bootstrap --token=$&#123;TOKEN_ID&#125;.$&#123;TOKEN_SECRET&#125;</span><br><span class="line">sudo kubectl config --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf set-context bootstrap --user=kubelet-bootstrap --cluster=$&#123;CLUSTER&#125;</span><br><span class="line">sudo kubectl config --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf use-context bootstrap</span><br><span class="line"></span><br><span class="line"># Copy the following files from master to the new node</span><br><span class="line">scp joshuazhang1c.mylabserver.com:/etc/kubernetes/bootstrap-kubelet.conf . &amp;&amp; sudo mv bootstrap-kubelet.conf /etc/kubernetes/</span><br><span class="line">scp joshuazhang1c.mylabserver.com:/etc/kubernetes/pki/ca.crt . &amp;&amp; sudo mv ca.crt /etc/kubernetes/pki/</span><br><span class="line">scp joshuazhang1c.mylabserver.com:/var/lib/kubelet/config.yaml . &amp;&amp; sudo mv config.yaml /var/lib/kubelet/</span><br><span class="line"></span><br><span class="line">c, Install kubelet in the new node joshuazhang2c.mylabserver.com</span><br><span class="line"></span><br><span class="line">sudo apt update &amp;&amp; sudo apt install -y apt-transport-https curl</span><br><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</span><br><span class="line">sudo bash -c &apos;cat &gt;/etc/apt/sources.list.d/kubernetes.list&apos; &lt;&lt;EOF</span><br><span class="line">deb https://apt.kubernetes.io/ kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y kubelet kubeadm kubectl</span><br><span class="line">sudo apt-mark hold kubelet kubeadm kubectl</span><br><span class="line">cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br><span class="line">sudo apt install -y docker.io</span><br><span class="line">sudo systemctl enable docker.service</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt;/lib/systemd/system/kubelet.service&apos; &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=kubelet: The Kubernetes Node Agent</span><br><span class="line">Documentation=https://kubernetes.io/docs/home/</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line">[Service]</span><br><span class="line">#ExecStart=/usr/bin/kubelet --bootstrap-kubeconfig=&quot;/etc/kubernetes/bootstrap-kubelet.conf&quot; --kubeconfig=&quot;/etc/kubernetes/kubeconfig.conf&quot; --config=&quot;/var/lib/kubernetes/config.yaml&quot;</span><br><span class="line">ExecStart=/usr/bin/kubelet --bootstrap-kubeconfig=&quot;/etc/kubernetes/bootstrap-kubelet.conf&quot; --kubeconfig=&quot;/etc/kubernetes/kubeconfig.conf&quot; --pod-manifest-path=&quot;/etc/kubernetes/manifests/&quot; --feature-gates=RotateKubeletClientCertificate=true</span><br><span class="line">Restart=always</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">RestartSec=10</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload; sudo systemctl restart kubelet</span><br><span class="line">sudo systemctl status kubelet</span><br><span class="line"></span><br><span class="line"># Verify</span><br><span class="line">kubectl get nodes joshuazhang2c.mylabserver.com</span><br><span class="line"># kubectl get csr</span><br><span class="line">NAME                                                   AGE   REQUESTOR                 CONDITION</span><br><span class="line">node-csr-mdou0axSg2vlk5wx2_a1uA0-buvaC-PsiF69Jvjg110   87s   system:bootstrap:iate9c   Approved,Issued</span><br><span class="line"># ls /var/lib/kubelet/pki/</span><br><span class="line">kubelet-client-2018-12-04-08-50-51.pem  kubelet-client-current.pem  kubelet.crt  kubelet.key</span><br><span class="line"># openssl x509 -noout -text -in /var/lib/kubelet/pki/kubelet-client-current.pem |grep system:node</span><br><span class="line">        Subject: O = system:nodes, CN = system:node:joshuazhang4c.mylabserver.com</span><br></pre></td></tr></table></figure>
<h2 id="附件-RBAC-authentication"><a href="#附件-RBAC-authentication" class="headerlink" title="附件 - RBAC authentication"></a>附件 - RBAC authentication</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line">kubectl create ns development</span><br><span class="line">kubectl create ns production</span><br><span class="line">$ kubectl config get-contexts</span><br><span class="line">CURRENT   NAME           CLUSTER        AUTHINFO   NAMESPACE</span><br><span class="line">*         juju-context   juju-cluster   admin</span><br><span class="line"></span><br><span class="line">sudo useradd -s /bin/bash DevHua</span><br><span class="line">sudo passwd DevHua</span><br><span class="line"></span><br><span class="line"># Generate a private key, then Certificate Signing Request (CSR) for DevHua</span><br><span class="line">openssl genrsa -out DevHua.key</span><br><span class="line">openssl req -new -key DevHua.key -out DevHua.csr -subj &quot;/CN=DevHua/O=development&quot;</span><br><span class="line"># Using the newly created request generate a self-signed certificate using the x509 protocol</span><br><span class="line">openssl x509 -req -in DevHua.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out DevHua.crt -days 45</span><br><span class="line"></span><br><span class="line">kubectl config view</span><br><span class="line">kubectl config set-credentials --help</span><br><span class="line">kubectl config set-credentials DevHua --client-certificate=./DevHua.crt --client-key=./DevHua.key</span><br><span class="line">kubectl config set-context --help</span><br><span class="line">kubectl config set-context DevHua-context --cluster=juju-cluster --namespace=development --user=DevHua</span><br><span class="line">kubectl --context=DevHua-context get pods</span><br><span class="line">#kubectl config use-context DevHua-context</span><br><span class="line">kubectl config get-contexts</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; role-dev.yaml&apos; &lt;&lt;EOF</span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: development</span><br><span class="line">  name: developer</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;, &quot;extensions&quot;, &quot;apps&quot;]</span><br><span class="line">  resources: [&quot;deployments&quot;, &quot;replicasets&quot;, &quot;pods&quot;]</span><br><span class="line">  verbs: [&quot;list&quot;, &quot;get&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f role-dev.yaml</span><br><span class="line">kubectl -n development describe roles developer</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; rolebind.yaml&apos; &lt;&lt;EOF</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: developer-role-binding</span><br><span class="line">  namespace: development</span><br><span class="line">subjects:</span><br><span class="line">  - kind: User</span><br><span class="line">    name: DevHua</span><br><span class="line">    apiGroup: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: developer</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line">EOF</span><br><span class="line">kubectl apply -f rolebind.yaml</span><br><span class="line">kubectl -n development describe rolebinding developer-role-binding</span><br><span class="line"></span><br><span class="line">kubectl --context=DevHua-context run nginx --image=nginx</span><br><span class="line">kubectl --context=DevHua-context get pods</span><br><span class="line">kubectl --context=DevHua-context delete deploy nginx</span><br><span class="line"></span><br><span class="line">sudo bash -c &apos;cat &gt; adminrolebind.yaml&apos; &lt;&lt;EOF</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: developer-adminrole-binding</span><br><span class="line">  namespace: development</span><br><span class="line">subjects:</span><br><span class="line">  - kind: User</span><br><span class="line">    name: DevHua</span><br><span class="line">    apiGroup: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line">EOF</span><br><span class="line">kubectl apply -f adminrolebind.yaml</span><br><span class="line">kubectl --context=DevHua-context get pods</span><br><span class="line"></span><br><span class="line">kubectl apply -f role-prod.yaml</span><br><span class="line">vim role-prod.yaml</span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: production #&lt;&lt;- This line</span><br><span class="line">  name: dev-prod #&lt;&lt;- and this line</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;, &quot;extensions&quot;, &quot;apps&quot;]</span><br><span class="line">  resources: [&quot;deployments&quot;, &quot;replicasets&quot;, &quot;pods&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;] #&lt;&lt;- and this one</span><br><span class="line"></span><br><span class="line">kubectl apply -f rolebindprod.yaml</span><br><span class="line">vim rolebindprod.yaml</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: production-role-binding</span><br><span class="line">  namespace: production</span><br><span class="line">subjects:</span><br><span class="line">- kind: User</span><br><span class="line">  name: DevDan</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: dev-prod</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line"></span><br><span class="line">kubectl config set-context ProdHua-context --cluster=kubernetes --namespace=production --user=DevHua</span><br><span class="line">kubectl --context=ProdHua-context run nginx --image=nginx</span><br></pre></td></tr></table></figure>
<h2 id="附件-RBAC-authentication-in-Dashboard"><a href="#附件-RBAC-authentication-in-Dashboard" class="headerlink" title="附件 - RBAC authentication in Dashboard"></a>附件 - RBAC authentication in Dashboard</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"># Use default anonymous user</span><br><span class="line"># generate client-certificate-data</span><br><span class="line">grep &apos;client-certificate-data&apos; /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.crt</span><br><span class="line"># generate client-key-data</span><br><span class="line">grep &apos;client-key-data&apos; /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.key</span><br><span class="line"># generate p12</span><br><span class="line">openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name &quot;kubernetes-client&quot;</span><br><span class="line"></span><br><span class="line">kubectl get secret -n kube-system | grep dashboard</span><br><span class="line">kubectlh -n kube-system  get secret kubernetes-dashboard-token-kglhd -o jsonpath=&#123;.data.token&#125;| base64 -d</span><br><span class="line"></span><br><span class="line"># Use admin user</span><br><span class="line">cat &gt; /tmp/admin-user.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line">cat &gt; /tmp/admin-user-role-binding.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f /tmp/admin-user.yaml</span><br><span class="line">kubectl create -f /tmp/admin-user-role-binding.yaml</span><br><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin | awk &apos;&#123;print $1&#125;&apos;)</span><br></pre></td></tr></table></figure>
<h2 id="附件-TLS-bootstrapping"><a href="#附件-TLS-bootstrapping" class="headerlink" title="附件 - TLS bootstrapping"></a>附件 - TLS bootstrapping</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/</span><br><span class="line">https://www.codercto.com/a/23740.html</span><br><span class="line">Workers must use a certificate issued by masters to communicatate with masters. To save the workload of creating certificates each time the worker is added, kubelet in worker will use a predefined certificate bootstrap-kubelet.conf to request masters to apply for cerfificate for this worker dynamically.</span><br><span class="line">kubelet has two ports, one is 10250 used to provide read/write tls private api, one is 10255 used to provide read-only non-tls private api.</span><br><span class="line">Bootstrap Token Secret (kubectl describe secrets --namespace=kube-system bootstrap-signer-token-8xsmh) will replace the previous token.csv.</span><br><span class="line"></span><br><span class="line">kube-apiserver side receives the requests for certificates from the kubelet and authenticates those requests:</span><br><span class="line">a, Recognizing CA that signs the client certificate</span><br><span class="line">   kube-apiserver --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-bootstrap-token-auth=true ...</span><br><span class="line">b, Authenticating the bootstrapping kubelet to the system:bootstrappers group</span><br><span class="line"># Create Bootstrap Token</span><br><span class="line">echo &quot;$(head -c 6 /dev/urandom | md5sum | head -c 6)&quot;.&quot;$(head -c 16 /dev/urandom | md5sum | head -c 16)&quot;</span><br><span class="line">vdb9xb.jiqhz35y355g1ngx</span><br><span class="line">vdb9xb.jiqhz35y355g1ngx,kubelet-bootstrap,10001,&quot;system:bootstrappers&quot;  #token.csv</span><br><span class="line">c, Authorize the bootstrapping kubelet to create a certificate signing request (CSR)</span><br><span class="line">kubectl describe roles.rbac.authorization.k8s.io --namespace=kube-system system:controller:bootstrap-signer</span><br><span class="line">sudo bash -c &apos;cat &lt; rolebinding.yaml&apos; &lt;&lt;EOF</span><br><span class="line"># enable bootstrapping nodes to create CSR</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: create-csrs-for-bootstrapping</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:node-bootstrapper</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kube-controller-manager side is responsible for issuing actual signed certificates:</span><br><span class="line">a, access to the “kuberetes CA key and certificate” that you created and distributed</span><br><span class="line">kube-controller-manager --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt --cluster-signing-key-file=/etc/kubernetes/pki/ca.key ...</span><br><span class="line">b, approve CSR signing automatically</span><br><span class="line">sudo bash -c &apos;cat &lt; certificatesigningrequests.yaml&apos; &lt;&lt;EOF</span><br><span class="line"># Approve all CSRs for the group &quot;system:bootstrappers&quot;</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-approve-csrs-for-group</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line">sudo bash -c &apos;cat &lt; renewal.yaml&apos; &lt;&lt;EOF</span><br><span class="line"># Approve renewal CSRs for the group &quot;system:nodes&quot;</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-approve-renewals-for-nodes</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubelet side:</span><br><span class="line">kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf ...</span><br><span class="line"># cat /etc/kubernetes/bootstrap-kubelet.conf</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: [xxx]</span><br><span class="line">    server: https://172.31.43.252:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: tls-bootstrap-token-user</span><br><span class="line">  name: tls-bootstrap-token-user@kubernetes</span><br><span class="line">current-context: tls-bootstrap-token-user@kubernetes</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: tls-bootstrap-token-user</span><br><span class="line">  user:</span><br><span class="line">    token: vdb9xb.jiqhz35y355g1ngx</span><br><span class="line"></span><br><span class="line">In Summary:</span><br><span class="line">kubectl get secrets -n kube-system |grep -i bootstrap</span><br><span class="line">kubectl -n kube-system get secret bootstrap-signer-token-8xsmh -o jsonpath=&#123;.data.token&#125;| base64 -d</span><br></pre></td></tr></table></figure>
<h2 id="附件-microk8s"><a href="#附件-microk8s" class="headerlink" title="附件 - microk8s"></a>附件 - microk8s</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#sudo snap install microk8s --beta --classic</span><br><span class="line">sudo snap install microk8s --edge --classic</span><br><span class="line">snap list</span><br><span class="line">journalctl -u snap.microk8s.daemon-apiserver.service</span><br><span class="line">microk8s.kubectl get no</span><br><span class="line">microk8s.enable dns dashboard</span><br><span class="line">microk8s.kubectl get all --all-namespaces</span><br><span class="line">lynx http://xxxx</span><br></pre></td></tr></table></figure>
<h2 id="附件-其他"><a href="#附件-其他" class="headerlink" title="附件 - 其他"></a>附件 - 其他</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br></pre></td><td class="code"><pre><span class="line"># How to generate yaml template</span><br><span class="line">kubectl run --restart=Always # creates a Deployment</span><br><span class="line">kubectl run --restart=Never # creates bare pod</span><br><span class="line">kubectl run --restart=OnFailure # creates a Job.</span><br><span class="line"></span><br><span class="line">https://kubernetes.io/docs/reference/kubectl/conventions/#generators</span><br><span class="line">pod template:</span><br><span class="line">  kubectl run --help |grep generator</span><br><span class="line">  kubectl run --generator=run-pod/v1 nginx --image=nginx --dry-run -o yaml</span><br><span class="line">service and deployment template:</span><br><span class="line">  kubectl run nginx --service-generator=&apos;service/v2&apos; --image=nginx --dry-run --expose --port 80 -o yaml</span><br><span class="line">job template:</span><br><span class="line">  kubectl run --generator=job/v1 nginx --image=nginx --dry-run -o yaml</span><br><span class="line"></span><br><span class="line"># jq, jsonpath, sort-by, kubectl top etc</span><br><span class="line">kubectl delete pods,services -l name=myLabel --include-uninitialized</span><br><span class="line">kubectl get pods --field-selector=status.phase=Running</span><br><span class="line">kubectl get pod ubuntu -o yaml |sed &apos;s/\(image: ubuntu\):.*$/\1:18.04/&apos; |kubectl replace -f -</span><br><span class="line">kubectl top pod -l name=nginx-ingress-kubernetes-worker</span><br><span class="line">kubectl get pods --sort-by=.metadata.name</span><br><span class="line"></span><br><span class="line">kubectl get -o template pod/web-pod-13je7 --template=&#123;&#123;.status.phase&#125;&#125;</span><br><span class="line"></span><br><span class="line">kubectl get nodes -o jsonpath=&apos;&#123;.items[*].metadata.name&#125;&apos; equals kubectl get nodes -o jsonpath=&apos;&#123;.items..metadata.name&#125;&apos;</span><br><span class="line">kubectl get nodes -o jsonpath=&apos;&#123;.items[].metadata.name&#125;&apos; equals kubectl get nodes -o jsonpath=&apos;&#123;.items[0].metadata.name&#125;&apos;</span><br><span class="line">kubectl get nodes -o jsonpath=&apos;&#123;.items[*].status.addresses[?(@.type==&quot;InternalIP&quot;)].address&#125;&apos;</span><br><span class="line"></span><br><span class="line">kubectl get pods -o json |jq &apos;.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name&apos; |grep -v null |sort |uniq</span><br><span class="line"></span><br><span class="line"># just get pod&apos;s names</span><br><span class="line">kubectl get pod -l app=nginx -o json |jq &apos;.items[].metadata.name&apos;</span><br><span class="line">kubectl get pods -l app=nginx -o=custom-columns=NAME:.metadata.name</span><br><span class="line">kubectl get pods -l app=nginx -o=name</span><br><span class="line"></span><br><span class="line"># dont&apos;s forget --record</span><br><span class="line">#kubectl rollout pause deployment/scale-deploy</span><br><span class="line">#kubectl set resources deployment/scale-deploy -c=nginx --limits=cpu=200m,memory=512Mi</span><br><span class="line">#kubectl rollout resume deployment/scale-deploy</span><br><span class="line">deployment.apps/nginx-deployment resource requirements updated</span><br><span class="line">kubectl set image deploy scale-deploy nginx=nginx:1.9.1 --record</span><br><span class="line">kubectl rollout history deployment/scale-deploy</span><br><span class="line">kubectl rollout history deployment/scale-deploy --revision=1</span><br><span class="line">kubectl rollout undo deployment/scale-deploy</span><br><span class="line">kubectl rollout undo deployment/scale-deploy --to-revision=2</span><br><span class="line">kubectl scale deployment/scale-deploy --replicas=2</span><br><span class="line">kubectl autoscale deployment/scale-deploy --min=3 --max=4 --cpu-percent=80</span><br><span class="line"></span><br><span class="line"># volume template</span><br><span class="line">cat &gt; test_pod.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pod</span><br><span class="line">spec:</span><br><span class="line">  #initContainers:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test</span><br><span class="line">      name: secret-volume</span><br><span class="line">    env:</span><br><span class="line">    - name: PASS</span><br><span class="line">      valueFrom:</span><br><span class="line">        secretKeyRef:</span><br><span class="line">          name: test-secret</span><br><span class="line">          key: passwd</span><br><span class="line">  volumes:</span><br><span class="line">  - name: hostpath-volume</span><br><span class="line">    hostPath:</span><br><span class="line">      path: /data</span><br><span class="line">  - name: emptydir-volume</span><br><span class="line">    emptyDir: &#123;&#125;</span><br><span class="line">  - name: secret-volume</span><br><span class="line">    secret:</span><br><span class="line">      secretName: test-secret</span><br><span class="line">EOF</span><br><span class="line">kubectl create --save-config -f test_pod.yaml</span><br><span class="line">kubectl apply --record -f test_pod.yaml</span><br><span class="line"></span><br><span class="line"># initcontainers</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: init-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: workdir</span><br><span class="line">      mountPath: /usr/share/nginx/html</span><br><span class="line">  initContainers:</span><br><span class="line">  - name: touch</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command: [&apos;touch&apos;, &apos;/work-dir/index.html&apos;]</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: workdir</span><br><span class="line">      mountPath: &quot;/work-dir&quot;</span><br><span class="line">  volumes:</span><br><span class="line">  - name: workdir</span><br><span class="line">    emptyDir: &#123;&#125;</span><br><span class="line"></span><br><span class="line"># Create a pod that uses secrets</span><br><span class="line">kubectl create secret generic test-secret --from-literal=usename=hua --from-literal=passwd=password --dry-run -o yaml</span><br><span class="line">kubectl create secret generic test-secret --from-literal=usename=hua --from-literal=passwd=password</span><br><span class="line">kubectl get pods --namespace=kube-system kube-flannel-ds-amd64-4mt82 -o yaml &gt; pod_template.yaml</span><br><span class="line">cat &gt; pod-secret.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: question1</span><br><span class="line">  name: pod-secret</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /mnt/secret</span><br><span class="line">      name: test-secret-vol</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-secret-vol</span><br><span class="line">    secret:</span><br><span class="line">      secretName: test-secret</span><br><span class="line">EOF</span><br><span class="line">kubectl exec pod-secret -- cat /mnt/secret/passwd</span><br><span class="line">cat &gt; pod_secret_env.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: question1</span><br><span class="line">  name: pod-secret-env</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx</span><br><span class="line">    env:</span><br><span class="line">    - name: PASS</span><br><span class="line">      valueFrom:</span><br><span class="line">        secretKeyRef:</span><br><span class="line">          name: test-secret</span><br><span class="line">          key: passwd</span><br><span class="line">EOF</span><br><span class="line">kubectl exec pod-secret-env -- env |grep PASS</span><br><span class="line"></span><br><span class="line"># etcd 3</span><br><span class="line">ETCDCTL_API=3 etcdctl --help |grep snap</span><br><span class="line">ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/apiserver-etcd-client.crt --key=/etc/kubernetes/pki/apiserver-etcd-client.key member list</span><br><span class="line">ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/apiserver-etcd-client.crt --key=/etc/kubernetes/pki/apiserver-etcd-client.key snapshot save snapshot.db</span><br><span class="line">etcdctl --endpoints=https://[127.0.0.1]:2379 --ca-file=/etc/kubernetes/pki/etcd/ca.crt --cert-file=/etc/kubernetes/pki/apiserver-etcd-client.crt --key-file=/etc/kubernetes/pki/apiserver-etcd-client.key cluster-health</span><br><span class="line"></span><br><span class="line"># PV &amp; PVC &amp; Pod</span><br><span class="line">cat &gt; pv.yaml &lt;&lt;EOF</span><br><span class="line">pv + hostpath</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: task-pv-volume</span><br><span class="line">  labels:</span><br><span class="line">    type: local</span><br><span class="line">spec:</span><br><span class="line">  storageClassName: manual</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 2Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  hostPath:</span><br><span class="line">    path: &quot;/mnt/data&quot;</span><br><span class="line">EOF</span><br><span class="line">cat &gt; pv.yaml &lt;&lt;EOF</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: task-pv-claim</span><br><span class="line">spec:</span><br><span class="line">  storageClassName: manual</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">EOF</span><br><span class="line">cat &gt; pv.yaml &lt;&lt;EOF</span><br><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: task-pv-pod</span><br><span class="line">spec:</span><br><span class="line">  volumes:</span><br><span class="line">    - name: task-pv-storage</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">       claimName: task-pv-claim</span><br><span class="line">  containers:</span><br><span class="line">    - name: task-pv-container</span><br><span class="line">      image: nginx</span><br><span class="line">      ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">          name: &quot;http-server&quot;</span><br><span class="line">      volumeMounts:</span><br><span class="line">        - mountPath: &quot;/usr/share/nginx/html&quot;</span><br><span class="line">          name: task-pv-storage</span><br><span class="line">EOF</span><br><span class="line"># NOTE: the following command should be runned in the pod which ship pod</span><br><span class="line">echo &apos;hello&apos; &gt; /mnt/data/index.html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># custom install master (TBD)</span><br><span class="line"># install kube* and etcd binary - https://kubernetes.io/docs/setup/scratch/</span><br><span class="line">wget https://github.com/kubernetes/kubernetes/releases/download/v1.13.0/kubernetes.tar.gz</span><br><span class="line">tar -xf kubernetes.tar.gz</span><br><span class="line">./kubernetes/cluster/get-kube-binaries.sh</span><br><span class="line">tar -xf kubernetes/server/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">sudo cp kubernetes/server/bin/&#123;kube-apiserver,kube-scheduler,kube-controller-manager,kube-proxy,kubectl,kubelet&#125; /usr/bin/</span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.3.10/etcd-v3.3.10-linux-amd64.tar.gz</span><br><span class="line">tar -xf etcd-v3.3.10-linux-amd64.tar.gz</span><br><span class="line">sudo cp etcd-v3.3.10-linux-amd64/&#123;etcd,etcdctl&#125; /usr/bin/</span><br><span class="line"></span><br><span class="line"># create cert</span><br><span class="line">sudo -i</span><br><span class="line">mkdir -p /etc/kubernetes &amp;&amp; cd /etc/kubernetes</span><br><span class="line">openssl genrsa -out ca.key</span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=quqi.cluster&quot; -days 5000 -out ca.crt</span><br><span class="line"># openssl x509 -in ca.crt -out ca.pem  #convert CRT to PEM</span><br><span class="line"></span><br><span class="line">#Create key pair for kube-master. NOTE: kube-master should be the same as it&apos;s hostname</span><br><span class="line">openssl genrsa -out server.key</span><br><span class="line">openssl req -new -key server.key -out server.csr -subj &quot;/CN=system:node:172.31.20.224/O=system:nodes&quot;</span><br><span class="line">openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 5000</span><br><span class="line">openssl x509  -noout -text -in ./server.crt</span><br><span class="line"></span><br><span class="line"># Create key pair for every kube-worker, here we will just create one for all-workers</span><br><span class="line">openssl genrsa -out client.key</span><br><span class="line">openssl req -new -key client.key -out client.csr -subj &quot;/CN=system:node:worker/O=system:nodes&quot;</span><br><span class="line">openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 5000</span><br><span class="line">openssl x509  -noout -text -in ./client.crt</span><br><span class="line"></span><br><span class="line"># static pod way</span><br><span class="line">sudo apt install -y docker.io</span><br><span class="line">sudo mkdir -p /etc/kubernetes/manifests</span><br><span class="line">sudo kubelet --register-node=false --pod-manifest-path=/etc/kubernetes/manifests</span><br><span class="line">https://medium.com/containerum/4-ways-to-bootstrap-a-kubernetes-cluster-de0d5150a1e4</span><br><span class="line"></span><br><span class="line"># systemd way - https://medium.com/containerum/4-ways-to-bootstrap-a-kubernetes-cluster-de0d5150a1e4</span><br><span class="line">git clone https://github.com/kubernetes/contrib.git</span><br><span class="line">cd ./contrib/init/systemd/</span><br><span class="line">sudo useradd kube</span><br><span class="line">sudo mv *.service /etc/systemd/system/</span><br><span class="line">sudo mv ./environ/* /etc/kubernetes/</span><br><span class="line">sudo mkdir -p  /var/run/kubernetes</span><br><span class="line">sudo systemctl enable kube-apiserver</span><br><span class="line">sudo systemctl restart kube-apiserver</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"># install etcd - https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/</span><br><span class="line">sudo touch /var/log/etcd.log &amp;&amp; sudo chown -R $(id -u) /var/log/etcd.log</span><br><span class="line">sudo etcd --listen-client-urls=http://0.0.0.0:2379 --advertise-client-urls=http://172.31.20.224:2379 &gt;&gt; /var/log/etcd.log 2&gt;&amp;1 &amp;</span><br><span class="line">sudo ETCDCTL_API=2 etcdctl --endpoints=http://172.31.20.224:2379 cluster-health</span><br><span class="line">sudo ETCDCTL_API=3 etcdctl --endpoints=http://172.31.20.224:2379 member list</span><br><span class="line">sudo ETCDCTL_API=3 etcdctl --endpoints=http://172.31.20.224:2379 snapshot save snapshot.save</span><br><span class="line"></span><br><span class="line"># run kube-apiserver</span><br><span class="line">sudo touch /var/log/kube-apiserver.log &amp;&amp; sudo chown -R $(id -u) /var/log/kube-apiserver.log</span><br><span class="line">#sudo kube-apiserver --logtostderr --v=0 --etcd-servers=http://172.31.20.224:2379 --insecure-bind-address=0.0.0.0 --insecure-port=8080 --service-cluster-ip-range=10.244.0.0/16 --admission-control=ServiceAccount,LimitRanger,ResourceQuota --bind-address=0.0.0.0 --secure-port=6443 --client-ca-file=/etc/kubernetes/ca.crt --tls-private-key-file=/etc/kubernetes/server.key --tls-cert-file=/etc/kubernetes/server.crt &gt;&gt; /var/log/kube-apiserver.log 2&gt;&amp;1 &amp;</span><br><span class="line">sudo kube-apiserver --logtostderr --v=0 --etcd-servers=http://172.31.20.224:2379 --insecure-bind-address=0.0.0.0 --insecure-port=8080 --service-cluster-ip-range=10.244.0.0/16 --admission-control=ServiceAccount,LimitRanger,ResourceQuota &gt;&gt; /var/log/kube-apiserver.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"># run kube-controller-manager</span><br><span class="line">sudo touch /var/log/kube-controller-manager.log &amp;&amp; sudo chown -R $(id -u) /var/log/kube-controller-manager.log</span><br><span class="line">#sudo kube-controller-manager --logtostderr --v=0 --master=https://172.31.20.224:6443 --service-account-private-key-file=/etc/kubernetes/server.key --root-ca-file=/etc/kubernetes/ca.crt</span><br><span class="line">sudo kube-controller-manager --logtostderr --v=0 --master=http://172.31.20.224:8080  &gt;&gt; /var/log/kube-controller-manager.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"># run kube-scheduler</span><br><span class="line">sudo touch /var/log/kube-scheduler.log &amp;&amp; sudo chown -R $(id -u) /var/log/kube-scheduler.log</span><br><span class="line">sudo kube-scheduler --logtostderr --v=0 --master=http://172.31.20.224:8080  &gt;&gt; /var/log/kube-scheduler.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"># verity master</span><br><span class="line">kubectl -s http://172.31.20.224:8080 get componentstatus</span><br><span class="line">kubectl -s http://172.31.20.224:8080 get node</span><br><span class="line"></span><br><span class="line"># run kube-proxy, docker and kubelet</span><br><span class="line">sudo touch /var/log/kube-proxy.log &amp;&amp; sudo chown -R $(id -u) /var/log/kube-proxy.log</span><br><span class="line">sudo kube-proxy --logtostderr --v=0 --master=http://172.31.20.224:8080  &gt;&gt; /var/log/kube-proxy.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line">sudo apt install docker.io</span><br><span class="line">sudo systemctl enable docker</span><br><span class="line"></span><br><span class="line">kubectl config view</span><br><span class="line">kubectl config set-credentials admin --username=admin --password=password</span><br><span class="line">kubectl config set-cluster quqi.cluster --insecure-skip-tls-verify=true --server=http://172.31.20.224:8080</span><br><span class="line">kubectl config set-context quqi.context --user=admin --namespace=default --cluster=quqi.cluster</span><br><span class="line">kubectl config use-context quqi.context</span><br><span class="line">sudo cp .kube/config /etc/kubernetes/kubeconfig</span><br><span class="line"></span><br><span class="line">sudo touch /var/log/kubelet.log &amp;&amp; sudo chown -R $(id -u) /var/log/kubelet.log</span><br><span class="line">sudo kubelet --logtostderr --v=0 --kubeconfig=/etc/kubernetes/kubeconfig  &gt;&gt; /var/log/kubelet.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"># self-hosted way</span><br><span class="line"># create kubeconfig</span><br><span class="line">NOTE: Put the kubeconfig(s) on every node. eg: in /var/lib/kube-proxy/kubeconfig and /var/lib/kubelet/kubeconfig.</span><br><span class="line">CLUSTER_NAME=quqicluster</span><br><span class="line">CA_CERT=/etc/kubernetes/pki/ca.crt</span><br><span class="line">CLI_CERT=/etc/kubernetes/pki/client.crt</span><br><span class="line">CLI_KEY=/etc/kubernetes/pki/client.key</span><br><span class="line">TOKEN=$(dd if=/dev/urandom bs=128 count=1 2&gt;/dev/null | base64 | tr -d &quot;=+/[:space:]&quot; | dd bs=32 count=1 2&gt;/dev/null)</span><br><span class="line">USER=admin</span><br><span class="line">CONTEXT_NAME=admin_context</span><br><span class="line">MASTER_IP=172.31.29.147</span><br><span class="line">sudo kubectl config set-cluster $CLUSTER_NAME --certificate-authority=$CA_CERT --embed-certs=true --server=https://$MASTER_IP</span><br><span class="line">sudo kubectl config set-credentials $USER --client-certificate=$CLI_CERT --client-key=$CLI_KEY --embed-certs=true --token=$TOKEN</span><br><span class="line">sudo kubectl config set-context $CONTEXT_NAME --cluster=$CLUSTER_NAME --user=$USER</span><br><span class="line">sudo kubectl config use-context $CONTEXT_NAME</span><br><span class="line"></span><br><span class="line"># install docker</span><br><span class="line">#iptables -t nat -F</span><br><span class="line">#ip link set docker0 down</span><br><span class="line">#ip link delete docker0</span><br><span class="line">sudo apt install -y docker.io</span><br><span class="line">sudo systemctl enable docker</span><br><span class="line"></span><br><span class="line"># Install kubelet</span><br><span class="line">sudo mkdir -p /var/lib/kubelet</span><br><span class="line">sudo cp ~/.kube/config /var/lib/kubelet/kubeconfig</span><br><span class="line">sudo kubelet --kubeconfig=/var/lib/kubelet/kubeconfig</span><br><span class="line"></span><br><span class="line">kubelet --kubeconfig=/var/lib/kubelet/kubeconfig --cgroup-driver=cgroupfs --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.1</span><br><span class="line"></span><br><span class="line"># Install kube-proxy</span><br><span class="line">sudo mkdir -p /var/lib/kube-proxy</span><br><span class="line">sudo cp ~/.kube/config /var/lib/kube-proxy/kubeconfig</span><br><span class="line">sudo kube-proxy --master=https://$MASTER_IP --kubeconfig=/var/lib/kube-proxy/kubeconfig</span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="http://blog.spider.im/2018/06/26/cka-exam/" target="_blank" rel="external">http://blog.spider.im/2018/06/26/cka-exam/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/02/Using-kubeadm-to-deploy-k8s/" data-id="cjr2rybtd000jaxbpmhrsw9mo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Use-Octavia-to-Implement-HTTPS-Health-Monitors" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/31/Use-Octavia-to-Implement-HTTPS-Health-Monitors/" class="article-date">
  <time datetime="2018-12-31T08:29:50.000Z" itemprop="datePublished">2018-12-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/31/Use-Octavia-to-Implement-HTTPS-Health-Monitors/">Use Octavia to Implement HTTPS Health Monitors</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>采用Neutron LBaaS v2实现HTTPS Health Monitors时的配置如下(步骤见附件 - Neutron LBaaS v2)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">    mode tcp</span><br><span class="line">    balance leastconn</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    option ssl-hello-chk</span><br><span class="line">    server 37a1f5a8-ec7e-4208-9c96-27d2783a594f 192.168.21.13:443 weight 1 check inter 5s fall 2</span><br><span class="line">    server 8e722b4b-08b8-4089-bba5-8fa5dd26a87f 192.168.21.8:443 weight 1 check inter 5s fall 2</span><br></pre></td></tr></table></figure></p>
<p>这种配置会有一个问题, 当使用自定义签名证书时一切正常, 但使用机构颁发的证书时反而有问题.<br>1, 对于ssl check, 严格一点的是check-ssl, 但haproxy没有证书不支持严格的客户端认证, 所以需添加”check check-ssl verify none”参数禁止对客户端参数进行验证. lbaasv2由于久远不支持(那时都还是haproxy 1.7以前必须不支持), ocatavia则有对ssl check的支持.(<a href="https://github.com/openstack/octavia/blob/master/octavia/common/jinja/haproxy/templates/macros.j2" target="_blank" rel="external">https://github.com/openstack/octavia/blob/master/octavia/common/jinja/haproxy/templates/macros.j2</a>)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">154         &#123;% if pool.health_monitor.type == constants.HEALTH_MONITOR_HTTPS %&#125;</span><br><span class="line">155             &#123;% set monitor_ssl_opt = &quot; check-ssl verify none&quot; %&#125;</span><br></pre></td></tr></table></figure></p>
<p>下面的配置works<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">backend 79024d4d-4de4-492c-a3e2-21730b096a37</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 317e4dea-5a62-4df0-a2f1-ea7bad4a9c5d 192.168.21.7:443 weight 1 check check-ssl verify none inter 5s fall 3 rise 4</span><br></pre></td></tr></table></figure></p>
<p>但是似乎ocatavia的client有点问题, 它设置出来的是:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    option httpchk None None</span><br><span class="line">    http-check expect rstatus None</span><br><span class="line">    server 317e4dea-5a62-4df0-a2f1-ea7bad4a9c5d 192.168.21.7:443 weight 1 check check-ssl verify none inter 5s fall 3 rise 4</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTPS --name https-monitor --http-method GET --url-path / --expected-codes 200 pool1</span><br><span class="line">http_method is not a valid option for health monitors of type HTTPS (HTTP 400) (Request-ID: req-2d81bafa-1240-4f73-8e2e-cb0dd7691fdb)</span><br></pre></td></tr></table></figure></p>
<p>2, ssl backend side采用了严格的客户端认证的话, 需改用TLS-HELLO check (<a href="https://docs.openstack.org/octavia/latest/user/guides/basic-cookbook.html)其实已经有说明" target="_blank" rel="external">https://docs.openstack.org/octavia/latest/user/guides/basic-cookbook.html)其实已经有说明</a>, 如下:<br>HTTPS health monitors operate exactly like HTTP health monitors, but with ssl back-end servers. Unfortunately, this causes problems if the servers are performing client certificate validation, as HAProxy won’t have a valid cert. In this case, using TLS-HELLO type monitoring is an alternative.<br>TLS-HELLO health monitors simply ensure the back-end server responds to SSLv3 client hello messages. It will not check any other health metrics, like status code or body contents.<br><a href="https://review.openstack.org/#/c/475944/" target="_blank" rel="external">https://review.openstack.org/#/c/475944/</a></p>
<p>实际上客户并未使用客户端认证, 所以不是上面的原因, 应该是SNI所致. 因为后端有SNI认证, haproxy端需传入hostname, 但haproxy端无法传入hostname, 所以出错.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --cacert ca.crt https://10.5.150.5</span><br><span class="line">curl: (51) SSL: certificate subject name (www.server1.com) does not match target host name &apos;10.5.150.5&apos;</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server1.com:443:10.5.150.5 -k https://www.server1.com</span><br><span class="line">test1</span><br></pre></td></tr></table></figure></p>
<p>什么是SNI, 就是ssl server端可能会根据每个节点的hostname生成不同的cert, 并启用SNI. 这样ssl client访问ssl server端时也应该将hostname也传过去.<br>‘curl -k’的方式测试无法很好的测试SNI, 最好是通过’openstack s_client’测试:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#Ideal Test to connect with SSLv3/No SNI</span><br><span class="line">openssl s_client -ssl3 -connect 103.245.215.4:443</span><br><span class="line">#We can also send SNI using -servername:</span><br><span class="line">openssl s_client -ssl3 -servername CERT_HOSTNAME -connect 103.245.215.4:443</span><br></pre></td></tr></table></figure></p>
<p>这个文档 (<a href="https://cbonte.github.io/haproxy-dconv/1.7/configuration.html#option%20ssl-hello-chk" target="_blank" rel="external">https://cbonte.github.io/haproxy-dconv/1.7/configuration.html#option%20ssl-hello-chk</a> )指出ssl-hello-chk只检查SSLv3不检查HTTP, 事实上, HTTPS health check也不检查HTTP只是多了个SSL negotiation. check-ssl check似乎能做更多.<br>LBaas v2模板目前只支持”httpchk”与”ssl-hello-chk”, 这只有SSL check, 没有HTTP check. 所以问题很可能是出在SSLv3 hello (without SNI)有问题.做个SNI相关的实验验证一下:<br>1, 两个证书, 略. lb_tls_secret_1的hostname是www.server1.com, lb_tls_secret_2的hostname是www.server2.com<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">secret1_id=$(openstack secret list |grep lb_tls_secret_1 |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">secret2_id=$(openstack secret list |grep lb_tls_secret_2 |awk &apos;&#123;print $2&#125;&apos;)</span><br></pre></td></tr></table></figure></p>
<p>2, 创建listener时使用( –sni-container-refs $secret1_id $secret2_id )加入了两个域名的SNI<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">IP=192.168.21.7</span><br><span class="line">secret1_id=$(openstack secret list |grep lb_tls_secret_1 |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">secret2_id=$(openstack secret list |grep lb_tls_secret_2 |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">subnetid=$(openstack subnet show private_subnet -f value -c id); echo $subnetid</span><br><span class="line">lb_id=$(openstack loadbalancer show lb3 -f value -c id)</span><br><span class="line">#lb_id=$(openstack loadbalancer create --name test_tls_termination --vip-subnet-id $subnetid -f value -c id); echo $lb_id</span><br><span class="line">listener_id=$(openstack loadbalancer listener create $lb_id --name https_listener --protocol-port 443 --protocol TERMINATED_HTTPS --default-tls-container=$secret1_id --sni-container-refs $secret1_id $secret2_id -f value -c id); echo $listener_id</span><br><span class="line">pool_id=$(openstack loadbalancer pool create --protocol HTTP --listener $listener_id --lb-algorithm ROUND_ROBIN -f value -c id); echo $pool_id</span><br><span class="line">openstack loadbalancer member create --address $&#123;IP&#125; --subnet-id $subnetid --protocol-port 80 $pool_id</span><br><span class="line"></span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">vip=$(openstack loadbalancer show $lb_id -c vip_address -f value)</span><br><span class="line">vip_port=$(openstack port list --fixed-ip ip-address=$vip -c ID -f value)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address $vip --port $vip_port</span><br></pre></td></tr></table></figure></p>
<p>3, 测试, client传入www.server1.com或www.server2.com两个域名时, server端能正常响应, 但传入一个域名www.server3.com时就报了这个错:’does not match target host name ‘www.server3.com’’</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server1.com:443:10.5.150.5 --cacert ca.crt https://www.server1.com</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server2.com:443:10.5.150.5 --cacert ca.crt https://www.server2.com</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server3.com:443:10.5.150.5 --cacert ca.crt https://www.server3.com</span><br><span class="line">curl: (51) SSL: certificate subject name (www.server1.com) does not match target host name &apos;www.server3.com&apos;</span><br></pre></td></tr></table></figure>
<p>为什么会这样呢?</p>
<p>LBaaS v2中的ssl check将在haproxy中添加下列配置, 实际上有ssl-hello-chk时httpchk将被覆盖(haproxy忽略的). haproxy 1.7开始添加了更高级的check-ssl(xenial使用haproxy 1.6, 不支持), 估计就是早期的lbaas为ssl check添加ssl-hello-chk的原因<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mode tcp</span><br><span class="line">option httpchk GET /</span><br><span class="line">http-check expect rstatus 303</span><br><span class="line">option ssl-hello-chk</span><br></pre></td></tr></table></figure></p>
<p>haproxy(<a href="http://cbonte.github.io/haproxy-dconv/1.6/configuration.html#4-option%20ssl-hello-chk)将为ssl-hello-chk伪造SSLv3包" target="_blank" rel="external">http://cbonte.github.io/haproxy-dconv/1.6/configuration.html#4-option%20ssl-hello-chk)将为ssl-hello-chk伪造SSLv3包</a>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">When some SSL-based protocols are relayed in TCP mode through HAProxy, it is</span><br><span class="line">possible to test that the server correctly talks SSL instead of just testing</span><br><span class="line">that it accepts the TCP connection. When &quot;option ssl-hello-chk&quot; is set, pure</span><br><span class="line">SSLv3 client hello messages are sent once the connection is established to</span><br><span class="line">the server, and the response is analyzed to find an SSL server hello message.</span><br><span class="line">The server is considered valid only when the response contains this server</span><br><span class="line">hello message.</span><br><span class="line">All servers tested till there correctly reply to SSLv3 client hello messages,</span><br><span class="line">and most servers tested do not even log the requests containing only hello</span><br><span class="line">messages, which is appreciable.</span><br><span class="line">Note that this check works even when SSL support was not built into haproxy</span><br><span class="line">because it forges the SSL message. When SSL support is available, it is best</span><br><span class="line">to use native SSL health checks instead of this one.</span><br></pre></td></tr></table></figure></p>
<p>这是haproxy相关处理的源代码, 它没使用SSL libray, 先发硬编码的SSLv3 hello消息, 然后从response里找0x15 (SSL3_RT_ALERT) or 0x16 (SSL3_RT_HANDSHAKE), 若没找着就返回HCHK_STATUS_L6RSP(Layer6 invalid response) - <a href="https://github.com/haproxy/haproxy/blob/master/src/checks.c#L915" target="_blank" rel="external">https://github.com/haproxy/haproxy/blob/master/src/checks.c#L915</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">case PR_O2_SSL3_CHK:</span><br><span class="line">	if (!done &amp;&amp; b_data(&amp;check-&gt;bi) &lt; 5)</span><br><span class="line">		goto wait_more_data;</span><br><span class="line"></span><br><span class="line">	/* Check for SSLv3 alert or handshake */</span><br><span class="line">	if ((b_data(&amp;check-&gt;bi) &gt;= 5) &amp;&amp; (*b_head(&amp;check-&gt;bi) == 0x15 || *b_head(&amp;check-&gt;bi) == 0x16))</span><br><span class="line">		set_server_check_status(check, HCHK_STATUS_L6OK, NULL);</span><br><span class="line">	else</span><br><span class="line">		set_server_check_status(check, HCHK_STATUS_L6RSP, NULL);</span><br><span class="line">	break;</span><br></pre></td></tr></table></figure></p>
<p>错误’Layer6 invalid response’正是从客户日志中看到的:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Oct 25 04:50:34 neut002 haproxy[54990]: Server aaa0a533-073b-4b0f-8b81-777b6a8f3900/f2dc685f-58f7-4201-8060-3409d2d73a0d is DOWN, reason: Layer6 invalid response, check duration: 4ms. 0 active and 0 backup servers left. 0 sessions active, 0 requeued, 0 remaining in queue.</span><br></pre></td></tr></table></figure></p>
<p>所以backend ssl server端应该返回0x15, 客户究竟在haproxy之前运行什么ssl backend端, 我们不清楚. 假设它们运行的是apache2. 我们搭建一个测试环境, apache2采用默认的tls1.2, 而haproxy里还使用老的sslv3 hello时, apache2 ssl backend将返回下列的ssl协商错误:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openssl s_client -ssl3 -connect www.server1.com:443</span><br><span class="line">140306875094680:error:140A90C4:SSL routines:SSL_CTX_new:null ssl method passed:ssl_lib.c:1878:</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openssl s_client -ssl3 -servername www.server1.com -connect www.server1.com:443</span><br><span class="line">139626113296024:error:140A90C4:SSL routines:SSL_CTX_new:null ssl method passed:ssl_lib.c:1878:</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openssl s_client -ssl3 -servername www.server2.com -connect www.server1.com:443</span><br><span class="line">140564176807576:error:140A90C4:SSL routines:SSL_CTX_new:null ssl method passed:ssl_lib.c:1878:</span><br></pre></td></tr></table></figure></p>
<p>为什么ssl backend端不返回0x15或0x16呢, 理论上可能有以下几个原因<br>a, SSLv3现在已经被废弃了, 主流http server已经禁用了SSLv3支持, apach2收到haproxy过来的SSLv3 hello包时, apache2的SSL实现可能会响应别的消息而不是0x15/0x15<br>b, 因为haproxy过来的SSLv3 hello请求里没有SNI, 这样若启用了SNI的backend端(如apache2)就会ssl协商失败了, 这样也就未返回0x15/0x16<br>c, 其他原因<br>具体原因还需继续在backend抓包(tcpdump -eni ens3 -w ssl-test.pcap -s 0 port 443 or port 8443)确认.</p>
<h2 id="安装Octavia"><a href="#安装Octavia" class="headerlink" title="安装Octavia"></a>安装Octavia</h2><p>或者<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">sudo bash -c &apos;cat &gt;overlays/octavia.yaml&quot; &lt;&lt;EOF</span><br><span class="line">debug:                      &amp;debug                     True</span><br><span class="line">openstack_origin:           &amp;openstack_origin          cloud:bionic-rocky</span><br><span class="line">applications:</span><br><span class="line">  octavia:</span><br><span class="line">    #series: bionic</span><br><span class="line">    charm: cs:octavia</span><br><span class="line">    num_units: 1</span><br><span class="line">    constraints: mem=2G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">  octavia-dashboard:</span><br><span class="line">    charm: cs:octavia-dashboard</span><br><span class="line">relations:</span><br><span class="line">- - mysql:shared-db</span><br><span class="line">  - octavia:shared-db</span><br><span class="line">- - keystone:identity-service</span><br><span class="line">  - octavia:identity-service</span><br><span class="line">- - rabbitmq-server:amqp</span><br><span class="line">  - octavia:amqp</span><br><span class="line">- - neutron-api:neutron-load-balancer</span><br><span class="line">  - octavia:neutron-api</span><br><span class="line">- - neutron-openvswitch:neutron-plugin</span><br><span class="line">  - octavia:neutron-openvswitch</span><br><span class="line">- - openstack-dashboard:dashboard-plugin</span><br><span class="line">  - octavia-dashboard:dashboard</span><br><span class="line">EOF</span><br><span class="line">sudo bash -c &apos;cat &gt;overlays/octavia.yaml&quot; &lt;&lt;EOF</span><br><span class="line">debug:                      &amp;debug                     True</span><br><span class="line">verbose:                    &amp;verbose                   True</span><br><span class="line">openstack_origin:           &amp;openstack_origin</span><br><span class="line">applications:</span><br><span class="line">  barbican:</span><br><span class="line">    charm: cs:~openstack-charmers-next/barbican</span><br><span class="line">    num_units: 1</span><br><span class="line">    constraints: mem=1G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">relations:</span><br><span class="line">  - [ barbican, rabbitmq-server ]</span><br><span class="line">  - [ barbican, mysql ]</span><br><span class="line">  - [ barbican, keystone ]</span><br><span class="line">EOF</span><br><span class="line">./generate-bundle.sh --series bionic --release rocky --barbican</span><br><span class="line">juju deploy ./b/openstack.yaml --overlay ./b/o/barbican.yaml --overlay overlays/octavia.yaml</span><br></pre></td></tr></table></figure></p>
<p>或者:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">juju add-model bionic-barbican-octavia</span><br><span class="line">./generate-bundle.sh --series bionic --barbican</span><br><span class="line">#./generate-bundle.sh --series bionic --release rocky --barbican</span><br><span class="line">juju deploy ./b/openstack.yaml --overlay ./b/o/barbican.yaml</span><br><span class="line">#https://github.com/openstack-charmers/openstack-bundles/blob/master/stable/overlays/loadbalancer-octavia.yaml</span><br><span class="line">#NOTE: need to comment to:lxd related lines from loadbalancer-octavia.yaml, and change nova-compute num to 3</span><br><span class="line">juju deploy ./b/openstack.yaml --overlay ./overlays/loadbalancer-octavia.yaml</span><br><span class="line"></span><br><span class="line"># Or we can:</span><br><span class="line"># 2018-12-25 03:30:39 DEBUG update-status fatal error: runtime: out of memory</span><br><span class="line">juju deploy octavia --config openstack-origin=cloud:bionic:queens --constraints mem=4G</span><br><span class="line">juju deploy octavia-dashboard</span><br><span class="line">juju add-relation octavia-dashboard openstack-dashboard</span><br><span class="line">juju add-relation octavia rabbitmq-server</span><br><span class="line">juju add-relation octavia mysql</span><br><span class="line">juju add-relation octavia keystone</span><br><span class="line">juju add-relation octavia neutron-openvswitch</span><br><span class="line">juju add-relation octavia neutron-api</span><br><span class="line"></span><br><span class="line"># Initialize and unseal vault</span><br><span class="line"># https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-vault.html</span><br><span class="line"># https://lingxiankong.github.io/2018-07-16-barbican-introduction.html</span><br><span class="line"># /snap/vault/1315/bin/vault server -config /var/snap/vault/common/vault.hcl</span><br><span class="line">sudo snap install vault</span><br><span class="line">export VAULT_ADDR=&quot;http://$(juju run --unit vault/0 unit-get private-address):8200&quot;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ vault operator init -key-shares=5 -key-threshold=3</span><br><span class="line">Unseal Key 1: UB7XDri5FRcMLirKBIysdUb2PN7Ia5EVMP0Z9wD9Hyll</span><br><span class="line">Unseal Key 2: mD8Gnr3hdB2LjjNB4ugxvvsvb8+EQQ/0AXm2p+c2qYFT</span><br><span class="line">Unseal Key 3: vymYLAdou3qky24IEKDufYsZXAIPLWtErAKy/RkfgghS</span><br><span class="line">Unseal Key 4: xOwDbqgNLLipsZbp+FAmVhBc3ZxA8CI3DchRc4AClRyQ</span><br><span class="line">Unseal Key 5: nRlZ8WX6CS9nOw2ct5U9o0Za5jlUAtjN/6XLxjf62CnR</span><br><span class="line">Initial Root Token: s.VJKGhNvIFCTgHVbQ6WvL0OLe</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vault operator unseal UB7XDri5FRcMLirKBIysdUb2PN7Ia5EVMP0Z9wD9Hyll</span><br><span class="line">vault operator unseal mD8Gnr3hdB2LjjNB4ugxvvsvb8+EQQ/0AXm2p+c2qYFT</span><br><span class="line">vault operator unseal vymYLAdou3qky24IEKDufYsZXAIPLWtErAKy/RkfgghS</span><br><span class="line">export VAULT_TOKEN=s.VJKGhNvIFCTgHVbQ6WvL0OLe</span><br><span class="line">vault token create -ttl=10m</span><br><span class="line">$ vault token create -ttl=10m</span><br><span class="line">Key                  Value</span><br><span class="line">---                  -----</span><br><span class="line">token                s.7ToXh9HqE6FiiJZybFhevL9v</span><br><span class="line">token_accessor       6dPkFpsPmx4D7g8yNJXvEpKN</span><br><span class="line">token_duration       10m</span><br><span class="line">token_renewable      true</span><br><span class="line">token_policies       [&quot;root&quot;]</span><br><span class="line">identity_policies    []</span><br><span class="line">policies             [&quot;root&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Authorize vault charm to use a root token to be able to create secrets storage back-ends and roles to allow other app to access vault</span><br><span class="line">juju run-action vault/0 authorize-charm token=s.7ToXh9HqE6FiiJZybFhevL9v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># upload Amphora image</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">http_proxy=http://squid.internal:3128 wget http://tarballs.openstack.org/octavia/test-images/test-only-amphora-x64-haproxy-ubuntu-xenial.qcow2</span><br><span class="line">#openstack image create --tag octavia-amphora --disk-format=qcow2 --container-format=bare --private amphora-haproxy-xenial --file ./test-only-amphora-x64-haproxy-ubuntu-xenial.qcow2</span><br><span class="line">glance image-create --tag octavia-amphora --disk-format qcow2 --name amphora-haproxy-xenial --file ./test-only-amphora-x64-haproxy-ubuntu-xenial.qcow2 --visibility public --container-format bare --progress</span><br><span class="line"></span><br><span class="line">cd stsstack-bundles/openstack/</span><br><span class="line">./configure</span><br><span class="line">./tools/sec_groups.sh</span><br><span class="line">./tools/instance_launch.sh 2 xenial</span><br><span class="line">neutron floatingip-create ext_net</span><br><span class="line">neutron floatingip-associate $(neutron floatingip-list |grep 10.5.150.4 |awk &apos;&#123;print $2&#125;&apos;) $(neutron port-list |grep &apos;192.168.21.3&apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">or</span><br><span class="line">fix_ip=192.168.21.3</span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address $fix_ip --port $(openstack port list --fixed-ip ip-address=$fix_ip -c id -f value)</span><br><span class="line"></span><br><span class="line">cd ~/ca  #https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-octavia.html</span><br><span class="line">juju config octavia \</span><br><span class="line">    lb-mgmt-issuing-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-private-key=&quot;$(base64 controller_ca_key.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-key-passphrase=foobar \</span><br><span class="line">    lb-mgmt-controller-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-controller-cert=&quot;$(base64 controller_cert_bundle.pem)&quot;</span><br></pre></td></tr></table></figure></p>
<p>配置资源:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># the code search &apos;configure_resources&apos;</span><br><span class="line">juju config octavia create-mgmt-network</span><br><span class="line">juju run-action --wait octavia/0 configure-resources</span><br><span class="line"></span><br><span class="line"># some deubg ways:</span><br><span class="line">openstack security group rule create $(openstack security group show lb-mgmt-sec-grp -f value -c id) --protocol udp --dst-port 546 --ethertype IPv6</span><br><span class="line">openstack security group rule create $(openstack security group show lb-mgmt-sec-grp -f value -c id) --protocol icmp --ethertype IPv6</span><br><span class="line">neutron security-group-rule-create --protocol icmpv6 --direction egress --ethertype IPv6 lb-mgmt-sec-grp</span><br><span class="line">neutron security-group-rule-create --protocol icmpv6 --direction ingress --ethertype IPv6 lb-mgmt-sec-grp</span><br><span class="line"></span><br><span class="line">neutron port-show octavia-health-manager-octavia-0-listen-port -f value -c status</span><br><span class="line">neutron port-update --admin-state-up True octavia-health-manager-octavia-0-listen-port</span><br><span class="line">AGENT=$(neutron l3-agent-list-hosting-router lb-mgmt -f value -c id)</span><br><span class="line">neutron l3-agent-router-remove $AGENT lb-mgmt</span><br><span class="line">neutron l3-agent-router-add $AGENT lb-mgmt</span><br></pre></td></tr></table></figure></p>
<p>上面configure-resources命令 (juju run-action –wait octavia/0 configure-resources)将会自动配置IPv6管理网段, 并且会配置一个binding:host在octavia/0节点上的名为octavia-health-manager-octavia-0-listen-port的port.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ neutron router-list |grep mgmt</span><br><span class="line">| 0a839377-6b19-419b-9868-616def4d749f | lb-mgmt         | null                                                                                                                                                                                    | False       | False |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ neutron net-list |grep mgmt</span><br><span class="line">| ae580dc8-31d6-4ec3-9d44-4a9c7b9e80b6 | lb-mgmt-net | ea9c7d5c-d224-4dd3-b40c-3acae9690657 fc00:4a9c:7b9e:80b6::/64 |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ neutron subnet-list |grep mgmt</span><br><span class="line">| ea9c7d5c-d224-4dd3-b40c-3acae9690657 | lb-mgmt-subnetv6 | fc00:4a9c:7b9e:80b6::/64 | &#123;&quot;start&quot;: &quot;fc00:4a9c:7b9e:80b6::2&quot;, &quot;end&quot;: &quot;fc00:4a9c:7b9e:80b6:ffff:ffff:ffff:ffff&quot;&#125; |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ neutron port-list |grep fc00</span><br><span class="line">| 5cb6e3f3-ebe5-4284-9c05-ea272e8e599b |                                                      | fa:16:3e:9e:82:6a | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6::1&quot;&#125;                  |</span><br><span class="line">| 983c56d2-46dd-416c-abc8-5096d76f75e2 | octavia-health-manager-octavia-0-listen-port         | fa:16:3e:99:8c:ab | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6:f816:3eff:fe99:8cab&quot;&#125; |</span><br><span class="line">| af38a60d-a370-4ddb-80ac-517fda175535 |                                                      | fa:16:3e:5f:cd:ae | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6:f816:3eff:fe5f:cdae&quot;&#125; |</span><br><span class="line">| b65f90d1-2e1f-4994-a0e9-2bb13ead4cab |                                                      | fa:16:3e:10:34:84 | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6:f816:3eff:fe10:3484&quot;&#125; |</span><br></pre></td></tr></table></figure></p>
<p>并且在octavia/0上会创建一个名为o-hm0的接口, 此接口的IP地址与octavia-health-manager-octavia-0-listen-port port同.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ juju ssh octavia/0 -- ip addr show o-hm0 |grep global</span><br><span class="line">Connection to 10.5.0.110 closed.</span><br><span class="line">    inet6 fc00:4a9c:7b9e:80b6:f816:3eff:fe99:8cab/64 scope global dynamic mngtmpaddr noprefixroute</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ juju ssh octavia/0 -- sudo ovs-vsctl show</span><br><span class="line">490bbb36-1c7d-412d-8b44-31e6f796306a</span><br><span class="line">    Manager &quot;ptcp:6640:127.0.0.1&quot;</span><br><span class="line">        is_connected: true</span><br><span class="line">    Bridge br-tun</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;gre-0a05006b&quot;</span><br><span class="line">            Interface &quot;gre-0a05006b&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.110&quot;, out_key=flow, remote_ip=&quot;10.5.0.107&quot;&#125;</span><br><span class="line">        Port br-tun</span><br><span class="line">            Interface br-tun</span><br><span class="line">                type: internal</span><br><span class="line">        Port patch-int</span><br><span class="line">            Interface patch-int</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-tun&#125;</span><br><span class="line">        Port &quot;gre-0a050016&quot;</span><br><span class="line">            Interface &quot;gre-0a050016&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.110&quot;, out_key=flow, remote_ip=&quot;10.5.0.22&quot;&#125;</span><br><span class="line">    Bridge br-data</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port phy-br-data</span><br><span class="line">            Interface phy-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=int-br-data&#125;</span><br><span class="line">        Port br-data</span><br><span class="line">            Interface br-data</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-int</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port patch-tun</span><br><span class="line">            Interface patch-tun</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-int&#125;</span><br><span class="line">        Port &quot;o-hm0&quot;</span><br><span class="line">            tag: 1</span><br><span class="line">            Interface &quot;o-hm0&quot;</span><br><span class="line">                type: internal</span><br><span class="line">        Port br-int</span><br><span class="line">            Interface br-int</span><br><span class="line">                type: internal</span><br><span class="line">        Port int-br-data</span><br><span class="line">            Interface int-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=phy-br-data&#125;</span><br><span class="line">    Bridge br-ex</span><br><span class="line">        Port br-ex</span><br><span class="line">            Interface br-ex</span><br><span class="line">                type: internal</span><br><span class="line">    ovs_version: &quot;2.10.0&quot;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ juju ssh neutron-gateway/0 -- sudo ovs-vsctl show</span><br><span class="line">ec3e2cb6-5261-4c22-8afd-5bacb0e8ce85</span><br><span class="line">    Manager &quot;ptcp:6640:127.0.0.1&quot;</span><br><span class="line">        is_connected: true</span><br><span class="line">    Bridge br-ex</span><br><span class="line">        Port br-ex</span><br><span class="line">            Interface br-ex</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-int</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;tap62c03d3b-b1&quot;</span><br><span class="line">            tag: 2</span><br><span class="line">            Interface &quot;tap62c03d3b-b1&quot;</span><br><span class="line">        Port &quot;tapb65f90d1-2e&quot;</span><br><span class="line">            tag: 3</span><br><span class="line">            Interface &quot;tapb65f90d1-2e&quot;</span><br><span class="line">        Port int-br-data</span><br><span class="line">            Interface int-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=phy-br-data&#125;</span><br><span class="line">        Port patch-tun</span><br><span class="line">            Interface patch-tun</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-int&#125;</span><br><span class="line">        Port &quot;tap6f1478be-b1&quot;</span><br><span class="line">            tag: 1</span><br><span class="line">            Interface &quot;tap6f1478be-b1&quot;</span><br><span class="line">        Port &quot;tap01efd82b-53&quot;</span><br><span class="line">            tag: 2</span><br><span class="line">            Interface &quot;tap01efd82b-53&quot;</span><br><span class="line">        Port &quot;tap5cb6e3f3-eb&quot;</span><br><span class="line">            tag: 3</span><br><span class="line">            Interface &quot;tap5cb6e3f3-eb&quot;</span><br><span class="line">        Port br-int</span><br><span class="line">            Interface br-int</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-data</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;ens7&quot;</span><br><span class="line">            Interface &quot;ens7&quot;</span><br><span class="line">        Port br-data</span><br><span class="line">            Interface br-data</span><br><span class="line">                type: internal</span><br><span class="line">        Port phy-br-data</span><br><span class="line">            Interface phy-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=int-br-data&#125;</span><br><span class="line">    Bridge br-tun</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port patch-int</span><br><span class="line">            Interface patch-int</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-tun&#125;</span><br><span class="line">        Port &quot;gre-0a05007a&quot;</span><br><span class="line">            Interface &quot;gre-0a05007a&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.122&quot;&#125;</span><br><span class="line">        Port &quot;gre-0a05006b&quot;</span><br><span class="line">            Interface &quot;gre-0a05006b&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.107&quot;&#125;</span><br><span class="line">        Port br-tun</span><br><span class="line">            Interface br-tun</span><br><span class="line">                type: internal</span><br><span class="line">        Port &quot;gre-0a050079&quot;</span><br><span class="line">            Interface &quot;gre-0a050079&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.121&quot;&#125;</span><br><span class="line">        Port &quot;gre-0a05006e&quot;</span><br><span class="line">            Interface &quot;gre-0a05006e&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.110&quot;&#125;</span><br><span class="line">    ovs_version: &quot;2.10.0&quot;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ juju ssh neutron-gateway/0 -- cat /var/lib/neutron/ra/0a839377-6b19-419b-9868-616def4d749f.radvd.conf</span><br><span class="line">interface qr-5cb6e3f3-eb</span><br><span class="line">&#123;</span><br><span class="line">   AdvSendAdvert on;</span><br><span class="line">   MinRtrAdvInterval 30;</span><br><span class="line">   MaxRtrAdvInterval 100;</span><br><span class="line">   AdvLinkMTU 1458;</span><br><span class="line">   prefix fc00:4a9c:7b9e:80b6::/64</span><br><span class="line">   &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">   &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-health-mgr-sec-grp</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| 09a92cb2-9942-44d4-8a96-9449a6758967 | None        | None     |            | None                  |</span><br><span class="line">| 20daa06c-9de6-4c91-8a1e-59645f23953a | udp         | None     | 5555:5555  | None                  |</span><br><span class="line">| 8f7b9966-c255-4727-a172-60f22f0710f9 | None        | None     |            | None                  |</span><br><span class="line">| 90f86b27-12f8-4a9a-9924-37b31d26cbd8 | icmpv6      | None     |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-mgmt-sec-grp</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| 54f79f92-a6c5-411d-a309-a02b39cc384b | icmpv6      | None     |            | None                  |</span><br><span class="line">| 574f595e-3d96-460e-a3f2-329818186492 | None        | None     |            | None                  |</span><br><span class="line">| 5ecb0f58-f5dd-4d52-bdfa-04fd56968bd8 | tcp         | None     | 22:22      | None                  |</span><br><span class="line">| 7ead3a3a-bc45-4434-b7a2-e2a6c0dc3ce9 | None        | None     |            | None                  |</span><br><span class="line">| cf82d108-e0f8-4916-95d4-0c816b6eb156 | tcp         | None     | 9443:9443  | None                  |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ source ~/novarc</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list default</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+--------------------------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range  | Port Range | Remote Security Group                |</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+--------------------------------------+</span><br><span class="line">| 15b56abd-c2af-4c0a-8585-af68a8f09e3c | icmpv6      | None      |            | None                                 |</span><br><span class="line">| 2ad77fa3-32c7-4a20-a572-417bea782eff | icmp        | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">| 2c2aec15-e4ad-4069-abd2-0191fe80f9bb | None        | None      |            | None                                 |</span><br><span class="line">| 3b775807-3c61-45a3-9677-aaf9631db677 | udp         | 0.0.0.0/0 | 3389:3389  | None                                 |</span><br><span class="line">| 3e9a6e7f-b9a2-47c9-97ca-042b22fbf308 | icmpv6      | None      |            | None                                 |</span><br><span class="line">| 42a3c09e-91c8-471d-b4a8-c1fe87dab066 | None        | None      |            | None                                 |</span><br><span class="line">| 47f9cec2-4bc0-4d71-9a02-3a27d46b59f8 | icmp        | None      |            | None                                 |</span><br><span class="line">| 94297175-9439-4df2-8c93-c5576e52e138 | udp         | None      | 546:546    | None                                 |</span><br><span class="line">| 9c6ac9d2-3b9e-4bab-a55a-04a1679b66be | None        | None      |            | c48a1bf5-7b7e-4337-afdf-8057ae8025af |</span><br><span class="line">| b6e95f76-1b64-4135-8b62-b058ec989f7e | None        | None      |            | c48a1bf5-7b7e-4337-afdf-8057ae8025af |</span><br><span class="line">| de5132a5-72e2-4f03-8b6a-dcbc2b7811c3 | tcp         | 0.0.0.0/0 | 3389:3389  | None                                 |</span><br><span class="line">| e72bea9f-84ce-4e3a-8597-c86d40b9b5ef | tcp         | 0.0.0.0/0 | 22:22      | None                                 |</span><br><span class="line">| ecf1415c-c6e9-4cf6-872c-4dac1353c014 | tcp         | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+--------------------------------------+</span><br></pre></td></tr></table></figure></p>
<p>底层OpenStack环境(OpenStack Over Openstack)需要做 (见: <a href="https://blog.csdn.net/quqi99/article/details/78437988" target="_blank" rel="external">https://blog.csdn.net/quqi99/article/details/78437988</a> ):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openstack security group rule create $secgroup --protocol udp --dst-port 546 --ethertype IPv6</span><br></pre></td></tr></table></figure></p>
<p>最容易出现的问题是health-manager-octavia-0-listen-port port为DOWN, 从而o-hm0网络不通而无法从dhcp server处获得IP, 网段不通多半是br-int上的flow rules的问题, 我多次遇到这种情况, 但后来重建环境不知为什么又好了.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-11:~# ovs-ofctl dump-flows br-int</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.932s, table=0, n_packets=978, n_bytes=76284, priority=10,icmp6,in_port=&quot;o-hm0&quot;,icmp_type=136 actions=resubmit(,24)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.930s, table=0, n_packets=0, n_bytes=0, priority=10,arp,in_port=&quot;o-hm0&quot; actions=resubmit(,24)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.219s, table=0, n_packets=0, n_bytes=0, priority=2,in_port=&quot;int-br-data&quot; actions=drop</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.943s, table=0, n_packets=10939, n_bytes=2958167, priority=9,in_port=&quot;o-hm0&quot; actions=resubmit(,25)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.898s, table=0, n_packets=10032, n_bytes=1608826, priority=0 actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.903s, table=23, n_packets=0, n_bytes=0, priority=0 actions=drop</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.940s, table=24, n_packets=675, n_bytes=52650, priority=2,icmp6,in_port=&quot;o-hm0&quot;,icmp_type=136,nd_target=fc00:4a9c:7b9e:80b6:f816:3eff:fe99:8cab actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.938s, table=24, n_packets=0, n_bytes=0, priority=2,icmp6,in_port=&quot;o-hm0&quot;,icmp_type=136,nd_target=fe80::f816:3eff:fe99:8cab actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.879s, table=24, n_packets=303, n_bytes=23634, priority=0 actions=drop</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.951s, table=25, n_packets=10939, n_bytes=2958167, priority=2,in_port=&quot;o-hm0&quot;,dl_src=fa:16:3e:99:8c:ab actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.896s, table=60, n_packets=21647, n_bytes=4620009, priority=3 actions=NORMAL</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-11:~# ovs-ofctl dump-flows br-data</span><br><span class="line"> cookie=0xb41c0c7781ded568, duration=426779.130s, table=0, n_packets=16816, n_bytes=3580386, priority=2,in_port=&quot;phy-br-data&quot; actions=drop</span><br><span class="line"> cookie=0xb41c0c7781ded568, duration=426779.201s, table=0, n_packets=0, n_bytes=0, priority=0 actions=NORMAL</span><br></pre></td></tr></table></figure></p>
<p>如果o-hm0总是无法获得IP, 我们也可以手工配置一个IPv4管理网段试试.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">neutron router-gateway-clear lb-mgmt</span><br><span class="line">neutron router-interface-delete lb-mgmt lb-mgmt-subnetv6</span><br><span class="line">neutron subnet-delete lb-mgmt-subnetv6</span><br><span class="line">neutron port-list |grep fc00</span><br><span class="line">#neutron port-delete 464e6d47-9830-4966-a2b7-e188c19c407a</span><br><span class="line">openstack subnet create --subnet-range 192.168.0.0/24 --allocation-pool start=192.168.0.2,end=192.168.0.200 --network lb-mgmt-net lb-mgmt-subnet</span><br><span class="line">neutron router-interface-add lb-mgmt lb-mgmt-subnet</span><br><span class="line">#neutron router-gateway-set lb-mgmt ext_net</span><br><span class="line">neutron port-list |grep 192.168.0.1</span><br><span class="line"></span><br><span class="line">#openstack security group create lb-mgmt-sec-grp --project $(openstack security group show lb-mgmt-sec-grp -f value -c project_id)</span><br><span class="line">openstack security group rule create --protocol udp --dst-port 5555 lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol tcp --dst-port 22 lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol tcp --dst-port 9443 lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol icmp lb-mgmt-sec-grp</span><br><span class="line">openstack security group show lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol udp --dst-port 5555 lb-health-mgr-sec-grp</span><br><span class="line">openstack security group rule create --protocol icmp lb-health-mgr-sec-grp</span><br><span class="line"></span><br><span class="line"># create a management port o-hm0 on octavia/0 node, first use neutron to allocate a port, then call ovs-vsctl to add-port</span><br><span class="line">LB_HOST=$(juju ssh octavia/0 -- hostname)</span><br><span class="line">juju ssh octavia/0 -- sudo ovs-vsctl del-port br-int o-hm0</span><br><span class="line"># Use LB_HOST to replace juju-70ea4e-bionic-barbican-octavia-11, don&apos;t know why it said &apos;bind failed&apos; when using $LB_HOST directly</span><br><span class="line">neutron port-create --name mgmt-port --security-group $(openstack security group show lb-health-mgr-sec-grp -f value -c id) --device-owner Octavia:health-mgr --binding:host_id=juju-acadb9-bionic-rocky-barbican-octavia-without-vault-9 lb-mgmt-net --tenant-id $(openstack security group show lb-health-mgr-sec-grp -f value -c project_id)</span><br><span class="line"></span><br><span class="line">juju ssh octavia/0 -- sudo ovs-vsctl --may-exist add-port br-int o-hm0 -- set Interface o-hm0 type=internal -- set Interface o-hm0 external-ids:iface-status=active -- set Interface o-hm0 external-ids:attached-mac=$(neutron port-show mgmt-port -f value -c mac_address) -- set Interface o-hm0 external-ids:iface-id=$(neutron port-show mgmt-port -f value -c id)</span><br><span class="line">juju ssh octavia/0 -- sudo ip link set dev o-hm0 address $(neutron port-show mgmt-port -f value -c mac_address)</span><br><span class="line">ping 192.168.0.2</span><br></pre></td></tr></table></figure></p>
<h2 id="测试虚机中安装HTTPS测试服务"><a href="#测试虚机中安装HTTPS测试服务" class="headerlink" title="测试虚机中安装HTTPS测试服务"></a>测试虚机中安装HTTPS测试服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># Prepare CA and ssl pairs for lb server</span><br><span class="line">openssl genrsa -passout pass:password -out ca.key</span><br><span class="line">openssl req -x509 -passin pass:password -new -nodes -key ca.key -days 3650 -out ca.crt -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl genrsa -passout pass:password -out lb.key</span><br><span class="line">openssl req -new -key lb.key -out lb.csr -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl x509 -req -in lb.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out lb.crt -days 3650</span><br><span class="line">cat lb.crt lb.key &gt; lb.pem</span><br><span class="line">#openssl pkcs12 -export -inkey lb.key -in lb.crt -certfile ca.crt -passout pass:password -out lb.p12</span><br><span class="line"></span><br><span class="line"># Create two test servers and run</span><br><span class="line">sudo apt install python-minimal -y</span><br><span class="line">sudo bash -c &apos;cat &gt;simple-https-server.py&apos; &lt;&lt;EOF</span><br><span class="line">#!/usr/bin/env python</span><br><span class="line"># coding=utf-8</span><br><span class="line">import BaseHTTPServer, SimpleHTTPServer</span><br><span class="line">import ssl</span><br><span class="line">httpd = BaseHTTPServer.HTTPServer((&apos;0.0.0.0&apos;, 443), SimpleHTTPServer.SimpleHTTPRequestHandler)</span><br><span class="line">httpd.socket = ssl.wrap_socket (httpd.socket, certfile=&apos;./lb.pem&apos;, server_side=True)</span><br><span class="line">httpd.serve_forever()</span><br><span class="line">EOF</span><br><span class="line">sudo bash -c &apos;cat &gt;index.html&apos; &lt;&lt;EOF</span><br><span class="line">test1</span><br><span class="line">EOF</span><br><span class="line">nohup sudo python simple-https-server.py &amp;</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl -k https://10.5.150.4</span><br><span class="line">test1</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl -k https://10.5.150.5</span><br><span class="line">test2</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl --cacert ~/ca/ca.crt https://10.5.150.4</span><br><span class="line">curl: (51) SSL: certificate subject name (www.quqi.com) does not match target host name &apos;10.5.150.4&apos;</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl --resolve www.quqi.com:443:10.5.150.4 --cacert ~/ca/ca.crt https://www.quqi.com</span><br><span class="line">test1</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl --resolve www.quqi.com:443:10.5.150.4 -k https://www.quqi.com</span><br><span class="line">test1</span><br></pre></td></tr></table></figure>
<p>或者使用apache2安装ssl<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/apache2/sites-available/default-ssl.conf</span><br><span class="line">  ServerName server1.com</span><br><span class="line">  ServerAlias www.server1.com</span><br><span class="line">  SSLCertificateFile      /home/ubuntu/www.server1.com.crt</span><br><span class="line">  SSLCertificateKeyFile /home/ubuntu/www.server1.com.key</span><br><span class="line"></span><br><span class="line">vim /etc/apache2/sites-available/000-default.conf</span><br><span class="line">  ServerName server1.com</span><br><span class="line">  ServerAlias www.server1.com</span><br><span class="line"></span><br><span class="line">sudo apachectl configtest</span><br><span class="line">sudo a2enmod ssl</span><br><span class="line">sudo a2ensite default-ssl</span><br><span class="line">sudo systemctl restart apache2.service</span><br></pre></td></tr></table></figure></p>
<h2 id="测试虚机中安装HTTP测试服务"><a href="#测试虚机中安装HTTP测试服务" class="headerlink" title="测试虚机中安装HTTP测试服务"></a>测试虚机中安装HTTP测试服务</h2><p>下面的这种HTTP测试服务实际上有问题, 会导致haproxy对backend作check时报下列错误.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ae847e94-5aeb-4da6-9b66-07e1a385465b is UP, reason: Layer7 check passed, code: 200, info: &quot;HTTP status check returned code &lt;3C&gt;200&lt;3E&gt;&quot;, check duration: 7ms. 1 active and 0 backup servers online. 0 sessions requeued, 0 total in queue.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1, deploy http server in backend</span><br><span class="line">MYIP=$(ifconfig ens2|grep &apos;inet addr&apos;|awk -F: &apos;&#123;print $2&#125;&apos;| awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">while true; do echo -e &quot;HTTP/1.0 200 OK\r\n\r\nWelcome to $MYIP&quot; | sudo nc -l -p 80 ; done</span><br><span class="line">2, test it</span><br><span class="line">sudo ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b curl http://192.168.21.7:80</span><br><span class="line">3, add it into haproxy</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.7 --protocol-port 80 pool1</span><br></pre></td></tr></table></figure>
<p>并且还会导致在作haproxy vip作curl测试时返回Bad Gateway的错误.<br>所以最后在backend上运行”sudo python -m SimpleHTTPServer 80”之后解决.</p>
<h2 id="How-to-ssh-into-amphora-service-vm"><a href="#How-to-ssh-into-amphora-service-vm" class="headerlink" title="How to ssh into amphora service vm"></a>How to ssh into amphora service vm</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /etc/octavia/.ssh &amp;&amp; sudo chown -R $(id -u):$(id -g) /etc/octavia/.ssh</span><br><span class="line">ssh-keygen -b 2048 -t rsa -N &quot;&quot; -f /etc/octavia/.ssh/octavia_ssh_key</span><br><span class="line">openstack user list --domain service_domain</span><br><span class="line"># NOTE: we must add &apos;--user&apos; option to avoid the error &apos;Invalid key_name provided&apos;</span><br><span class="line">nova keypair-add --pub-key=/etc/octavia/.ssh/octavia_ssh_key.pub octavia_ssh_key --user $(openstack user show octavia --domain service_domain -f value -c id)</span><br><span class="line">nova keypair-list --user $(openstack user show octavia --domain service_domain -f value -c id)</span><br><span class="line"></span><br><span class="line">vim /etc/octavia/octavia.conf</span><br><span class="line">vim /var/lib/juju/agents/unit-octavia-0/charm/templates/rocky/octavia.conf</span><br><span class="line">vim /usr/lib/python3/dist-packages/octavia/compute/drivers/nova_driver.py</span><br><span class="line">vim /usr/lib/python3/dist-packages/octavia/controller/worker/tasks/compute_tasks.py  #import pdb;pdb.set_trace()</span><br><span class="line">[controller_worker]</span><br><span class="line">amp_ssh_key_name = octavia_ssh_key</span><br><span class="line">sudo ip netns exec qrouter-0a839377-6b19-419b-9868-616def4d749f ssh -6 -i</span><br><span class="line">~/octavia_ssh_key ubuntu@fc00:4a9c:7b9e:80b6:f816:3eff:fe5f:cdae</span><br><span class="line"></span><br><span class="line">NOTE:</span><br><span class="line">we can&apos;t ssh by: ssh -i /etc/octavia/octavia_ssh_key ubuntu@10.5.150.15</span><br><span class="line">but we can ssh by:</span><br><span class="line">sudo ip netns exec qrouter-0a839377-6b19-419b-9868-616def4d749f ssh -i ~/octavia_ssh_key ubuntu@192.168.0.12 -v</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ nova list --all</span><br><span class="line">+--------------------------------------+----------------------------------------------+----------------------------------+--------+------------+-------------+-------------------------------------------------------------+</span><br><span class="line">| ID                                   | Name                                         | Tenant ID                        | Status | Task State | Power State | Networks                                                    |</span><br><span class="line">+--------------------------------------+----------------------------------------------+----------------------------------+--------+------------+-------------+-------------------------------------------------------------+</span><br><span class="line">| 1f50fa16-bbbe-47a7-b66b-86de416d0c5e | amphora-2fae038f-08b5-4bce-a2b7-f7bd543c0314 | 5165bc7f79304f67a135fcde3cd78ae1 | ACTIVE | -          | Running     | lb-mgmt-net=192.168.0.12; private=192.168.21.6, 10.5.150.15 |</span><br><span class="line"></span><br><span class="line">openstack security group rule create lb-300e5ee7-2793-4df3-b901-17ce76da0b09 --protocol icmp --remote-ip 0.0.0.0/0</span><br><span class="line">openstack security group rule create lb-300e5ee7-2793-4df3-b901-17ce76da0b09 --protocol tcp --dst-port 22</span><br></pre></td></tr></table></figure>
<h2 id="Deploy-a-non-terminated-HTTPS-load-balancer"><a href="#Deploy-a-non-terminated-HTTPS-load-balancer" class="headerlink" title="Deploy a non-terminated HTTPS load balancer"></a>Deploy a non-terminated HTTPS load balancer</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python-octaviaclient</span><br><span class="line">openstack loadbalancer create --name lb1 --vip-subnet-id private_subnet</span><br><span class="line">#lb_vip_port_id=$(openstack loadbalancer create -f value -c vip_port_id --name lb1 --vip-subnet-id private_subnet)</span><br><span class="line"># Re-run the following until lb1 shows ACTIVE and ONLINE statuses:</span><br><span class="line">openstack loadbalancer show lb1</span><br><span class="line">nova list --all</span><br><span class="line">openstack loadbalancer listener create --name listener1 --protocol HTTPS --protocol-port 443 lb1</span><br><span class="line">openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTPS</span><br><span class="line">#openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTPS --url-path / pool1</span><br><span class="line">openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type TLS-HELLO pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.10 --protocol-port 443 pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.12 --protocol-port 443 pool1</span><br><span class="line">openstack loadbalancer member list pool1</span><br><span class="line"></span><br><span class="line">root@amphora-a9cf0b97-7f30-4b9c-b16a-7bc54526e0d0:~# ps -ef |grep haproxy</span><br><span class="line">root      1459     1  0 04:34 ?        00:00:00 /usr/sbin/haproxy-systemd-wrapper -f /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.pid -L UlKGE8M_cxJTcktjV8M-eKJkh-g</span><br><span class="line">nobody    1677  1459  0 04:35 ?        00:00:00 /usr/sbin/haproxy -f /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.pid -L UlKGE8M_cxJTcktjV8M-eKJkh-g -Ds -sf 1625</span><br><span class="line">nobody    1679  1677  0 04:35 ?        00:00:00 /usr/sbin/haproxy -f /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.pid -L UlKGE8M_cxJTcktjV8M-eKJkh-g -Ds -sf 1625</span><br><span class="line">root      1701  1685  0 04:36 pts/0    00:00:00 grep --color=auto haproxy</span><br><span class="line">root@amphora-a9cf0b97-7f30-4b9c-b16a-7bc54526e0d0:~#</span><br><span class="line">root@amphora-a9cf0b97-7f30-4b9c-b16a-7bc54526e0d0:~# cat /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer eda3efa5-dd91-437c-81d9-b73d28b5312f</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">frontend b9d5a192-1a6a-4df7-83d4-fe96ac9574c0</span><br><span class="line">    option tcplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    bind 192.168.21.16:443</span><br><span class="line">    mode tcp</span><br><span class="line">    default_backend 502b6689-40ad-4201-b704-f221e0fddd58</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend 502b6689-40ad-4201-b704-f221e0fddd58</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option ssl-hello-chk</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 49f16402-69f4-49bb-8dc0-5ec13a0f1791 192.168.21.10:443 weight 1 check inter 5s fall 3 rise 4</span><br><span class="line">    server 1ab624e1-9cd8-49f3-9297-4fa031a3ca58 192.168.21.12:443 weight 1 check inter 5s fall 3 rise 4</span><br></pre></td></tr></table></figure>
<p>有时候service vm已经创建好, 但octavia-worker因为下列原因退出导致”openstack loadbalancer create –name lb1 –vip-subnet-id private_subnet”这步执行后状态总不对.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2019-01-04 06:30:45.574 8173 INFO cotyledon._service [-] Caught SIGTERM signal, graceful exiting of service ConsumerService(0) [8173]</span><br><span class="line">2019-01-04 06:30:45.573 7983 INFO cotyledon._service_manager [-] Caught SIGTERM signal, graceful exiting of master process</span><br><span class="line">2019-01-04 06:30:45.581 8173 INFO octavia.controller.queue.consumer [-] Stopping consumer...</span><br><span class="line">2019-01-04 06:30:45.593 8173 INFO cotyledon._service [-] Caught SIGTERM signal, graceful exiting of service ConsumerService(0) [8173]</span><br></pre></td></tr></table></figure>
<h2 id="Deploy-a-TLS-terminated-HTTPS-load-balancer"><a href="#Deploy-a-TLS-terminated-HTTPS-load-balancer" class="headerlink" title="Deploy a TLS-terminated HTTPS load balancer"></a>Deploy a TLS-terminated HTTPS load balancer</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -passout pass:password -out ca.key</span><br><span class="line">openssl req -x509 -passin pass:password -new -nodes -key ca.key -days 3650 -out ca.crt -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl genrsa -passout pass:password -out lb.key</span><br><span class="line">openssl req -new -key lb.key -out lb.csr -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl x509 -req -in lb.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out lb.crt -days 3650</span><br><span class="line">cat lb.crt lb.key &gt; lb.pem</span><br><span class="line">openssl pkcs12 -export -inkey lb.key -in lb.crt -certfile ca.crt -passout pass:password -out lb.p12</span><br><span class="line"></span><br><span class="line">sudo apt install python-barbicanclient</span><br><span class="line">#openstack secret delete $(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;)</span><br><span class="line">openstack secret store --name=&apos;tls_lb_secret&apos; -t &apos;application/octet-stream&apos; -e &apos;base64&apos; --payload=&quot;$(base64 &lt; lb.p12)&quot;</span><br><span class="line">openstack acl user add -u $(openstack user show octavia --domain service_domain -f value -c id) $(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;)</span><br><span class="line">openstack secret list</span><br><span class="line">openstack loadbalancer create --name lb1 --vip-subnet-id private_subnet</span><br><span class="line"># Re-run the following until lb1 shows ACTIVE and ONLINE statuses:</span><br><span class="line">openstack loadbalancer show lb1</span><br><span class="line"></span><br><span class="line">openstack loadbalancer member list pool1</span><br><span class="line">openstack loadbalancer member delete pool1 &lt;member&gt;</span><br><span class="line">openstack loadbalancer pool delete pool1</span><br><span class="line">openstack loadbalancer listener delete listener1</span><br><span class="line">openstack loadbalancer listener create --protocol-port 443 --protocol TERMINATED_HTTPS --name listener1 --default-tls-container=$(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;) lb1</span><br><span class="line">openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTP</span><br><span class="line">openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.10 --protocol-port 80 pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.12 --protocol-port 80 pool1</span><br></pre></td></tr></table></figure>
<p>但是出错了:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca⟫ openstack loadbalancer listener create --protocol-port 443 --protocol TERMINATED_HTTPS --name listener1 --default-tls-container=$(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;) lb1</span><br><span class="line">Could not retrieve certificate: [&apos;http://10.5.0.25:9312/v1/secrets/7c706fb2-4319-46fc-b78d-81f34393f581&apos;] (HTTP 400) (Request-ID: req-c0c0e4d5-f395-424c-9aab-5c4c4e72fb3d)</span><br></pre></td></tr></table></figure>
<p>出错的原因找到, 是创建密钥时不能加密码:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out ca.key</span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -days 3650 -out ca.crt -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl genrsa -out lb.key</span><br><span class="line">openssl req -new -key lb.key -out lb.csr -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl x509 -req -in lb.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out lb.crt -days 3650</span><br><span class="line">cat lb.crt lb.key &gt; lb.pem</span><br><span class="line">openssl pkcs12 -export -inkey lb.key -in lb.crt -certfile ca.crt -passout pass: -out lb.p12</span><br></pre></td></tr></table></figure></p>
<p>但是仍然不成功, 原因已查明, 与密钥无关, 而是之前没有执行这一句(octavia_user_id=$(openstack user show octavia –domain service_domain -f value -c id); openstack acl user add -u $octavia_user_id $secret_id) 所致, 一个完整的脚本如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">#https://wiki.openstack.org/wiki/Network/LBaaS/docs/how-to-create-tls-loadbalancer#Update_neutron_config</span><br><span class="line">#https://lingxiankong.github.io/2018-04-29-octavia-tls-termination-test.html</span><br><span class="line">DOMAIN1=www.server1.com</span><br><span class="line">DOMAIN2=www.server2.com</span><br><span class="line"></span><br><span class="line">echo &quot;Create CA cert(self-signed) and key...&quot;</span><br><span class="line">CA_SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=CA&quot;</span><br><span class="line">openssl req -new -x509 -nodes -days 3650 -newkey rsa:2048 -keyout ca.key -out ca.crt -subj $CA_SUBJECT</span><br><span class="line"></span><br><span class="line">openssl genrsa -des3 -out $DOMAIN1_encrypted.key 1024</span><br><span class="line">openssl rsa -in $DOMAIN1_encrypted.key -out $DOMAIN1.key</span><br><span class="line">openssl genrsa -des3 -out $DOMAIN2_encrypted.key 1024</span><br><span class="line">openssl rsa -in $DOMAIN2_encrypted.key -out $DOMAIN2.key</span><br><span class="line"></span><br><span class="line">echo &quot;Create server certificate signing request...&quot;</span><br><span class="line">SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=$DOMAIN1&quot;</span><br><span class="line">openssl req -new -nodes -subj $SUBJECT -key $DOMAIN1.key -out $DOMAIN1.csr</span><br><span class="line">SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=$DOMAIN2&quot;</span><br><span class="line">openssl req -new -nodes -subj $SUBJECT -key $DOMAIN2.key -out $DOMAIN2.csr</span><br><span class="line"></span><br><span class="line">echo &quot;Sign SSL certificate...&quot;</span><br><span class="line">openssl x509 -req -days 3650 -in $DOMAIN1.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out $DOMAIN1.crt</span><br><span class="line">openssl x509 -req -days 3650 -in $DOMAIN2.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out $DOMAIN2.crt</span><br><span class="line"></span><br><span class="line"># NOTE: must without password when using barbican to save p12</span><br><span class="line">openssl pkcs12 -export -inkey www.server1.com.key -in www.server1.com.crt -certfile ca.crt -passout pass: -out www.server1.com.p12</span><br><span class="line">openssl pkcs12 -export -inkey www.server2.com.key -in www.server2.com.crt -certfile ca.crt -passout pass: -out www.server2.com.p12</span><br><span class="line"></span><br><span class="line">secret1_id=$(openstack secret store --name=&apos;lb_tls_secret_1&apos; -t &apos;application/octet-stream&apos; -e &apos;base64&apos; --payload=&quot;$(base64 &lt; www.server1.com.p12)&quot; -f value -c &quot;Secret href&quot;)</span><br><span class="line">secret2_id=$(openstack secret store --name=&apos;lb_tls_secret_2&apos; -t &apos;application/octet-stream&apos; -e &apos;base64&apos; --payload=&quot;$(base64 &lt; www.server2.com.p12)&quot; -f value -c &quot;Secret href&quot;)</span><br><span class="line"></span><br><span class="line"># allow octavia service user to visit the cert saved in barbican by the user in the novarc</span><br><span class="line">octavia_user_id=$(openstack user show octavia --domain service_domain -f value -c id); echo $octavia_user_id;</span><br><span class="line">openstack acl user add -u $octavia_user_id $secret1_id</span><br><span class="line">openstack acl user add -u $octavia_user_id $secret2_id</span><br><span class="line"></span><br><span class="line">IP=192.168.21.7</span><br><span class="line">subnetid=$(openstack subnet show private_subnet -f value -c id); echo $subnetid</span><br><span class="line">#lb_id=$(openstack loadbalancer create --name lb3 --vip-subnet-id $subnetid -f value -c id); echo $lb_id</span><br><span class="line">lb_id=22ce64e5-585d-43bd-80eb-5c3ff22abacd</span><br><span class="line">listener_id=$(openstack loadbalancer listener create $lb_id --name https_listener --protocol-port 443 --protocol TERMINATED_HTTPS --default-tls-container=$secret1_id --sni-container-refs $secret1_id $secret2_id -f value -c id); echo $listener_id</span><br><span class="line">pool_id=$(openstack loadbalancer pool create --protocol HTTP --listener $listener_id --lb-algorithm ROUND_ROBIN -f value -c id); echo $pool_id</span><br><span class="line">openstack loadbalancer member create --address $&#123;IP&#125; --subnet-id $subnetid --protocol-port 80 $pool_id</span><br><span class="line"></span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">vip=$(openstack loadbalancer show $lb_id -c vip_address -f value)</span><br><span class="line">vip_port=$(openstack port list --fixed-ip ip-address=$vip -c ID -f value)</span><br><span class="line">#openstack floating ip set $fip --fixed-ip-address $vip --port $vip_port</span><br><span class="line">neutron floatingip-associate $fip $vip_port</span><br><span class="line"></span><br><span class="line">curl -k https://$fip</span><br><span class="line">curl --resolve www.server1.com:443:$fip --cacert ~/ca3/ca.crt https://www.server1.com</span><br><span class="line">curl --resolve www.server2.com:443:$fip --cacert ~/ca3/ca.crt https://www.server2.com</span><br><span class="line"></span><br><span class="line">nobody    2202  2200  0 07:23 ?        00:00:00 /usr/sbin/haproxy -f /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523/dfa44538-2c12-411b-b3b3-c709bc139523.pid -L 1_a8OAWpvKuB7hMNzt8UwaJ2M00 -Ds -sf 2148</span><br><span class="line"></span><br><span class="line">root@amphora-2fae038f-08b5-4bce-a2b7-f7bd543c0314:~# cat /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer 22ce64e5-585d-43bd-80eb-5c3ff22abacd</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">frontend dfa44538-2c12-411b-b3b3-c709bc139523</span><br><span class="line">    option httplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    redirect scheme https if !&#123; ssl_fc &#125;</span><br><span class="line">    bind 192.168.21.16:443 ssl crt /var/lib/octavia/certs/dfa44538-2c12-411b-b3b3-c709bc139523/b16771bdb053d138575d60e3035d77fa0598ef5c.pem crt /var/lib/octavia/certs/dfa44538-2c12-411b-b3b3-c709bc139523</span><br><span class="line">    mode http</span><br><span class="line">    default_backend e6c4444a-a06e-4c1c-80d4-389516059d46</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend e6c4444a-a06e-4c1c-80d4-389516059d46</span><br><span class="line">    mode http</span><br><span class="line">    balance roundrobin</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 234ff0d3-5196-4536-bd49-dfbab94732d4 192.168.21.7:80 weight 1</span><br></pre></td></tr></table></figure></p>
<p>目前剩下的问题是service vm无法访问backend 192.168.21.7, 原理应该是:<br>octavia通过_plug_amphora_vip方法添加一个vip port (octavia-lb-vrrp-7e56de03-298e-43dd-a78f-33aa8d4af735), 它应该往amphora虚机上再添加一个port, 然后为此vip添加allowed_address_pairs. 但是在amphora虚机上我们没有发现这块新添的vip NIC, 重新运行下列’nova interface-attach’也不好使<br>nova list –all<br>nova interface-attach –port-id $(neutron port-show octavia-lb-vrrp-f63f0c5b-a541-442a-929c-b8ed7f7b3604 -f value -c id) 044f42c9-d205-4a11-aa8f-6b9aea896861<br>使用下列方法也不好使:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">lb_id=$(openstack loadbalancer show lb3 -f value -c id)</span><br><span class="line">old_vip=$(openstack loadbalancer show lb3 -f value -c vip_address)</span><br><span class="line">private_subnet_id=$(neutron subnet-show private_subnet -f value -c id)</span><br><span class="line"># delete old vip port (named &apos;octavia-lb-$lb_id&apos;)</span><br><span class="line">neutron port-delete octavia-lb-$lb_id</span><br><span class="line"># create new vip port with the same name and vip and binding:host_id is amphora service vm&apos;s host</span><br><span class="line"># nova show $(nova list --all |grep amphora |awk &apos;&#123;print $2&#125;&apos;) |grep OS-EXT-SRV-ATTR:host</span><br><span class="line">neutron port-create --name octavia-lb-$lb_id --device-owner Octavia --binding:host_id=juju-50fb86-bionic-rocky-barbican-octavia-8 --fixed-ip subnet_id=$&#123;private_subnet_id&#125;,ip_address=$&#123;old_vip&#125; private</span><br><span class="line">mac=$(neutron port-show octavia-lb-$lb_id -f value -c mac_address)</span><br><span class="line">nova interface-attach --port-id $(neutron port-show octavia-lb-$lb_id -f value -c id) $(nova list --all |grep amphora |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line"></span><br><span class="line">接着发现admin-state-up为False, 但enable(neutron port-update --admin-state-up True 6dc5b0bd-d0b7-4b29-9fce-b8f7b23c7914)后status仍然为DOWN. 继续检查设置如下;</span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /etc/netns/amphora-haproxy/network/interfaces</span><br><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line">source /etc/netns/amphora-haproxy/network/interfaces.d/*.cfg</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /etc/netns/amphora-haproxy/network/interfaces.d/eth1.cfg</span><br><span class="line"># Generated by Octavia agent</span><br><span class="line">auto eth1 eth1:0</span><br><span class="line">iface eth1 inet static</span><br><span class="line">address 192.168.21.34</span><br><span class="line">broadcast 192.168.21.255</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 192.168.21.1</span><br><span class="line">mtu 1458</span><br><span class="line">iface eth1:0 inet static</span><br><span class="line">address 192.168.21.5</span><br><span class="line">broadcast 192.168.21.255</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line"># Add a source routing table to allow members to access the VIP</span><br><span class="line">post-up /sbin/ip route add default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">post-down /sbin/ip route del default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">post-up /sbin/ip route add 192.168.21.0/24 dev eth1 src 192.168.21.5 scope link table 1</span><br><span class="line">post-down /sbin/ip route del 192.168.21.0/24 dev eth1 src 192.168.21.5 scope link table 1</span><br><span class="line">post-up /sbin/ip rule add from 192.168.21.5/32 table 1 priority 100</span><br><span class="line">post-down /sbin/ip rule del from 192.168.21.5/32 table 1 priority 100</span><br><span class="line">post-up /sbin/iptables -t nat -A POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line">post-down /sbin/iptables -t nat -D POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /var/lib/octavia/plugged_interfaces</span><br><span class="line">fa:16:3e:e2:3a:7f eth1</span><br><span class="line"></span><br><span class="line">ip netns exec amphora-haproxy ifdown eth1</span><br><span class="line">ip netns exec amphora-haproxy ifup eth1</span><br><span class="line">ip netns exec amphora-haproxy ifup eth1.0</span><br><span class="line">ip netns exec amphora-haproxy ip addr show</span><br><span class="line"></span><br><span class="line">但发现无法ifup eth1.0:</span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# ip netns exec amphora-haproxy ifup eth1.0</span><br><span class="line">Unknown interface eth1.0</span><br><span class="line"></span><br><span class="line">手工执行它:</span><br><span class="line">ip netns exec amphora-haproxy ifdown eth1</span><br><span class="line">ip netns exec amphora-haproxy ip addr add 192.168.21.34/24 dev eth1</span><br><span class="line">ip netns exec amphora-haproxy ip addr add 192.168.21.5/24 dev eth1</span><br><span class="line">ip netns exec amphora-haproxy ifconfig eth1 up</span><br><span class="line">ip netns exec amphora-haproxy ip route add default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">ip netns exec amphora-haproxy ip route add 192.168.21.0/24 dev eth1 src 192.168.21.5 scope link table 1</span><br><span class="line">ip netns exec amphora-haproxy ip rule add from 192.168.21.5/32 table 1 priority 100</span><br><span class="line">ip netns exec amphora-haproxy iptables -t nat -A POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line"></span><br><span class="line">此时, 可以从amphora-haproxy ping backedn vm 192.168.21.7</span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# ip netns exec amphora-haproxy ping -c 1 192.168.21.7</span><br><span class="line">PING 192.168.21.7 (192.168.21.7) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.21.7: icmp_seq=1 ttl=64 time=3.83 ms</span><br><span class="line"></span><br><span class="line">但是从neutron-gateway节点仍然无法ping vip 192.168.21.5</span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-6:~# ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b ping 192.168.21.5</span><br><span class="line">PING 192.168.21.5 (192.168.21.5) 56(84) bytes of data.</span><br><span class="line"></span><br><span class="line">继续为这个ha port添加allowed-address-pairs port, 但仍然无果.</span><br><span class="line">neutron port-update 6dc5b0bd-d0b7-4b29-9fce-b8f7b23c7914 --allowed-address-pairs type=dict list=true mac_address=fa:16:3e:e2:3a:7f,ip_address=192.168.21.5</span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# iptables-save |grep &apos;IP/MAC pairs&apos;</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.5/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.34/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-sfad3d0f9-3 -s 192.168.0.16/32 -m mac --mac-source FA:16:3E:EA:54:4F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# iptables-save |grep &apos;IP/MAC pairs&apos;</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.5/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.34/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-sfad3d0f9-3 -s 192.168.0.16/32 -m mac --mac-source FA:16:3E:EA:54:4F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# ovs-appctl bridge/dump-flows br-int |grep 192.168.21</span><br><span class="line">table_id=24, duration=513s, n_packets=6, n_bytes=252, priority=2,arp,in_port=4,arp_spa=192.168.21.5,actions=goto_table:25</span><br><span class="line">table_id=24, duration=513s, n_packets=1, n_bytes=42, priority=2,arp,in_port=4,arp_spa=192.168.21.34,actions=goto_table:25</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# ovs-appctl bridge/dump-flows br-int |grep 25,</span><br><span class="line">table_id=25, duration=48s, n_packets=0, n_bytes=0, priority=2,in_port=4,dl_src=fa:16:3e:e2:3a:7f,actions=goto_table:60</span><br><span class="line">table_id=25, duration=48s, n_packets=6, n_bytes=1396, priority=2,in_port=3,dl_src=fa:16:3e:ea:54:4f,actions=goto_table:60</span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# ovs-appctl bridge/dump-flows br-int |grep 60,</span><br><span class="line">table_id=60, duration=76s, n_packets=20, n_bytes=3880, priority=3,actions=NORMAL</span><br></pre></td></tr></table></figure></p>
<p>继续查找原因, 既然从service vm能ping backend说明网络都没问题, 现在只是无法从gateway ping service vm那说明应该还是防火墙的问题. 采用’neutron port-show <ha-vip-port>‘查看该vip port关联的是一个新security group, 添加之后问题解决:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openstack security group rule create --protocol tcp --dst-port 22 lb-7f2985f0-c0d5-47ab-b805-7f5dafe20d3e</span><br><span class="line">openstack security group rule create --protocol icmp lb-7f2985f0-c0d5-47ab-b805-7f5dafe20d3e</span><br></pre></td></tr></table></figure></ha-vip-port></p>
<p>接着就是报这个错, 后来确认是上面在backend模拟HTTP服务的方法有问题, 后改成”sudo python -m SimpleHTTPServer 80”后问题解决 .<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-6:~# ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b curl -k https://192.168.21.5</span><br><span class="line">&lt;html&gt;&lt;body&gt;&lt;h1&gt;502 Bad Gateway&lt;/h1&gt;</span><br><span class="line">Jan  6 05:14:38 amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af haproxy[2688]: 192.168.21.1:41372 [06/Jan/2019:05:14:38.038] a5b442f3-7d40-4849-8b88-7f02697bfd5b~ e25b432a-ea45-4191-9448-c364661326dc/ae847e94-5aeb-4da6-9b66-07e1a385465b 28/0/9/-1/40 502 250 - - PH-- 0/0/0/0/0 0/0 &quot;GET / HTTP/1.1</span><br></pre></td></tr></table></figure></p>
<p>整个实验结果见链接- <a href="https://paste.ubuntu.com/p/PPHv9Zfdf6/" target="_blank" rel="external">https://paste.ubuntu.com/p/PPHv9Zfdf6/</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~⟫ curl -k https://10.5.150.5</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ curl --resolve www.quqi.com:443:10.5.150.5 --cacert ~/ca2_without_pass/ca.crt https://www.quqi.com</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ curl --resolve www.quqi.com:443:10.5.150.5 -k https://www.quqi.com</span><br><span class="line">Hello World!</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-6:~# ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b curl -k https://192.168.21.5</span><br><span class="line">Hello World!</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# ip netns exec amphora-haproxy curl 192.168.21.7</span><br><span class="line">Hello World!</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /var/lib/octavia/a5b442f3-7d40-4849-8b88-7f02697bfd5b/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer 7f2985f0-c0d5-47ab-b805-7f5dafe20d3e</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/a5b442f3-7d40-4849-8b88-7f02697bfd5b.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">frontend a5b442f3-7d40-4849-8b88-7f02697bfd5b</span><br><span class="line">    option httplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    redirect scheme https if !&#123; ssl_fc &#125;</span><br><span class="line">    bind 192.168.21.5:443 ssl crt /var/lib/octavia/certs/a5b442f3-7d40-4849-8b88-7f02697bfd5b/4aa85f186d19a766c29109577d88734a8fca6385.pem crt /var/lib/octavia/certs/a5b442f3-7d40-4849-8b88-7f02697bfd5b</span><br><span class="line">    mode http</span><br><span class="line">    default_backend e25b432a-ea45-4191-9448-c364661326dc</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend e25b432a-ea45-4191-9448-c364661326dc</span><br><span class="line">    mode http</span><br><span class="line">    balance roundrobin</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server ae847e94-5aeb-4da6-9b66-07e1a385465b 192.168.21.7:80 weight 1 check inter 5s fall 3 rise 4</span><br></pre></td></tr></table></figure>
<h2 id="附件-Neutron-LBaaS-v2"><a href="#附件-Neutron-LBaaS-v2" class="headerlink" title="附件 - Neutron LBaaS v2"></a>附件 - Neutron LBaaS v2</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">https://docs.openstack.org/mitaka/networking-guide/config-lbaas.html</span><br><span class="line">neutron lbaas-loadbalancer-create --name test-lb private_subnet</span><br><span class="line">neutron lbaas-listener-create --name test-lb-https --loadbalancer test-lb --protocol HTTPS --protocol-port 443</span><br><span class="line">neutron lbaas-pool-create --name test-lb-pool-https --lb-algorithm LEAST_CONNECTIONS --listener test-lb-https --protocol HTTPS</span><br><span class="line">neutron lbaas-member-create --subnet private_subnet --address 192.168.21.13 --protocol-port 443 test-lb-pool-https</span><br><span class="line">neutron lbaas-member-create --subnet private_subnet --address 192.168.21.8 --protocol-port 443 test-lb-pool-https</span><br><span class="line">neutron lbaas-healthmonitor-create --delay 5 --max-retries 2 --timeout 10 --type HTTPS --pool test-lb-pool-https --name monitor1</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl -k  https://192.168.21.14</span><br><span class="line">test1</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl -k  https://192.168.21.14</span><br><span class="line">test2</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl --cacert /home/ubuntu/lb.pem  https://192.168.21.14</span><br><span class="line">curl: (51) SSL: certificate subject name (www.quqi.com) does not match target host name &apos;192.168.21.14&apos;</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl --cacert /home/ubuntu/lb.pem  --resolve www.quqi.com:443:192.168.21.14 https://www.quqi.com</span><br><span class="line">test1</span><br><span class="line"></span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# echo &apos;show stat;show table&apos; | socat stdio /var/lib/neutron/lbaas/v2/84fd9a6c-24a2-4c0f-912b-eedc254ac1f4/haproxy_stats.sock</span><br><span class="line"># pxname,svname,qcur,qmax,scur,smax,slim,stot,bin,bout,dreq,dresp,ereq,econ,eresp,wretr,wredis,status,weight,act,bck,chkfail,chkdown,lastchg,downtime,qlimit,pid,iid,sid,throttle,lbtot,tracked,type,rate,rate_lim,rate_max,check_status,check_code,check_duration,hrsp_1xx,hrsp_2xx,hrsp_3xx,hrsp_4xx,hrsp_5xx,hrsp_other,hanafail,req_rate,req_rate_max,req_tot,cli_abrt,srv_abrt,comp_in,comp_out,comp_byp,comp_rsp,lastsess,last_chk,last_agt,qtime,ctime,rtime,ttime,</span><br><span class="line">c2a42906-e160-44dd-8590-968af2077b4a,FRONTEND,,,0,0,2000,0,0,0,0,0,0,,,,,OPEN,,,,,,,,,1,2,0,,,,0,0,0,0,,,,,,,,,,,0,0,0,,,0,0,0,0,,,,,,,,</span><br><span class="line">52112201-05ce-4f4d-b5a8-9e67de2a895a,37a1f5a8-ec7e-4208-9c96-27d2783a594f,0,0,0,0,,0,0,0,,0,,0,0,0,0,no check,1,1,0,,,,,,1,3,1,,0,,2,0,,0,,,,,,,,,,0,,,,0,0,,,,,-1,,,0,0,0,0,</span><br><span class="line">52112201-05ce-4f4d-b5a8-9e67de2a895a,8e722b4b-08b8-4089-bba5-8fa5dd26a87f,0,0,0,0,,0,0,0,,0,,0,0,0,0,no check,1,1,0,,,,,,1,3,2,,0,,2,0,,0,,,,,,,,,,0,,,,0,0,,,,,-1,,,0,0,0,0,</span><br><span class="line">52112201-05ce-4f4d-b5a8-9e67de2a895a,BACKEND,0,0,0,0,200,0,0,0,0,0,,0,0,0,0,UP,2,2,0,,0,117,0,,1,3,0,,0,,1,0,,0,,,,,,,,,,,,,,0,0,0,0,0,0,-1,,,0,0,0,0,</span><br><span class="line"></span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# cat /var/lib/neutron/lbaas/v2/84fd9a6c-24a2-4c0f-912b-eedc254ac1f4/haproxy.conf</span><br><span class="line"># Configuration for test-lb</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    group nogroup</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    maxconn 2000</span><br><span class="line">    stats socket /var/lib/neutron/lbaas/v2/84fd9a6c-24a2-4c0f-912b-eedc254ac1f4/haproxy_stats.sock mode 0666 level user</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout client 50000</span><br><span class="line">    timeout server 50000</span><br><span class="line">frontend c2a42906-e160-44dd-8590-968af2077b4a</span><br><span class="line">    option tcplog</span><br><span class="line">    bind 192.168.21.14:443</span><br><span class="line">    mode tcp</span><br><span class="line">    default_backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">    mode tcp</span><br><span class="line">    balance leastconn</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    option ssl-hello-chk</span><br><span class="line">    server 37a1f5a8-ec7e-4208-9c96-27d2783a594f 192.168.21.13:443 weight 1 check inter 5s fall 2</span><br><span class="line">    server 8e722b4b-08b8-4089-bba5-8fa5dd26a87f 192.168.21.8:443 weight 1 check inter 5s fall 2</span><br><span class="line"></span><br><span class="line"># TCP monitor</span><br><span class="line">neutron lbaas-healthmonitor-delete monitor1</span><br><span class="line">neutron lbaas-healthmonitor-create --delay 5 --max-retries 2 --timeout 10 --type TCP --pool test-lb-pool-https --name monitor1 --url-path /</span><br><span class="line">backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">    mode tcp</span><br><span class="line">    balance leastconn</span><br><span class="line">    timeout check 10s</span><br><span class="line">    server 37a1f5a8-ec7e-4208-9c96-27d2783a594f 192.168.21.13:443 weight 1 check inter 5s fall 2</span><br><span class="line">    server 8e722b4b-08b8-4089-bba5-8fa5dd26a87f 192.168.21.8:443 weight 1 check inter 5s fall 2</span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="http://www.iceyao.com.cn/2017/11/19/Neutron-lbaas%E4%BB%A3%E7%90%86https%E5%AE%9E%E8%B7%B5/" target="_blank" rel="external">http://www.iceyao.com.cn/2017/11/19/Neutron-lbaas%E4%BB%A3%E7%90%86https%E5%AE%9E%E8%B7%B5/</a><br>[2] <a href="https://wiki.openstack.org/wiki/Network/LBaaS/docs/how-to-create-tls-loadbalancer#Update_neutron_config" target="_blank" rel="external">https://wiki.openstack.org/wiki/Network/LBaaS/docs/how-to-create-tls-loadbalancer#Update_neutron_config</a><br>[3] <a href="https://serversforhackers.com/c/using-ssl-certificates-with-haproxy" target="_blank" rel="external">https://serversforhackers.com/c/using-ssl-certificates-with-haproxy</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/31/Use-Octavia-to-Implement-HTTPS-Health-Monitors/" data-id="cjr2rybty000yaxbpljprcj0z" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-为租户下的虚机提供IPv6-DNS服务" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/29/为租户下的虚机提供IPv6-DNS服务/" class="article-date">
  <time datetime="2018-10-29T09:37:02.000Z" itemprop="datePublished">2018-10-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/29/为租户下的虚机提供IPv6-DNS服务/">为租户下的虚机提供IPv6 DNS服务</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>当虚机运行下列代码时，我们需要考虑为tenant下的VM提供DNS服务:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import dns</span><br><span class="line">import dns.resolver</span><br><span class="line">answers = dns.resolver.query(&apos;node1&apos;, &apos;AAAA&apos;)</span><br><span class="line">print answers[0].address</span><br></pre></td></tr></table></figure>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>需要截获neutron port event把IP/MAC拿到写到DNS的record中去。neutron port表的fixed_ips字段（在neutron ipallocations表里）同时记录了VM的IPv4与IPv6(netaddr.IPNetwork(fixed_ip[‘ip_address’]).version == 6)地址 [1]，neutron dns_integration特性可以从这里面将IPv4与IPv6地址都取出来记录到neutron-dhcp-agent下的dnsmasq中从而实现ml2-dns内置DNS服务。</p>
<h2 id="IPv6"><a href="#IPv6" class="headerlink" title="IPv6"></a>IPv6</h2><p>如果只是让OpenStack tenant network支持IPv6的话，很简单，直接用下列命令（下列命令有两个重要属性：<strong>ipv6_address_mode 与 ipv6_ra_mode</strong>）。当然，如果是OpenStack Over Openstack环境的话，可以让底层provider network也支持IPv6。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">neutron subnet-create --ip-version=6 --name=zhhuabj_admin_subnet_v6 --ipv6-address-mode=slaac --ipv6-ra-mode=slaac zhhuabj_admin_net 2001:db8:0:1::/64</span><br><span class="line">neutron router-interface-add zhhuabj_router zhhuabj_admin_subnet_v6</span><br></pre></td></tr></table></figure>
<p>上面命令相当于：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ cat /var/lib/neutron/ra/5c33033b-a4e1-494d-ab20-e0498b423b6c.radvd.conf</span><br><span class="line">interface qr-10bb0b85-53</span><br><span class="line">&#123;</span><br><span class="line">   AdvSendAdvert on;</span><br><span class="line">   MinRtrAdvInterval 30;</span><br><span class="line">   MaxRtrAdvInterval 100;</span><br><span class="line">   AdvLinkMTU 1458;</span><br><span class="line">   prefix 2001:db8:0:1::/64</span><br><span class="line">   &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">   &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">$ sudo ip netns exec qdhcp-be442335-ec55-4df8-b68d-dd03fa6edf00 ps -ef|grep radvd</span><br><span class="line">root     16114     1  0 Nov01 ?        00:00:00 radvd -C /var/lib/neutron/ra/5c33033b-a4e1-494d-ab20-e0498b423b6c.radvd.conf -p /var/lib/neutron/external/pids/5c33033b-a4e1-494d-ab20-e0498b423b6c.pid.radvd -m syslog</span><br><span class="line">root     16115 16114  0 Nov01 ?        00:00:00 radvd -C /var/lib/neutron/ra/5c33033b-a4e1-494d-ab20-e0498b423b6c.radvd.conf -p /var/lib/neutron/external/pids/5c33033b-a4e1-494d-ab20-e0498b423b6c.pid.radvd -m syslog</span><br><span class="line">$ sudo ip netns exec qrouter-5c33033b-a4e1-494d-ab20-e0498b423b6c ip addr show qr-10bb0b85-53 |grep inet6 |grep global</span><br><span class="line">    inet6 2001:db8:0:2::1/64 scope global</span><br><span class="line">$ sudo ip netns exec qdhcp-be442335-ec55-4df8-b68d-dd03fa6edf00 ip addr show ns-af35afad-b2 |grep inet6 |grep global</span><br><span class="line">    inet6 2001:db8:0:2:f816:3eff:feef:5190/64 scope global</span><br></pre></td></tr></table></figure>
<p>如果它不work的话，多半两个原因：<br>1, 防火墙</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo ip6tables -t filter -A INPUT -p udp -m udp --sport 547 --dport 546 -j ACCEPT</span><br><span class="line">#secgroup=$(openstack security group list |grep default| awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">#openstack security group rule create $secgroup --protocol udp --dst-port 546 --ethertype IPv6</span><br></pre></td></tr></table></figure>
<p>2, radvd进程是否正常启动</p>
<p>附1： 若是juju搭建的OpenStack环境要enable IPv6支持的话直接在yaml里添加下列内容即可：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">overrides:</span><br><span class="line">  prefer-ipv6: true</span><br></pre></td></tr></table></figure>
<p>附2： 使用OpenStack IPv6环境时，直接设置OS_AUTH_URL环境变量指向keystone的IPv6地址即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export OS_AUTH_URL=$&#123;OS_AUTH_PROTOCOL:-http&#125;://[2001:db8:0:1:f816:3eff:fe3e:5e47]:5000/v2.0</span><br></pre></td></tr></table></figure>
<h2 id="Enable-ML2-DNS"><a href="#Enable-ML2-DNS" class="headerlink" title="Enable ML2-DNS"></a>Enable ML2-DNS</h2><p>该特性有dns_name与dns_domain两个重要的属性，dns_domain可用在network与floatingip中，dns_name可用在port和floatingip中。如创建network时指定dns_name (neutron port-create my-net –dns_name my-port), 这样该dns_name和IP会作为dns record。</p>
<p>检查OpenStack是否支持dns extention API。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">neutron ext-list |grep dns</span><br><span class="line">| dns-integration           | DNS Integration</span><br></pre></td></tr></table></figure>
<p>如果不支持，可以修改下列两个文件去支持，dns_domain相当于dnsmasq给不同组织的IP提供DNS服务时的一个区别标志。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/neutron/neutron.conf</span><br><span class="line">dns_domain = example.org.</span><br><span class="line">vi /etc/neutron/plugins/ml2/ml2_conf.ini</span><br><span class="line">[ml2]</span><br><span class="line">extension_drivers = port_security,dns</span><br></pre></td></tr></table></figure>
<p>如果OpenStack是由juju创建，直接使用下列命令即可enable上述两个配置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">juju config neutron-api enable-ml2-dns</span><br><span class="line">juju config neutron-api enable-ml2-dns=True</span><br></pre></td></tr></table></figure>
<h2 id="Test-ML2-DNS"><a href="#Test-ML2-DNS" class="headerlink" title="Test ML2-DNS"></a>Test ML2-DNS</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#sudo ip addr del 2001:db8:0:122::1/64 dev ens3</span><br><span class="line">dig google.com @&lt;DNS-SERVER&gt; -p 53 AAAA</span><br><span class="line">sudo tcpdump -ni ens3 -vv ip6</span><br><span class="line">sudo dhclient -6 -d ens3</span><br></pre></td></tr></table></figure>
<h2 id="designate"><a href="#designate" class="headerlink" title="designate"></a>designate</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/neutron/neutron.conf</span><br><span class="line">external_dns_driver = designate</span><br><span class="line"></span><br><span class="line">juju deploy queens_heat_designate_20181025.yaml #https://paste.ubuntu.com/p/zMsY8j57sG/</span><br><span class="line">juju config designate nameservers=&quot;openstack-au-east-2.oc.rabonet.com.&quot;</span><br><span class="line">./configure keystonev3</span><br><span class="line"></span><br><span class="line">#https://docs.openstack.org/python-designateclient/latest/user/shell-v2.html</span><br><span class="line">openstack zone create --email test@test.com quqi.com.</span><br><span class="line">#openstack zone create --email --email test@test.com --type SECONDARY quqi2.com. --master quqi.com.</span><br><span class="line">openstack recordset list quqi.com.</span><br><span class="line">openstack recordset create --type A --record 192.0.2.20 quqi.com. test1</span><br><span class="line">dig test1.quqi.com @10.5.0.29</span><br><span class="line"></span><br><span class="line">neutron net-update 37aaff3a-6047-45ac-bf4f-a825e56fd2b3 --dns_domain example.org.</span><br><span class="line">openstack recordset list example.org.</span><br><span class="line">neutron port-create 37aaff3a-6047-45ac-bf4f-a825e56fd2b3 --dns_name my-vm</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20181029172830827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_27,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>designate的架构如上图:</p>
<ul>
<li>designate-api, 接收来自远端用户的HTTP/HTTPS请求，通过Keystone验证远端用户的合法性，将HTTP/HTTPS请求传递给Central模块。</li>
<li>designate-sink, 监听来自Nova和Neutron的某些事件，用于自动生成域名资源记录，比如当监听到Nova的compute.instance.create.end事件通知后，自动创建一条对应于刚创建的实例的A记录；当监听到Nuetron的floatingip.update.end事件通知后，自动更新一条相应的A记录。</li>
<li>designate-central, 业务逻辑处理核心。响应API请求以及处理Sink所监听到的来自Nova和Neutron的特定通知事件。同时会存取数据库，对业务逻辑处理所产生的数据进行持久化存储。</li>
<li>designate-mdns, 实现了标准的DNS Notify和Zone Transfer的处理. designate-mdns is the service that sends DNS NOTIFY and answers zone transfer (AXFR) requests. This allows Designate to integrate with any DNS server that supports these very standard methods of communicating. designate-mdns also encapsulates all other forms of DNS protocol that Designate performs. For example, sending SOA queries to check that a change is live.</li>
<li>designate-pool-manager, 连接后端驱动，管理DNS服务器池，与MiniDNS(即designate-mdns)配合同步DNS服务器的域名以及资源记录等数据。</li>
</ul>
<p>MiniDNS(designate-mdns)：Hidden Master设计<br><a href="https://blog.csdn.net/andyron/article/details/46053241" target="_blank" rel="external">https://blog.csdn.net/andyron/article/details/46053241</a><br>Hidden Master是DNS网络安全管理系统设计中所推荐的一种最佳实践。主DNS服务器“隐藏”在内网防火墙背后，负责DNS域名资源的管理并同步变更到从DNS服务器；从DNS服务器部署在DMZ区域，对外提供DNS查询服务。由于主DNS服务器不接受DNS查询，增强了安全性。Designate MiniDNS功能模块就采用了Hidden Master的设计思想。所有托管到Designate中的DNS域都将MiniDNS视为主DNS服务器，而其被委托的DNS服务器都作为从DNS服务器。MiniDNS实现了标准的DNS Notify和Zone Transfer协议，负责同步DNS域名资源记录到从DNS服务器上。<br>其工作流程如下图:<br><img src="https://img-blog.csdnimg.cn/20181029173149275.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li>首先，用户通过Desingate API创建一个example.com的DNS域；</li>
<li>Designate API将请求传递给Central，Central先将example.com域保存到数据库，接着发送RPC请求给Pool Manager；</li>
<li>Pool Manager收到来自Central的创建域名的请求之后，调用DNS后端驱动，在该域名被委托的服务器池中的所有服务器中创建example.com域。同时在这些服务器中，指定example.com的master服务器是MiniDNS；</li>
<li>Pool Manager完成所有从服务器上example.com域的创建之后，发送RPC请求给MiniDNS。</li>
<li>MiniDNS收到Pool Manager的RPC请求之后，向从服务器发送DNS Notify消息，告诉从服务器example.com有资源更新。</li>
<li>从服务器收到DNS Notify消息后，要求主从数据库启动Zone Transfer，域迁移的方式可以是AXFR，也可以是IXFR。</li>
<li>主服务器从数据库中读取为example.com域自动创建的SOA和NS记录，并将SOA和NS记录传送到从服务器。<br>后续任何对example.com域的变更操作都会遵循上述过程，由MiniDNS将变更同步到Designate所委派管理example.com域的DNS服务器上。</li>
</ul>
<p>看一下代码结构, designate支持很多backend(eg: bind), 安装bind服务的机器上可使用rndc命令行工具create/delete zone remotely. The traffic between rndc and bind/named(953/tcp) is authenticated with a key. designate将为每个pool生成下列配置, 这样就可以远程运行rndc命令了(rndc -s 10.5.0.29 -p 953 -k /etc/designate/rndc.key status), 其中5353是designate-mdns监听的端口:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/designate/pools.yaml</span><br><span class="line">- id: 794ccc2c-d751-44fe-b57f-8894c9f5c842</span><br><span class="line">  name: default</span><br><span class="line">  description: Pool genergated by Juju</span><br><span class="line">  ns_records:</span><br><span class="line">    - hostname: openstack-au-east-2.oc.xxx.com.</span><br><span class="line">      priority: 10</span><br><span class="line">  nameservers:</span><br><span class="line">    - host: 10.5.0.29</span><br><span class="line">      port: 53</span><br><span class="line">  targets:</span><br><span class="line">    - type: bind9</span><br><span class="line">      masters:</span><br><span class="line">        - host: 10.5.0.23</span><br><span class="line">          port: 5354</span><br><span class="line">      options:</span><br><span class="line">        host: 10.5.0.29</span><br><span class="line">        rndc_host: 10.5.0.29</span><br><span class="line">        rndc_key_file: /etc/designate/rndc.key</span><br><span class="line">  also_notifies: []</span><br></pre></td></tr></table></figure></p>
<p>在designate-bind节点上装有bind服务(运行在953端口, /usr/sbin/named -f -u bind), 需要确保bind能够访问/etc/bind/named.conf和/etc/bind/rndc.key, 并且能够接受从Pool Manager过来的rndc流量:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/bind/named.conf</span><br><span class="line">include &quot;/etc/bind/named.conf.options&quot;;</span><br><span class="line">include &quot;/etc/bind/named.conf.local&quot;;</span><br><span class="line">include &quot;/etc/bind/named.conf.default-zones&quot;;</span><br><span class="line">controls &#123;</span><br><span class="line">  inet 127.0.0.1 allow &#123;localhost;&#125;;</span><br><span class="line">  inet 10.5.0.29 allow &#123; 10.5.0.23; &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"># cat /etc/bind/named.conf.options</span><br><span class="line">options &#123;</span><br><span class="line">        directory &quot;/var/cache/bind&quot;;</span><br><span class="line">        dnssec-validation auto;</span><br><span class="line">        auth-nxdomain no;    # conform to RFC1035</span><br><span class="line">        listen-on-v6 &#123; any; &#125;;</span><br><span class="line">        allow-new-zones yes;</span><br><span class="line">        request-ixfr no;</span><br><span class="line">        recursion no;</span><br><span class="line">        statistics-file &quot;/var/cache/bind/named.stats&quot;;</span><br><span class="line">        zone-statistics yes;</span><br><span class="line">        allow-notify &#123; 10.5.0.23; &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>rndc命令:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rndc querylog</span><br><span class="line">rndc status</span><br><span class="line">dig -t A openstack-au-east-2.oc.xxx.com@10.5.0.23</span><br><span class="line">dig -t MX openstack-au-east-2.oc.xxx.com@10.5.0.23</span><br></pre></td></tr></table></figure></p>
<p>bind DNS服务器可作为缓存服务器, 主DNS服务器和辅助DNS服务器, 配置分配如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 缓存服务器, 不负责解析，仅为加速，不需要注册</span><br><span class="line">options &#123;</span><br><span class="line">       forward only;</span><br><span class="line">       forwarders &#123;</span><br><span class="line">               168.95.1.1;</span><br><span class="line">               139.175.10.20;</span><br><span class="line">       &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"># 主DNS服务器, 负责解析本地客户端请求</span><br><span class="line">zone &quot;test.com&quot; IN &#123;</span><br><span class="line">       type master;</span><br><span class="line">       file &quot;test.com.zone&quot;;</span><br><span class="line">&#125;;</span><br><span class="line"># 辅助DNS服务器, 辅助服务器的区域数据都是从主服务器复制而来，其数据都是只读的. 根据序列号大小决定是否复制</span><br><span class="line">zone &quot;test.com&quot; IN &#123;</span><br><span class="line">       type slave;</span><br><span class="line">       masters &#123;ip;&#125;;</span><br><span class="line">       file &quot;slaves/test.com.zone&quot;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>区域传送, 解析库文件同步的过程，即辅助DNS服务器从主DNS服务器或其他的辅助DNS服务器请求数据传输过程 。</p>
<ul>
<li>完全区域传送：传送区域的所有数据，简称AXFR</li>
<li>增量区域传送：传送区域中改变的数据部分，简称IXFR<br>bind配置中之DNS主从同步，区域安全传送<br><a href="http://www.it165.net/admin/html/201403/2548.html" target="_blank" rel="external">http://www.it165.net/admin/html/201403/2548.html</a></li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://github.com/openstack/neutron/blob/stable/pike/neutron/plugins/ml2/extensions/dns_integration.py#L285" target="_blank" rel="external">https://github.com/openstack/neutron/blob/stable/pike/neutron/plugins/ml2/extensions/dns_integration.py#L285</a><br>[2] <a href="https://docs.openstack.org/mitaka/networking-guide/config-dns-int.html" target="_blank" rel="external">https://docs.openstack.org/mitaka/networking-guide/config-dns-int.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/10/29/为租户下的虚机提供IPv6-DNS服务/" data-id="cjr2rybte000kaxbp9aghukan" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/10/hello-world/" class="article-date">
  <time datetime="2018-09-10T05:57:54.513Z" itemprop="datePublished">2018-09-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/10/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/10/hello-world/" data-id="cjr2rybtb000gaxbpgeiol0ri" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Win-10-UEFI-Ubuntu-18-04-UEFI-双系统" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/09/Win-10-UEFI-Ubuntu-18-04-UEFI-双系统/" class="article-date">
  <time datetime="2018-09-08T17:28:15.000Z" itemprop="datePublished">2018-09-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/09/Win-10-UEFI-Ubuntu-18-04-UEFI-双系统/">Win 10 UEFI + Ubuntu 18.04 UEFI 双系统</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本人昨天买了一块SSD, 结果后来发现原来这块SSD存在硬件质量问题, 造成了软件上的种种诡异问题, 如U盘时而识别时而不识别, 如触摸屏左键时而抽风, 如ghost安装win10时几乎到100%的进度时忽然来一个无响应, 重启系统后出现了”To interrupt normal start up, press the blue ThinkVantage button.”, 此时键盘无反应, 既进不了系统, 也进不了BIOS. 拨CMOS电源也无效. 最后发现是这块SSD有质量问题. 估计是SSD有控制器主要是软件吧, 控制器软件有bug导致运行ghost这种软件时也能导致硬件挂住.<br>也正是因为这个问题吧, 七搞八搞, 一不小心在重试的过程中将之前的一块linux分区误删了, 于是之前打算的迁移双系统的想法泡汤(当然, 那些通过分区助手或者ghost来迁移分区的网上文章照着做没一个是成功的).<br>这样, 有机会事隔多年再一次重装双系统的机会, 但是发现世道变了, 之前百试不爽的方法现在行不通了. 后经查证, 主要原因是ubuntu 18.04开始默认采用UEFI, 而win10默认仍然是MBR. 这样会导致一系列的问题, 如报错: grub-efi-amd64-signed failed to install 18.04, 统一采用UEFI安装.</p>
<h2 id="BIOS设置"><a href="#BIOS设置" class="headerlink" title="BIOS设置"></a>BIOS设置</h2><p>在BIOS中将Boot Mode设置为UEFI Only, 如果有Secure Boot选项还要disable它(不做这一步可能会造成按F12键之后无法找到U盘)<br>注: 改成UEFI only之后, 运行双系统, 四系统都没问题, 但后来进不了U盘的livecd, 报: couldn’t get UEFI db list, 所以只得改回Both, 但UEFI优先.</p>
<h2 id="安装win10"><a href="#安装win10" class="headerlink" title="安装win10"></a>安装win10</h2><ul>
<li>下载大白菜UEFI专版 - <a href="http://www.bigbaicai.com/download.html?down2" target="_blank" rel="external">http://www.bigbaicai.com/download.html?down2</a></li>
<li>下载win10 ghost - axel -n 10 <a href="http://xz.win10cjb.com/18.5/win10_64/DEEP_Win10x64_201805.rar" target="_blank" rel="external">http://xz.win10cjb.com/18.5/win10_64/DEEP_Win10x64_201805.rar</a></li>
<li>制作大白菜启动U盘, 如果界面上有UEFI字眼就点上(不记得了, 有就点上), 还要注意一点, 记得点里面的格式转换, 将FAT32格式(HDD-FAT32)转换成NTFS(HDD-NTFS)转换, 否则HDD-FAT32格式不能拷贝大于4G的ghost文件哦,</li>
<li>按F12选U盘启动进入大白菜后, 用DiskGenius工具重新分区, 必须将BIOS+MBR格式转UEFI+GPT格式. 分区表格式为GUID而不是MBR, window上管EFI分区叫ESP/MSR分区</li>
<li><p>注意, 不要修改推荐的卷标, 这个卷就是指向的ESP/MSR分区.</p>
<h2 id="安装win10后"><a href="#安装win10后" class="headerlink" title="安装win10后"></a>安装win10后</h2><p>安装win10后需要将禁用掉快速启动, 否则会造成按F12无法选择U盘启动. 菜单路径为: “设置 -&gt; 系统 -&gt; 电源与睡眠 -&gt; 其他电源设置 -&gt; 选择电源按钮的功能 -&gt; 更改当前不可用的设置 -&gt; 启动快速启动”</p>
<h2 id="安装ubuntu-18-04"><a href="#安装ubuntu-18-04" class="headerlink" title="安装ubuntu 18.04"></a>安装ubuntu 18.04</h2><p>像安装win10一样, 一样要注意重要一点, 需创建大概300M左右的UEF分区, 另外, 还可以创建一个根分区和一个备份文件用的bak分区.<br>注意, windows非常霸道, 它是总修改bios里的启动顺序, 将它的”Windows boot Manager”放在”ubuntu grub”的前面, 可以在bios里锁定启动顺序</p>
<h2 id="安装win7"><a href="#安装win7" class="headerlink" title="安装win7"></a>安装win7</h2><p>win7若没有sata的驱动, 所以得先改回IDE, 装完win7之后再改回AHCI, 否则也容易挂在启动界面不动了.<br>注: 我未遇到以上问题, 可能因为我装的win7并不是原版的, 已经带了sata驱动</p>
<h2 id="加装SSD"><a href="#加装SSD" class="headerlink" title="加装SSD"></a>加装SSD</h2><p>如果加装了SSD之后呢? 那得注意:</p>
</li>
<li><p>装win10时同样需要进大白菜或老毛桃后用DiskGenius在SSD上划分ESP/MSR分区</p>
</li>
<li>装ubuntu时, 分区处也要创建EFI分区, 同时grub设置安装在SSD上, 相当于: grub-install /dev/sdX.</li>
<li>bios里选择哪块硬盘启动. 其实在SSD上安装grub后, 这个grub会连HDD上原先的win10与ubuntu一起放在启动列表里. 注意, windows非常霸道, 它是总修改bios里的启动顺序, 将它的”Windows boot Manager”放在”ubuntu grub”的前面, 可以在bios里锁定启动顺序</li>
<li><p>有时候需要对ssd优化, 例如不要将swap分区放在ssd以延长寿命, 如更改i/o调度策略为noop, 如使用bcache</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>装完之后进入win10发现thinkpad小红点左键失灵, 再切换进ubuntu发现小红点左键正常(实际上, 5次大概有一次有问题, 只是登录界面左键与右键似乎混乱了, 登录之后就正常了. 再换PE进系统发现小红点左键依然有问题. 所以基本断定和硬件没有关系, 应该是win10上的小红点驱动有问题.<br>但搜索了很多帖子, 没一个能解决问题的, 联想的小红点win10驱动做得太烂了. 所以决定回到win7, 回到win7之后该问题解决. 另外, PE回到win7的过程中不会伤害之前SSD上安装的ubuntu系统, 也不会伤害原HDD里的双系统.</p>
<h2 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h2><p>现在在笔记本x220t上装了win10, 也装了ubuntu 18.04, 但是如何将工作机t440p的根分区迁移到x220t的根分区呢? 因为我们已经在x220t上安装了ubuntu 18.04, 这样省去了采用命令划分EFI分区, 以及最后填充EFI分区的步骤. 现在将精力集中在如何快速迁移根分区上.</p>
</li>
<li><p>目的机x220t因为有写操作, 故要以livecd启动, 启动ssh server, 并将根分区加载到/mnt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo -i</span><br><span class="line">apt install openssh-server</span><br><span class="line">passwd</span><br><span class="line">echo &apos;PermitRootLogin yes&apos; &gt;&gt; /etc/ssh/sshd_config</span><br><span class="line">service ssh restart</span><br><span class="line">fdisk -l</span><br><span class="line">mount /dev/sdb8 /mnt</span><br></pre></td></tr></table></figure>
</li>
<li><p>源机t440p最好也以livecd启动, 注意: 例如源机上有一个软链指向了/bak分区, 但因为此时没有挂载/bak分区, 所以在rsync命令迁移时会报错退出. 人工删除该软链重新运行即可.  且需要注意 rsync命令中的/mnt/后应该有/, 否则会将mnt目录迁移到根分区的mnt目录下.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo -i</span><br><span class="line">fdisk -l</span><br><span class="line">mount /dev/sda9 /mnt</span><br><span class="line"></span><br><span class="line"># rsync will now copy all files, directories, permissions and owners over to the destination machine.</span><br><span class="line"># It also skips all files and directories that are not on the root filesystem, like /dev/, /sys/, /proc/.</span><br><span class="line"># If there are filesystems that are mounted separately on the source machine and your want those copied too, use rsync again on those mountpoints too.</span><br><span class="line">rsync -xavP --numeric-ids --exclude=&apos;tmp&apos; /mnt root@192.168.99.128:/</span><br><span class="line">#rsync -xavP --numeric-ids --exclude=&apos;tmp&apos; --exclude=&apos;/nas&apos; /mnt/ root@192.168.99.128:/mnt/</span><br></pre></td></tr></table></figure>
</li>
<li><p>更新grub, 此时会报”canot find EFI directory”, 这样会导致这时生成grub时无法找到原HDD中的双系统, 不要紧, 只要找到目前SSD中的双系统即可. 呆会下一步再运行一下grub命令即可解决</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/sdb8 /mnts</span><br><span class="line">for d in dev sys proc; do mount --bind /$d /mnt/$d; done</span><br><span class="line">chroot /mnt/ grub-install /dev/sdb   # canot find EFI directory</span><br><span class="line">chroot /mnt/ update-grub</span><br></pre></td></tr></table></figure>
</li>
<li><p>修复fstab, 之前运行上述迁移命令前忘了备份x220t上的fstab系统, 导致它被覆盖, OK, 我们修复它.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">blkid</span><br><span class="line">e2label /dev/sdb8 &quot;ROOT_SSD&quot;</span><br><span class="line">tee &quot;/mnt/etc/fstab&quot; &lt;&lt;EOF</span><br><span class="line">#UUID can be found via blkid command</span><br><span class="line">#LABEL=boot /boot ext2 sync 0 2</span><br><span class="line">#UUID=735b3be3-779c-4d21-a944-b033225f3ab4 none   swap    sw      0       0</span><br><span class="line">#LABEL=SWAP none swap sw 0 0</span><br><span class="line">UUID=9401-D2EA /boot/efi vfat defaults 0 2</span><br><span class="line">LABEL=ROOT_SSD / ext4 errors=remount-ro 0 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
<li><p>这时重启系统, 就可以以grub选择启动SSD上的双系统了, 如果还想把HDD的原有的双系统也加到grub的话, 那进ubuntu系统后再执行一次update-grub命令即可.</p>
</li>
<li>这种迁移方式效果非常好, 各种工作软件不需要再重装了. 呵呵<h2 id="调整分区"><a href="#调整分区" class="headerlink" title="调整分区"></a>调整分区</h2>一个分区不够用时, 可以使用gpartd合并相邻的空闲分区.注意一点, 要合并的分区必须是umount状态时才能合并.<h2 id="SSD优化"><a href="#SSD优化" class="headerlink" title="SSD优化"></a>SSD优化</h2></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"># disable scanning for btrfs filesystems when boot</span><br><span class="line">sudo apt-get purge btrfs-tools</span><br><span class="line">sudo update-initramfs -ukall</span><br><span class="line"></span><br><span class="line"># enable TRIM feature by adding discard option</span><br><span class="line"># what&apos;s TRIM - https://blog.csdn.net/quqi99/article/details/50963308</span><br><span class="line"># the option noatime is used to disable access time for a file</span><br><span class="line">sudo hdparm -I /dev/sdb |grep TRIM</span><br><span class="line">vi /etc/fstab</span><br><span class="line">LABEL=ROOT_SSD /               ext4    noatime,discard,errors=remount-ro 0       1</span><br><span class="line">sudo mount -o remount /dev/sdb8</span><br><span class="line">sudo mount |grep sdb8 |grep discard</span><br><span class="line"></span><br><span class="line"># Try not to use swap space unless it&apos;s running out of memory.</span><br><span class="line">echo 1 &gt; /proc/sys/vm/swappiness</span><br><span class="line"></span><br><span class="line"># avoid visiting ssd by using ramdisk for /tmp instead of tmpfs</span><br><span class="line">vim /etc/fstab</span><br><span class="line">tmpfs /tmp tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">tmpfs /var/tmp tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">tmpfs /var/log tmpfs defaults,noatime,mode=1777 0 0</span><br><span class="line">sudo mount -o remount /</span><br><span class="line"></span><br><span class="line"># Set chrome to use ramdisk cache</span><br><span class="line">cd ~/.cache/google-chrome/Default</span><br><span class="line">rm -rf Cache</span><br><span class="line">sudo ln -s /tmp Cache</span><br><span class="line">rm -rf Media\ Cache/</span><br><span class="line">sudo ln -s /tmp Media\ Cache</span><br><span class="line"></span><br><span class="line"># Use noop for I/O elevator</span><br><span class="line">cat /sys/block/sda/queue/scheduler</span><br><span class="line">sudo vi /etc/default/grub</span><br><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=&quot;elevator=noop&quot;</span><br><span class="line">sudo update-grub</span><br><span class="line"></span><br><span class="line"># Test SSD speed</span><br><span class="line">$ sudo hdparm -Tt /dev/sdb</span><br><span class="line">/dev/sdb:</span><br><span class="line"> Timing cached reads:   9128 MB in  2.00 seconds = 4569.28 MB/sec</span><br><span class="line"> Timing buffered disk reads: 818 MB in  3.01 seconds = 272.07 MB/sec</span><br><span class="line"></span><br><span class="line"># Make sure 4K align</span><br><span class="line">$ sudo fdisk -lu |grep sdb |grep sectors</span><br><span class="line">Disk /dev/sdb: 232.9 GiB, 250059350016 bytes, 488397168 sectors</span><br><span class="line"></span><br><span class="line"># Health check</span><br><span class="line">$ sudo smartctl -s on -a /dev/sdb |grep PASSED</span><br><span class="line">SMART overall-health self-assessment test result: PASSED</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/09/Win-10-UEFI-Ubuntu-18-04-UEFI-双系统/" data-id="cjr2rybth000maxbp8ywd2r3q" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-也谈wifi断流问题" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/03/也谈wifi断流问题/" class="article-date">
  <time datetime="2018-09-03T04:02:42.000Z" itemprop="datePublished">2018-09-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/03/也谈wifi断流问题/">也谈wifi断流问题</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-09-03)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>笔者最近应该是遇到了常听大家说起的wifi断流问题, 新入一款安卓原生系统手机, 但是在使用wifi上网时会感觉到某些APP上网不流畅, 尤其是使用京东APP搜索商品时会总说找不着网络, 但此时显然是有网络的. 为此, 笔者先做了一系统排除性实验:</p>
<ul>
<li>排除法测试, 使用京东APP搜索商品时说找不着网络, 但使用京东APP的其他功能没有问题, 并且使用京东以外的其他APP也没问题</li>
<li>排除法测试, 切换为4G网络使用京东APP搜索商品正常, 仅仅只是使用WIFI网络时才会出问题.</li>
<li>排除法测试, 去麦当劳使用WIFI确认无问题, 但速度也不快, 但能打开页面.</li>
<li>排除法测试, 难道是家里的WIFI有问题吗? 但换个手机型号使用京东APP搜索商品却又正常.</li>
<li>排除法测试, 难道是VPN的问题? 关掉VPN, 恢复DNS国内设置依然有问题. </li>
<li>排除法测试, 继续换一个没有VPN的干净的OpenWRT路由器依然有问题, 可惜家里没有Non-OpenWRT路由器可供测试.</li>
<li>排除法测试, 路由器上修改802.11g, 802.11n, 802.11ac等设置后问题依旧.</li>
<li>排除法测试, 检查了路由器上的MAC地址是否与其他机器重复, 未发现异常</li>
<li>排除法测试, 使用114.114.114.114作为DNS, 问题依旧</li>
<li>排除法测试, OpenWRT路由器使用tcpdump抓包, 干扰条目过多, 未深入</li>
<li>排除法测试, 现在问题看起来只是发生在这款特定手机型号与特定的OpenWRT路由器与特定的某些APP如京东, 手机刷机到android 8.1与7.1两个版本问题依旧.</li>
<li>排除法测试, google搜索大量京东或别的某些应用在各种手机型号上出问题的帖子, 试着更改帖子中的各种切换手机配置的操作, 如不对京东使用电源优化,问题依旧.</li>
<li>排除法测试, 绝大多数时候打不开京东的这个搜索商品的功能, 但极少数情况又能打开, 但非常慢, 使用别家的wifi网络时也是非常慢, 很难说清楚现象.<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2>上述一系列排除性测试让我相信该问题仅和我使用特定的手机型号, 使用特定的OpenWRT路由器, 使用特定的某些APP如京东有关.<br>京东APP, 一个上层应用而已, 理论上只有下列几个因素会影响到上层应用:</li>
<li>DNS</li>
<li>IPv6/IPv4 fallback</li>
<li>MTU<br>理论让我将目光回到MTU, 修改OpenWRT路由器WAN口的MTU=1492后问题依旧.继续深挖:</li>
<li>路由器背后的手机操作系统应该有/proc/sys/net/ipv4/ip_no_pmtu_disc=0让手机可以根据pmtu来确实应用所需的mss值. 遗憾地是, 手机没有root, 无法检查此项值.</li>
<li>OpenWRT路由器tcpdump抓包, 看到的mss值确实不小. 既然无root权限无法修改手机的ip_no_pmtu_disc参数, 那有没有方法直接修改OpenWRT路由器强迫修改mss值呢?<br>OK, 在路由器上添加如下两个命令, 问题就这么解决了:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#iptables -A FORWARD -j ACCEPT</span><br><span class="line">iptables -t mangle -A FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# iptables-save |grep mss</span><br><span class="line">:mssfix - [0:0]</span><br><span class="line">-A FORWARD -j mssfix</span><br><span class="line">-A FORWARD -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">-A mssfix -o pppoe-wan -p tcp -m tcp --tcp-flags SYN,RST SYN -m comment --comment &quot;wan (mtu_fix)&quot; -j TCPMSS --clamp-mss-to-pmtu</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这款手机的操作系统没有设置ip_no_pmtu_disc参数去协商mss值, 而OpenWRT路由器刚好缺一条iptables rule (iptables -t mangle -A FORWARD -p tcp –tcp-flags SYN,RST SYN -j TCPMSS –clamp-mss-to-pmtu), 这样遭遇了pppoe的1492 MTU问题.<br>换句话说, 当我外出时, 如果所连的路由器没有加这条设置, 那么这个问题仍然又遇到. 手机操作系统ip_no_pmtu_disc设置才能彻底解决某些应用wifi网络不能上网的问题. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/03/也谈wifi断流问题/" data-id="cjr2rybti000naxbpah1lx81w" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-IPv6来啦" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/03/IPv6来啦/" class="article-date">
  <time datetime="2018-08-03T08:01:05.000Z" itemprop="datePublished">2018-08-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/03/IPv6来啦/">IPv6来啦</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-08-03)</strong><br><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-08-03)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>家里用的是中国移动的宽带, 一直挺稳定的, 而且昨天发现ISP下发了IPv6地址(不是子网, 形如: 2409:8a00:7805:xxxx:xxxx:xxxx:xxxx:xxxx/64, 打xxxx的部分是动态变化的). 好吧, 咱就用用.</p>
<h2 id="路由器配置"><a href="#路由器配置" class="headerlink" title="路由器配置"></a>路由器配置</h2><ul>
<li><p>配置/etc/config/network使用’option ip6assign ‘64’</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config interface &apos;lan&apos;</span><br><span class="line">        ...</span><br><span class="line">        option ip6assign &apos;64&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置/etc/confignetwork删除config globals ‘globals’段中和 IPv6 ULA-Prefix相关的配置 (注: 使用IPv6 ULA-Prefix的话, LAN中机器就会得到一个以它打头的IPv6地址, 但如何从外网访问这个地址呢? 有三种方式: 一是使用我们现在使用的relay方式得到是ISP提供的全球可路由的IPv6地址；二是配置ULA-Prefix=2409:8a00:7805:1::/80之后再使用下列的neigh proxy的方法解决, 但这种一般是子网长度80比64大, 但ISP并没有给我们分配subnet, 只是分配了IPv6地址, 所以无法保证2409:8a00:7805:1::/80这个前缀与ISP分配的2409:8a00:7805:xxxx:xxxx:xxxx:xxxx:xxxx/64一致；三是ULA-Prefix配置一个与ISP分配的不同的路由然后通过配置路由的方式但前提是也得有全球可路由的IPv6 subnet啊. 所以这里我们选择了relay模式来实现外网访问内网的目的.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv6.conf.all.proxy_ndp=1</span><br><span class="line">ip -6 neigh add proxy 2409:8a00:7805:1::430 dev pppoe-wan</span><br><span class="line">ip -6 neigh show proxy</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置/etc/config/dhcp使用relay模式, relay模式意味着openwrt通过默认的odhcpd作为中继自动为LAN的其他机器配置ISP的IPv6地址</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">config dhcp &apos;wan&apos;</span><br><span class="line">        option interface &apos;wan&apos;</span><br><span class="line">        option ignore &apos;1&apos;</span><br><span class="line">        option dhcpv6 &apos;disabled&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br><span class="line">        option master &apos;1&apos;</span><br><span class="line">config dhcp &apos;lan&apos;</span><br><span class="line">        option interface &apos;lan&apos;</span><br><span class="line">        option start &apos;100&apos;</span><br><span class="line">        option limit &apos;150&apos;</span><br><span class="line">        option leasetime &apos;12h&apos;</span><br><span class="line">        list dhcp_option &apos;6,192.168.99.1&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br><span class="line">        option dhcpv6 &apos;relay&apos;</span><br><span class="line"></span><br><span class="line"># actually I use 60, not 64</span><br><span class="line">cat /etc/config/network</span><br><span class="line">config interface &apos;lan&apos;</span><br><span class="line">	...</span><br><span class="line">	option ip6assign &apos;60&apos;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>配置完之后就可以通过下列命令重启路由器服务就可以在br-lan与pppoe-wan上获得ISP分配的IPv6地址了.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/network restart</span><br><span class="line">/etc/init.d/odhcpd restart</span><br></pre></td></tr></table></figure></p>
<p>内网机器直接通过’sudo /etc/init.d/network-manager restart’重启网络也会获取ISP分配的IPv6地址.</p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><ul>
<li>内网机器访问br-lan内网网关, 能通是因为下列路由的功能:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hua@t440p:~$ ip -6 route list |grep 2409:8a00:7805:b7df::/64</span><br><span class="line">2409:8a00:7805:b7df::/64 dev eth0  proto ra  metric 100  pref medium</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# route -A inet6 |grep ::/0</span><br><span class="line">::/0                                        fe80::200:5eff:fe00:134                 UG    1024   0        0</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>注: 后面我们会看到::/0的默认路由会造成很多问题.</p>
<ul>
<li><p>内网机器访问pppoe-wan外网网关<br>对于relay模式由于内网机器拿到的本来就是ISP分配的可路由的IP所以自然能通. 但对于nat模式由于内网机器分配的是和ISP不同网段的IP, 所以需要在路由器上做NAT6, 如:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#ip6tables -t nat -I POSTROUTING -o pppoe-wan -j MASQUERADE</span><br><span class="line">ip6tables -t nat -I POSTROUTING -s `uci get network.globals.ula_prefix` -j MASQUERADE &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
</li>
<li><p>外网访问内网机器<br>如果使用relay由于内网机器使用的是全球可路由的IPv6地址, 外网直接就是可以访问内网机器的；但如果是不同子网需要做路由；如果只是前缀相同只是子网长度不同可以做neigh proxy</p>
</li>
<li>但是此时我们发现内网机器无法访问外网(如ping6 ipv6.baidu.com), 但此时在路由器上却是可以访问外网的. 原因就在于上面使用::/0的默认路由似乎有问题(报这个错: Destination unreachable: Unknown code 5), 改成了2000::/3就好了:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route -A inet6 add 2000::/3 `route -A inet6 | grep ::/0 | awk &apos;NR==1&#123;print&quot;gw &quot;$2&quot; dev &quot;$7&#125;&apos;`</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>或者:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip -6 route add default from 2409:8a00:7805::48 dev pppoe-wan</span><br></pre></td></tr></table></figure></p>
<p>但上面两种方法仍然遇到了不稳定的问题, 感觉是openwrt的odhcpd不稳定, 照下列方法更换为6relayd之后仍然不好使.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">wget https://www.shintaku.cc/files/6relayd_2013-10-21_ar71xx.ipk</span><br><span class="line">opkg install 6relayd_2013-10-21_ar71xx.ipk</span><br><span class="line">vi /etc/config/6relayd</span><br><span class="line">config relay</span><br><span class="line">        option master &apos;wan&apos;</span><br><span class="line">        option network &apos;lan&apos;</span><br><span class="line">        option rd &apos;relay&apos;</span><br><span class="line">        option dhcpv6 &apos;relay&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">/etc/init.d/odhcpd disable</span><br><span class="line">/etc/init.d/odhcpd stop</span><br><span class="line">/etc/init.d/6relayd enable</span><br><span class="line">/etc/init.d/6relayd start</span><br></pre></td></tr></table></figure></p>
<p>接着使用tcpdump查看好像是DHCPv6 reply包从pppoe-wan过不来br-lan口:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">08:22:53.810272 IP6 2400:da00:2::29 &gt; 2409:8a00:7805:b7df:8d79:6c9:315a:9ca3: ICMP6, echo reply, seq 7, length 64</span><br></pre></td></tr></table></figure></p>
<p>所以接着, 在/etc/config/firewall文件的 Allow-ICMPv6-Forward项中添加了下列行后确认已经有了129(129就是reply)相关的iptables rules之后仍然不好使.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">        list icmp_type &apos;router-solicitation&apos;</span><br><span class="line">        list icmp_type &apos;neighbour-solicitation&apos;</span><br><span class="line">        list icmp_type &apos;router-advertisement&apos;</span><br><span class="line">        list icmp_type &apos;neighbour-advertisement&apos;</span><br><span class="line"></span><br><span class="line">root@OpenWrt:~# ip6tables-save |grep Allow-ICMPv6-Forward |grep 129</span><br><span class="line">-A zone_wan_forward -p ipv6-icmp -m icmp6 --icmpv6-type 129 -m limit --limit 1000/sec -m comment --comment Allow-ICMPv6-Forward -j ACCEPT</span><br></pre></td></tr></table></figure></p>
<p>google查到的和这个bug相同(<a href="https://github.com/openwrt/odhcpd/issues/37" target="_blank" rel="external">https://github.com/openwrt/odhcpd/issues/37</a>), 但里面的所有方法都试过了不成功.<br>似乎是ISP使用的是Statefull DHCPV6的方式, 6relayd可以把ra信息relay过来，但LAN端机器似乎无法跟DHCPV6服务器通信。</p>
<h2 id="2018-0805更新"><a href="#2018-0805更新" class="headerlink" title="2018-0805更新"></a>2018-0805更新</h2><p>今天通过这个帖子(<a href="https://bbs.pku.edu.cn/v2/post-read.php?bid=35&amp;threadid=15501646)解决了上面的问题" target="_blank" rel="external">https://bbs.pku.edu.cn/v2/post-read.php?bid=35&amp;threadid=15501646)解决了上面的问题</a>:<br>OpenWRT默认是在wan口使用DHCPv6 Client, 在LAN口使用odhcpd开启RA和DHCPv6. 这个默认配置适用于国外主流ISP, 因为他们DHCPv6-PD (prefix delegation)把一个至少/64地址段分配给客户使用(还有的使用小于64的地址段给客户分配静态IP).<br>不过中国移动给客户分配的是SLAAC地址, 没有使用DHCPv6, 也就没使用DHCPv6-PD, 这样拿不到前缀(ISP分配的2409:8a00:7805:xxx::/64地址的第4段总是变化的), 所以odhcpd也就无法根据这个前缀设置路由, 所以我们需要手工设置确保可以在OpenWrt上ping通内网机器, 这样才能保证reply消息到达br-lan之后能到达内网机器, 如:<br>route -A inet6 add 2409:8a00:7805:d9b1::/64 dev br-lan<br>所以最终添加在/etc/firewall.user的内容如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># make ipv6 relay to work</span><br><span class="line">PREFIX=`ip -6 route list dev br-lan |grep 2409:8a00 |awk -F &apos;::/&apos; &apos;&#123;print $1&quot;::/64&quot;&#125;&apos; |uniq`</span><br><span class="line">ip -6 route del $PREFIX dev br-lan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line"># NOTE: too too important, we must add &apos;metric&apos; option, or this route will have expire time, or use &apos;ip&apos; to add route</span><br><span class="line">route -A inet6 add $PREFIX dev br-lan metric 1 &gt; /dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line"># make ipv6 nat to work</span><br><span class="line">#ip -6 route add default from $PREFIX dev pppoe-wan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">#route -A inet6 add 2000::/3 `route -A inet6 | grep ::/0 | awk &apos;NR==1&#123;print&quot;gw &quot;$2&quot; dev &quot;$7&#125;&apos;` &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure></p>
<p>再就是得配置replay消息能从pppoe-wan到达br-lan, 所以最终使用下列配置(也记得去掉IPv6 ULA-Prefix):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">config dhcp &apos;wan&apos;</span><br><span class="line">        option interface &apos;wan&apos;</span><br><span class="line">        option ignore &apos;1&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br><span class="line">        option master &apos;1&apos;</span><br><span class="line">config dhcp &apos;lan&apos;</span><br><span class="line">        option interface &apos;lan&apos;</span><br><span class="line">        option start &apos;100&apos;</span><br><span class="line">        option limit &apos;150&apos;</span><br><span class="line">        option leasetime &apos;12h&apos;</span><br><span class="line">        list dhcp_option &apos;6,192.168.99.1&apos;</span><br><span class="line">        option ndp &apos;relay&apos;</span><br><span class="line">        option ra &apos;relay&apos;</span><br></pre></td></tr></table></figure></p>
<p>可新问题又来了, 这条路由总是过期, 如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2409:8a00:7805:da41::/64 dev br-lan  proto kernel  metric 256  expires 259019sec</span><br></pre></td></tr></table></figure></p>
<p>重新执行一下上面的命令又能恢复, 太不稳定了, 还是转回ipv6 NAT模式吧.</p>
<h2 id="20180902更新"><a href="#20180902更新" class="headerlink" title="20180902更新"></a>20180902更新</h2><p>上述静态路由过期的问题原因找到, 原因是需要添加metric</p>
<ul>
<li>route -A inet6 add 2409:8a00:7805:d9b1::/64 dev br-lan               # 会有过期时间</li>
<li>route -A inet6 add 2409:8a00:7805:d9b1::/64 dev br-lan metric 1 # 无过期时间<br>或者使用ip命令它添加的无过期时间 - ip -6 route del 2409:8a00:7805:d9b1::/64 dev br-lan</li>
</ul>
<h2 id="转试NAT6"><a href="#转试NAT6" class="headerlink" title="转试NAT6"></a>转试NAT6</h2><p>上面使用replay时的bug解不了, 无奈之下, 只好使用NAT6, 外面访问不了内网就访问不了吧, 起码可以内网访问外网啊.</p>
<ul>
<li><p>在/etc/config/network中配置了ula_prefix=2001:192:168:99::/64, 这时路由器上的br-lan除了ISP分配的IP之外, 也会多时我们这个自己配置的地址: 2001:192:168:99:0:0:0:1/64</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">config globals &apos;globals&apos;</span><br><span class="line">        option ula_prefix &apos;2001:192:168:99::/64&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改/etc/config/dhcp将relay模式改到server模式即NAT模式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">config dhcp &apos;lan&apos;</span><br><span class="line">        option interface &apos;lan&apos;</span><br><span class="line">        option start &apos;100&apos;</span><br><span class="line">        option limit &apos;150&apos;</span><br><span class="line">        option leasetime &apos;12h&apos;</span><br><span class="line">        list dhcp_option &apos;6,192.168.99.1&apos;</span><br><span class="line">        option dhcpv6 &apos;server&apos;</span><br><span class="line">        option ra_management &apos;2&apos;</span><br><span class="line">        option ra &apos;server&apos;</span><br><span class="line">        option ra_default &apos;1&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在/etc/firewall.user中添加下列SNAT规则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip6tables -t nat -I POSTROUTING -s `uci get network.globals.ula_prefix` -j MASQUERADE &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">route -A inet6 add 2000::/3 `route -A inet6 | grep ::/0 | awk &apos;NR==1&#123;print&quot;gw &quot;$2&quot; dev &quot;$7&#125;&apos;` &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>之后, 内网机器随便手动配置一个IP如2001:192:168:99:0:0:0:3/64并添加默认路由之后就可以访问外网了.<br>如果想外网访问2001:192:168:99::3/64, 是不能够使用下面的neigh proxy方式的, 因为网段和ISP分配的可路由网段根据就不一样嘛. 唯一的办法其实就是做DNAT<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv6.conf.all.proxy_ndp=1</span><br><span class="line">ip -6 neigh add proxy 2001:192:168:99:0:0:0:3 dev pppoe-wan</span><br><span class="line">ip -6 neigh show proxy</span><br></pre></td></tr></table></figure></p>
<h2 id="VPS不支持IPv6时如何使用IPv6"><a href="#VPS不支持IPv6时如何使用IPv6" class="headerlink" title="VPS不支持IPv6时如何使用IPv6"></a>VPS不支持IPv6时如何使用IPv6</h2><p>VPS若不支持IPv6, 可以通过tunnelbroker来配置6in4隧道支持IPv6, 但前提是VPS要能支持配置允许proto-41流量通过 (iptables -A INPUT -p 41 -j ACCEPT), 目前google cloud VPS是无法配置这个的.<br>若您的VPS支持这个, 可以继续. 先在<a href="https://www.tunnelbroker.net/" target="_blank" rel="external">https://www.tunnelbroker.net/</a> 登录后在’User Functions -&gt; Create Regular Tunnel’菜单创建 Create Regular Tunnel, 然后:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt; EOF | sudo tee -a /etc/network/interfaces</span><br><span class="line">auto he-ipv6</span><br><span class="line">iface he-ipv6 inet6 v4tunnel</span><br><span class="line">        address 2001:470:a:xx::2</span><br><span class="line">        netmask 64</span><br><span class="line">        endpoint 216.218.226.xx</span><br><span class="line">        local 162.xx.xx.xx</span><br><span class="line">        ttl 255</span><br><span class="line">        gateway 2001:470:a:4c4::1</span><br><span class="line">EOF</span><br><span class="line">cat &lt;&lt; EOF | sudo tee -a /etc/sysctl.conf</span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 0</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 0</span><br><span class="line">EOF</span><br><span class="line">sudo sysctl -p</span><br><span class="line">sudo apt install -y ifupdown</span><br><span class="line">sudo ifup he-ipv6</span><br><span class="line"># can&apos;t do tunnelbroker as 6in4 is unsupported (NAT/gateways won&apos;t pass proto-41)</span><br><span class="line">#sudo iptables -t nat -A PREROUTING -p 41 -d &lt;VPS-IP&gt; -j DNAT --to-destination &lt;tunnelbroker-ip&gt;</span><br><span class="line">#sudo iptables -t nat -A POSTROUTING -p 41 -d &lt;tunnelbroker-ip&gt; -j SNAT --to-source &lt;VPS-IP&gt;</span><br><span class="line">#sudo iptables -A INPUT -p 41 -j ACCEPT</span><br></pre></td></tr></table></figure>
<p>使用tunnelbroker需要VPS有公网IPv4地址, 若没有, 可以使用miredo(sudo apt-get install miredo), 但前提也是要防火墙允许proto-41的流量</p>
<h2 id="附件-OpenWRT自动恢复网络脚本"><a href="#附件-OpenWRT自动恢复网络脚本" class="headerlink" title="附件 - OpenWRT自动恢复网络脚本"></a>附件 - OpenWRT自动恢复网络脚本</h2><p>1, /etc/init.d/cron enable<br>2, crontab -e<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">*/4 * * * * /root/auto_restart.sh &gt;&gt; /var/log/cron.log 2&gt;&amp;1</span><br><span class="line">0 1 * * * /root/auto_restart_haproxy.sh &gt;&gt; /var/log/cron.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure></p>
<p>3, auto_restart.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# cat /root/auto_restart.sh</span><br><span class="line">#! /bin/sh</span><br><span class="line"># /etc/init.d/cron start</span><br><span class="line"># /etc/init.d/cron enable</span><br><span class="line"># crontab -e</span><br><span class="line"># */5 * * * * /root/auto_restart.sh &gt;&gt; /var/log/cron.log 2&gt;&amp;1</span><br><span class="line">EXIST=$(ip route list 0.0.0.0/0)</span><br><span class="line">if test -z &quot;$EXIST&quot;</span><br><span class="line">then</span><br><span class="line">   echo $(date) &apos;default route disappears, adding it now ...&apos;</span><br><span class="line">   route add default dev pppoe-wan</span><br><span class="line">   sleep 5</span><br><span class="line">   echo $(date) &apos;check network connection ...&apos;</span><br><span class="line">   #ping -c 1 114.114.114.114 &amp;&gt; /dev/null &amp;&amp; echo &apos;success&apos; || /etc/init.d/network restart;</span><br><span class="line">   if ping -c 1 114.114.114.114 &amp;&gt; /dev/null</span><br><span class="line">   then</span><br><span class="line">      echo &apos;ping success&apos;</span><br><span class="line">   else</span><br><span class="line">      echo &apos;ping failed&apos;</span><br><span class="line">      /etc/init.d/network restart</span><br><span class="line">      # for ipv6</span><br><span class="line">      /etc/init.d/odhcpd restart</span><br><span class="line">      sleep 5</span><br><span class="line">      PREFIX=`ip -6 route list dev br-lan |grep 2409:8a00 |awk -F &apos;::/&apos; &apos;&#123;print $1&quot;::/64&quot;&#125;&apos; |uniq`</span><br><span class="line">      ip -6 route del $PREFIX dev br-lan &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">      # NOTE: too too important, we must add &apos;metric&apos; option, or this route will have expire time, or use &apos;ip&apos; to add route</span><br><span class="line">      route -A inet6 add $PREFIX dev br-lan metric 1 &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">   fi</span><br><span class="line">fi</span><br><span class="line">root@OpenWrt:~# cat /root/auto_restart_haproxy.sh</span><br><span class="line">#! /bin/sh</span><br><span class="line">echo $(date) &apos;restarting haproxy ...&apos;</span><br><span class="line">/etc/init.d/haproxy restart</span><br></pre></td></tr></table></figure></p>
<h2 id="20190119更新-最终的设置"><a href="#20190119更新-最终的设置" class="headerlink" title="20190119更新 - 最终的设置"></a>20190119更新 - 最终的设置</h2><p>使用relay模式即使按上面说的加metric之后有缓解但还是容易时不是断线, 不清楚什么原因, 这里一个android关于忽略RA的帖子, 估计有关吧. - <a href="https://issuetracker.google.com/issues/36949115" target="_blank" rel="external">https://issuetracker.google.com/issues/36949115</a><br>换回stateful IPv6还需要继续在openwrt上配置DHCPv6  Server的, 并且android等某些系统并不支持stateful IPv6<br>换回stateless IPv6也有问题, 在ubuntu系统上可以通过命令”echo ‘precedence ::ffff:0:0/96 100’ &gt;&gt; /etc/gai.conf”配置IPv4优先, 但android系统下对4G网络可以配置是否使用IPv4/IPv6, 但对于wifi则没这个配置项. 而stateless IPv6会给android分配2001:192:168:99::1的DHCPv6, 而在openwrt上要pdnsd支持IPv6的话还得再编译, 也是麻烦.<br>所以最后退回为单纯的SLAAC配置, 仅是通过openwrt路由器拿RA, 并不配置DHCPv6. 所以最终的配置为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">config dhcp &apos;lan&apos;</span><br><span class="line">        option interface &apos;lan&apos;</span><br><span class="line">        option start &apos;100&apos;</span><br><span class="line">        option limit &apos;150&apos;</span><br><span class="line">        option leasetime &apos;12h&apos;</span><br><span class="line">        list dhcp_option &apos;6,192.168.99.1&apos;</span><br><span class="line">        option ra &apos;server&apos;</span><br></pre></td></tr></table></figure></p>
<p>并且禁用掉用于提供DHCPv6的odhcpd服务.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/odhcpd disable</span><br><span class="line">/etc/init.d/odhcpd stop</span><br></pre></td></tr></table></figure></p>
<p>看来要想支持IPv6好, 需要全生态链的所有软件都能支持IPv6好并且方便啊, 目前看到的android, openwrt与pdnsd在这方面都就有所欠缺.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/03/IPv6来啦/" data-id="cjr2rybsp0000axbp8ibgzni2" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-用OpenSSL做自签名的证书" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/13/用OpenSSL做自签名的证书/" class="article-date">
  <time datetime="2018-07-13T05:10:13.000Z" itemprop="datePublished">2018-07-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/13/用OpenSSL做自签名的证书/">用OpenSSL做自签名的证书</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>作者：张华  发表于：2014-04-18<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</p>
<p>(<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</p>
<p>加密技术回顾<br>非对称加密算法如RSA的特点如下:<br>1, 公钥加密私钥解密, 大家都可以用我的公钥给我发加密的数据了, 因为只有我有私钥才能解密.<br>2, 私钥加密公钥解密叫数字签名(例如所谓的UEFI secure boot就是在主板硬件里集成一些操作系统的公钥，由主板硬件去校验操作系统是法合法，但关键是微软把持了公钥的申请，主板硬件厂商没有提供界面让用法自定义公钥，尤其在移动领域很多win8的硬件根本不提供关闭secure boot的选项这样就造成只能安装win8一种系统）, 大家收到我用私钥加密后的数据, 看用公钥能不能打得开, 能打开说明这数据确实是由我所发的, 因为别人没有我的私钥不可能伪造这些数据.<br>非对称加密去处很费时间, 我们一般采用对称密钥算法如DES来加密, 但对称密钥的保存是一个问题.<br>所以我们可以采用非对称加密算法来加密先协商交换对称密钥, 这就叫SSL. 假设客户端A的公私钥对是(P1,V1), 服务端B的公私钥对是(P2,V2), A需要确认和它通信的是B, 那么SSL的过程是:<br>首先, A和B都持有对方的公钥.<br>step1, A-&gt;B: hello 是step2, B-&gt;A: 用V2加密过的P1（即用户证书，A就用P2解密出P1, 这种数字签名方式让A确定了和它通信的是B）<br>step3, A-&gt;B: ok<br>step4, B-&gt;A: 用V1加密的一段信息<br>step5, A-&gt;B: 用P1加密一个自动生成的对称密钥K（用之前的P1解密成功这段信息则认为B是可信的了）<br>step6, B-&gt;A: 用K加密的数据（之后两对密钥功能结束，由K来加解密数据）<br>总结一下, 这里(P2,V2)就是certificate authority (CA)用来给客户签名用的公私钥。<br>(P1,V1)是客户自己的公私钥，提交给CA，CA所做的事情就是上述step2用(P2,V2)来给客户的(P1,V1)签名，简单吧？<br>V2是CA公司要保密的，而P2就是公用CA证书要安装到客户端</p>
<p>用V2加密过（签名过）的P1，称为用户证书，和用户私钥V1连起一个文件后, 一般被安装在服务器端。</p>
<p>X.509证书是一些标准字段的集合, 是包含有关用户或设备及其相应公钥信息的一种非常通用的证书格式, 目前版本是3. 必要字段包括:<br>1, 版本号<br>2, 由CA给每一个证书分配的序列号;<br>3, 证书使用的签名算法<br>4, 证书的认证机构<br>5, 证书的有效日期<br>6, 证书的所有人的唯一标识<br>7, 认证机构使用私钥的数字签名<br>8, 公钥信息<br>不同于PGP证书任何人都可以扮演认证者的角色, X.509证书的认证者只能是CA或由CA指定的人.要获得一份X.509证书，必须请求CA发给你证书。用户提供自己的公钥，证明自己拥有相应的私钥，并提供有关自己的某些特定信息。然后在这些信息上数字签名，并将整个数据包(称为证书请求)发给CA。CA做一些努力来验证用户提供的信息是正确的，然后就生成证书并返回给用户。<br>OpenSSL对X.509的支持如下:<br>(1) 证书请求管理<br>(2) 证书生成<br>(3) 证书吊销及CRL管理<br>(4) X509名字管理<br>(5) 属性管理<br>(6) 扩展管理<br>(7) 验证及信任管理</p>
<p>用OpenSSL做自签名的证书(pem格式)步骤:<br>1, 先生成CA的公私钥<br>   mkdir CA &amp; cd CA<br>   mkdir newcerts private<br>   echo ‘01’ &gt; serial #会生成以为个数字为名字的pem文件, 且每个数字自增1<br>   touch index.txt #生成记录数据库<br>   使用配置文件, 由于openssl命令行参数太多, 为避免写太多, 就使用一个配置文件代替, 如<a href="https://github.com/openstack/nova/blob/master/nova/CA/openssl.cnf.tmpl" target="_blank" rel="external">https://github.com/openstack/nova/blob/master/nova/CA/openssl.cnf.tmpl</a><br>   生成(P2,V2), 这时候P2=cacert.pem, V2=private/cakey.pem<br>   openssl req -new -x509 -extensions v3_ca -keyout private/cakey.pem -out cacert.pem -days 365 -config ./openssl.cnf -batch -nodes<br>   查看证书信息, openssl x509 -in cacert.pem -noout -text<br>2, 生成<p1,v1>,即Certificate signing Reqeust(CSR), P1=req.pem, V1=key.pem<br>   openssl req -new -nodes -out req.pem -config ./openssl.cnf<br>3, 用CA的私钥V2为P1签名, 即在newcerts目录生成用户证书cert.pem, 并更新数据库文件index.txt及serail文件<br>   openssl ca -out cert.pem -config ./openssl.cnf -infiles req.pem<br>   查看证书信息, openssl x509 -in cert.pem -noout -text<br>4, 安装证书<br>   用户私钥key.pem(V1)和用V2加密过的用户公钥(cert.pem)安装到服务端(有的服务器碉要把这两个文件连成一个,可以执行: cat key.pem cert.pem &gt; key-cert.pem), 如:<br>   /home/httpd/ssl/cert.pem Site certificate<br>   /home/httpd/ssl/key.pem Site private key<br>   最后将CA的公钥P2=cacert.pem安装到客户端</p1,v1></p>
<p>在OpenStack PKI认证中：<br>1, Keystone产生了CA公私钥: CA.pem, CA.key<br>2, Keystone产生了用户公私钥: keystone.pub, keystone.key<br>3, Keystone产生了用户证书: keystone.pem (即使用CA.key对keystone.pub进行了签名)<br>假如nova要使用PKI认证的话：<br>1, CA端，即keystone端，安装有: CA.pem, CA.key, keystone.key, keystone.pem<br>2, 用户端，即nova端，安装有：keystone.pem<br>过程：<br>1, 用户拿用户名和密码去keystone认证，keystone将用户信息通过keystone.key进行签名后作为token返回用户<br>2, 用户用这一token去访问nova, nova拿到token后，使用keystone.pem解密。（而原来的UUID方式nova还得再拿token去keystone那边验证一下是否有效，所以使用PKI方式能减轻keystone的压力。</p>
<p>再举个例子，如在安装openconnect时生成证书：</p>
<p>sudo apt-get -y install build-essential pkg-config libgnutls28-dev libreadline-dev libseccomp-dev libwrap0-dev libnl-nf-3-dev liblz4-dev gnutls-bin</p>
<p>#Create CA certificate<br>mkdir -p /tmp/cert &amp;&amp; cd /tmp/cert<br>cat &gt; /tmp/cert/ca.tmpl &lt;&lt; EOF<br>cn = “sts CA”<br>organization = “sts CA”<br>serial = 1<br>expiration_days = 3650<br>ca<br>signing_key<br>cert_signing_key<br>crl_signing_key<br>EOF</p>
<p>#Generate CA secret KEY: V2<br>certtool –generate-privkey –outfile CA.key</p>
<p>#Generate CA certifice: P2 signed by V2<br>certtool –generate-self-signed –load-privkey CA.key –template ca.tmpl –outfile CA.pem</p>
<p>#Create User certificate (here is for VPN server)<br>cat &gt; /tmp/cert/vpnserver.tmpl &lt;&lt; EOF<br>cn = “sts vpn server”<br>organization = “sts”<br>expiration_days = 3650<br>signing_key<br>encryption_key<br>tls_www_server<br>EOF</p>
<p>#Generate User secret KEY: V1<br>certtool –generate-privkey –outfile vpnserver.key</p>
<p>#Generate User certificate: <p1 signed="" by="" v2=""><br>certtool –generate-certificate –load-privkey vpnserver.key –load-ca-certificate CA.pem –load-ca-privkey CA.key –template vpnserver.tmpl –outfile vpnserver.pem</p1></p>
<p>#CA.pem,vpnserver,pem,vpnserver.key need to be installed in vpnserver<br>sudo cp CA.pem /etc/ssl/certs/CA.pem<br>sudo cp vpnserver.pem /etc/ssl/private/vpnserver.pem<br>sudo cp vpnserver.key /etc/ssl/private/vpnserver.key<br>OpenStack创建CA的方法：</p>
<p>openssl genrsa -out /etc/keystone/ssl/private/cakey.pem 1024<br>openssl req -new -x509 -extensions v3_ca -key /etc/keystone/ssl/private/cakey.pem -out /etc/keystone/ssl/certs/ca.pem -days 3650 -config /etc/keystone/ssl/certs/openssl.conf -subj /C=US/ST=Unset/L=Unset/O=Unset/CN=localhost<br>openssl genrsa -out /etc/keystone/ssl/private/keystonekey.pem 1024<br>openssl req -key /etc/keystone/ssl/private/keystonekey.pem -new -out /etc/keystone/ssl/certs/req.pem -config /etc/keystone/ssl/certs/openssl.conf -subj /C=US/ST=Unset/L=Unset/O=Unset/CN=localhost<br>openssl ca -batch -out /etc/keystone/ssl/certs/keystone.pem -config /etc/keystone/ssl/certs/openssl.conf -days 3650d -cert /etc/keystone/ssl/certs/ca.pem -keyfile /etc/keystone/ssl/private/cakey.pem -infiles /etc/keystone/ssl/certs/req.pem</p>
<p>再看一个使用easy-rsa为openvpn生成证书的实例：</p>
<p>sudo apt-get install easy-rsa openssl<br>sudo cp -r /usr/share/easy-rsa/ /etc/openvpn<br>cd /etc/openvpn/easy-rsa<br>sudo chown -R <code>whoami</code>:root /etc/openvpn<br>mkdir /etc/openvpn/easy-rsa/keys<br>source ./vars<br>export KEY_COUNTRY=CN<br>export KEY_PROVINCE=BJ<br>export KEY_CITY=BJ<br>export KEY_ORG=sts<br>export KEY_OU=sts<br>export KEY_NAME=sts<br>export KEY_EMAIL=root@sts<br>export KEY_NAME=”server”<br>./clean-all<br>./build-ca<br>$ ls keys/<br>ca.crt  ca.key  index.txt  serial<br>./build-key-server server<br>$ ls keys/<br>01.pem  ca.key     index.txt.attr  serial      server.crt  server.key<br>ca.crt  index.txt  index.txt.old   serial.old  server.csr<br>cp /etc/openvpn/easy-rsa/keys/{server.crt,server.key,ca.crt} /etc/openvpn</p>
<p>#It’s ideal for each client connecting to the VPN to have its own unique certificate and key.</p>
<p>#This is preferable to generating one general certificate and key to use among all client devices.<br>./build-key client1<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/client1.crt /etc/openvpn/<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/client1.key /etc/openvpn/<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/client.ovpn /etc/openvpn/<br>scp ubuntu@<server>:/etc/openvpn/easy-rsa/keys/ca.crt /etc/openvpn/</server></server></server></server></p>
<p>常见证书格式及转换</p>
<p>PKCS(Public-Key Cryptography Standards), 是由RSA实验室与其他安全系统开发商共同制定的一个公钥密码标准<br>X.509是常用的通用的证书格式, 所有的证书都符合PKI(Public Key Infrastructure)制定的的ITU-T X509国际标准<br>.cer/.crt是用于存储证书, 以二进制形式存储, 不含私钥<br>.pem跟.cer/.crt的区别是它以ascii来表示<br>pfx/p12用于存放个人证书/私钥, 他通常包含保护密码, 二进制存储, 转换如:openssl pkcs12 -export -clcerts -in server-cert.cer -inkey server-key.key -out server.p12<br>JKS和JCEKS是Java密钥库(KeyStore)的两种比较常见类型, 可以使用java提供的证书工具keytool(openssl和keytool都是可以用来管理证书的工具而已)进行转换(如:keytool -import -v -trustcacerts -storepass 123456 -alias server -file cacert.pem -keystore server.jks)</p>
<p>例如： k8s中的dashboard若不在浏览器里导入p12证书在采用RBAC授权时就会什么也看不到：</p>
<h1 id="generate-client-certificate-data"><a href="#generate-client-certificate-data" class="headerlink" title="generate client-certificate-data"></a>generate client-certificate-data</h1><p>grep ‘client-certificate-data’ /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk ‘{print $2}’ | base64 -d &gt;&gt; kubecfg.crt</p>
<h1 id="generate-client-key-data"><a href="#generate-client-key-data" class="headerlink" title="generate client-key-data"></a>generate client-key-data</h1><p>grep ‘client-key-data’ /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk ‘{print $2}’ | base64 -d &gt;&gt; kubecfg.key</p>
<h1 id="generate-p12"><a href="#generate-p12" class="headerlink" title="generate p12"></a>generate p12</h1><p>openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name “kubernetes-client”</p>
<p>非对称算法可以使用开源的GPG工具，可参考文档： <a href="http://wenku.baidu.com/link?url=d5fWoN46-y7581212dDUEt7dkUfFkriW0bKy_gwUjps4zpKH64jytimWDm-yfuKIwAtu0jFoWW_ocVTJhSeRb2_QQLUz8oIBQulU6jSI133" target="_blank" rel="external">http://wenku.baidu.com/link?url=d5fWoN46-y7581212dDUEt7dkUfFkriW0bKy_gwUjps4zpKH64jytimWDm-yfuKIwAtu0jFoWW_ocVTJhSeRb2_QQLUz8oIBQulU6jSI133</a></p>
<p>及：<br><a href="https://help.ubuntu.com/community/GnuPrivacyGuardHowto" target="_blank" rel="external">https://help.ubuntu.com/community/GnuPrivacyGuardHowto</a></p>
<p>sudo apt-get install rng-tools<br>sudo rngd -r /dev/urandom</p>
<p>sudo apt-get install gnupg-agent<br>killall -q gpg-agent<br>eval $(gpg-agent –daemon)</p>
<p>创建密钥对：gpg –gen-key， 如创建了：”Zhang Hua (zhhuabj) <a href="&#109;&#97;&#105;&#108;&#x74;&#x6f;&#58;&#x76;&#x65;&#x72;&#121;&#104;&#117;&#x61;&#50;&#x30;&#x30;&#x36;&#64;&#103;&#x6d;&#x61;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#x6d;">&#x76;&#x65;&#x72;&#121;&#104;&#117;&#x61;&#50;&#x30;&#x30;&#x36;&#64;&#103;&#x6d;&#x61;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#x6d;</a>“</p>
<pre><code>export GPGKEY=A24B36AE
</code></pre><p>查看公钥：gpg –list-public<br>查看私钥：gpg –list-secret-key<br>查看签名：gpg –list-sig<br>查看公钥指纹：gpg –fingerprint $GPGKEY<br>提取公钥：gpg –armor –output public.key –export $GPGKEY  或者： gpg –export -a $GPGKEY &gt; public.key</p>
<p>提取私钥：gpg -a –export-secret-keys $KEYID &gt; customer-mirror.key<br>生成公钥回收证书，当私钥出问题时可将它上传密钥服务器声明公钥作废:<br>  gpg –output revoke.asc –gen-revoke $GPGKEY<br>  声明作废：gpg –keyserver Server Address –send-keys $GPGKEY</p>
<p>迁移KEY</p>
<p>gpg –output mygpgkey_pub.gpg –armor –export  $GPGKEY<br>gpg –output mygpgkey_sec.gpg –armor –export-secret-key $GPGKEY</p>
<p>gpg –import mygpgkey_pub.gpg<br>gpg –allow-secret-key-import –import mygpgkey_sec.gpg</p>
<p>上传公钥到密钥服务器，如：gpg –send-keys –keyserver keyserver.ubuntu.com $GPGKEY 或把公钥导成文本之后直接在<a href="http://keyserver.ubuntu.com/这里提交公钥。" target="_blank" rel="external">http://keyserver.ubuntu.com/这里提交公钥。</a></p>
<p>交互命令窗口：gpg –cert-digest-algo=SHA256 –edit-key $GPGKEY</p>
<p>给自己加密文件，加密是用公钥，gpg –encrypt -r veryhua2006@gmail.com test.txt, 会生成名为test.txt.gpg的加密文件<br>给自己解决文件，gpg –decrypt test.txt.gpg &gt; test.txt</p>
<p>给别人加密文件当然要先导入别人的公钥：gpg –import otherpublic.key<br>核对对方的公钥指纹：gpg –fingerprint other@gmail.com<br>为别人加密文件: gpg –encrypt –recipient other@gmail.com test.txt<br>对别人的公钥进行签名，这样别人知道是你发的： gpg –sign-key other@gmail.com</p>
<p>对文件进行签名： gpg –clearsign file<br>验证签名是否完整： gpg –verity file.asc</p>
<p>OpenPGP能用于加密邮件，将GPG指纹注册到launchpad中(<a href="https://launchpad.net/~zhhuabj)，这样launchpad将给你发签名或加密过的邮件，然后再用openPGP" target="_blank" rel="external">https://launchpad.net/~zhhuabj)，这样launchpad将给你发签名或加密过的邮件，然后再用openPGP</a> enabled的邮件客户端如thunderbird来接收解密邮件和验证签名。<br>thunderbird通过enigmail插件来支持OpenPGP, Configure OpenPGP support in Thunderbird under Enigmail-&gt;Preferences and add under GnuPG executable path. The path for GnuPG is /usr/bin/gpg.<br>如果不想用邮件客户端，直接用firefox来访问如gmail等webmail的话，安装firegpg插件即可。chrome不需要装插件直接支持pgp解密。</p>
<p>将GPG指纹（gpg –fingerprint)注册到launchpad中(<a href="https://launchpad.net/~zhhuabj)后会收到一封邮件，内容类似如下，将其存成一个文件，再解密(gpg" target="_blank" rel="external">https://launchpad.net/~zhhuabj)后会收到一封邮件，内容类似如下，将其存成一个文件，再解密(gpg</a> –decrypt file.txt)后就生成了一个验证链接如<a href="https://launchpad.net/token/Hc7J9x7kF55CHTZJs，点击验证即可。" target="_blank" rel="external">https://launchpad.net/token/Hc7J9x7kF55CHTZJs，点击验证即可。</a><br>—–BEGIN PGP MESSAGE—–<br>Version: GnuPG v1.4.11 (GNU/Linux)<br>…….<br>52gY/bZADAl0xhScHvvuYquGS3oApfgtNM3UJWXa<br>=ZgnD<br>—–END PGP MESSAGE—–</p>
<p>Signed Ubuntu Code of Conduct in <a href="https://launchpad.net/~zhhuabj，" target="_blank" rel="external">https://launchpad.net/~zhhuabj，</a><br>1, 先下载UbuntuCodeofConduct-2.0.txt, <a href="https://launchpad.net/codeofconduct/2.0/+download" target="_blank" rel="external">https://launchpad.net/codeofconduct/2.0/+download</a><br>2, gpg –clearsign UbuntuCodeofConduct-2.0.txt<br>3, 将生成的UbuntuCodeofConduct-2.0.txt.asc文件再上传至 <a href="https://launchpad.net/codeofconduct/2.0/+sign即可。" target="_blank" rel="external">https://launchpad.net/codeofconduct/2.0/+sign即可。</a></p>
<p>2014-5-23日添加，配置使用Google Authenticator服务</p>
<p>Google帐户支持密码+临时验证码的两阶段验证方式。<br>临时验证码也支持直接短信发到手机上，也可以在Android手机上安装Google Authenticator服务来接收临时验证码。<br>具体先在<a href="https://accounts.google.com/b/0/SmsAuthConfig页面配置，并先生成google服务端为安装了Google" target="_blank" rel="external">https://accounts.google.com/b/0/SmsAuthConfig页面配置，并先生成google服务端为安装了Google</a> Authenticator服务的客户端生成的密钥。然后再在Google Authenticator里输入这个密钥就可以实现一次一密了。</p>
<p>参考:<br><a href="http://www.blogjava.net/alwayscy/archive/2006/12/01/84852.html" target="_blank" rel="external">http://www.blogjava.net/alwayscy/archive/2006/12/01/84852.html</a><br><a href="http://blog.sina.com.cn/s/blog_9e9d2211010199yj.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_9e9d2211010199yj.html</a></p>
<p><a href="http://lingxiankong.github.io/blog/2014/02/06/openstack-ssl/" target="_blank" rel="external">http://lingxiankong.github.io/blog/2014/02/06/openstack-ssl/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/13/用OpenSSL做自签名的证书/" data-id="cjr2rybtq000uaxbp9zhbc3uf" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Set-up-k8s-development-env-by-quqi99" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/10/Set-up-k8s-development-env-by-quqi99/" class="article-date">
  <time datetime="2018-07-10T09:47:57.000Z" itemprop="datePublished">2018-07-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/10/Set-up-k8s-development-env-by-quqi99/">Set up k8s development env (by quqi99)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (作者：张华 发表于：2018-07-10)</strong></p>
<h2 id="Sign-the-CLA"><a href="#Sign-the-CLA" class="headerlink" title="Sign the CLA"></a>Sign the CLA</h2><p>Sign via Hellosign - <a href="https://github.com/kubernetes/community/blob/master/CLA.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/CLA.md</a><br>then set email for github - <a href="https://github.com/settings/emails" target="_blank" rel="external">https://github.com/settings/emails</a><br>git config –global user.email “xxx@gmail.com”</p>
<h2 id="Run-local-k8s-via-source-code"><a href="#Run-local-k8s-via-source-code" class="headerlink" title="Run local k8s  via source code"></a>Run local k8s  via source code</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># Install some packages</span><br><span class="line">sudo apt install -y gcc make socat git build-essential</span><br><span class="line"></span><br><span class="line"># Install docker</span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line">sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt-cache policy docker-ce</span><br><span class="line">sudo apt install docker-ce</span><br><span class="line"></span><br><span class="line"># Change default location of docker image</span><br><span class="line">service docker stop</span><br><span class="line">rsync -aXS /var/lib/docker/* /bak/.docker/</span><br><span class="line">rm -rf /var/lib/docker/*</span><br><span class="line">echo /bak/.docker/ /var/lib/docker none bind 0 0 &gt;&gt; /etc/fstab</span><br><span class="line">mount –a</span><br><span class="line">service docker start</span><br><span class="line"></span><br><span class="line"># Install etcd &gt; 3.2.13</span><br><span class="line">ETCD_VER=v3.2.18</span><br><span class="line">DOWNLOAD_URL=&quot;https://github.com/coreos/etcd/releases/download&quot;</span><br><span class="line">curl -L $&#123;DOWNLOAD_URL&#125;/$&#123;ETCD_VER&#125;/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz -o /tmp/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz</span><br><span class="line">tar xzvf /tmp/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz</span><br><span class="line">sudo /bin/cp -f etcd-$&#123;ETCD_VER&#125;-linux-amd64/&#123;etcd,etcdctl&#125; /usr/bin</span><br><span class="line">rm -rf /tmp/etcd-$&#123;ETCD_VER&#125;-linux-amd64.tar.gz etcd-$&#123;ETCD_VER&#125;-linux-amd64</span><br><span class="line"></span><br><span class="line"># Install golang &gt; 1.10.2</span><br><span class="line">wget https://dl.google.com/go/go1.10.3.linux-amd64.tar.gz</span><br><span class="line">sudo rm -rf /usr/lib/go &amp;&amp; sudo tar -C /usr/lib -xzf go1.10.3.linux-amd64.tar.gz</span><br><span class="line">export GOROOT=/usr/lib/go</span><br><span class="line">export GOPATH=/bak/golang</span><br><span class="line">export PATH=$GOROOT/bin:$GOPATH/bin:$PATH</span><br><span class="line"></span><br><span class="line"># Install and run kubernetes in local env - https://www.cnblogs.com/edisonxiang/p/6951787.html</span><br><span class="line">mkdir -p $GOPATH/src/k8s.io</span><br><span class="line">#go get -d k8s.io/kubernetes</span><br><span class="line">git clone git@github.com:zhhuabj/kubernetes.git $GOPATH/src/k8s.io/kubernetes</span><br><span class="line">#make GOGCFLAGS=&quot;-N -l&quot;  #Debug it</span><br><span class="line">sudo usermod -a -G docker $&#123;USER&#125;</span><br><span class="line">sudo systemctl restart docker.service</span><br><span class="line">sudo systemctl disable kubelet.service</span><br><span class="line">sudo systemctl stop kubelet.service</span><br><span class="line"></span><br><span class="line">#注意：一直不成功的原因是需要用小写true，它是区分大小写的</span><br><span class="line">KUBE_ENABLE_CLUSTER_DASHBOARD=true ./hack/local-up-cluster.sh</span><br><span class="line">#注意：加GO_OUT可避免再次编译</span><br><span class="line">GO_OUT=/bak/golang/src/k8s.io/kubernetes/_output/bin</span><br><span class="line">KUBE_ENABLE_CLUSTER_DASHBOARD=true ./hack/local-up-cluster.sh</span><br><span class="line"></span><br><span class="line"># Test local env</span><br><span class="line">export KUBECONFIG=/var/run/kubernetes/admin.kubeconfig</span><br><span class="line">cluster/kubectl.sh get pods --all-namespaces</span><br></pre></td></tr></table></figure>
<h2 id="github-process"><a href="#github-process" class="headerlink" title="github process"></a>github process</h2><p><a href="https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md</a><br>k8s与openstack不一样，openstack使用gerrit来review code, 但是k8s使用github的PR机制。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">kubernetes提交PR的流程可以采用pull模型（Shared Repository Model，https://gist.github.com/seshness/3943237），也可以采用fork模型（https://www.cnblogs.com/edisonxiang/p/6951787.html）。我们采用fork模型：</span><br><span class="line"></span><br><span class="line"># Click &apos;Fork&apos; button to fork your own branch - https://github.com/kubernetes/kubernetes, then we have https://github.com/zhhuabj/kubernetes</span><br><span class="line">mkdir -p $GOPATH/src/k8s.io</span><br><span class="line">git clone git@github.com:zhhuabj/kubernetes.git $GOPATH/src/k8s.io/kubernetes</span><br><span class="line">cd kubernetes</span><br><span class="line">hack/local-up-cluster.sh</span><br><span class="line"></span><br><span class="line"># set up upstream branch</span><br><span class="line">git remote add upstream https://github.com/kubernetes/kubernetes.git</span><br><span class="line">git remote set-url --push upstream no_push</span><br><span class="line">git remote -v</span><br><span class="line"></span><br><span class="line"># Update our branch</span><br><span class="line">git fetch upstream</span><br><span class="line">git checkout master</span><br><span class="line">git rebase upstream/master</span><br><span class="line">#git pull upstream master</span><br><span class="line"></span><br><span class="line"># Add new branch myfeature</span><br><span class="line">git checkout -b myfeature</span><br><span class="line">git config --global user.email &quot;veryhua2006@gmail.com&quot;</span><br><span class="line">git config --global user.name &quot;zhhuabj&quot;</span><br><span class="line"># Add or Modify files</span><br><span class="line">...</span><br><span class="line">git add .</span><br><span class="line">git commit -a -F ./msg</span><br><span class="line">git commit --amend -a -F ./message</span><br><span class="line">git commit -m &quot;update&quot;</span><br><span class="line">git push origin myfeature</span><br><span class="line">git push origin :myfeature  #delete remote branch</span><br><span class="line"></span><br><span class="line"># Rebase unmerged PR into our repo</span><br><span class="line">git fetch upstream pull/56136/head:BRANCHNAME</span><br><span class="line"></span><br><span class="line"># Merge multiple local commits into a full commit by using &apos;git squash&apos;</span><br><span class="line">git log</span><br><span class="line">git rebase -i HEAD~6 把顶部的六个版本聚到一起进入编辑页面</span><br><span class="line">　　把需要压缩的日志前面的pick都改为s（squash的缩写）</span><br><span class="line">　　注意必须保留一个pick，如果将所有的pick都改为了s那就没有合并的载体了就会报如下错误</span><br><span class="line">　　依次输入CTRL+X Y ENTER三个命令完成编辑。</span><br><span class="line">　　最后Git Push orgin branchname</span><br><span class="line"></span><br><span class="line"># Pull Request - https://github.com/zhhuabj/kubernetes, 在新上传的Branch上，点击Compare &amp; Pull Request按钮创建一个Pull Requst</span><br><span class="line"></span><br><span class="line"># 最后https://github.com/kubernetes/kubernetes/pulls就可以找到刚刚提交的Pull Request。</span><br></pre></td></tr></table></figure></p>
<h2 id="Review-process"><a href="#Review-process" class="headerlink" title="Review process"></a>Review process</h2><p><a href="https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md#the-testing-and-merge-workflow" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md#the-testing-and-merge-workflow</a><br> openstack社区更开放，使用gerrit机制，新人都能review代码，并能+1。<br>但k8s使用github的PR，相对封闭一些，新人是不能review代码的，新人的角色叫contributor，可以修改issue (在issue上回复/assign)并提交代码。<br>只有每个子模块下OWNERS文件定义的reviewer, approver角色的人员(<a href="https://github.com/kubernetes/community/blob/master/community-membership.md)才能review代码(reviewer可以LDTM(looks" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/community-membership.md)才能review代码(reviewer可以LDTM(looks</a> good to me, +1), approver可以+2，一个+1一个+2就可以进代码，但openstack中是只能两个+2才可以)</p>
<p>如果要为某个issue创建PR, 需要在PR的描述里填写fixes #issue_num 。这样PR在 merge后issue会“自动”关闭。PR创建后，k8s机器人会做以下几件事：<br>在相应OWNER列表里选取一个人做为reviewer<br>如果是kubernetes member，则启动CI来检查PR，例如UT, e2e test；如果不是kuberentes member ，则需要一个member帮忙启动相应ci<br>待CI没有问题后，可以ping相应的reviewers来检查代码了</p>
<p>在reviewer认为可以后，需要标lgtm (look go to me) 标签；同时需要该模块的approver标记approve标签。两个标签都有了以后，就可以等待合并了。代码的合并也是由k8s机器人完成的，可以在 <a href="http://submit-queue.k8s.io/#/queue" target="_blank" rel="external">http://submit-queue.k8s.io/#/queue</a> 看到等待合并的PR。在合并之前，k8s机器人也会自动重新跑ci以保证代码没有问题。<br>以上三步差不多就可以将typo提交到主干上。其中大部分工作都有k8s机器人自动完成，比如分配reviewer。<br>  Bot命令如下：</p>
<ul>
<li>Jenkins verification: @k8s-bot verify test this</li>
<li>GCE E2E: @k8s-bot cvm gce e2e test this</li>
<li>Test all: @k8s-bot test this please, issue #IGNORE</li>
<li>CRI test: @k8s-bot cri test this.</li>
<li>Verity test: @k8s-bot verify test this</li>
<li>LGTM (only applied if you are one of assignees):: /lgtm</li>
<li>LGTM cancel: /lgtm cancel<br>更多命令见 <a href="https://prow.k8s.io/command-help" target="_blank" rel="external">https://prow.k8s.io/command-help</a><h2 id="How-to-do-test"><a href="#How-to-do-test" class="headerlink" title="How to do test"></a>How to do test</h2><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md</a><br>make verify<br>make test<br>make test-integration<h2 id="How-to-debug-k8s"><a href="#How-to-debug-k8s" class="headerlink" title="How to debug k8s"></a>How to debug k8s</h2>local-up-cluster.sh是通过_output/local/bin/linux/amd64/hyperkube在容器里启动k8s各服务的，那样是不方便使用(dlv exec ${OUTDIR}/bin/kubelet – $kubelet_flags)来调试基于B/S的k8s服务的，那首先将k8s各服务以本地进程的形式启动，这样调试k8s服务就变得像调试openstack服务一样。</li>
</ul>
<p>1， 第一步创建systemd启动配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line">$ cat /lib/systemd/system/kube-etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-etcd Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/bin/etcd -name etcd -data-dir /var/lib/etcd \</span><br><span class="line">          -listen-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001 \</span><br><span class="line">          -advertise-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-apiserver Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-apiserver \</span><br><span class="line">            --admission-control=NamespaceAutoProvision,LimitRanger,SecurityContextDeny \</span><br><span class="line">            --apiserver-count=1 \</span><br><span class="line">            --cors-allowed-origins=.* \</span><br><span class="line">            --enable-garbage-collector=false \</span><br><span class="line">            --etcd-servers=http://127.0.0.1:2379 \</span><br><span class="line">            --insecure-bind-address=0.0.0.0 \</span><br><span class="line">            --insecure-port=8080 \</span><br><span class="line">            --log-dir=~/.kube/log/kube-apiserver \</span><br><span class="line">            --logtostderr=false \</span><br><span class="line">            --service-cluster-ip-range=10.0.0.0/16 \</span><br><span class="line">            --v=5 \</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-controller-manager Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-controller-manager \</span><br><span class="line">          --enable-garbage-collector=false \</span><br><span class="line">          --logtostderr=false \</span><br><span class="line">          --log-dir=~/.kube/log/kube-controller-manager \</span><br><span class="line">          --pod-eviction-timeout=5m0s \</span><br><span class="line">          --master=http://0.0.0.0:8080 \</span><br><span class="line">          --node-monitor-grace-period=40s \</span><br><span class="line">          --terminated-pod-gc-threshold=12500 \</span><br><span class="line">          --leader-elect=true \</span><br><span class="line">          --v=4 \</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-scheduler.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kube-scheduler Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-scheduler \</span><br><span class="line">            --log-dir=~/.k8s/log/kube-scheduler \</span><br><span class="line">            --logtostderr=false \</span><br><span class="line">            --master=http://0.0.0.0:8080 \</span><br><span class="line">            --leader-elect=true \</span><br><span class="line">            --v=5 \</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"></span><br><span class="line"># prepare kubelet.kubeconfig and kube-proxy.kubeconfig</span><br><span class="line">export KUBE_APISERVER=&quot;http://127.0.0.1:8080&quot;</span><br><span class="line">./_output/bin/kubectl config set-cluster myk8s --server=$&#123;KUBE_APISERVER&#125; --kubeconfig=kubelet.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-credentials kubelet --kubeconfig=kubelet.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-context myk8s-context --cluster=myk8s --user=kubelet --kubeconfig=kubelet.kubeconfig</span><br><span class="line">./_output/bin/kubectl config use-context myk8s-context --kubeconfig=kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line">./_output/bin/kubectl config set-cluster myk8s --server=$&#123;KUBE_APISERVER&#125; --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-credentials kube-proxy --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">./_output/bin/kubectl config set-context myk8s-context --cluster=myk8s --user=kube-proxy --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">./_output/bin/kubectl config use-context myk8s-context --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">cp *.kubeconfig /home/hua/.kube/</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=kubelet: The Kubernetes Node Agent</span><br><span class="line">Documentation=http://kubernetes.io/docs/</span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kubelet \</span><br><span class="line">          --address=127.0.0.1 --port=10250 --hostname-override=127.0.0.1 \</span><br><span class="line">          --pod-infra-container-image=docker.io/kubernetes/pause \</span><br><span class="line">          --fail-swap-on=false --cgroup-driver=cgroupfs \</span><br><span class="line">          --kubeconfig=/home/hua/.kube/kubelet.kubeconfig \</span><br><span class="line">          --runtime-cgroups=/systemd/system.slice \</span><br><span class="line">          --kubelet-cgroups=/systemd/system.slice \</span><br><span class="line">          --eviction-hard=&apos;nodefs.available&lt;1%&apos; \</span><br><span class="line">          --logtostderr=false --log-dir=~/.kube/log/kubelet --v=4</span><br><span class="line">Restart=always</span><br><span class="line">StartLimitInterval=0</span><br><span class="line">RestartSec=10</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">$ cat /lib/systemd/system/kube-proxy.service[Unit]</span><br><span class="line">Description=Kube-proxy Service</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/bak/golang/src/k8s.io/kubernetes/_output/bin/kube-proxy \</span><br><span class="line">            --log-dir=~/.k8s/log/kube-proxy \</span><br><span class="line">            --logtostderr=false \</span><br><span class="line">            --master=http://0.0.0.0:8080 \</span><br><span class="line">            --kubeconfig=/home/hua/.kube/kube-proxy.kubeconfig \</span><br><span class="line">            --proxy-mode=userspace \</span><br><span class="line">            --v=5</span><br><span class="line">Restart=always</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br></pre></td></tr></table></figure></p>
<p>2， 第二步，启动各服务:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl --system daemon-reload</span><br><span class="line">sudo systemctl start kube-etcd.service</span><br><span class="line">etcdctl -C http://localhost:4001 cluster-health</span><br><span class="line">sudo systemctl start kube-apiserver.service</span><br><span class="line">sudo systemctl start kube-controller-manager.service</span><br><span class="line">sudo systemctl start kube-scheduler.service</span><br><span class="line">sudo systemctl start kubelet.service</span><br></pre></td></tr></table></figure></p>
<p>3, 第二步，验证安装是否正确：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">$ /bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl -s http://127.0.0.1:8080 get componentstatus</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">controller-manager   Healthy   ok</span><br><span class="line">scheduler            Healthy   ok</span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br><span class="line"></span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config set-cluster myk8s --server=http://127.0.0.1:8080</span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config set-context myk8s-context --cluster=myk8s --namespace=default --user=client</span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config use-context myk8s-context</span><br><span class="line">/bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl config set preferences.colors true</span><br><span class="line">$ cat ~/.kube/config</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    server: http://127.0.0.1:8080</span><br><span class="line">  name: myk8s</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: myk8s</span><br><span class="line">    namespace: default</span><br><span class="line">    user: client</span><br><span class="line">  name: myk8s-context</span><br><span class="line">current-context: myk8s-context</span><br><span class="line">kind: Config</span><br><span class="line">preferences:</span><br><span class="line">  colors: true</span><br><span class="line">users: []</span><br><span class="line"></span><br><span class="line">$ /bak/golang/src/k8s.io/kubernetes/_output/bin/kubectl get componentstatus</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">controller-manager   Healthy   ok</span><br><span class="line">scheduler            Healthy   ok</span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br><span class="line">$ ./_output/bin/kubectl get nodes</span><br><span class="line">NAME        STATUS    ROLES     AGE       VERSION</span><br><span class="line">127.0.0.1   Ready     &lt;none&gt;    11m       v1.12.0-alpha.0.1999+32dc6cc08aa034-dirty</span><br><span class="line">$ ./_output/bin/kubectl get events</span><br></pre></td></tr></table></figure></p>
<p>4，第四步，例如要调试kubelet服务的话，先停止该服务(sudo systemctl stop kubelet)，然后使用(dlv exec ${OUTDIR}/bin/kubelet – $kubelet_flags)命令启动，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sudo /bak/golang/bin/dlv --headless -l 127.0.0.1:1234 exec /bak/golang/src/k8s.io/kubernetes/_output/bin/kubelet -- --fail-swap-on=False --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice  --v=4</span><br><span class="line">API server listening at: 127.0.0.1:1234</span><br><span class="line"></span><br><span class="line">$ sudo /bak/golang/bin/dlv connect 127.0.0.1:1234</span><br><span class="line">Type &apos;help&apos; for list of commands.</span><br><span class="line">(dlv) b main.main</span><br><span class="line">Breakpoint 1 set at 0x2d08348 for main.main() ./_output/local/go/src/k8s.io/kubernetes/cmd/kubelet/kubelet.go:36</span><br><span class="line">(dlv) c</span><br></pre></td></tr></table></figure></p>
<h2 id="安装dashboard"><a href="#安装dashboard" class="headerlink" title="安装dashboard"></a>安装dashboard</h2><p>该命令(KUBE_ENABLE_CLUSTER_DASHBOARD=true ./hack/local-up-cluster.sh）会自动安装dashboard。<br>注意：如果不成功原因是需要用小写true，它是区分大小写的。</p>
<p>安装成功后使用命令（cluster/kubectl.sh cluster-info）查看它的访问地址如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://localhost:6443//api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure></p>
<p>这个链接有点问题，在api处有两个斜线会造成看不到UI，改成如下的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://localhost:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure></p>
<p>也可运行命令（kubectl proxy –port=8001 –kubeconfig=/var/run/kubernetes/admin.kubeconfig –accept-hosts=’^*$’）访问：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure></p>
<p>上面的’–accept-hosts’用于在非本机外部访问，但Dashboard只允许localhost和127.0.0.1使用HTTP连接进行访问，而其它地址只允许使用HTTPS。因此，如果需要在非本机访问Dashboard的话，只能采用NodePort:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system edit service kubernetes-dashboard</span><br><span class="line">$ kubectl -n kube-system get service kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.0.0.232   &lt;none&gt;        443:31050/TCP   1h</span><br><span class="line">visit: https://192.168.99.216:31050/</span><br></pre></td></tr></table></figure></p>
<p>这时访问dashboard仍然有下列问题:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;message&quot;: &quot;services \&quot;https:kubernetes-dashboard:\&quot; is forbidden: User \&quot;system:anonymous\&quot; cannot get services/proxy in the namespace \&quot;kube-system\&quot;: no RBAC policy matched&quot;,</span><br></pre></td></tr></table></figure></p>
<p>这是因为最新版的k8s默认启用了RBAC(–authorization-mode=Node,RBAC)，并为未认证用户赋予了一个默认的身份：anonymous<br>对于API Server来说，它是使用证书进行认证的，我们需要先创建一个证书：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># generate client-certificate-data</span><br><span class="line">grep &apos;client-certificate-data&apos; /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.crt</span><br><span class="line"># generate client-key-data</span><br><span class="line">grep &apos;client-key-data&apos; /var/run/kubernetes/admin.kubeconfig | head -n 1 | awk &apos;&#123;print $2&#125;&apos; | base64 -d &gt;&gt; kubecfg.key</span><br><span class="line"># generate p12</span><br><span class="line">openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name &quot;kubernetes-client&quot;</span><br></pre></td></tr></table></figure></p>
<p>然后将该p12证书导入到浏览器即可。此时默认的anonymous身份的token可以这样获取:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cluster/kubectl.sh get secret -n kube-system | grep dashboard</span><br><span class="line">cluster/kubectl.sh -n kube-system  get secret kubernetes-dashboard-token-kglhd -o jsonpath=&#123;.data.token&#125;| base64 -d</span><br></pre></td></tr></table></figure></p>
<p>anonymous身份可能看不到很多东西，所以我们再在kube-system名空间下再创建一个admin用户并和cluster-admin角色关联：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /tmp/admin-user.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line">cat &gt; /tmp/admin-user-role-binding.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line">cluster/kubectl.sh create -f /tmp/admin-user.yaml</span><br><span class="line">cluster/kubectl.sh create -f /tmp/admin-user-role-binding.yaml</span><br><span class="line">cluster/kubectl.sh -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin | awk &apos;&#123;print $1&#125;&apos;)</span><br></pre></td></tr></table></figure>
<p>##直接修改local-up-cluster.sh代替hyperkube用本地进程启动 ##<br>或者直接修改脚本去掉hyperkube, 然后运行ENABLE_CLUSTER_DASHBOARD=True ./hack/local-up-cluster.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">diff --git a/hack/local-up-cluster.sh b/hack/local-up-cluster.sh</span><br><span class="line">index 3b688d3..95de0df 100755</span><br><span class="line">--- a/hack/local-up-cluster.sh</span><br><span class="line">+++ b/hack/local-up-cluster.sh</span><br><span class="line">@@ -202,7 +202,8 @@ do</span><br><span class="line"> done</span><br><span class="line"></span><br><span class="line"> if [ &quot;x$GO_OUT&quot; == &quot;x&quot; ]; then</span><br><span class="line">-    make -C &quot;$&#123;KUBE_ROOT&#125;&quot; WHAT=&quot;cmd/kubectl cmd/hyperkube&quot;</span><br><span class="line">+    #make -C &quot;$&#123;KUBE_ROOT&#125;&quot; WHAT=&quot;cmd/kubectl cmd/hyperkube&quot;</span><br><span class="line">+    make -C &quot;$&#123;KUBE_ROOT&#125;&quot; GOGCFLAGS=&quot;-N -l&quot; WHAT=&quot;cmd/kubelet cmd/kube-proxy cmd/kube-apiserver cmd/kube-controller-manager cmd/cloud-controller-manager cmd/kube-scheduler cmd/kubectl&quot;</span><br><span class="line"> else</span><br><span class="line">     echo &quot;skipped the build.&quot;</span><br><span class="line"> fi</span><br><span class="line">@@ -578,7 +579,7 @@ function start_apiserver &#123;</span><br><span class="line">     fi</span><br><span class="line"></span><br><span class="line">     APISERVER_LOG=$&#123;LOG_DIR&#125;/kube-apiserver.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/hyperkube&quot; apiserver $&#123;swagger_arg&#125; $&#123;audit_arg&#125; $&#123;authorizer_arg&#125; $&#123;priv_arg&#125; $&#123;runtime_config&#125; \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/kube-apiserver&quot; $&#123;swagger_arg&#125; $&#123;audit_arg&#125; $&#123;authorizer_arg&#125; $&#123;priv_arg&#125; $&#123;runtime_config&#125; \</span><br><span class="line">       $&#123;cloud_config_arg&#125; \</span><br><span class="line">       $&#123;advertise_address&#125; \</span><br><span class="line">       $&#123;node_port_range&#125; \</span><br><span class="line">@@ -650,7 +651,7 @@ function start_controller_manager &#123;</span><br><span class="line">     fi</span><br><span class="line"></span><br><span class="line">     CTLRMGR_LOG=$&#123;LOG_DIR&#125;/kube-controller-manager.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/hyperkube&quot; controller-manager \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/kube-controller-manager&quot; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --vmodule=&quot;$&#123;LOG_SPEC&#125;&quot; \</span><br><span class="line">       --service-account-private-key-file=&quot;$&#123;SERVICE_ACCOUNT_KEY&#125;&quot; \</span><br><span class="line">@@ -685,7 +686,7 @@ function start_cloud_controller_manager &#123;</span><br><span class="line">     fi</span><br><span class="line"></span><br><span class="line">     CLOUD_CTLRMGR_LOG=$&#123;LOG_DIR&#125;/cloud-controller-manager.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; $&#123;EXTERNAL_CLOUD_PROVIDER_BINARY:-&quot;$&#123;GO_OUT&#125;/hyperkube&quot; cloud-controller-manager&#125; \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; $&#123;EXTERNAL_CLOUD_PROVIDER_BINARY:-&quot;$&#123;GO_OUT&#125;/cloud-controller-manager&quot;&#125; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --vmodule=&quot;$&#123;LOG_SPEC&#125;&quot; \</span><br><span class="line">       $&#123;node_cidr_args&#125; \</span><br><span class="line">@@ -791,7 +792,7 @@ function start_kubelet &#123;</span><br><span class="line">     )</span><br><span class="line"></span><br><span class="line">     if [[ -z &quot;$&#123;DOCKERIZE_KUBELET&#125;&quot; ]]; then</span><br><span class="line">-      sudo -E &quot;$&#123;GO_OUT&#125;/hyperkube&quot; kubelet &quot;$&#123;all_kubelet_flags[@]&#125;&quot; &gt;&quot;$&#123;KUBELET_LOG&#125;&quot; 2&gt;&amp;1 &amp;</span><br><span class="line">+      sudo -E &quot;$&#123;GO_OUT&#125;/kubelet&quot; &quot;$&#123;all_kubelet_flags[@]&#125;&quot; &gt;&quot;$&#123;KUBELET_LOG&#125;&quot; 2&gt;&amp;1 &amp;</span><br><span class="line">       KUBELET_PID=$!</span><br><span class="line">     else</span><br><span class="line"></span><br><span class="line">@@ -889,14 +890,14 @@ EOF</span><br><span class="line">       done</span><br><span class="line">     fi &gt;&gt;/tmp/kube-proxy.yaml</span><br><span class="line"></span><br><span class="line">-    sudo &quot;$&#123;GO_OUT&#125;/hyperkube&quot; proxy \</span><br><span class="line">+    sudo &quot;$&#123;GO_OUT&#125;/kube-proxy&quot; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --config=/tmp/kube-proxy.yaml \</span><br><span class="line">       --master=&quot;https://$&#123;API_HOST&#125;:$&#123;API_SECURE_PORT&#125;&quot; &gt;&quot;$&#123;PROXY_LOG&#125;&quot; 2&gt;&amp;1 &amp;</span><br><span class="line">     PROXY_PID=$!</span><br><span class="line"></span><br><span class="line">     SCHEDULER_LOG=$&#123;LOG_DIR&#125;/kube-scheduler.log</span><br><span class="line">-    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/hyperkube&quot; scheduler \</span><br><span class="line">+    $&#123;CONTROLPLANE_SUDO&#125; &quot;$&#123;GO_OUT&#125;/kube-scheduler&quot; \</span><br><span class="line">       --v=$&#123;LOG_LEVEL&#125; \</span><br><span class="line">       --kubeconfig &quot;$CERT_DIR&quot;/scheduler.kubeconfig \</span><br><span class="line">       --feature-gates=&quot;$&#123;FEATURE_GATES&#125;&quot; \</span><br></pre></td></tr></table></figure></p>
<h2 id="How-to-read-source-code"><a href="#How-to-read-source-code" class="headerlink" title="How to read source code"></a>How to read source code</h2><p><a href="http://dockone.io/article/895" target="_blank" rel="external">http://dockone.io/article/895</a></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://kubernetes.io/docs/imported/community/devel/" target="_blank" rel="external">https://kubernetes.io/docs/imported/community/devel/</a><br>[2] <a href="https://github.com/kubernetes/community/tree/master/contributors/devel" target="_blank" rel="external">https://github.com/kubernetes/community/tree/master/contributors/devel</a><br>[3] Bug - <a href="https://github.com/kubernetes/community/issues" target="_blank" rel="external">https://github.com/kubernetes/community/issues</a><br>[4] Submit code review - <a href="https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/pull-requests.md</a><br>[5] Membership - <a href="https://github.com/kubernetes/community/blob/master/community-membership.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/community-membership.md</a><br>[6] CONTRIBUTING - <a href="https://github.com/kubernetes/community/blob/master/CONTRIBUTING.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/CONTRIBUTING.md</a><br>[7] Code format - <a href="https://github.com/golang/go/wiki/CodeReviewComments" target="_blank" rel="external">https://github.com/golang/go/wiki/CodeReviewComments</a><br>[8] Slack - <a href="https://kubernetes.slack.com/messages" target="_blank" rel="external">https://kubernetes.slack.com/messages</a><br>[9] Mail-list - <a href="https://groups.google.com/forum/#!forum/kubernetes-dev" target="_blank" rel="external">https://groups.google.com/forum/#!forum/kubernetes-dev</a><br>[10] SIG-list (Special Interest Groups) - <a href="https://github.com/kubernetes/community/blob/master/sig-list.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/sig-list.md</a><br>[11] open-bug - <a href="https://github.com/kubernetes/community/blob/master/contributors/guide/issue-triage.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/guide/issue-triage.md</a><br>[12] BP - <a href="https://github.com/kubernetes/community/tree/master/contributors/design-proposals" target="_blank" rel="external">https://github.com/kubernetes/community/tree/master/contributors/design-proposals</a><br>[13] <a href="https://github.com/kubernetes/community/blob/master/community-membership.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/community-membership.md</a><br>[14] test - <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md" target="_blank" rel="external">https://github.com/kubernetes/community/blob/master/contributors/devel/testing.md</a><br>[15] <a href="https://ress.infoq.com/minibooks/Kubernetes-handbook/zh/pdf/kubernetes.pdf" target="_blank" rel="external">https://ress.infoq.com/minibooks/Kubernetes-handbook/zh/pdf/kubernetes.pdf</a><br>[16] <a href="https://kubernetes.io/docs/home/" target="_blank" rel="external">https://kubernetes.io/docs/home/</a><br>[17] <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way" target="_blank" rel="external">https://github.com/kelseyhightower/kubernetes-the-hard-way</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/10/Set-up-k8s-development-env-by-quqi99/" data-id="cjr2rybt7000caxbp3v9iwri7" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/01/18/Set-ip-IPv6-env/">Set ip IPv6 env</a>
          </li>
        
          <li>
            <a href="/2019/01/02/Using-kubeadm-to-deploy-k8s/">Using kubeadm to deploy k8s</a>
          </li>
        
          <li>
            <a href="/2018/12/31/Use-Octavia-to-Implement-HTTPS-Health-Monitors/">Use Octavia to Implement HTTPS Health Monitors</a>
          </li>
        
          <li>
            <a href="/2018/10/29/为租户下的虚机提供IPv6-DNS服务/">为租户下的虚机提供IPv6 DNS服务</a>
          </li>
        
          <li>
            <a href="/2018/09/10/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 张华<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>