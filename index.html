<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>技术并艺术着</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="blog.csdn.net/quqi99">
<meta property="og:type" content="website">
<meta property="og:title" content="技术并艺术着">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="blog.csdn.net/quqi99">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="技术并艺术着">
<meta name="twitter:description" content="blog.csdn.net/quqi99">
  
    <link rel="alternate" href="/atom.xml" title="技术并艺术着" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">技术并艺术着</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">张华的技术博客 - blog.csdn.net/quqi99</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-OpenWRT与QNAP上通过PXE安装Xenial" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/02/OpenWRT与QNAP上通过PXE安装Xenial/" class="article-date">
  <time datetime="2017-12-02T12:04:42.000Z" itemprop="datePublished">2017-12-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/02/OpenWRT与QNAP上通过PXE安装Xenial/">OpenWRT与QNAP上通过PXE安装Xenial</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="Set-up-tftp-on-QNAP"><a href="#Set-up-tftp-on-QNAP" class="headerlink" title="Set up tftp on QNAP"></a>Set up tftp on QNAP</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># NOTE: We need to configure PXE dir and authority to /Public/tftpboot in QNPA GUI, then use &apos;tftp 192.168.99.122&apos; to test</span><br><span class="line"># /etc/init.d/opentftp.sh restart</span><br><span class="line"># [/share/HDA_DATA/Public/tftpboot] # ps |grep tftp</span><br><span class="line"># 15861 admin      1016 S   /usr/sbin/opentftpd -i /etc/opentftpd.ini -l /share/HDA_DATA/Public/tftpboot/opentftpd.log</span><br><span class="line">sudo mount -o loop /bak/images/ubuntu-16.04.2-server-amd64.iso /mnt/</span><br><span class="line">mkdir /tmp/tftpboot &amp;&amp; sudo cp -r /mnt/install/netboot/* /tmp/tftpboot/</span><br><span class="line">sudo bash -c &apos;cat &gt; /tmp/tftpboot/pxelinux.cfg/default &lt;&lt; EOF</span><br><span class="line">default linux </span><br><span class="line">label linux</span><br><span class="line">    kernel ubuntu-installer/amd64/linux</span><br><span class="line">    append vga=normal initrd=ubuntu-installer/amd64/initrd.gz --</span><br><span class="line">EOF&apos;</span><br><span class="line">scp -r /tmp/tftpboot/* admin@192.168.99.122:/share/HDA_DATA/Public/tftpboot/</span><br></pre></td></tr></table></figure>
<h2 id="Configure-dnsmasq-on-OpenWRT-to-use-external-tftp-server"><a href="#Configure-dnsmasq-on-OpenWRT-to-use-external-tftp-server" class="headerlink" title="Configure dnsmasq on OpenWRT to use external tftp server"></a>Configure dnsmasq on OpenWRT to use external tftp server</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/dnsmasq.conf &lt;&lt; EOF</span><br><span class="line">enable-tftp</span><br><span class="line">dhcp-boot=pxelinux.0,pxeboot,192.168.99.122</span><br><span class="line">EOF</span><br><span class="line">/etc/init.d/dnsmasq restart</span><br></pre></td></tr></table></figure>
<h2 id="Create-ks-cfg-file-on-QNAP"><a href="#Create-ks-cfg-file-on-QNAP" class="headerlink" title="Create ks.cfg file on QNAP"></a>Create ks.cfg file on QNAP</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"># then can visit via - http://192.168.99.122:8080/ks.cfg, so the key line is &apos;url --url http://192.168.99.122:8080&apos;</span><br><span class="line">cat &gt; /home/httpd/ks.cfg &lt;&lt; EOF</span><br><span class="line">#Generated by Kickstart Configurator</span><br><span class="line">#platform=AMD64 or Intel EM64T</span><br><span class="line">#System language</span><br><span class="line">lang en_US</span><br><span class="line">#Language modules to install</span><br><span class="line">langsupport en_US</span><br><span class="line">#System keyboard</span><br><span class="line">keyboard us</span><br><span class="line">#System mouse</span><br><span class="line">mouse</span><br><span class="line">#System timezone</span><br><span class="line">timezone Asia/Chongqing</span><br><span class="line">#Root password</span><br><span class="line">rootpw --disabled</span><br><span class="line">#Initial user</span><br><span class="line">user hua --fullname hua --password password</span><br><span class="line">#Reboot after installation</span><br><span class="line">reboot</span><br><span class="line">#Use text mode install</span><br><span class="line">text</span><br><span class="line">#Install OS instead of upgrade</span><br><span class="line">install</span><br><span class="line">#Use Web installation media</span><br><span class="line">url --url http://192.168.99.122:8080</span><br><span class="line">#System bootloader configuration</span><br><span class="line">bootloader --location=mbr </span><br><span class="line">#Clear the Master Boot Record</span><br><span class="line">zerombr yes</span><br><span class="line">#Partition clearing information</span><br><span class="line">clearpart --all --initlabel </span><br><span class="line">#Disk partitioning information</span><br><span class="line">part swap --size 2048 </span><br><span class="line">part /boot --fstype ext4 --size 512 </span><br><span class="line">part / --fstype ext4 --size 1 --grow </span><br><span class="line">#System authorization infomation</span><br><span class="line">auth  --useshadow  --enablemd5 </span><br><span class="line">#Network information</span><br><span class="line">network --bootproto=dhcp --device=eth0</span><br><span class="line">#network --bootproto=static--ip=192.168.5.168 --netmask=255.255.255.0 --gateway=192.168.100.1--nameserver=8.8.8.8 --device=eth0</span><br><span class="line">#Firewall configuration</span><br><span class="line">firewall --disabled </span><br><span class="line">#Do not configure the X Window System</span><br><span class="line">skipx</span><br><span class="line"># Additional packages to install</span><br><span class="line">%packages</span><br><span class="line">ca-certificates</span><br><span class="line">openssl</span><br><span class="line">python</span><br><span class="line">openssh-server</span><br><span class="line">vim</span><br><span class="line">ubuntu-desktop</span><br><span class="line">unity</span><br><span class="line"># Add your custom post installation script here</span><br><span class="line">%post</span><br><span class="line"># Add post installation script to /usr/local/bin/ directory</span><br><span class="line">ls .</span><br><span class="line"># Fix locale</span><br><span class="line">echo &apos;LANG=&quot;en_US.UTF-8&quot;&apos; &gt; /etc/default/locale</span><br><span class="line">echo &apos;LANGUAGE=&quot;en_US:en&quot;&apos; &gt;&gt; /etc/default/locale</span><br><span class="line">echo &apos;LC_ALL=&quot;en_US.UTF-8&quot;&apos; &gt;&gt; /etc/default/locale</span><br><span class="line"># Clean</span><br><span class="line">apt-get -f -y install</span><br><span class="line">apt-get -y autoremove</span><br><span class="line">apt-get clean</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="Create-Preseed-file-on-QNAP"><a href="#Create-Preseed-file-on-QNAP" class="headerlink" title="Create Preseed file on QNAP"></a>Create Preseed file on QNAP</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#https://help.ubuntu.com/lts/installation-guide/armhf/apbs01.html</span><br><span class="line"># https://www.debian.org/releases/squeeze/example-preseed.txt</span><br><span class="line">cat &gt; /home/httpd/ubuntu-auto.seed &lt;&lt; EOF</span><br><span class="line"># Unmount drives with active partitions. Without this command all the installation process would stop and require confirmation to unmount drives that are already mounted.</span><br><span class="line">d-i preseed/early_command string umount /media || true</span><br><span class="line"># Don&apos;t install recommended items</span><br><span class="line">d-i preseed base-installer/install-recommends boolean false</span><br><span class="line"># Install only security updates automatically</span><br><span class="line">d-i preseed pkgsel/update-policy select unattended-upgrades</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="Use-ks-cfg-and-preseed"><a href="#Use-ks-cfg-and-preseed" class="headerlink" title="Use ks.cfg and preseed"></a>Use ks.cfg and preseed</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## Modify the file /share/HDA_DATA/Public/tftpboot/pxelinux.cfg/default</span><br><span class="line">append ks=http://192.168.99.122:8080/ks.cfg preseed/url=http://192.168.99.122:8080/ubuntu-auto.seed vga=normal initrd=ubuntu-installer/amd64/initrd.gz --</span><br></pre></td></tr></table></figure>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">images_root=/bak/images</span><br><span class="line">rootdisk=$images_root/test.img</span><br><span class="line">domain_xml=test.xml</span><br><span class="line">dpkg -s virtinst &amp;&gt;/dev/null || sudo apt install virtinst -y</span><br><span class="line">if ! [ -e &quot;$rootdisk&quot; ]; then</span><br><span class="line">    qemu-img create -f qcow2 $rootdisk 20G</span><br><span class="line">fi</span><br><span class="line">sudo bash -c &apos;cat &gt;&gt; /etc/network/interfaces &lt;&lt; EOF</span><br><span class="line">auto enp0s25</span><br><span class="line">iface enp0s25 inet manual</span><br><span class="line">    mtu 1500</span><br><span class="line">auto br-enp0s25</span><br><span class="line">iface br-enp0s25 inet static</span><br><span class="line">    address 192.168.99.135/24</span><br><span class="line">    gateway 192.168.99.1</span><br><span class="line">    bridge_ports enp0s25</span><br><span class="line">EOF&apos;</span><br><span class="line">ifup br-enp0s25</span><br><span class="line">sudo virt-install \</span><br><span class="line">    --name=bootstrap \</span><br><span class="line">    --connect=qemu:///system --ram=2048 --vcpus=1 --hvm \</span><br><span class="line">    --virt-type=kvm \</span><br><span class="line">    --pxe --boot network,hd \</span><br><span class="line">    --graphics vnc --noautoconsole --os-type=linux --accelerate \</span><br><span class="line">    --disk=$&#123;rootdisk&#125;,bus=virtio,format=qcow2 \</span><br><span class="line">    --network=bridge=juju-vm-br,model=virtio \</span><br><span class="line">    --print-xml 2 &gt; $domain_xml</span><br><span class="line">echo &quot;test domain definition is now available at $domain_xml&quot;</span><br></pre></td></tr></table></figure>
<h2 id="相关日志"><a href="#相关日志" class="headerlink" title="相关日志"></a>相关日志</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[/home/httpd] # tail -f /share/HDA_DATA/Public/tftpboot/opentftpd.log           </span><br><span class="line">[02-Dec-17 19:54:25] Client 192.168.99.150:49162 /share/HDA_DATA/Public/tftpboot/pxelinux.cfg/default, 2 Blocks Served</span><br><span class="line">[02-Dec-17 19:54:44] Client 192.168.99.150:49163 /share/HDA_DATA/Public/tftpboot/ubuntu-installer/amd64/linux, 5025 Blocks Served</span><br><span class="line">[02-Dec-17 19:56:30] Client 192.168.99.150:49164 /share/HDA_DATA/Public/tftpboot/ubuntu-installer/amd64/initrd.gz, 28718 Blocks Served</span><br><span class="line">[02-Dec-17 20:20:44] Client 192.168.99.136:59249 /share/HDA_DATA/Public/tftpboot/pxelinux.0, 31 Blocks Served</span><br><span class="line">[02-Dec-17 20:20:45] Client 192.168.99.136:49152 /share/HDA_DATA/Public/tftpboot/ldlinux.c32, 84 Blocks Served</span><br><span class="line">[02-Dec-17 20:20:45] Client 192.168.99.136:49163 /share/HDA_DATA/Public/tftpboot/pxelinux.cfg/default, 2 Blocks Served</span><br><span class="line">[02-Dec-17 20:21:01] Client 192.168.99.136:49164 /share/HDA_DATA/Public/tftpboot/ubuntu-installer/amd64/linux, 5025 Blocks Served</span><br><span class="line">[02-Dec-17 20:22:44] Client 192.168.99.136:49165 /share/HDA_DATA/Public/tftpboot/ubuntu-installer/amd64/initrd.gz, 28718 Blocks Served</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/12/02/OpenWRT与QNAP上通过PXE安装Xenial/" data-id="cjapajjp90000k6bppkhw3j1b" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Test-multipath-feature-by-openstack-lioadm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/29/Test-multipath-feature-by-openstack-lioadm/" class="article-date">
  <time datetime="2017-11-29T08:08:13.000Z" itemprop="datePublished">2017-11-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/29/Test-multipath-feature-by-openstack-lioadm/">Test multipath feature by openstack lioadm</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>之前写过一篇关于使用tgtadm测试OpenStack Multipath特性的<a href="http://blog.csdn.net/quqi99/article/details/54973369" target="_blank" rel="external">文章</a>。tgt是一个用户态的iscsi target，lio是内核核的iscsi target并且它已经被集成到了Linux内核。<br>在OpenStack Icehouse版本，由于仅支持单target (即cinder还不支持iscsi_secondary_ip_addresses选项用于配置第二个target)，所以基于Icehouse的tgtadm将无法支持multipath。但使用lioadm改点配置可以支持。</p>
<h2 id="基于OpenStack环境"><a href="#基于OpenStack环境" class="headerlink" title="基于OpenStack环境"></a>基于OpenStack环境</h2><p>搭建一个简单带cinder的openstack环境即可，不需要ceph支持。可参考<a href="http://blog.csdn.net/quqi99/article/details/54973369" target="_blank" rel="external">这篇文章</a>的一小部分安装。</p>
<h2 id="cinder节点安装LIO-target与加载target-core-mod模块"><a href="#cinder节点安装LIO-target与加载target-core-mod模块" class="headerlink" title="cinder节点安装LIO-target与加载target_core_mod模块"></a>cinder节点安装LIO-target与加载target_core_mod模块</h2><p>先加载target_core_mod模块<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">juju ssh cinder/0</span><br><span class="line">sudo apt install linux-image-extra-$(uname -r)  #Avoid the error &apos;Module target_core_mod not found&apos;</span><br><span class="line">sudo apt build-dep linux-image-$(uname -r)</span><br><span class="line">sudo modprobe target_core_mod</span><br></pre></td></tr></table></figure></p>
<p>cinder节点上需要安装LIO-target<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#Install LIO-target - https://www.thomas-krenn.com/de/wiki/Linux-IO_Target_(LIO)_unter_Ubuntu_14.04</span><br><span class="line">sudo apt install open-iscsi targetcli python-urwid lio-utils python-pyparsing python-prettytable python-rtslib python-configshell</span><br><span class="line">sudo pip install &apos;rtslib-fb&gt;=2.1.39&apos;</span><br></pre></td></tr></table></figure></p>
<p>需要说明的是，这里面有一个bug，因为Icehouse版本 /usr/bin/cinder-rtstool文件中使用了rtslib-fb&gt;=2.1.39，所以我们必须使用“sudo pip install ‘rtslib-fb&gt;=2.1.39’”命令安装它。但是rtslib-fb这个模块比较老又被废弃了，targetcli工具又使用了比较新的rtslib模块。<br>如果我们删除rtslib-fb模块(sudo pip uninstall y rtslib-fb)而使用rtslib模块targetcli工具将会恢复正常，但是/usr/bin/cinder-rtstool工具在运行下列命令时会报错：’ImportError: No module named rtslib_fb’<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cinder-rootwrap /etc/cinder/rootwrap.conf cinder-rtstool create /dev/cinder-volumes/volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea zAXMzsNKJ4kBvDYCZBec VyhWebHq3GBKE22zYjpX</span><br></pre></td></tr></table></figure></p>
<p>幸好，/usr/bin/cinder-rtstool里没有使用targetcli，所以我们必须使用‘rtslib-fb&gt;=2.1.39’模块。<br>下面是正常使用targetcli工具的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root@juju-c0c753-trusty-icehouse-0:~# targetcli</span><br><span class="line">targetcli GIT_VERSION (rtslib GIT_VERSION)</span><br><span class="line">Copyright (c) 2011-2013 by Datera, Inc.</span><br><span class="line">All rights reserved.</span><br><span class="line">/&gt; ls</span><br><span class="line">o- / ............................................................................................................... [...]</span><br><span class="line">  o- backstores .................................................................................................... [...]</span><br><span class="line">  | o- fileio ......................................................................................... [0 Storage Object]</span><br><span class="line">  | o- iblock ......................................................................................... [0 Storage Object]</span><br><span class="line">  | o- pscsi .......................................................................................... [0 Storage Object]</span><br><span class="line">  | o- rd_dr .......................................................................................... [0 Storage Object]</span><br><span class="line">  | o- rd_mcp ......................................................................................... [0 Storage Object]</span><br><span class="line">  o- ib_srpt ................................................................................................. [0 Targets]</span><br><span class="line">  o- iscsi ................................................................................................... [0 Targets]</span><br><span class="line">  o- loopback ................................................................................................ [0 Targets]</span><br><span class="line">  o- qla2xxx ................................................................................................. [0 Targets]</span><br><span class="line">  o- tcm_fc .................................................................................................. [0 Targets]</span><br><span class="line">/&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Cinder节点继续修改"><a href="#Cinder节点继续修改" class="headerlink" title="Cinder节点继续修改"></a>Cinder节点继续修改</h2><p>Icehouse的lioadm默认也是只支持一个iscsi target的，要想支持多个，需要做如下的修改，<strong>让一个cinder节点(10.5.0.22)的两个端口(3260, 3261)去做multipath</strong>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo sed -i &apos;s/import rtslib/import rtslib_fb as rtslib/g&apos; /usr/bin/cinder-rtstool</span><br><span class="line">sudo sed -i &apos;s/if target == None:/if not target:/g&apos; /usr/bin/cinder-rtstool</span><br><span class="line"># For this step, you must replace IPADDRESS with the actual IP of the cinder/0 node.</span><br><span class="line">sudo sed -i &quot;s/rtslib.NetworkPortal(tpg_new, &apos;0.0.0.0&apos;, 3260, mode=&apos;any&apos;)/rtslib.NetworkPortal(tpg_new, &apos;10.5.0.22&apos;, 3260, mode=&apos;any&apos;)\n\t rtslib.NetworkPortal(tpg_new, &apos;10.5.0.22&apos;, 3261, mode=&apos;any&apos;)/g&quot; /usr/bin/cinder-rtstool</span><br></pre></td></tr></table></figure></p>
<p>通过charm变更使用lioadm，当然也可以手工修改<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http_proxy=http://squid.internal:3128 git clone https://github.com/openstack/charm-cinder.git</span><br><span class="line">cd charm-cinder</span><br><span class="line">sed -i &apos;s/tgtadm/lioadm/g&apos; templates/icehouse/cinder.conf</span><br><span class="line">juju upgrade-charm cinder --path $PWD</span><br></pre></td></tr></table></figure></p>
<p>停止tgt服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">juju ssh cinder/0 sudo service tgt stop</span><br></pre></td></tr></table></figure></p>
<p>使用lioadm时，<strong>不需要</strong>像tgtadm那样在计算节点的nova.conf中配置下列参考支持multipath:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[libvirt]</span><br><span class="line">iscsi_use_multipath = True</span><br></pre></td></tr></table></figure></p>
<h2 id="使用windows镜像"><a href="#使用windows镜像" class="headerlink" title="使用windows镜像"></a>使用windows镜像</h2><p>我们使用windows镜像测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">source ~/novarc &amp;&amp; glance image-download --file windows2012R2_virtio.raw --progress 31dd4e9f-ccd3-4c57-b10e-6b5e99366240</span><br><span class="line">source novarc &amp;&amp; glance image-create --name windows2012R2 --file /bak/windows2012R2_virtio.raw --visibility public --progress --container-format bare --disk-format raw</span><br><span class="line">nova keypair-add --pub-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">nova flavor-create myflavor auto 3200 45 1 </span><br><span class="line">openstack server create --wait --image windows2012R2 --flavor myflavor --key-name mykey --nic net-id=dd269a94-5b76-4e24-8046-4d377fa3be5f --min 1 --max 1 i1</span><br><span class="line">nova floating-ip-create</span><br><span class="line">nova floating-ip-associate i1 10.5.150.2</span><br><span class="line">./tools/sec_groups.sh</span><br></pre></td></tr></table></figure></p>
<p>Windows镜像比较大，有31G，所以默认创建的glance硬盘不够会失败，删除glance节点再通过‘root-disk=90G’参数重新安装：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">juju remove-unit glance/0</span><br><span class="line">juju remove-application glance</span><br><span class="line">juju deploy cs:~openstack-charmers-next/glance --constraints &quot;mem=1G root-disk=90G&quot; --series trusty</span><br><span class="line">juju add-relation nova-cloud-controller glance</span><br><span class="line">juju add-relation nova-compute glance</span><br><span class="line">juju add-relation glance mysql</span><br><span class="line">juju add-relation glance keystone</span><br><span class="line">juju add-relation glance &quot;cinder:image-service&quot;</span><br><span class="line">juju add-relation glance rabbitmq-server</span><br></pre></td></tr></table></figure></p>
<p>至于如何在多层内网情况下仍然能够通过图形化RDP界面而不是命令行来访问windows虚机，可<a href="http://blog.csdn.net/quqi99/article/details/78662647" target="_blank" rel="external">参考文章</a>。</p>
<h2 id="为虚机创建磁盘"><a href="#为虚机创建磁盘" class="headerlink" title="为虚机创建磁盘"></a>为虚机创建磁盘</h2><p>为虚机创建磁盘：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cinder create --display_name test_volume 1</span><br><span class="line">nova volume-attach i1 1a3e3146-5df7-49ed-8041-de1de257a300</span><br><span class="line"></span><br><span class="line">root@juju-c0c753-trusty-icehouse-7:~# sudo iscsiadm -m session</span><br><span class="line">tcp: [1] 10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-8237a312-7512-41f5-a02a-34856fa3896e</span><br><span class="line">tcp: [2] 10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1a3e3146-5df7-49ed-8041-de1de257a300</span><br><span class="line">root@juju-c0c753-trusty-icehouse-7:~# sudo iscsiadm -m node</span><br><span class="line">10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1a3e3146-5df7-49ed-8041-de1de257a300</span><br><span class="line">10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-8237a312-7512-41f5-a02a-34856fa3896e</span><br></pre></td></tr></table></figure></p>
<p>登录windows虚机后在Powershell中使用”Get-Disk”命令可以看到一个新磁盘。<br>同时登录计算节点看到libvirt已经为windows虚机生成了配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;disk type=&apos;block&apos; device=&apos;disk&apos;&gt;</span><br><span class="line">     &lt;driver name=&apos;qemu&apos; type=&apos;raw&apos; cache=&apos;none&apos;/&gt;</span><br><span class="line">     &lt;source dev=&apos;/dev/mapper/360014050fd353e4dd274f20b1abd70e4&apos;/&gt;</span><br><span class="line">     &lt;target dev=&apos;vdb&apos; bus=&apos;virtio&apos;/&gt;</span><br><span class="line">     &lt;serial&gt;1035ee80-339e-4e4e-b4c9-6c925cb259ea&lt;/serial&gt;</span><br><span class="line">     &lt;alias name=&apos;virtio-disk1&apos;/&gt;</span><br><span class="line">     &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x05&apos; function=&apos;0x0&apos;/&gt;</span><br><span class="line">   &lt;/disk&gt;</span><br></pre></td></tr></table></figure></p>
<p>mutlipath信息如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install multipath-tools</span><br><span class="line"># multipath -ll</span><br><span class="line">360014050fd353e4dd274f20b1abd70e4 dm-0 LIO-ORG ,IBLOCK          </span><br><span class="line">size=1.0G features=&apos;0&apos; hwhandler=&apos;0&apos; wp=rw</span><br><span class="line">|-+- policy=&apos;round-robin 0&apos; prio=1 status=active</span><br><span class="line">| `- 4:0:0:0 sdc   8:32   active ready  running</span><br><span class="line">`-+- policy=&apos;round-robin 0&apos; prio=1 status=enabled</span><br><span class="line">  `- 5:0:0:0 sdd   8:48   active ready  running</span><br><span class="line"></span><br><span class="line">root@juju-c0c753-trusty-icehouse-7:~# sudo iscsiadm -m session</span><br><span class="line">tcp: [1] 10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-8237a312-7512-41f5-a02a-34856fa3896e</span><br><span class="line">tcp: [2] 10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1a3e3146-5df7-49ed-8041-de1de257a300</span><br><span class="line">tcp: [3] 10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br><span class="line">tcp: [4] 10.5.0.22:3261,1 iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br><span class="line">root@juju-c0c753-trusty-icehouse-7:~# sudo iscsiadm -m node</span><br><span class="line">10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1a3e3146-5df7-49ed-8041-de1de257a300</span><br><span class="line">10.5.0.22:3261,1 iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br><span class="line">10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br><span class="line">10.5.0.22:3260,1 iqn.2010-10.org.openstack:volume-8237a312-7512-41f5-a02a-34856fa3896e</span><br><span class="line"></span><br><span class="line">root@juju-c0c753-trusty-icehouse-7:~# ls /dev/mapper/360014050fd353e4dd274f20b1abd70e4</span><br><span class="line">/dev/mapper/360014050fd353e4dd274f20b1abd70e4</span><br></pre></td></tr></table></figure></p>
<h2 id="detach磁盘"><a href="#detach磁盘" class="headerlink" title="detach磁盘"></a>detach磁盘</h2><p>detach磁盘，在syslog中看到了一系列的错误日志，但是功能正常，能够正常detach<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nova volume-dettach i1  1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">2017-11-29 07:30:13.641 25277 WARNING cinder.context [-] Arguments dropped when creating context: &#123;&apos;user&apos;: u&apos;186c37006bd94287ae768e1f80676584&apos;, &apos;tenant&apos;: u&apos;becbf8797c954e2492d62a42a43a4324&apos;, &apos;user_identity&apos;: u&apos;186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -&apos;&#125;</span><br><span class="line">2017-11-29 07:30:13.867 25277 WARNING cinder.context [-] Arguments dropped when creating context: &#123;&apos;user&apos;: u&apos;186c37006bd94287ae768e1f80676584&apos;, &apos;tenant&apos;: u&apos;becbf8797c954e2492d62a42a43a4324&apos;, &apos;user_identity&apos;: u&apos;186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -&apos;&#125;</span><br><span class="line">2017-11-29 07:30:13.876 25277 DEBUG cinder.openstack.common.lockutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Got semaphore &quot;1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume&quot; for method &quot;lvo_inner2&quot;... inner /usr/lib/python2.7/dist-packages/cinder/openstack/common/lockutils.py:191</span><br><span class="line">2017-11-29 07:30:13.877 25277 DEBUG cinder.openstack.common.lockutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Attempting to grab file lock &quot;1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume&quot; for method &quot;lvo_inner2&quot;... inner /usr/lib/python2.7/dist-packages/cinder/openstack/common/lockutils.py:202</span><br><span class="line">2017-11-29 07:30:13.878 25277 DEBUG cinder.openstack.common.lockutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Got file lock &quot;1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume&quot; at /var/lock/cinder/cinder-1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume for method &quot;lvo_inner2&quot;... inner /usr/lib/python2.7/dist-packages/cinder/openstack/common/lockutils.py:232</span><br><span class="line">2017-11-29 07:30:14.245 25277 DEBUG cinder.volume.manager [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] volume 1035ee80-339e-4e4e-b4c9-6c925cb259ea: removing export detach_volume /usr/lib/python2.7/dist-packages/cinder/volume/manager.py:687</span><br><span class="line">2017-11-29 07:30:14.263 25277 INFO cinder.brick.iscsi.iscsi [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Removing iscsi_target: 1035ee80-339e-4e4e-b4c9-6c925cb259ea</span><br><span class="line">2017-11-29 07:30:14.264 25277 DEBUG cinder.openstack.common.processutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Running cmd (subprocess): sudo cinder-rootwrap /etc/cinder/rootwrap.conf cinder-rtstool delete iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea execute /usr/lib/python2.7/dist-packages/cinder/openstack/common/processutils.py:147</span><br><span class="line">2017-11-29 07:30:14.738 25277 DEBUG cinder.openstack.common.processutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Result was 0 execute /usr/lib/python2.7/dist-packages/cinder/openstack/common/processutils.py:171</span><br><span class="line">2017-11-29 07:30:14.754 25277 DEBUG cinder.openstack.common.lockutils [req-e5121fa9-5b8d-48ac-a378-21c5c049fda8 186c37006bd94287ae768e1f80676584 becbf8797c954e2492d62a42a43a4324 - - -] Released file lock &quot;1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume&quot; at /var/lock/cinder/cinder-1035ee80-339e-4e4e-b4c9-6c925cb259ea-detach_volume for method &quot;lvo_inner2&quot;... inner /usr/lib/python2.7/dist-packages/cinder/openstack/common/lockutils.py:239</span><br><span class="line">2017-11-29 07:31:02.297 25277 DEBUG cinder.openstack.common.periodic_task [-] Running periodic task VolumeManager._publish_service_capabilities run_periodic_tasks /usr/lib/python2.7/dist-packages/cinder/openstack/common/periodic_task.py:178</span><br><span class="line">2017-11-29 07:31:02.300 25277 DEBUG cinder.manager [-] Notifying Schedulers of capabilities ... _publish_service_capabilities /usr/lib/python2.7/dist-packages/cinder/manager.py:128</span><br><span class="line">2017-11-29 07:31:02.321 25277 DEBUG cinder.openstack.common.periodic_task [-] Running periodic task VolumeManager._report_driver_status run_periodic_tasks /usr/lib/python2.7/dist-packages/cinder/openstack/common/periodic_task.py:178</span><br><span class="line">2017-11-29 07:31:02.323 25277 INFO cinder.volume.manager [-] Updating volume status</span><br><span class="line">2017-11-29 07:31:02.323 25277 DEBUG cinder.volume.drivers.lvm [-] Updating volume stats _update_volume_stats /usr/lib/python2.7/dist-packages/cinder/volume/drivers/lvm.py:346</span><br><span class="line">2017-11-29 07:31:02.325 25277 DEBUG cinder.openstack.common.processutils [-] Running cmd (subprocess): sudo cinder-rootwrap /etc/cinder/rootwrap.conf env LC_ALL=C vgs --noheadings --unit=g -o name,size,free,lv_count,uuid --separator : --nosuffix cinder-volumes execute /usr/lib/python2.7/dist-packages/cinder/openstack/common/processutils.py:147</span><br><span class="line">2017-11-29 07:31:02.469 25277 DEBUG cinder.openstack.common.processutils [-] Result was 0 execute /usr/lib/python2.7/dist-packages/cinder/openstack/common/processutils.py:171</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Nov 29 07:29:57 juju-c0c753-trusty-icehouse-7 kernel: [86241.589558]  connection1:0: detected conn error (1020)</span><br><span class="line"></span><br><span class="line">Nov 29 07:29:57 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:29:57 juju-c0c753-trusty-icehouse-7 kernel: [86242.360928]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:29:58 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:00 juju-c0c753-trusty-icehouse-7 kernel: [86244.630641]  connection1:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:00 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:00 juju-c0c753-trusty-icehouse-7 kernel: [86245.399222]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:01 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:03 juju-c0c753-trusty-icehouse-7 kernel: [86247.672850]  connection1:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:03 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:03 juju-c0c753-trusty-icehouse-7 kernel: [86248.442433]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:04 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:06 juju-c0c753-trusty-icehouse-7 kernel: [86250.702435]  connection1:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:06 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:06 juju-c0c753-trusty-icehouse-7 kernel: [86251.461198]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:07 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:09 juju-c0c753-trusty-icehouse-7 kernel: [86253.725045]  connection1:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:09 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 kernel: [86254.494474]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 kernel: [86254.659090] type=1400 audit(1511940610.186:17): apparmor=&quot;STATUS&quot; operation=&quot;profile_replace&quot; profile=&quot;unconfined&quot; name=&quot;libvirt-6e468b3b-6cb4-4d5d-a9d6-6ba32b4bd8cb&quot; pid=16120 comm=&quot;apparmor_parser&quot;</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: dm-0: add map (uevent)</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: dm-0: devmap already registered</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:10 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: dm-0: remove map (uevent)</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: 360014050fd353e4dd274f20b1abd70e4: devmap removed</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: 360014050fd353e4dd274f20b1abd70e4: stop event checker thread (140170797860608)</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: dm-0: remove map (uevent)</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: uevent trigger error</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: sdc: remove path (uevent)</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 kernel: [86255.657776] sd 4:0:0:0: [sdc] Synchronizing SCSI cache</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 multipathd: sdd: remove path (uevent)</span><br><span class="line">Nov 29 07:30:11 juju-c0c753-trusty-icehouse-7 kernel: [86256.365042] sd 5:0:0:0: [sdd] Synchronizing SCSI cache</span><br><span class="line">Nov 29 07:30:12 juju-c0c753-trusty-icehouse-7 iscsid: Connection3:0 to [target: iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea, portal: 10.5.0.22,3260] through [iface: default] is shutdown.</span><br><span class="line">Nov 29 07:30:12 juju-c0c753-trusty-icehouse-7 iscsid: Connection4:0 to [target: iqn.2010-10.org.openstack:volume-1035ee80-339e-4e4e-b4c9-6c925cb259ea, portal: 10.5.0.22,3261] through [iface: default] is shutdown.</span><br><span class="line">Nov 29 07:30:12 juju-c0c753-trusty-icehouse-7 kernel: [86257.129920]  connection1:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:13 juju-c0c753-trusty-icehouse-7 kernel: [86257.893417]  connection2:0: detected conn error (1020)</span><br><span class="line">Nov 29 07:30:13 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:14 juju-c0c753-trusty-icehouse-7 iscsid: conn 0 login rejected: target error (03/01)</span><br><span class="line">Nov 29 07:30:16 juju-c0c753-trusty-icehouse-7 iscsid: connect to 10.5.0.22:3260 failed (Connection refused)</span><br><span class="line">Nov 29 07:30:16 juju-c0c753-trusty-icehouse-7 iscsid: connect to 10.5.0.22:3260 failed (Connection refused)</span><br><span class="line">Nov 29 07:30:19 juju-c0c753-trusty-icehouse-7 iscsid: connect to 10.5.0.22:3260 failed (Connection refused)</span><br><span class="line">Nov 29 07:30:20 juju-c0c753-trusty-icehouse-7 iscsid: connect to 10.5.0.22:3260 failed (Connection refused)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/29/Test-multipath-feature-by-openstack-lioadm/" data-id="cjapajjqa0008k6bpl59nsxif" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-远程访问双层嵌套Openstack云下的Windows虚机" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/29/远程访问双层嵌套Openstack云下的Windows虚机/" class="article-date">
  <time datetime="2017-11-29T02:42:21.000Z" itemprop="datePublished">2017-11-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/29/远程访问双层嵌套Openstack云下的Windows虚机/">远程访问双层嵌套Openstack云下的Windows虚机</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>遇到这么一个奇葩组合问题，一个Bug只在Windows虚机上出现，实验环境是远程OpenStack云上再嵌套OpenStack云上提供的一个Windows虚机，两个OpenStack云都采用内网IP，现在的问题是如何远程登录到Windows虚机中。环境如下：</p>
<ul>
<li>Bastion中转机，是由Underlying OpenStack提供的一台虚机，它的floating ip是10.230.65.8，可通过VPN连接到该IP。众所周知的原因，VPN连接是容易断的。所以平时是先ssh连接到VPS，再在VPS启动VPN连接这台机器的。由于平时都是使用命令行所以没遇到问题，但是现在是采用RDP图形化界面连接Windows虚机的，那么网速就跟不上了。无奈，只能继续将VPN创建在本机上。</li>
<li>Tenant OpenStack -  最上层的OpenStack是由Underlying OpenStack提供的虚机创建的。上层Tenant OpenStack的为这台Windows虚机提供的浮动IP是10.5.150.2</li>
<li>如果我们将Windows虚机创建在Underlying OpenStack上，那么它可以分到10.230网段的IP，那么问题就简化了，登录VPN打通网络后直接通过remmina远程连接即可。但由于Underlying OpenStack我无权限控制，Windows虚机创建在Tenant OpenStack上，那样问题就复杂化了。 <h2 id="访问Tenant-OpenStack的Horizon界面"><a href="#访问Tenant-OpenStack的Horizon界面" class="headerlink" title="访问Tenant OpenStack的Horizon界面"></a>访问Tenant OpenStack的Horizon界面</h2>这个简单，登录VPN后，再在本机运行sshuttle命令即可访问horizon界面。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sshuttle -D -r ubuntu@10.230.65.8 10.5.0.0/24</span><br><span class="line">http://10.5.0.52/horizon</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="通过noVNC访问Tenant-OpenStack提供的Linux虚机"><a href="#通过noVNC访问Tenant-OpenStack提供的Linux虚机" class="headerlink" title="通过noVNC访问Tenant OpenStack提供的Linux虚机"></a>通过noVNC访问Tenant OpenStack提供的Linux虚机</h2><p>Linux虚机要是通过命令行来访问，那就没这些问题了。若要图形化访问，可以采用novnc方案。<br>1， 在控制节点上安装下列四个组件。计算节点不需要安装包。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nova-consoleauth novnc python-novnc nova-novncproxy</span><br><span class="line">sudo service nova-consoleauth restart</span><br><span class="line">sudo service nova-novncproxy restart</span><br><span class="line">sudo service libvirt-bin restart</span><br></pre></td></tr></table></figure></p>
<p>2， 在控制节点和计算节点上同时配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vnc_enabled = True</span><br><span class="line">novnc_enabled = True</span><br><span class="line">vncserver_proxyclient_address=10.5.0.49</span><br><span class="line">vncserver_listen=0.0.0.0</span><br><span class="line">novncproxy_base_url=http://10.5.0.43:6080/vnc_auto.html</span><br></pre></td></tr></table></figure></p>
<p>3, 通过下列命令就可以获得novnc连接并访问了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nova get-vnc-console i1 novnc</span><br><span class="line">sshuttle -D -r ubuntu@10.230.65.8 10.5.0.0/24</span><br></pre></td></tr></table></figure></p>
<p>上面命令相当于手动打开虚机的vnc支持：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo virsh edit i1</span><br><span class="line">   &lt;graphics type=&apos;vnc&apos; port=&apos;-1&apos; autoport=&apos;yes&apos; listen=&apos;192.168.99.124&apos; passwd=&apos;password&apos; keymap=&apos;en-us&apos;/&gt;</span><br><span class="line">sudo virsh shutdown i1 &amp;&amp; sudo virsh start i1</span><br><span class="line">#sudo virsh -c qemu+ssh://hua@node1/system vncdisplay i1</span><br><span class="line">sudo virsh vncdisplay i1</span><br><span class="line">vncviewer 192.168.99.124:1</span><br></pre></td></tr></table></figure></p>
<p>如果本机开了VPN后通过’ssh -X’远程连接中转机，再通过上面的vncviewer也是可以连接Linux虚机的。<br>但是该Windows虚机不支持VNC，但它默认启动了RDP。同理，我们也可以本机开了VPN后通过’ssh -X’远程连接中转机，再通过remmina访问(或者采用rdesktop命令行方式 )，但是这种方式奇慢无比，于是有了本文的探讨。</p>
<h2 id="通过tunnel-remmina访问Tenant-OpenStack提供的Windows虚机"><a href="#通过tunnel-remmina访问Tenant-OpenStack提供的Windows虚机" class="headerlink" title="通过tunnel+remmina访问Tenant OpenStack提供的Windows虚机"></a>通过tunnel+remmina访问Tenant OpenStack提供的Windows虚机</h2><p>设想的方案是通过如果的ssh正向隧道方式，本机上执行如下命令，本机的13389端口通过ssh server 10.230.65.8映射到远程的10.5.150.2:3389上。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 22 -L localhost:13389:10.5.150.2:3389 ubuntu@10.230.65.8 -N -v</span><br><span class="line">#sudo rdesktop 127.0.0.1:13389</span><br><span class="line">sudo rdesktop -z -r sound:local -g workarea -D -K -a 16 -u Administrator -p password 127.0.0.1:13389</span><br></pre></td></tr></table></figure></p>
<p>但是发现不好使，原因在于在中转机10.230.65.8上都无法运行telnet 10.5.150.2 3389’命令。<br>VNC的5900-5910这些端口与RDP的3389端口似乎还有点不一样，<strong>5900-5910是运行虚机的物理机上的端口，而3389是Windows虚机的端口</strong>。</p>
<p>所以第一步，应该将Windows虚机所在的物理机的Security group规则打开，这个得在Tenant OpenStack环境中执行如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">nova secgroup-add-rule default tcp 3389 3389 0.0.0.0/0</span><br><span class="line">nova secgroup-add-rule default udp 3389 3389 0.0.0.0/0</span><br><span class="line">#secgroup=$&#123;1:-`openstack security group list --project admin| grep default| awk &apos;&#123;print $2&#125;&apos;`&#125;</span><br><span class="line">#openstack security group rule create $secgroup --protocol tcp --remote-ip 0.0.0.0/0 --dst-port 3389 --project admin</span><br><span class="line"></span><br><span class="line">#计算节点上通过下列命令验证：</span><br><span class="line">$ sudo iptables-save |grep 3389</span><br><span class="line">-A neutron-openvswi-i2f32d9bf-6 -p tcp -m tcp --dport 3389 -j RETURN</span><br><span class="line">-A neutron-openvswi-i2f32d9bf-6 -p udp -m udp --dport 3389 -j RETURN</span><br><span class="line"></span><br><span class="line">#网络节点上继续通过下列命令验证通过：</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 telnet 192.168.21.2 3389</span><br></pre></td></tr></table></figure></p>
<p>第二步，要想通过192.168.21.2的floating ip (10.5.150.2)访问，还得将Tenant OpenStack的FWaaS服务中的3389端口打开。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">neutron firewall-rule-create --protocol tcp --destination-port 80 --action allow --name tcp_3389</span><br><span class="line">neutron firewall-rule-create --protocol udp --destination-port 80 --action allow --name udp_3389</span><br><span class="line">neutron firewall-policy-create --firewall-rules &quot;tcp_3389 udp_3389&quot; policy_3389</span><br><span class="line">neutron firewall-create policy_3389 --name myfirewall</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 iptables-save |grep 3389</span><br><span class="line"></span><br><span class="line">#也可以通过下列命令直接手动添加：</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 iptables -A neutron-vpn-agen-iv49ecd7359 -p tcp -m tcp --dport 3389 -j ACCEPT</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 iptables -A neutron-vpn-agen-iv49ecd7359 -p udp -m udp --dport 3389 -j ACCEPT</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 iptables -A neutron-vpn-agen-ov49ecd7359 -p tcp -m tcp --dport 3389 -j ACCEPT</span><br><span class="line">sudo ip netns exec qrouter-d07093c5-f8b3-49c4-9f35-2f43a618b588 iptables -A neutron-vpn-agen-ov49ecd7359 -p udp -m udp --dport 3389 -j ACCEPT</span><br><span class="line"></span><br><span class="line">#添加成功后在网络节点上通过下列命令验证成功：</span><br><span class="line">telnet 10.5.150.2 3389</span><br></pre></td></tr></table></figure></p>
<p>第三步，要想在中断机上也能成功运行’telnet 10.5.150.2 3389’, 由于中断机和Tenant OpenStack的网络节点都是由Underlying OpenStack提供的虚机，所以还需要在Underlying OpenStack中的Security Group设置3389支持。具体命令可以参考第一步，但由于我没有Underlying OpenStack的权限，所以这步做不了，此路不通，做罢，但理论应该是对的。</p>
<h2 id="通过端口映射的方案访问Tenant-OpenStack提供的Windows虚机"><a href="#通过端口映射的方案访问Tenant-OpenStack提供的Windows虚机" class="headerlink" title="通过端口映射的方案访问Tenant OpenStack提供的Windows虚机"></a>通过端口映射的方案访问Tenant OpenStack提供的Windows虚机</h2><p>理论上也可以在中转机上将3389端口映射到Windows虚机的3389端口解决，但同样由于我没有Underlying OpenStack的权限无法解决在中转机上’telent 10.5.150.2 3389’，所以此方案也无法测试。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 3389 -j DNAT --to-destination 10.10.10.7:3389</span><br><span class="line">iptables -A FORWARD -p tcp --dport 3389 -j ACCEPT</span><br></pre></td></tr></table></figure></p>
<h2 id="最后的方案"><a href="#最后的方案" class="headerlink" title="最后的方案"></a>最后的方案</h2><p>没了Underlying OpenStack的权限，这个实验似乎做不下去了，还剩下两个手段：</p>
<ul>
<li><p>一个使用Underlying OpenStack环境的tenant用户为Tenant OpenStack的网络节点再分配一个10.230打头的floating ip （如10.230.65.118)，因为Tenant Network上的网络节点上是可以运行’telent 10.5.150.2 3389’的，同时，10.230的IP也可以在登录VPN后直接访问。但是10.230.65.118代表的网络节点是由Tenant OpenStack提供的，所以从本机登录时应该从中转机拷贝~/.local/share/juju/ssh/juju_id_rsa。这种方式目前已经测试成功。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scp ubuntu@10.230.65.8:/home/ubuntu/.local/share/juju/ssh/juju_id_rsa /home/hua/.ssh/</span><br><span class="line">#ssh -i ~/.ssh/juju_id_rsa ubuntu@10.230.65.118</span><br><span class="line">ssh -i ~/.ssh/juju_id_rsa -p 22 -L localhost:13389:10.5.150.2:3389 ubuntu@10.230.65.118 -N -v</span><br><span class="line">#sudo rdesktop 127.0.0.1:13389</span><br><span class="line">sudo rdesktop -z -r sound:local -g workarea -D -K -a 16 -u Administrator -p password 127.0.0.1:13389</span><br></pre></td></tr></table></figure>
<p>-在Windows虚机中通过下列命令打开Powershell Remote, 再通过pywinrm库(<a href="https://github.com/diyan/pywinrm)通过命令行或程序(https://gist.github.com/vtapia/c4a87289298c73b9f75afcf36ed6a89b)操作Windows，这种方式蛮麻烦。" target="_blank" rel="external">https://github.com/diyan/pywinrm)通过命令行或程序(https://gist.github.com/vtapia/c4a87289298c73b9f75afcf36ed6a89b)操作Windows，这种方式蛮麻烦。</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Set-ExecutionPolicy -ExecutionPolicy Bypass -Force</span><br><span class="line">Enable-PSRemoting -force</span><br><span class="line">Set-Item WSMan:\localhost\Client\TrustedHosts * -force</span><br><span class="line">winrm set winrm/config/service/auth &apos;@&#123;Basic=&quot;true&quot;&#125;&apos;</span><br><span class="line">winrm set winrm/config/service &apos;@&#123;AllowUnencrypted=&quot;true&quot;&#125;&apos;</span><br><span class="line">restart-Service winrm</span><br></pre></td></tr></table></figure>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/29/远程访问双层嵌套Openstack云下的Windows虚机/" data-id="cjapajjqd0009k6bpozpkwans" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-通配符中一个星号两个星号和globstar的关系" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/16/通配符中一个星号两个星号和globstar的关系/" class="article-date">
  <time datetime="2017-11-16T07:48:59.000Z" itemprop="datePublished">2017-11-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/16/通配符中一个星号两个星号和globstar的关系/">通配符中一个星号两个星号和globstar的关系</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>今天在处理一个AppArmor的问题时，遇到一个奇怪的问题，在/etc/apparmor.d/usr.bin.nova-compute文件中明明已经有了下面对/tmp及/var/tmp目录的配置。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/tmp/* rw,</span><br><span class="line">/tmp/*/ rw,</span><br><span class="line">/tmp/** rw,</span><br><span class="line">/var/tmp/* rw,</span><br></pre></td></tr></table></figure></p>
<p>但是在运行”sudo /etc/init.d/apparmor reload &amp;&amp; sudo service nova-compute restart“命令后仍然在syslog里能看到下列错误信息。奇了怪了，这是怎么一回事呢？<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Nov 15 12:49:36 juju-864213-xenial-mitaka-ceph-11 kernel: [705198.766810] audit: type=1400 audit(1510750176.727:10140): apparmor=&quot;DENIED&quot; operation=&quot;open&quot; profile=&quot;/usr/bin/nova-compute&quot; name=&quot;/tmp/&quot; pid=16922 comm=&quot;nova-compute&quot; requested_mask=&quot;r&quot; denied_mask=&quot;r&quot; fsuid=113 ouid=0</span><br><span class="line">Nov 15 12:49:36 juju-864213-xenial-mitaka-ceph-11 kernel: [705198.766828] audit: type=1400 audit(1510750176.727:10141): apparmor=&quot;DENIED&quot; operation=&quot;open&quot; profile=&quot;/usr/bin/nova-compute&quot; name=&quot;/var/tmp/&quot; pid=16922 comm=&quot;nova-compute&quot; requested_mask=&quot;r&quot; denied_mask=&quot;r&quot; fsuid=113 ouid=0</span><br></pre></td></tr></table></figure></p>
<h2 id="globstar模式下的通配符"><a href="#globstar模式下的通配符" class="headerlink" title="globstar模式下的通配符"></a>globstar模式下的通配符</h2><p>通配符有一个星号，两个星号，还有逗号，globstar模式可以开启，还可以关闭。这些混在一起会有什么影响呢？<br>如果想要很方便地遍历所有的目录和文件得用两个星号的通配符。globstar是Bash 4.0才引入的选项，当设置启用globstar(shopt -s globstar)时，两个星号意为对通配符进行展开就可以匹配任何当前目录(包括子目录)以及其的文件；若不启用globstar(shopt -u globstar)，两个星号通配符的作用和一个星号通配符是相同的。</p>
<ul>
<li>~/tmp/* -  匹配当前目录的文件，及当前目录的下一级目录(不包括当前目录），与’ls ~/tmp’及”ls ~/tmp/“的效果同。</li>
<li>~/tmp/*/ - 匹配当前目录的下一级目录(不包括当前目录）</li>
<li>~/tmp/<em>* - 禁用globstar时，与~/tmp/</em>完全一样(不包括当前目录）；但启用globstar时，不止取一级，递归取所有级的文件和目录（也包括当前目录）</li>
<li>~/tmp/<em>*/ - 禁用globstar时，与~/tmp/</em>/ 完全一样(不包括当前目录）；但启用globstar时，不止取一级，递归取所有级的目录（也包括当前目录）</li>
</ul>
<p>当启用globstar时，英语的解释如下（注：里面说的file包括文件和目录，在Linux里目录是特殊的文件）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Substitutes for any number of characters, except /.</span><br><span class="line">/tmp/* matches any file in /tmp. </span><br><span class="line">/tmp/*/ matches any directory in /tmp</span><br><span class="line"></span><br><span class="line">Substitutes for any number of characters, including /.</span><br><span class="line">/tmp/** matches all files and directories underneath /tmp.</span><br><span class="line">/tmp/**/ matches all directories underneath /tmp.</span><br></pre></td></tr></table></figure>
<p>请看实验数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">hua@t440p:~/tmp$ tree .</span><br><span class="line">.</span><br><span class="line">├── l0_dir1</span><br><span class="line">│   ├── l1_dir</span><br><span class="line">│   │   ├── l2_dir</span><br><span class="line">│   │   │   └── l3_file</span><br><span class="line">│   │   └── l2_file</span><br><span class="line">│   └── l1_file</span><br><span class="line">├── l0_dir2</span><br><span class="line">└── l0_file</span><br><span class="line">4 directories, 4 files</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ shopt -s globstar</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/*</span><br><span class="line">/home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/*/</span><br><span class="line">/home/hua/tmp/l0_dir1/:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2/:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/**</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir/l2_dir/l3_file  /home/hua/tmp/l0_dir1/l1_file</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir/l2_file         /home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/:</span><br><span class="line">l0_dir1  l0_dir2  l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir:</span><br><span class="line">l2_dir  l2_file</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir/l2_dir:</span><br><span class="line">l3_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/**/</span><br><span class="line">/home/hua/tmp/:</span><br><span class="line">l0_dir1  l0_dir2  l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1/:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir/:</span><br><span class="line">l2_dir  l2_file</span><br><span class="line">/home/hua/tmp/l0_dir1/l1_dir/l2_dir/:</span><br><span class="line">l3_file</span><br><span class="line">/home/hua/tmp/l0_dir2/:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/&#123;,**&#125;</span><br><span class="line">/home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/:</span><br><span class="line">l0_dir1  l0_dir2  l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ shopt -u globstar</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/*</span><br><span class="line">/home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/*/</span><br><span class="line">/home/hua/tmp/l0_dir1/:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2/:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/**</span><br><span class="line">/home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/**/</span><br><span class="line">/home/hua/tmp/l0_dir1/:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2/:</span><br><span class="line"></span><br><span class="line">hua@t440p:~/tmp$ ls ~/tmp/&#123;,**&#125;</span><br><span class="line">/home/hua/tmp/l0_file</span><br><span class="line">/home/hua/tmp/:</span><br><span class="line">l0_dir1  l0_dir2  l0_file</span><br><span class="line">/home/hua/tmp/l0_dir1:</span><br><span class="line">l1_dir  l1_file</span><br><span class="line">/home/hua/tmp/l0_dir2:</span><br></pre></td></tr></table></figure>
<h2 id="问题的解决"><a href="#问题的解决" class="headerlink" title="问题的解决"></a>问题的解决</h2><p>学习了上面的理论之后，是不是想到了问题所在了，那就是下列两个配置没有包括当前目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/tmp/** rw,</span><br><span class="line">/var/tmp/* rw,</span><br></pre></td></tr></table></figure></p>
<p>所以它应该修改为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/tmp/&#123;,**&#125; rw,</span><br><span class="line">/var/tmp/&#123;,**&#125; rw,</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/16/通配符中一个星号两个星号和globstar的关系/" data-id="cjapajjqf000ak6bp30w719sk" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Use-hexo-to-create-blog" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/13/Use-hexo-to-create-blog/" class="article-date">
  <time datetime="2017-11-13T09:02:52.000Z" itemprop="datePublished">2017-11-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/13/Use-hexo-to-create-blog/">Use hexo to create blog</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>独立博客可以采用wordpress搭建动态博客，也可以采用Markdown语法编写静态博客(no db, no cms, simple, minimal)发布到有git版本控制的github上, jekyll与hexo是一个将markdown文件产生目录生成静态网站的程序。</p>
<p>1, 登陆GitHub，新建一个repository, 命名为你的用户名 + github.io。如我的用户名为zhhuabj，所以repository命名为zhhuabj.github.io</p>
<p>2, 创建第一个网页index.html</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/zhhuabj/zhhuabj.github.io.git</span><br><span class="line">cd zhhuabj.github.io</span><br><span class="line">echo “my blog” &gt;&gt; index.html</span><br><span class="line">git add .</span><br><span class="line">git commit -m “first commit”</span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure>
<p>3, 访问<a href="https://zhhuabj.github.io/" target="_blank" rel="external">https://zhhuabj.github.io/</a></p>
<p>4, [使用jekyll可省略]打开<a href="https://github.com/zhhuabj/zhhuabj.github.io/settings，" target="_blank" rel="external">https://github.com/zhhuabj/zhhuabj.github.io/settings，</a> 点击Launch automatic page generator按钮开始设置样式。</p>
<p>5, CSDN博客迁移</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install beautifulsoup</span><br><span class="line">git clone https://github.com/gaocegege/csdn-blog-export.git</span><br><span class="line">cd csdn-blog-export</span><br><span class="line">./main.py -u quqi99 -f html</span><br><span class="line">./main.py -u quqi99 -f markdown</span><br></pre></td></tr></table></figure>
<p>6, 使用jekyll本地写博客</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install ruby ruby-dev</span><br><span class="line">gem sources --remove https://rubygems.org/</span><br><span class="line">gem sources -a https://ruby.taobao.org/</span><br><span class="line">gem sources -l</span><br><span class="line">sudo gem install jekyll</span><br><span class="line">cd zhhuabj.github.io/jekyll</span><br><span class="line">jekyll new .</span><br><span class="line">cp -r ../csdn-blog-export/*.md _posts/</span><br><span class="line">jekyll serve  #http://localhost:4000/</span><br><span class="line">vi _config.yml</span><br></pre></td></tr></table></figure>
<p>7, 改用jekyll-bootstrap, 先扫描 _post，layout, 然后是目录和 page，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">装入一个 site 对象后，用什么 Liquide render出来</span><br><span class="line">git clone https://github.com/plusjade/jekyll-bootstrap.git</span><br><span class="line">cp -r jekyll-bootstrap/* zhhuabj.github.io/*</span><br><span class="line">vi _config.yml</span><br><span class="line">cd zhhuabj.github.io</span><br><span class="line">sudo gem install jekyll-sitemap</span><br><span class="line">jekyll serve #http://127.0.0.1:4000/</span><br></pre></td></tr></table></figure>
<p>8, 改用hexo</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">   sudo apt install npm node.js nodejs-legacy </span><br><span class="line">   sudo npm install hexo hexo-generator-feed -g</span><br><span class="line">   sudo npm install hexo-deployer-git --save</span><br><span class="line">   sudo npm install git --save</span><br><span class="line">   cd zhhuabj.github.io</span><br><span class="line">   hexo init .</span><br><span class="line">   hexo server    #http://localhost:4000/</span><br><span class="line">   hexo new &quot;my test post&quot;</span><br><span class="line">   </span><br><span class="line">   $ vim _config.yml</span><br><span class="line">deploy:</span><br><span class="line">  type: git  #注意前面有两个空格，冒号后有一个空格</span><br><span class="line">  #repository: https://github.com/zhhuabj/zhhuabj.github.io.git</span><br><span class="line">  # 如果使用ssh免密码方式除了github上提交公钥，同时改成下面一句</span><br><span class="line">  repository: git@github.com:zhhuabj/zhhuabj.github.io.git</span><br><span class="line">  branch: master</span><br><span class="line">  #user: zhhuabj</span><br><span class="line">  #pass: password</span><br><span class="line">  </span><br><span class="line">   cp -r ../csdn-blog-export/*.md source/_posts/</span><br><span class="line">   hexo generate</span><br><span class="line">   hexo deploy  #cp -r public/* .</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/13/Use-hexo-to-create-blog/" data-id="cjapajjpq0004k6bphpddzkjl" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-使用Juju将OpenStack部署在单机的LXD容器上" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/13/使用Juju将OpenStack部署在单机的LXD容器上/" class="article-date">
  <time datetime="2017-11-13T07:18:08.000Z" itemprop="datePublished">2017-11-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/13/使用Juju将OpenStack部署在单机的LXD容器上/">使用Juju将OpenStack部署在单机的LXD容器上</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>作者：张华  发表于：2016-08-05<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br><a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</strong></p>
<h2 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h2><ol>
<li>iscsi还不能运行在容器里（因为netlink还不支持namesapce)，本文采用rbd使用ceph代替iscsi</li>
<li>ovs, kvm通过定义profile支持运行在容器里。ovs目前只支持security.privileged: “true”</li>
</ol>
<h2 id="配置LXD"><a href="#配置LXD" class="headerlink" title="配置LXD"></a>配置LXD</h2><p>参考<a href="http://blog.csdn.net/quqi99/article/details/52131486" target="_blank" rel="external">Play with LXD</a>一文 在ubuntu 16.04上部署LXD环境。</p>
<h2 id="LXD上部署OpenStack"><a href="#LXD上部署OpenStack" class="headerlink" title="LXD上部署OpenStack"></a>LXD上部署OpenStack</h2><p>1, 从这个<a href="https://jujucharms.com/openstack-base/" target="_blank" rel="external">链接</a>下载 ‘openstack-base.zip’ ，里面有下面要用到的bundle.yaml<br>2, 运行’juju bootstrap’，注意：运行这一步时先不要修改profile<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#sudo snap install lxd</span><br><span class="line">export PATH=/snap/bin:$PATH</span><br><span class="line">juju bootstrap --debug --config bootstrap-series=xenial --config agent-stream=devel localhost lxd-controller</span><br><span class="line">lxc exec `lxc list |grep juju- |awk -F &apos;|&apos; &apos;&#123;print $2&#125;&apos;` bash</span><br></pre></td></tr></table></figure></p>
<p>3,  创建model，且<strong>它会自动生成juju-openstack-model profile</strong> （’juju add-model’会自动执行这一句‘lxc profile create juju-openstack-model 2&gt;/dev/null || echo “juju-openstack-model profile already exists”’）, <strong>如果不定义model，就会有一个名为default的model，那么这时下面第4步要编辑juju-default profile</strong>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">juju add-model openstack-model</span><br><span class="line">juju models</span><br><span class="line">lxc profile show juju-openstack-model</span><br></pre></td></tr></table></figure></p>
<p>4, 编辑juju-openstack-model profile。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install --reinstall linux-image-extra-$(uname -r)</span><br><span class="line">sudo modprobe nbd</span><br><span class="line">sudo modprobe ip_tables</span><br><span class="line">sudo modprobe openvswitch</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; juju-openstack-model.yaml</span><br><span class="line">name: juju-openstack-model</span><br><span class="line">config:</span><br><span class="line">  boot.autostart: &quot;true&quot;</span><br><span class="line">  security.nesting: &quot;true&quot;</span><br><span class="line">  security.privileged: &quot;true&quot;</span><br><span class="line">  raw.lxc: lxc.aa_profile=unconfined</span><br><span class="line">  linux.kernel_modules: openvswitch,nbd,ip_tables,ip6_tables,ebtables,netlink_diag,nf_nat,overlay</span><br><span class="line">devices:</span><br><span class="line">  eth0:</span><br><span class="line">    mtu: &quot;9000&quot;</span><br><span class="line">    name: eth0</span><br><span class="line">    nictype: bridged</span><br><span class="line">    parent: lxdbr1</span><br><span class="line">    type: nic</span><br><span class="line">  eth1:</span><br><span class="line">    mtu: &quot;9000&quot;</span><br><span class="line">    name: eth1</span><br><span class="line">    nictype: bridged</span><br><span class="line">    parent: lxdbr1</span><br><span class="line">    type: nic</span><br><span class="line">  kvm:</span><br><span class="line">    path: /dev/kvm</span><br><span class="line">    type: unix-char</span><br><span class="line">  mem:</span><br><span class="line">    path: /dev/mem</span><br><span class="line">    type: unix-char</span><br><span class="line">  root:</span><br><span class="line">    path: /</span><br><span class="line">    pool: default</span><br><span class="line">    type: disk</span><br><span class="line">  tun:</span><br><span class="line">    path: /dev/net/tun</span><br><span class="line">    type: unix-char</span><br><span class="line">EOF</span><br><span class="line">cat lxd-profile.yaml | lxc profile edit juju-openstack-model</span><br><span class="line">#其他命令演示</span><br><span class="line">#lxc profile set juju-openstack-model raw.lxc lxc.aa_profile=unconfined</span><br><span class="line">#lxc profile device add juju-openstack-model fuse unix-char path=/dev/fuse</span><br><span class="line">#/snap/bin/lxc network create lxdbr1 ipv4.address=auto ipv4.nat=true ipv6.address=none</span><br></pre></td></tr></table></figure></p>
<p>5, 使用juju一键部署openstack</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://api.jujucharms.com/charmstore/v5/openstack-base/archive/bundle.yaml</span><br><span class="line">juju deploy bundle.yaml</span><br><span class="line">juju status</span><br><span class="line">juju debug-log</span><br></pre></td></tr></table></figure>
<h2 id="安装过程中遇到的问题"><a href="#安装过程中遇到的问题" class="headerlink" title="安装过程中遇到的问题"></a>安装过程中遇到的问题</h2><ul>
<li>如果报这个错 - failed to bootstrap model: cannot start bootstrap instance: The container’s root device is missing the pool property， 那是要在profile中的root元素下添加：pool: default</li>
<li>bootstrap时报这个错 - FATAL: Module ip6_tables，ebtables，netlink_diag not found in directory /lib/modules/4.4.0-98-generic - 运行‘sudo apt-get install –reinstall linux-image-extra-$(uname -r)’安装模块（/lib/modules/$(uname -r)/kernel/net/netlink/netlink_diag.ko）。<strong>此外是因为profile中写的这些模块名是从网页拷过来的存在乱码</strong>。</li>
</ul>
<h2 id="配置使用OpenStack"><a href="#配置使用OpenStack" class="headerlink" title="配置使用OpenStack"></a>配置使用OpenStack</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">source novarc</span><br><span class="line">$ cat novarc </span><br><span class="line">#!/bin/bash</span><br><span class="line">export OS_USERNAME=admin</span><br><span class="line">export OS_PASSWORD=openstack</span><br><span class="line">export OS_TENANT_NAME=admin</span><br><span class="line">export OS_REGION_NAME=RegionOne</span><br><span class="line">export OS_AUTH_URL=$&#123;OS_AUTH_PROTOCOL:-http&#125;://`juju run --unit  keystone/0 &quot;unit-get private-address&quot;`:5000/v2.0</span><br><span class="line"></span><br><span class="line">curl http://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img</span><br><span class="line">openstack image create --public --container-format=bare --disk-format=qcow2 xenial</span><br><span class="line"></span><br><span class="line">./neutron-ext-net -g 10.0.8.1 -c 10.0.8.0/24 \ -f 10.0.8.201:10.0.8.254 ext_net</span><br><span class="line">./neutron-tenant-net -t admin -r provider-router \ -N 10.0.8.1 internal 192.168.20.0/24</span><br><span class="line"></span><br><span class="line">nova keypair-add --pub-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">nova boot --image xenial --flavor m1.small --key-name mykey --nic net-id=$(neutron net-list | grep internal | awk &apos;&#123; print $2 &#125;&apos;) i1</span><br><span class="line"></span><br><span class="line">cinder create --name testvolume 10</span><br><span class="line">nova volume-attach xenial $(cinder list | grep testvolume | awk &apos;&#123; print $2 &#125;&apos;) /dev/vdc</span><br><span class="line"></span><br><span class="line">nova floating-ip-create </span><br><span class="line">nova add-floating-ip &lt;uuid-of-instance&gt; &lt;new-floating-ip&gt;</span><br><span class="line"></span><br><span class="line">neutron security-group-rule-create --protocol icmp --direction ingress $(nova secgroup-list | grep default | awk &apos;&#123; print $2 &#125;&apos;) </span><br><span class="line">neutron security-group-rule-create --protocol tcp  --port-range-min 22 --port-range-max 22  --direction ingress $(nova secgroup-list | grep default | awk &apos;&#123; print $2 &#125;&apos;)</span><br><span class="line"></span><br><span class="line">ssh ubuntu@&lt;new-floating-ip&gt;</span><br></pre></td></tr></table></figure>
<h2 id="又一例-部署opencontrail在lxd单机上"><a href="#又一例-部署opencontrail在lxd单机上" class="headerlink" title="又一例 - 部署opencontrail在lxd单机上"></a>又一例 - 部署opencontrail在lxd单机上</h2><p>下面的yaml是juju2.0的，如果是juju1.x可见：<a href="http://pastebin.ubuntu.com/24170320/" target="_blank" rel="external">http://pastebin.ubuntu.com/24170320/</a><br>实际上,opencontrail vrouter部署在容器里会报下列错，此例子只是说明yaml怎么写。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2017-03-13 11:46:06 INFO juju-log Loading kernel module vrouter</span><br><span class="line">2017-03-13 11:46:06 INFO install modprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file &apos;/lib/modules/4.8.0-34-generic/modules.dep.bin&apos;</span><br><span class="line">2017-03-13 11:46:06 INFO juju-log vrouter kernel module failed to load, clearing pagecache and retrying</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">series: trusty</span><br><span class="line">services:</span><br><span class="line">  # openstack</span><br><span class="line">  ubuntu:</span><br><span class="line">    charm: cs:trusty/ubuntu</span><br><span class="line">    num_units: 1</span><br><span class="line">  ntp:</span><br><span class="line">    charm: cs:trusty/ntp</span><br><span class="line">  mysql:</span><br><span class="line">    charm: cs:trusty/mysql</span><br><span class="line">    options:</span><br><span class="line">      dataset-size: 15%</span><br><span class="line">      max-connections: 1000</span><br><span class="line">    num_units: 1</span><br><span class="line">  rabbitmq-server:</span><br><span class="line">    charm: cs:trusty/rabbitmq-server</span><br><span class="line">    num_units: 1</span><br><span class="line">  keystone:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/keystone</span><br><span class="line">    options:</span><br><span class="line">      admin-password: password</span><br><span class="line">      admin-role: admin</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  nova-cloud-controller:</span><br><span class="line">    charm: cs:trusty/nova-cloud-controller</span><br><span class="line">    options:</span><br><span class="line">      network-manager: Neutron</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  neutron-api:</span><br><span class="line">    charm: cs:trusty/neutron-api</span><br><span class="line">    options:</span><br><span class="line">      manage-neutron-plugin-legacy-mode: false</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  glance:</span><br><span class="line">    charm: cs:trusty/glance</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  openstack-dashboard:</span><br><span class="line">    charm: cs:trusty/openstack-dashboard</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  nova-compute:</span><br><span class="line">    charm: cs:trusty/nova-compute</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  # contrail</span><br><span class="line">  cassandra:</span><br><span class="line">    charm: cs:trusty/cassandra</span><br><span class="line">    options:</span><br><span class="line">      authenticator: AllowAllAuthenticator</span><br><span class="line">      install_sources: |</span><br><span class="line">        - deb http://www.apache.org/dist/cassandra/debian 22x main</span><br><span class="line">        - ppa:openjdk-r/ppa</span><br><span class="line">        - ppa:stub/cassandra</span><br><span class="line">    num_units: 1</span><br><span class="line">  zookeeper:</span><br><span class="line">    charm: cs:~charmers/trusty/zookeeper</span><br><span class="line">    num_units: 1</span><br><span class="line">  kafka:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/apache-kafka</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-configuration:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-configuration</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-control:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-control</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-analytics:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-analytics</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-webui:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-webui</span><br><span class="line">    num_units: 1</span><br><span class="line">  neutron-api-contrail:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/neutron-api-contrail</span><br><span class="line">    num_units: 0</span><br><span class="line">  neutron-contrail:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/neutron-contrail</span><br><span class="line">    num_units: 0</span><br><span class="line"></span><br><span class="line">relations:</span><br><span class="line">  # openstack</span><br><span class="line"> - [ ubuntu, ntp ]</span><br><span class="line"> - [ keystone, mysql ]</span><br><span class="line"> - [ glance, mysql ]</span><br><span class="line"> - [ glance, keystone ]</span><br><span class="line"> - [ nova-cloud-controller, mysql ]</span><br><span class="line"> - [ nova-cloud-controller, rabbitmq-server ]</span><br><span class="line"> - [ nova-cloud-controller, keystone ]</span><br><span class="line"> - [ nova-cloud-controller, glance ]</span><br><span class="line"> - [ neutron-api, mysql ]</span><br><span class="line"> - [ neutron-api, rabbitmq-server ]</span><br><span class="line"> - [ neutron-api, nova-cloud-controller ]</span><br><span class="line"> - [ neutron-api, keystone ]</span><br><span class="line"> - [ neutron-api, neutron-api-contrail ]</span><br><span class="line"> - [ &quot;nova-compute:shared-db&quot;, &quot;mysql:shared-db&quot; ]</span><br><span class="line"> - [ &quot;nova-compute:amqp&quot;, &quot;rabbitmq-server:amqp&quot; ]</span><br><span class="line"> - [ nova-compute, glance ]</span><br><span class="line"> - [ nova-compute, nova-cloud-controller ]</span><br><span class="line"> - [ nova-compute, ntp ]</span><br><span class="line"> - [ openstack-dashboard, keystone ]</span><br><span class="line">  # contrail</span><br><span class="line"> - [ kafka, zookeeper ]</span><br><span class="line"> - [ &quot;contrail-configuration:cassandra&quot;, &quot;cassandra:database&quot; ]</span><br><span class="line"> - [ contrail-configuration, zookeeper ]</span><br><span class="line"> - [ contrail-configuration, rabbitmq-server ]</span><br><span class="line"> - [ &quot;contrail-configuration:identity-admin&quot;, &quot;keystone:identity-admin&quot; ]</span><br><span class="line"> - [ &quot;contrail-configuration:identity-service&quot;, &quot;keystone:identity-service&quot; ]</span><br><span class="line"> - [ neutron-api-contrail, contrail-configuration ]</span><br><span class="line"> - [ neutron-api-contrail, keystone ]</span><br><span class="line"> - [ &quot;contrail-control:contrail-api&quot;, &quot;contrail-configuration:contrail-api&quot; ]</span><br><span class="line"> - [ &quot;contrail-control:contrail-discovery&quot;, &quot;contrail-configuration:contrail-discovery&quot; ]</span><br><span class="line"> - [ &quot;contrail-control:contrail-ifmap&quot;, &quot;contrail-configuration:contrail-ifmap&quot; ]</span><br><span class="line"> - [ contrail-control, keystone ]</span><br><span class="line"> - [ &quot;contrail-analytics:cassandra&quot;, &quot;cassandra:database&quot; ]</span><br><span class="line"> - [ contrail-analytics, kafka ]</span><br><span class="line"> - [ contrail-analytics, zookeeper ]</span><br><span class="line"> - [ &quot;contrail-analytics:contrail-api&quot;, &quot;contrail-configuration:contrail-api&quot; ]</span><br><span class="line"> - [ &quot;contrail-analytics:contrail-discovery&quot;, &quot;contrail-configuration:contrail-discovery&quot; ]</span><br><span class="line"> - [ &quot;contrail-analytics:identity-admin&quot;, &quot;keystone:identity-admin&quot; ]</span><br><span class="line"> - [ &quot;contrail-analytics:identity-service&quot;, &quot;keystone:identity-service&quot; ]</span><br><span class="line"> - [ &quot;contrail-configuration:contrail-analytics-api&quot;, &quot;contrail-analytics:contrail-analytics-api&quot; ]</span><br><span class="line"> - [ nova-compute, neutron-contrail ]</span><br><span class="line"> - [ &quot;neutron-contrail:contrail-discovery&quot;, &quot;contrail-configuration:contrail-discovery&quot; ]</span><br><span class="line"> - [ &quot;neutron-contrail:contrail-api&quot;, &quot;contrail-configuration:contrail-api&quot; ]</span><br><span class="line"> - [ neutron-contrail, keystone ]</span><br><span class="line"> - [ contrail-webui, keystone ]</span><br><span class="line"> - [ &quot;contrail-webui:cassandra&quot;, &quot;cassandra:database&quot; ]</span><br></pre></td></tr></table></figure>
<h2 id="通过conjure-up安装OpenStack"><a href="#通过conjure-up安装OpenStack" class="headerlink" title="通过conjure-up安装OpenStack"></a>通过conjure-up安装OpenStack</h2><p>我们也可以通过conjure-up安装OpenStack,</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">#Install a lxd container</span><br><span class="line">sudo lxc init ubuntu:16.04 openstack -c security.privileged=true -c security.nesting=true -c &quot;linux.kernel_modules=iptable_nat, ip6table_nat, ebtables, openvswitch, nbd&quot;</span><br><span class="line">printf &quot;lxc.cap.drop=\nlxc.aa_profile=unconfined\n&quot; | sudo lxc config set openstack raw.lxc -</span><br><span class="line">sudo lxc config get openstack raw.lxc</span><br><span class="line">lxc config device add openstack mem unix-char path=/dev/mem</span><br><span class="line">lxc start openstack</span><br><span class="line">lxc list</span><br><span class="line"></span><br><span class="line">#Install conjure-up inside the lxd container</span><br><span class="line">#lxc exec openstack bash</span><br><span class="line">lxc exec openstack -- apt update</span><br><span class="line">#lxc exec openstack -- apt dist-upgrade -y</span><br><span class="line">lxc exec openstack -- apt install squashfuse -y</span><br><span class="line">lxc exec openstack -- ln -s /bin/true /usr/local/bin/udevadm</span><br><span class="line">lxc exec openstack -- snap install conjure-up --classic</span><br><span class="line"></span><br><span class="line">#Init lxd container</span><br><span class="line">#Use the “dir” storage backend (“zfs” doesn’t work in a nested container)</span><br><span class="line">#Do NOT configure IPv6 networking (conjure-up/juju don’t play well with it)</span><br><span class="line">#lxc exec openstack -- lxd init</span><br><span class="line">lxc exec openstack -- snap install lxd</span><br><span class="line">sleep 10  #avoid the error &apos;Unable to talk to LXD: Get http://unix.socket/1.0&apos;</span><br><span class="line">lxc exec openstack -- /snap/bin/lxd init --auto</span><br><span class="line">lxc exec openstack -- /snap/bin/lxc network create lxdbr0 ipv4.address=auto ipv4.nat=true ipv6.address=none</span><br><span class="line">lxc exec openstack -- /snap/bin/lxc profile show default</span><br><span class="line"></span><br><span class="line">#Deploying OpenStack with conjure-up in nested LXD</span><br><span class="line">#conjure-up is a nice, user friendly, tool that interfaces with Juju to deploy complex services.</span><br><span class="line">#Step 1, select “OpenStack with NovaLXD”</span><br><span class="line">#Step 2, select “localhost” as the deployment target (uses LXD)</span><br><span class="line">#Step 3, select default in all middle steps, and click “Deploy all remaining applications”</span><br><span class="line">lxc exec openstack -- sudo -u ubuntu -i conjure-up</span><br><span class="line">hua@node1:~$ sudo lxc list</span><br><span class="line">+-----------+---------+--------------------------------+------+------------+-----------+</span><br><span class="line">|   NAME    |  STATE  |              IPV4              | IPV6 |    TYPE    | SNAPSHOTS |</span><br><span class="line">+-----------+---------+--------------------------------+------+------------+-----------+</span><br><span class="line">| openstack | RUNNING | 10.73.227.154 (eth0)           |      | PERSISTENT | 0         |</span><br><span class="line">|           |         | 10.164.92.1 (lxdbr0)           |      |            |           |</span><br><span class="line">|           |         | 10.101.0.1 (conjureup0)        |      |            |           |</span><br><span class="line">+-----------+---------+--------------------------------+------+------------+-----------+</span><br><span class="line"></span><br><span class="line">#Or deploy OpenStack with conjure-up in physical node</span><br><span class="line">sudo snap install lxd</span><br><span class="line">export PATH=/snap/bin:$PATH</span><br><span class="line">sudo /snap/bin/lxd init --auto</span><br><span class="line">sudo /snap/bin/lxc network create lxdbr0 ipv4.address=auto ipv4.nat=true ipv6.address=none</span><br><span class="line">sudo -i</span><br><span class="line">conjure-up openstack #but I hit the error &apos;This should _not_ be run as root or with sudo&apos; even though I&apos;ve already used root</span><br></pre></td></tr></table></figure>
<p>下面粘一些使用conjure-up过程中的截图：<br><img src="http://img.blog.csdn.net/20171112101736564?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171112101801150?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171112101813090?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://stgraber.org/2016/10/26/lxd-2-0-lxd-and-openstack-1112/" target="_blank" rel="external">https://stgraber.org/2016/10/26/lxd-2-0-lxd-and-openstack-1112/</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/13/使用Juju将OpenStack部署在单机的LXD容器上/" data-id="cjapajjq00006k6bpimn4z3ko" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-将kubernetes跑在本地LXD容器中" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/12/将kubernetes跑在本地LXD容器中/" class="article-date">
  <time datetime="2017-11-12T13:19:18.000Z" itemprop="datePublished">2017-11-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/12/将kubernetes跑在本地LXD容器中/">将kubernetes跑在本地LXD容器中</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本文将kubernetest跑在本地LXD容器中。</p>
<h2 id="Kubernetes是什么"><a href="#Kubernetes是什么" class="headerlink" title="Kubernetes是什么"></a>Kubernetes是什么</h2><p>Kubernetes是什么，见<a href="http://blog.csdn.net/quqi99/article/details/42058833" target="_blank" rel="external">我的博客</a>。</p>
<h2 id="安装LXD"><a href="#安装LXD" class="headerlink" title="安装LXD"></a>安装LXD</h2><p>如何安装LXD，见<a href="http://blog.csdn.net/quqi99/article/details/52131486" target="_blank" rel="external">我的博客</a>。<br>这篇文章和之前的在LXD上运行容器化的OpenStack类似，见<a href="http://blog.csdn.net/quqi99/article/details/52132140" target="_blank" rel="external">我的博客</a>。</p>
<h2 id="LXD上安装Kubernetes"><a href="#LXD上安装Kubernetes" class="headerlink" title="LXD上安装Kubernetes"></a>LXD上安装Kubernetes</h2><p>1,  从<a href="https://jujucharms.com/canonical-kubernetes/" target="_blank" rel="external">这个链接</a>下载 ‘canonical-kubernetes.zip’ ，里面有下面要用到的bundle.yaml<br>2, 运行’juju bootstrap’，<strong>注意：运行这一步时先不要修改profile</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#sudo snap install lxd</span><br><span class="line">export PATH=/snap/bin:$PATH</span><br><span class="line">juju bootstrap --debug --config bootstrap-series=xenial --config agent-stream=devel localhost lxd-controller</span><br></pre></td></tr></table></figure></p>
<p>3, 这步会产生 juju-kubernetes profile<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">juju add-model kubernetes</span><br><span class="line">juju models</span><br><span class="line">lxc profile show juju-kubernetes</span><br></pre></td></tr></table></figure></p>
<p>4, 修改juju-kubernetes profile<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install --reinstall linux-image-extra-$(uname -r)</span><br><span class="line">sudo modprobe nbd</span><br><span class="line">sudo modprobe ebtables</span><br><span class="line">sudo modprobe ip_tables</span><br><span class="line">sudo modprobe ip6_tables</span><br><span class="line">sudo modprobe netlink_diag</span><br><span class="line">sudo modprobe openvswitch</span><br><span class="line">sudo modprobe nf_nat</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; juju-kubernetes.yaml</span><br><span class="line">name: juju-kubernetes</span><br><span class="line">config:</span><br><span class="line">  user.user-data: |</span><br><span class="line">    #cloud-config</span><br><span class="line">    ssh_authorized_keys:</span><br><span class="line">      - @@SSHPUB@@</span><br><span class="line">  boot.autostart: &quot;true&quot;</span><br><span class="line">  linux.kernel_modules: ip_tables,ip6_tables,netlink_diag,nf_nat,overlay</span><br><span class="line">  raw.lxc: |</span><br><span class="line">    lxc.aa_profile=unconfined</span><br><span class="line">    lxc.mount.auto=proc:rw sys:rw</span><br><span class="line">    lxc.cap.drop=</span><br><span class="line">  security.nesting: &quot;true&quot;</span><br><span class="line">  security.privileged: &quot;true&quot;</span><br><span class="line">description: &quot;&quot;</span><br><span class="line">devices:</span><br><span class="line">  aadisable:</span><br><span class="line">    path: /sys/module/nf_conntrack/parameters/hashsize</span><br><span class="line">    source: /dev/null</span><br><span class="line">    type: disk</span><br><span class="line">  aadisable1:</span><br><span class="line">    path: /sys/module/apparmor/parameters/enabled</span><br><span class="line">    source: /dev/null</span><br><span class="line">    type: disk</span><br><span class="line">EOF</span><br><span class="line">sed -ri &quot;s&apos;@@SSHPUB@@&apos;$(cat ~/.ssh/id_rsa.pub)&apos;&quot; juju-kubernetes.yaml</span><br><span class="line">lxc profile edit &quot;juju-kubernetes&quot; &lt; juju-kubernetes.yaml</span><br></pre></td></tr></table></figure></p>
<p>5, 使用juju一键部署kubernetes</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://api.jujucharms.com/charmstore/v5/canonical-kubernetes/archive/bundle.yaml</span><br><span class="line">juju deploy bundle.yaml</span><br></pre></td></tr></table></figure>
<h2 id="安装配置验证Kubernetes"><a href="#安装配置验证Kubernetes" class="headerlink" title="安装配置验证Kubernetes"></a>安装配置验证Kubernetes</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#Install the former as a snap and copy the k8s config using juju</span><br><span class="line">sudo snap install kubectl --classic</span><br><span class="line">mkdir -p ~/.kube</span><br><span class="line">juju scp kubernetes-master/0:config ~/.kube/config</span><br><span class="line">#For the k8s UI experience, get the URL and credentials using</span><br><span class="line">kubectl config view</span><br><span class="line">kubectl cluster-info</span><br><span class="line">kubectl -s https://10.241.244.49:443 get componentstatuses</span><br></pre></td></tr></table></figure>
<p>验证数据如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">root@test1:~# cat ~/.kube/config</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: ...</span><br><span class="line">    server: https://10.241.244.49:443</span><br><span class="line">  name: juju-cluster</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: juju-cluster</span><br><span class="line">    user: admin</span><br><span class="line">  name: juju-context</span><br><span class="line">current-context: juju-context</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: admin</span><br><span class="line">  user:</span><br><span class="line">    as-user-extra: &#123;&#125;</span><br><span class="line">    password: 9nvGaeQYtu3PSCpMYk6tKFRExoq29pwT</span><br><span class="line">    username: admin</span><br><span class="line"></span><br><span class="line">root@test1:~# kubectl config view</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: REDACTED</span><br><span class="line">    server: https://10.241.244.49:443</span><br><span class="line">  name: juju-cluster</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: juju-cluster</span><br><span class="line">    user: admin</span><br><span class="line">  name: juju-context</span><br><span class="line">current-context: juju-context</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: admin</span><br><span class="line">  user:</span><br><span class="line">    password: 9nvGaeQYtu3PSCpMYk6tKFRExoq29pwT</span><br><span class="line">    username: admin</span><br><span class="line"></span><br><span class="line">root@test1:~# kubectl cluster-info</span><br><span class="line">Kubernetes master is running at https://10.241.244.49:443</span><br><span class="line">Heapster is running at https://10.241.244.49:443/api/v1/namespaces/kube-system/services/heapster/proxy</span><br><span class="line">KubeDNS is running at https://10.241.244.49:443/api/v1/namespaces/kube-system/services/kube-dns/proxy</span><br><span class="line">kubernetes-dashboard is running at https://10.241.244.49:443/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy</span><br><span class="line">Grafana is running at https://10.241.244.49:443/api/v1/namespaces/kube-system/services/monitoring-grafana/proxy</span><br><span class="line">InfluxDB is running at https://10.241.244.49:443/api/v1/namespaces/kube-system/services/monitoring-influxdb/proxy</span><br><span class="line"></span><br><span class="line">root@test1:~# kubectl -s https://10.241.244.49:443 get componentstatuses</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">scheduler            Healthy   ok                   </span><br><span class="line">controller-manager   Healthy   ok                   </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;  </span><br><span class="line"></span><br><span class="line">root@test1:~# kubectl -s https://10.241.244.49:443 get nodes</span><br><span class="line">NAME            STATUS    ROLES     AGE       VERSION</span><br><span class="line">juju-893965-6   Ready     &lt;none&gt;    10h       v1.8.2</span><br><span class="line">juju-893965-7   Ready     &lt;none&gt;    10h       v1.8.2</span><br><span class="line">juju-893965-8   Ready     &lt;none&gt;    10h       v1.8.2</span><br></pre></td></tr></table></figure>
<h2 id="使用Kubernetes编排应用到容器"><a href="#使用Kubernetes编排应用到容器" class="headerlink" title="使用Kubernetes编排应用到容器"></a>使用Kubernetes编排应用到容器</h2><p>以kubernetes官方包中的examples/guestbook作为例子，该例子是一个典型的WEB应用，分为Frontend, Redis Backend, Redis Backend分为Redis Master和Redis Slave。从中我们可以看到:<br>Kubernetest的数据模型很通用(Pod, Replication Controller, Service, Label, Node)，所以用Kubernetest编排容器化应用时只需要为应用分解的每一个微服务用yaml编写RC(Replication Controller)模板和Service模板即可。Kubernetes只编排容器，Juju不仅编排容器还可编排虚机数据模型更通用。如图, Juju的数据模型是一个树状的(Cloud, Bundle, Charm, Service, Application, Relation, Machine):</p>
<ul>
<li>Machine, 相当于Kubernetes中的Node</li>
<li>Bundle, 分布式应用的抽象， 一个Bundle可包含多个Charm</li>
<li>Charm, 相当于组成应用的模块(即微服务，如假设OpenStack是一个Bundle的话，那么neutron可以做为一个Charm), Kubernetes中使用Yaml来编写RC和Service，Juju则要写Charm。一个Charm可包含多个Service。</li>
<li>Service, 相当于Kubernetes中的Service，一个Service下可以包含多个Application和Relation. 一个Service可以HA部署在多个Machine上，一个Machine可以承载多个Service; 相当于Kubernetes中的一个Service可以通过HA部署在多个Node上的Pod里, 一台Node上可以承载多个Pod</li>
<li>Application, Juju相比Kubernetes不仅可以编排容器还可以编排虚机，所以它比Kubernetes多出一个Application的数据模型<br>Relation, 它包括Provide与Reqire两个类型。Kubernetes中是通过yaml中的selector元素来定义关系，Juju是通过yaml中的relations段集中定义关系，二者类似</li>
<li>Unit,相当于Kubernetes中的Pod下的Container（Kubernetes以Pod为最小单位管理，Unit相当于容器，比Pod更小一级）。Kubernetes有Label用于Replication Controller来区别Pod做HA，Juju在这一块是通过’juju add-unit’的形式通过一个单独的haproxy charm来实现HA。</li>
<li>Cloud, Juju也支持Cloud的概念，可以同时部署在裸机和虚拟化环境和公有云，kubernetes也有这些。</li>
</ul>
<p><img src="http://img.blog.csdn.net/20171113110016341?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/kubernetes/kubernetes/releases/download/v1.1.1/kubernetes.tar.gz</span><br><span class="line">tar -xf kubernetes.tar.gz &amp;&amp; cd kubernetes/examples/guestbook</span><br></pre></td></tr></table></figure></p>
<p>1, 创建Redis Master Replication Controller模板，并且根据模板创建Pod</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">root@test1:~/kubernetes/examples/guestbook# kubectl create -f redis-master-controller.yaml </span><br><span class="line">replicationcontroller &quot;redis-master&quot; created</span><br><span class="line">root@test1:~/kubernetes/examples/guestbook# kubectl get replicationcontroller redis-master</span><br><span class="line">NAME           DESIRED   CURRENT   READY     AGE</span><br><span class="line">redis-master   1         1         1         39s</span><br><span class="line">root@test1:~/kubernetes/examples/guestbook# kubectl get replicationcontroller</span><br><span class="line">NAME                       DESIRED   CURRENT   READY     AGE</span><br><span class="line">default-http-backend       1         1         1         10h</span><br><span class="line">nginx-ingress-controller   3         3         3         10h</span><br><span class="line">redis-master               1         1         1         56s</span><br><span class="line">root@test1:~/kubernetes/examples/guestbook# kubectl get pod --selector name=redis-master</span><br><span class="line">NAME                 READY     STATUS    RESTARTS   AGE</span><br><span class="line">redis-master-xbxwc   1/1       Running   0          1m</span><br><span class="line"></span><br><span class="line">root@test1:~/kubernetes/examples/guestbook# cat redis-master-controller.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-master</span><br><span class="line">  labels:</span><br><span class="line">    name: redis-master</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    name: redis-master</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: redis-master</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: master</span><br><span class="line">        image: redis</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 6379</span><br></pre></td></tr></table></figure>
<p>2, 创建Redis Master Service模板，并根据模板创建Service</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#redis-master-service.yaml模板中的selector属性指明了这个Service要关联名为redis-master的POD</span><br><span class="line">root@test1:~/kubernetes/examples/guestbook# cat redis-master-service.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-master</span><br><span class="line">  labels:</span><br><span class="line">    name: redis-master</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    # the port that this service should serve on</span><br><span class="line">  - port: 6379</span><br><span class="line">    targetPort: 6379</span><br><span class="line">  selector:</span><br><span class="line">    name: redis-master</span><br><span class="line"></span><br><span class="line">root@test1:~/kubernetes/examples/guestbook# kubectl create -f redis-master-service.yaml</span><br><span class="line">service &quot;redis-master&quot; created</span><br><span class="line"></span><br><span class="line">root@test1:~/kubernetes/examples/guestbook# kubectl get service</span><br><span class="line">NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">default-http-backend   ClusterIP   10.152.183.64   &lt;none&gt;        80/TCP     10h</span><br><span class="line">kubernetes             ClusterIP   10.152.183.1    &lt;none&gt;        443/TCP    10h</span><br><span class="line">redis-master           ClusterIP   10.152.183.31   &lt;none&gt;        6379/TCP   24s</span><br><span class="line"></span><br><span class="line">root@test1:~/kubernetes/examples/guestbook# kubectl get service redis-master</span><br><span class="line">NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">redis-master   ClusterIP   10.152.183.31   &lt;none&gt;        6379/TCP   1m</span><br></pre></td></tr></table></figure>
<p>3,  类似地，继续创建Redis Slave Pod与Service<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f redis-slave-controller.yaml</span><br><span class="line">kubectl get pod --selector name=redis-slave</span><br><span class="line">kubectl create -f redis-slave-service.yaml</span><br></pre></td></tr></table></figure></p>
<p>4， 类似地，继续创建Frontend Pod与Service<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f frontend-controller.yaml</span><br><span class="line">kubectl get pod --selector name=frontend</span><br><span class="line">kubectl create -f frontend-service.yaml </span><br><span class="line">root@test1:~/kubernetes/examples/guestbook# kubectl get service frontend</span><br><span class="line">NAME       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">frontend   ClusterIP   10.152.183.99   &lt;none&gt;        80/TCP    19s</span><br></pre></td></tr></table></figure></p>
<p>5， 设置Frontend Service的端口映射<br>上面的10.152.183.99是虚拟IP，要想从外网访问，需要使用NodePort特设置端口映射。即在原有frontend-service.yaml的ports元素上方添加一行‘type: NodePort’，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">root@test1:~/kubernetes/examples/guestbook# grep -r &apos;NodePort&apos; frontend-service.yaml -A 3</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    # the port that this service should serve on</span><br><span class="line">    - port: 80</span><br></pre></td></tr></table></figure></p>
<p>然后重新部署Frontend Service后就可以通过任何一个计算Node的IP(如使用‘juju status kubernetes-worker/0’查看）和NodePort(tcp:31375)访问WEB界面了（wget <a href="http://10.241.244.222:31375）" target="_blank" rel="external">http://10.241.244.222:31375）</a>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl replace -f frontend-service.yaml --force</span><br><span class="line">root@test1:~/kubernetes/examples/guestbook# kubectl get service frontend</span><br><span class="line">NAME       TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">frontend   NodePort   10.152.183.33   &lt;none&gt;        80:31375/TCP   35s</span><br></pre></td></tr></table></figure></p>
<h2 id="附录-Juju环境相关输出"><a href="#附录-Juju环境相关输出" class="headerlink" title="附录 - Juju环境相关输出"></a>附录 - Juju环境相关输出</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">root@test:~# juju status</span><br><span class="line">...</span><br><span class="line">Unit                      Workload  Agent  Machine  Public address  Ports           Message</span><br><span class="line">easyrsa/0*                active    idle   0        10.241.244.149                  Certificate Authority connected.</span><br><span class="line">etcd/0*                   active    idle   1        10.241.244.78   2379/tcp        Healthy with 3 known peers</span><br><span class="line">etcd/1                    active    idle   2        10.241.244.83   2379/tcp        Healthy with 3 known peers</span><br><span class="line">etcd/2                    active    idle   3        10.241.244.89   2379/tcp        Healthy with 3 known peers</span><br><span class="line">kubeapi-load-balancer/0*  active    idle   4        10.241.244.49   443/tcp         Loadbalancer ready.</span><br><span class="line">kubernetes-master/0*      active    idle   5        10.241.244.162  6443/tcp        Kubernetes master running.</span><br><span class="line">  flannel/0*              active    idle            10.241.244.162                  Flannel subnet 10.1.38.1/24</span><br><span class="line">kubernetes-worker/0       active    idle   6        10.241.244.222  80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line">  flannel/3               active    idle            10.241.244.222                  Flannel subnet 10.1.62.1/24</span><br><span class="line">kubernetes-worker/1*      active    idle   7        10.241.244.200  80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line">  flannel/1               active    idle            10.241.244.200                  Flannel subnet 10.1.93.1/24</span><br><span class="line">kubernetes-worker/2       active    idle   8        10.241.244.119  80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line">  flannel/2               active    idle            10.241.244.119                  Flannel subnet 10.1.67.1/24</span><br><span class="line"></span><br><span class="line">root@test1:~# juju ssh kubernetes-master/0 ps -ef|grep kube</span><br><span class="line">...</span><br><span class="line">root      3045     1  3 Nov12 ?        00:15:00 /snap/kube-scheduler/200/kube-scheduler --logtostderr --master http://127.0.0.1:8080 --v 2</span><br><span class="line">root      3096     1  9 Nov12 ?        00:45:47 /snap/kube-apiserver/200/kube-apiserver --admission-control Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,DefaultTolerationSeconds --allow-privileged=false --authorization-mode AlwaysAllow --basic-auth-file /root/cdk/basic_auth.csv --etcd-cafile /root/cdk/etcd/client-ca.pem --etcd-certfile /root/cdk/etcd/client-cert.pem --etcd-keyfile /root/cdk/etcd/client-key.pem --etcd-servers https://10.241.244.78:2379,https://10.241.244.83:2379,https://10.241.244.89:2379 --insecure-bind-address 127.0.0.1 --insecure-port 8080 --kubelet-certificate-authority /root/cdk/ca.crt --kubelet-client-certificate /root/cdk/client.crt --kubelet-client-key /root/cdk/client.key --logtostderr --min-request-timeout 300 --service-account-key-file /root/cdk/serviceaccount.key --service-cluster-ip-range 10.152.183.0/24 --storage-backend etcd2 --tls-cert-file /root/cdk/server.crt --tls-private-key-file /root/cdk/server.key --token-auth-file /root/cdk/known_tokens.csv --v 4</span><br><span class="line">root      3303     1  7 Nov12 ?        00:39:14 /snap/kube-controller-manager/191/kube-controller-manager --logtostderr --master http://127.0.0.1:8080 --min-resync-period 3m --root-ca-file /root/cdk/ca.crt --service-account-private-key-file /root/cdk/serviceaccount.key --v 2</span><br><span class="line"></span><br><span class="line">root@test1:~# juju ssh kubernetes-worker/0 ps -ef|grep kube</span><br><span class="line">...</span><br><span class="line">root     12872     1  0 Nov12 ?        00:04:20 /snap/kube-proxy/200/kube-proxy --cluster-cidr 10.1.0.0/16 --conntrack-max-per-core 0 --kubeconfig /root/cdk/kubeproxyconfig --logtostderr --master https://10.241.244.49:443 --v 0</span><br><span class="line">root     12881     1  6 Nov12 ?        00:32:10 /snap/kubelet/200/kubelet --address 0.0.0.0 --allow-privileged=false --anonymous-auth=false --client-ca-file /root/cdk/ca.crt --cluster-dns 10.152.183.10 --cluster-domain cluster.local --fail-swap-on=false --kubeconfig /root/cdk/kubeconfig --logtostderr --network-plugin cni --port 10250 --tls-cert-file /root/cdk/server.crt --tls-private-key-file /root/cdk/server.key --v 0</span><br></pre></td></tr></table></figure>
<h2 id="使用conjure-up部署Kubernetes"><a href="#使用conjure-up部署Kubernetes" class="headerlink" title="使用conjure-up部署Kubernetes"></a>使用conjure-up部署Kubernetes</h2><p>也可以使用conjure-up更加友好的在LXD容器里部署Kubernetes，它实际上也是调用上面的bundle.yaml进行部署的。脚本如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-add-repository ppa:juju/stable</span><br><span class="line">sudo apt-add-repository ppa:conjure-up/next</span><br><span class="line">sudo apt update</span><br><span class="line">sudo snap install lxd</span><br><span class="line">sudo snap install conjure-up --classic</span><br><span class="line">export PATH=/snap/bin:$PATH</span><br><span class="line">/snap/bin/lxd init --auto</span><br><span class="line">#Use lxdbr1 since the name lxdbr0 has been used in test env, can use &apos;lxc network list&apos; to see &apos;MANAGED&apos; field</span><br><span class="line">/snap/bin/lxc network create lxdbr1 ipv4.address=auto ipv4.nat=true ipv6.address=none</span><br><span class="line">#Must use non-root user to avoid the error &apos;This should _not_ be run as root or with sudo&apos;</span><br><span class="line">#Step1, select to install &apos;Kubernetes Core&apos;, see the picture below</span><br><span class="line">#Step2, select &apos;localhost&apos;, see the picture below</span><br><span class="line">#Step3, select the network bridge &apos;lxdbr1&apos;, see the picture below</span><br><span class="line">#Step4, click &apos;Deploy all 5 Remaining Applicatons, see the picture below</span><br><span class="line">sudo -u ubuntu -i conjure-up kubernetes</span><br><span class="line">tailf ~/.cache/conjure-up/conjure-up.log</span><br></pre></td></tr></table></figure></p>
<p>或者直接使用下列脚本安装：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/snap/bin:$PATH</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; default-profile.yaml</span><br><span class="line">config: &#123;&#125;</span><br><span class="line">description: Default LXD profile</span><br><span class="line">devices:</span><br><span class="line">  eth0:</span><br><span class="line">    nictype: bridged</span><br><span class="line">    parent: lxdbr1</span><br><span class="line">    type: nic</span><br><span class="line">  root:</span><br><span class="line">    path: /</span><br><span class="line">    pool: default</span><br><span class="line">    type: disk</span><br><span class="line">name: default</span><br><span class="line">used_by:</span><br><span class="line">- /1.0/containers/cache</span><br><span class="line">- /1.0/containers/kubernetes</span><br><span class="line">EOF</span><br><span class="line">lxc profile create default 2&gt;/dev/null || echo &quot;default profile already exists&quot;</span><br><span class="line">cat default-profile.yaml | lxc profile edit default</span><br><span class="line"></span><br><span class="line">#!/bin/bash</span><br><span class="line">lxc delete -f kubernetes</span><br><span class="line">#用default和juju-kubernetes两个profile创建一个容器</span><br><span class="line">lxc launch ubuntu:17.04 -p default -p juju-kubernetes kubernetes</span><br><span class="line">sleep 5s</span><br><span class="line">lxc exec kubernetes -- apt-get update</span><br><span class="line">lxc exec kubernetes -- snap install lxd</span><br><span class="line">lxc exec kubernetes -- apt-get install squashfuse</span><br><span class="line">lxc exec kubernetes -- snap install core --beta</span><br><span class="line">lxc exec kubernetes -- snap install conjure-up --classic --beta</span><br><span class="line"></span><br><span class="line">#注意，此命令一定要使用snap包里的/snap/bin/lxc来执行，而不是apt包里的/usr/bin/lxc</span><br><span class="line">/snap/bin/lxc exec kubernetes -- sudo -u ubuntu -i /snap/bin/conjure-up canonical-kubernetes localhost controller model</span><br></pre></td></tr></table></figure></p>
<p>贴一些相关的图如下：<br><img src="http://img.blog.csdn.net/20171112211641461?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171112211653333?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171112211707374?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171112211721152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="https://stgraber.org/2017/01/13/kubernetes-inside-lxd/" target="_blank" rel="external">https://stgraber.org/2017/01/13/kubernetes-inside-lxd/</a><br>[2] <a href="https://insights.ubuntu.com/2017/10/12/kubernetes-the-not-so-easy-way/" target="_blank" rel="external">https://insights.ubuntu.com/2017/10/12/kubernetes-the-not-so-easy-way/</a><br>[3] <a href="https://github.com/lenovo/workload-solution/wiki/juju-charm-layers" target="_blank" rel="external">https://github.com/lenovo/workload-solution/wiki/juju-charm-layers</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/12/将kubernetes跑在本地LXD容器中/" data-id="cjapajjqj000bk6bpwzwdy855" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Play-with-LXD" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/12/Play-with-LXD/" class="article-date">
  <time datetime="2017-11-12T06:28:36.000Z" itemprop="datePublished">2017-11-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/12/Play-with-LXD/">Play with LXD</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>作者：张华  发表于：2016-08-05<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明<br><a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</strong></p>
<h2 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h2><ol>
<li>iscsi还不能运行在容器里（因为netlink还不支持namesapce)，本文采用rbd使用ceph代替iscsi</li>
<li>ovs, kvm通过定义profile支持运行在容器里。ovs目前只支持security.privileged: “true”</li>
</ol>
<h2 id="配置LXD"><a href="#配置LXD" class="headerlink" title="配置LXD"></a>配置LXD</h2><p>参考<a href="http://blog.csdn.net/quqi99/article/details/52131486" target="_blank" rel="external">Play with LXD</a>一文 在ubuntu 16.04上部署LXD环境。略。然后继续执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">lxc profile create juju-default 2&gt;/dev/null || echo &quot;juju-default profile already exists&quot;</span><br><span class="line"># Download openstack-on-lxd from https://jujucharms.com/openstack-base/</span><br><span class="line">unzip openstack-on-lxd.zip</span><br><span class="line">modprobe nbd</span><br><span class="line">cat lxd-profile.yaml | lxc profile edit juju-default</span><br><span class="line">#lxc profile set default raw.lxc lxc.aa_profile=unconfined</span><br><span class="line">#lxc profile device add default fuse unix-char path=/dev/fuse</span><br><span class="line">#/snap/bin/lxc network create lxdbr1 ipv4.address=auto ipv4.nat=true ipv6.address=none</span><br><span class="line">$ cat lxd-profile.yaml </span><br><span class="line">name: juju-default</span><br><span class="line">config:</span><br><span class="line">  boot.autostart: &quot;true&quot;</span><br><span class="line">  security.nesting: &quot;true&quot;</span><br><span class="line">  security.privileged: &quot;true&quot;</span><br><span class="line">  raw.lxc: lxc.aa_profile=unconfined</span><br><span class="line">  linux.kernel_modules: openvswitch,nbd,ip_tables,ip6_tables，ebtables，netlink_diag,nf_nat,overlay</span><br><span class="line">devices:</span><br><span class="line">  eth0:</span><br><span class="line">    mtu: &quot;9000&quot;</span><br><span class="line">    name: eth0</span><br><span class="line">    nictype: bridged</span><br><span class="line">    parent: lxdbr1</span><br><span class="line">    type: nic</span><br><span class="line">  eth1:</span><br><span class="line">    mtu: &quot;9000&quot;</span><br><span class="line">    name: eth1</span><br><span class="line">    nictype: bridged</span><br><span class="line">    parent: lxdbr1</span><br><span class="line">    type: nic</span><br><span class="line">  kvm:</span><br><span class="line">    path: /dev/kvm</span><br><span class="line">    type: unix-char</span><br><span class="line">  mem:</span><br><span class="line">    path: /dev/mem</span><br><span class="line">    type: unix-char</span><br><span class="line">  root:</span><br><span class="line">    path: /</span><br><span class="line">    pool: default</span><br><span class="line">    type: disk</span><br><span class="line">  tun:</span><br><span class="line">    path: /dev/net/tun</span><br><span class="line">    type: unix-char</span><br></pre></td></tr></table></figure>
<h2 id="使用Juju在单机上部署OpenStack"><a href="#使用Juju在单机上部署OpenStack" class="headerlink" title="使用Juju在单机上部署OpenStack"></a>使用Juju在单机上部署OpenStack</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line">#Use the profile &apos;juju-default&apos; to bootstrap</span><br><span class="line">juju bootstrap --debug --config bootstrap-series=xenial --config agent-stream=devel localhost juju-default</span><br><span class="line">lxc exec `lxc list |grep juju- |awk -F &apos;|&apos; &apos;&#123;print $2&#125;&apos;` bash</span><br><span class="line">juju deploy bundle.yaml</span><br><span class="line">juju status</span><br><span class="line">juju debug-log</span><br><span class="line">$ cat bundle.yaml </span><br><span class="line">debug:                      &amp;debug                     True</span><br><span class="line">verbose:                    &amp;verbose                   True</span><br><span class="line">series: xenial</span><br><span class="line">services:</span><br><span class="line">  rabbitmq-server:</span><br><span class="line">    num_units: 1</span><br><span class="line">    charm: cs:~openstack-charmers-next/rabbitmq-server</span><br><span class="line">    constraints: mem=1G</span><br><span class="line">    options:</span><br><span class="line">      source: cloud:xenial-mitaka</span><br><span class="line">  keystone:</span><br><span class="line">    num_units: 1</span><br><span class="line">    charm: cs:~openstack-charmers-next/keystone</span><br><span class="line">    constraints: mem=1G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      admin-password: openstack</span><br><span class="line">      admin-token: ubuntutesting</span><br><span class="line">      openstack-origin: cloud:xenial-mitaka</span><br><span class="line">  openstack-dashboard:</span><br><span class="line">    num_units: 1</span><br><span class="line">    charm: cs:~openstack-charmers-next/openstack-dashboard</span><br><span class="line">    constraints: mem=1G</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:xenial-mitaka</span><br><span class="line">  nova-compute:</span><br><span class="line">    charm: cs:~openstack-charmers-next/nova-compute</span><br><span class="line">    num_units: 3</span><br><span class="line">    constraints: mem=4G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      enable-live-migration: True</span><br><span class="line">      enable-resize: True</span><br><span class="line">      migration-auth-type: ssh</span><br><span class="line">      openstack-origin: cloud:xenial-mitaka</span><br><span class="line">  nova-cloud-controller:</span><br><span class="line">    num_units: 1</span><br><span class="line">    charm: cs:~openstack-charmers-next/nova-cloud-controller</span><br><span class="line">    constraints: mem=1G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      network-manager: Neutron</span><br><span class="line">      openstack-origin: cloud:xenial-mitaka</span><br><span class="line">  neutron-gateway:</span><br><span class="line">    num_units: 1</span><br><span class="line">    charm: cs:~openstack-charmers-next/neutron-gateway</span><br><span class="line">    constraints: mem=4G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      instance-mtu: 1300</span><br><span class="line">      bridge-mappings: physnet1:br-ex</span><br><span class="line">      openstack-origin: cloud:xenial-mitaka</span><br><span class="line">  neutron-api:</span><br><span class="line">    num_units: 1</span><br><span class="line">    charm: cs:~openstack-charmers-next/neutron-api</span><br><span class="line">    constraints: mem=1G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      neutron-security-groups: True</span><br><span class="line">      flat-network-providers: physnet1</span><br><span class="line">      openstack-origin: cloud:xenial-mitaka</span><br><span class="line">  neutron-openvswitch:</span><br><span class="line">    charm: cs:~openstack-charmers-next/neutron-openvswitch</span><br><span class="line">  cinder:</span><br><span class="line">    num_units: 1</span><br><span class="line">    charm: cs:~openstack-charmers-next/cinder</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      block-device: /dev/vdb</span><br><span class="line">      ephemeral-unmount: &quot;/mnt&quot;</span><br><span class="line">      overwrite: &quot;true&quot;</span><br><span class="line">      glance-api-version: 2</span><br><span class="line">      openstack-origin: cloud:xenial-mitaka</span><br><span class="line">    constraints: mem=1G</span><br><span class="line">  glance:</span><br><span class="line">    num_units: 1</span><br><span class="line">    charm: cs:~openstack-charmers-next/glance</span><br><span class="line">    constraints: mem=1G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      verbose: *verbose</span><br><span class="line">      openstack-origin: cloud:xenial-mitaka</span><br><span class="line">  mysql:</span><br><span class="line">    num_units: 1</span><br><span class="line">    charm: cs:~openstack-charmers-next/percona-cluster</span><br><span class="line">    constraints: mem=4G</span><br><span class="line">    options:</span><br><span class="line">      dataset-size: 50%</span><br><span class="line">      max-connections: 20000</span><br><span class="line">      root-password: ChangeMe123</span><br><span class="line">      sst-password: ChangeMe123</span><br><span class="line">      source: cloud:xenial-mitaka</span><br><span class="line">relations:</span><br><span class="line">  - [ keystone, mysql ]</span><br><span class="line">  - [ nova-cloud-controller, mysql ]</span><br><span class="line">  - [ nova-cloud-controller, rabbitmq-server ]</span><br><span class="line">  - [ nova-cloud-controller, glance ]</span><br><span class="line">  - [ nova-cloud-controller, keystone ]</span><br><span class="line">  - [ nova-compute, nova-cloud-controller ]</span><br><span class="line">  - [ nova-compute, mysql ]</span><br><span class="line">  - - nova-compute</span><br><span class="line">    - rabbitmq-server:amqp</span><br><span class="line">  - [ nova-compute, glance ]</span><br><span class="line">  - [ glance, mysql ]</span><br><span class="line">  - [ glance, keystone ]</span><br><span class="line">  - [ glance, &quot;cinder:image-service&quot; ]</span><br><span class="line">  - [ glance, rabbitmq-server ]</span><br><span class="line">  - [ cinder, mysql ]</span><br><span class="line">  - [ cinder, rabbitmq-server ]</span><br><span class="line">  - [ cinder, nova-cloud-controller ]</span><br><span class="line">  - [ cinder, keystone ]</span><br><span class="line">  - [ neutron-gateway, nova-cloud-controller ]</span><br><span class="line">  - [ openstack-dashboard, keystone ]</span><br><span class="line">  - [ &quot;neutron-gateway:amqp&quot;, rabbitmq-server ]</span><br><span class="line">  - [ neutron-api, mysql ]</span><br><span class="line">  - [ neutron-api, rabbitmq-server ]</span><br><span class="line">  - [ neutron-api, nova-cloud-controller ]</span><br><span class="line">  - [ neutron-api, neutron-openvswitch ]</span><br><span class="line">  - [ neutron-api, keystone ]</span><br><span class="line">  - [ neutron-api, neutron-gateway ]</span><br><span class="line">  - [ neutron-openvswitch, nova-compute ]</span><br><span class="line">  - [ neutron-openvswitch, rabbitmq-server ]</span><br></pre></td></tr></table></figure>
<h2 id="配置使用OpenStack"><a href="#配置使用OpenStack" class="headerlink" title="配置使用OpenStack"></a>配置使用OpenStack</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">source novarc</span><br><span class="line">$ cat novarc </span><br><span class="line">#!/bin/bash</span><br><span class="line">export OS_USERNAME=admin</span><br><span class="line">export OS_PASSWORD=openstack</span><br><span class="line">export OS_TENANT_NAME=admin</span><br><span class="line">export OS_REGION_NAME=RegionOne</span><br><span class="line">export OS_AUTH_URL=$&#123;OS_AUTH_PROTOCOL:-http&#125;://`juju run --unit  keystone/0 &quot;unit-get private-address&quot;`:5000/v2.0</span><br><span class="line"></span><br><span class="line">curl http://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img</span><br><span class="line">openstack image create --public --container-format=bare --disk-format=qcow2 xenial</span><br><span class="line"></span><br><span class="line">./neutron-ext-net -g 10.0.8.1 -c 10.0.8.0/24 \ -f 10.0.8.201:10.0.8.254 ext_net</span><br><span class="line">./neutron-tenant-net -t admin -r provider-router \ -N 10.0.8.1 internal 192.168.20.0/24</span><br><span class="line"></span><br><span class="line">nova keypair-add --pub-key ~/.ssh/id_rsa.pub mykey</span><br><span class="line">nova boot --image xenial --flavor m1.small --key-name mykey --nic net-id=$(neutron net-list | grep internal | awk &apos;&#123; print $2 &#125;&apos;) i1</span><br><span class="line"></span><br><span class="line">cinder create --name testvolume 10</span><br><span class="line">nova volume-attach xenial $(cinder list | grep testvolume | awk &apos;&#123; print $2 &#125;&apos;) /dev/vdc</span><br><span class="line"></span><br><span class="line">nova floating-ip-create </span><br><span class="line">nova add-floating-ip &lt;uuid-of-instance&gt; &lt;new-floating-ip&gt;</span><br><span class="line"></span><br><span class="line">neutron security-group-rule-create --protocol icmp --direction ingress $(nova secgroup-list | grep default | awk &apos;&#123; print $2 &#125;&apos;) </span><br><span class="line">neutron security-group-rule-create --protocol tcp  --port-range-min 22 --port-range-max 22  --direction ingress $(nova secgroup-list | grep default | awk &apos;&#123; print $2 &#125;&apos;)</span><br><span class="line"></span><br><span class="line">ssh ubuntu@&lt;new-floating-ip&gt;</span><br></pre></td></tr></table></figure>
<h2 id="又一例-部署opencontrail在lxd单机上"><a href="#又一例-部署opencontrail在lxd单机上" class="headerlink" title="又一例 - 部署opencontrail在lxd单机上"></a>又一例 - 部署opencontrail在lxd单机上</h2><p>下面的yaml是juju2.0的，如果是juju1.x可见：<a href="http://pastebin.ubuntu.com/24170320/" target="_blank" rel="external">http://pastebin.ubuntu.com/24170320/</a><br>实际上,opencontrail vrouter部署在容器里会报下列错，此例子只是说明yaml怎么写。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2017-03-13 11:46:06 INFO juju-log Loading kernel module vrouter</span><br><span class="line">2017-03-13 11:46:06 INFO install modprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file &apos;/lib/modules/4.8.0-34-generic/modules.dep.bin&apos;</span><br><span class="line">2017-03-13 11:46:06 INFO juju-log vrouter kernel module failed to load, clearing pagecache and retrying</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">series: trusty</span><br><span class="line">services:</span><br><span class="line">  # openstack</span><br><span class="line">  ubuntu:</span><br><span class="line">    charm: cs:trusty/ubuntu</span><br><span class="line">    num_units: 1</span><br><span class="line">  ntp:</span><br><span class="line">    charm: cs:trusty/ntp</span><br><span class="line">  mysql:</span><br><span class="line">    charm: cs:trusty/mysql</span><br><span class="line">    options:</span><br><span class="line">      dataset-size: 15%</span><br><span class="line">      max-connections: 1000</span><br><span class="line">    num_units: 1</span><br><span class="line">  rabbitmq-server:</span><br><span class="line">    charm: cs:trusty/rabbitmq-server</span><br><span class="line">    num_units: 1</span><br><span class="line">  keystone:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/keystone</span><br><span class="line">    options:</span><br><span class="line">      admin-password: password</span><br><span class="line">      admin-role: admin</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  nova-cloud-controller:</span><br><span class="line">    charm: cs:trusty/nova-cloud-controller</span><br><span class="line">    options:</span><br><span class="line">      network-manager: Neutron</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  neutron-api:</span><br><span class="line">    charm: cs:trusty/neutron-api</span><br><span class="line">    options:</span><br><span class="line">      manage-neutron-plugin-legacy-mode: false</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  glance:</span><br><span class="line">    charm: cs:trusty/glance</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  openstack-dashboard:</span><br><span class="line">    charm: cs:trusty/openstack-dashboard</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  nova-compute:</span><br><span class="line">    charm: cs:trusty/nova-compute</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  # contrail</span><br><span class="line">  cassandra:</span><br><span class="line">    charm: cs:trusty/cassandra</span><br><span class="line">    options:</span><br><span class="line">      authenticator: AllowAllAuthenticator</span><br><span class="line">      install_sources: |</span><br><span class="line">        - deb http://www.apache.org/dist/cassandra/debian 22x main</span><br><span class="line">        - ppa:openjdk-r/ppa</span><br><span class="line">        - ppa:stub/cassandra</span><br><span class="line">    num_units: 1</span><br><span class="line">  zookeeper:</span><br><span class="line">    charm: cs:~charmers/trusty/zookeeper</span><br><span class="line">    num_units: 1</span><br><span class="line">  kafka:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/apache-kafka</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-configuration:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-configuration</span><br><span class="line">    options:</span><br><span class="line">      openstack-origin: cloud:trusty-mitaka</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-control:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-control</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-analytics:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-analytics</span><br><span class="line">    num_units: 1</span><br><span class="line">  contrail-webui:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/contrail-webui</span><br><span class="line">    num_units: 1</span><br><span class="line">  neutron-api-contrail:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/neutron-api-contrail</span><br><span class="line">    num_units: 0</span><br><span class="line">  neutron-contrail:</span><br><span class="line">    charm: cs:~sdn-charmers/trusty/neutron-contrail</span><br><span class="line">    num_units: 0</span><br><span class="line"></span><br><span class="line">relations:</span><br><span class="line">  # openstack</span><br><span class="line"> - [ ubuntu, ntp ]</span><br><span class="line"> - [ keystone, mysql ]</span><br><span class="line"> - [ glance, mysql ]</span><br><span class="line"> - [ glance, keystone ]</span><br><span class="line"> - [ nova-cloud-controller, mysql ]</span><br><span class="line"> - [ nova-cloud-controller, rabbitmq-server ]</span><br><span class="line"> - [ nova-cloud-controller, keystone ]</span><br><span class="line"> - [ nova-cloud-controller, glance ]</span><br><span class="line"> - [ neutron-api, mysql ]</span><br><span class="line"> - [ neutron-api, rabbitmq-server ]</span><br><span class="line"> - [ neutron-api, nova-cloud-controller ]</span><br><span class="line"> - [ neutron-api, keystone ]</span><br><span class="line"> - [ neutron-api, neutron-api-contrail ]</span><br><span class="line"> - [ &quot;nova-compute:shared-db&quot;, &quot;mysql:shared-db&quot; ]</span><br><span class="line"> - [ &quot;nova-compute:amqp&quot;, &quot;rabbitmq-server:amqp&quot; ]</span><br><span class="line"> - [ nova-compute, glance ]</span><br><span class="line"> - [ nova-compute, nova-cloud-controller ]</span><br><span class="line"> - [ nova-compute, ntp ]</span><br><span class="line"> - [ openstack-dashboard, keystone ]</span><br><span class="line">  # contrail</span><br><span class="line"> - [ kafka, zookeeper ]</span><br><span class="line"> - [ &quot;contrail-configuration:cassandra&quot;, &quot;cassandra:database&quot; ]</span><br><span class="line"> - [ contrail-configuration, zookeeper ]</span><br><span class="line"> - [ contrail-configuration, rabbitmq-server ]</span><br><span class="line"> - [ &quot;contrail-configuration:identity-admin&quot;, &quot;keystone:identity-admin&quot; ]</span><br><span class="line"> - [ &quot;contrail-configuration:identity-service&quot;, &quot;keystone:identity-service&quot; ]</span><br><span class="line"> - [ neutron-api-contrail, contrail-configuration ]</span><br><span class="line"> - [ neutron-api-contrail, keystone ]</span><br><span class="line"> - [ &quot;contrail-control:contrail-api&quot;, &quot;contrail-configuration:contrail-api&quot; ]</span><br><span class="line"> - [ &quot;contrail-control:contrail-discovery&quot;, &quot;contrail-configuration:contrail-discovery&quot; ]</span><br><span class="line"> - [ &quot;contrail-control:contrail-ifmap&quot;, &quot;contrail-configuration:contrail-ifmap&quot; ]</span><br><span class="line"> - [ contrail-control, keystone ]</span><br><span class="line"> - [ &quot;contrail-analytics:cassandra&quot;, &quot;cassandra:database&quot; ]</span><br><span class="line"> - [ contrail-analytics, kafka ]</span><br><span class="line"> - [ contrail-analytics, zookeeper ]</span><br><span class="line"> - [ &quot;contrail-analytics:contrail-api&quot;, &quot;contrail-configuration:contrail-api&quot; ]</span><br><span class="line"> - [ &quot;contrail-analytics:contrail-discovery&quot;, &quot;contrail-configuration:contrail-discovery&quot; ]</span><br><span class="line"> - [ &quot;contrail-analytics:identity-admin&quot;, &quot;keystone:identity-admin&quot; ]</span><br><span class="line"> - [ &quot;contrail-analytics:identity-service&quot;, &quot;keystone:identity-service&quot; ]</span><br><span class="line"> - [ &quot;contrail-configuration:contrail-analytics-api&quot;, &quot;contrail-analytics:contrail-analytics-api&quot; ]</span><br><span class="line"> - [ nova-compute, neutron-contrail ]</span><br><span class="line"> - [ &quot;neutron-contrail:contrail-discovery&quot;, &quot;contrail-configuration:contrail-discovery&quot; ]</span><br><span class="line"> - [ &quot;neutron-contrail:contrail-api&quot;, &quot;contrail-configuration:contrail-api&quot; ]</span><br><span class="line"> - [ neutron-contrail, keystone ]</span><br><span class="line"> - [ contrail-webui, keystone ]</span><br><span class="line"> - [ &quot;contrail-webui:cassandra&quot;, &quot;cassandra:database&quot; ]</span><br></pre></td></tr></table></figure>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><ul>
<li>如果报这个错 - failed to bootstrap model: cannot start bootstrap instance: The container’s root device is missing the pool property， 那是要在profile中的root元素下添加：pool: default</li>
<li>bootstrap时报这个错 - FATAL: Module ip6_tables，ebtables，netlink_diag not found in directory /lib/modules/4.4.0-98-generic - 运行‘sudo apt-get install –reinstall linux-image-extra-$(uname -r)’安装模块（/lib/modules/$(uname -r)/kernel/net/netlink/netlink_diag.ko）， 不过似乎装了也解决不了问题。</li>
</ul>
<h2 id="通过conjure-up安装OpenStack"><a href="#通过conjure-up安装OpenStack" class="headerlink" title="通过conjure-up安装OpenStack"></a>通过conjure-up安装OpenStack</h2><p>我们也可以通过conjure-up安装OpenStack,</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">#Install a lxd container</span><br><span class="line">sudo lxc init ubuntu:16.04 openstack -c security.privileged=true -c security.nesting=true -c &quot;linux.kernel_modules=iptable_nat, ip6table_nat, ebtables, openvswitch, nbd&quot;</span><br><span class="line">printf &quot;lxc.cap.drop=\nlxc.aa_profile=unconfined\n&quot; | sudo lxc config set openstack raw.lxc -</span><br><span class="line">sudo lxc config get openstack raw.lxc</span><br><span class="line">lxc config device add openstack mem unix-char path=/dev/mem</span><br><span class="line">lxc start openstack</span><br><span class="line">lxc list</span><br><span class="line"></span><br><span class="line">#Install conjure-up inside the lxd container</span><br><span class="line">#lxc exec openstack bash</span><br><span class="line">lxc exec openstack -- apt update</span><br><span class="line">#lxc exec openstack -- apt dist-upgrade -y</span><br><span class="line">lxc exec openstack -- apt install squashfuse -y</span><br><span class="line">lxc exec openstack -- ln -s /bin/true /usr/local/bin/udevadm</span><br><span class="line">lxc exec openstack -- snap install conjure-up --classic</span><br><span class="line"></span><br><span class="line">#Init lxd container</span><br><span class="line">#Use the “dir” storage backend (“zfs” doesn’t work in a nested container)</span><br><span class="line">#Do NOT configure IPv6 networking (conjure-up/juju don’t play well with it)</span><br><span class="line">#lxc exec openstack -- lxd init</span><br><span class="line">lxc exec openstack -- snap install lxd</span><br><span class="line">sleep 10  #avoid the error &apos;Unable to talk to LXD: Get http://unix.socket/1.0&apos;</span><br><span class="line">lxc exec openstack -- /snap/bin/lxd init --auto</span><br><span class="line">lxc exec openstack -- /snap/bin/lxc network create lxdbr0 ipv4.address=auto ipv4.nat=true ipv6.address=none</span><br><span class="line">lxc exec openstack -- /snap/bin/lxc profile show default</span><br><span class="line"></span><br><span class="line">#Deploying OpenStack with conjure-up in nested LXD</span><br><span class="line">#conjure-up is a nice, user friendly, tool that interfaces with Juju to deploy complex services.</span><br><span class="line">#Step 1, select “OpenStack with NovaLXD”</span><br><span class="line">#Step 2, select “localhost” as the deployment target (uses LXD)</span><br><span class="line">#Step 3, select default in all middle steps, and click “Deploy all remaining applications”</span><br><span class="line">lxc exec openstack -- sudo -u ubuntu -i conjure-up</span><br><span class="line">hua@node1:~$ sudo lxc list</span><br><span class="line">+-----------+---------+--------------------------------+------+------------+-----------+</span><br><span class="line">|   NAME    |  STATE  |              IPV4              | IPV6 |    TYPE    | SNAPSHOTS |</span><br><span class="line">+-----------+---------+--------------------------------+------+------------+-----------+</span><br><span class="line">| openstack | RUNNING | 10.73.227.154 (eth0)           |      | PERSISTENT | 0         |</span><br><span class="line">|           |         | 10.164.92.1 (lxdbr0)           |      |            |           |</span><br><span class="line">|           |         | 10.101.0.1 (conjureup0)        |      |            |           |</span><br><span class="line">+-----------+---------+--------------------------------+------+------------+-----------+</span><br><span class="line"></span><br><span class="line">#Or deploy OpenStack with conjure-up in physical node</span><br><span class="line">sudo snap install lxd</span><br><span class="line">export PATH=/snap/bin:$PATH</span><br><span class="line">sudo /snap/bin/lxd init --auto</span><br><span class="line">sudo /snap/bin/lxc network create lxdbr0 ipv4.address=auto ipv4.nat=true ipv6.address=none</span><br><span class="line">sudo -i</span><br><span class="line">conjure-up openstack #but I hit the error &apos;This should _not_ be run as root or with sudo&apos; even though I&apos;ve already used root</span><br></pre></td></tr></table></figure>
<p>下面粘一些使用conjure-up过程中的截图：<br><img src="http://img.blog.csdn.net/20171112101736564?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171112101801150?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171112101813090?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXVxaTk5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://stgraber.org/2016/10/26/lxd-2-0-lxd-and-openstack-1112/" target="_blank" rel="external">https://stgraber.org/2016/10/26/lxd-2-0-lxd-and-openstack-1112/</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/12/Play-with-LXD/" data-id="cjapajjpf0001k6bp9jsan58t" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-调研NFV编排工具" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/10/调研NFV编排工具/" class="article-date">
  <time datetime="2017-11-10T14:27:51.000Z" itemprop="datePublished">2017-11-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/10/调研NFV编排工具/">调研NFV编排工具</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a>)</strong></p>
<h2 id="裸机配置工具"><a href="#裸机配置工具" class="headerlink" title="裸机配置工具"></a>裸机配置工具</h2><ul>
<li>Cobbler, Dell开源的基于PXE的裸机部署工具</li>
<li>Ironic, OpenStack官方其于PXE+IPMI的裸机部署工具</li>
<li>MAAS, Canonical的基于PXE的裸机部署工具，电源管理(<a href="https://docs.ubuntu.com/maas/2.0/en/installconfig-power-types)方面既支持IPMI、HMC等也支持虚拟化的如virsh、VMware等" target="_blank" rel="external">https://docs.ubuntu.com/maas/2.0/en/installconfig-power-types)方面既支持IPMI、HMC等也支持虚拟化的如virsh、VMware等</a> - <a href="http://blog.csdn.net/quqi99/article/details/37990507" target="_blank" rel="external">http://blog.csdn.net/quqi99/article/details/37990507</a><h2 id="通用配置管理工具"><a href="#通用配置管理工具" class="headerlink" title="通用配置管理工具"></a>通用配置管理工具</h2></li>
<li>Puppet, 配置管理工具的鼻祖，由Ruby语言编写，使用基于XML的自有的puppet描述语言管理配置文件、用户、cron任务、软件包、系统服务等，语法复杂，可移植性差。</li>
<li>Chef, 一个类似于Puppet用来快速部署软件及其依赖包的脚本工具，将配置步骤通过脚本写出来(Puppet用基于XML的专用方法书写，Chef用Ruby书写），客户端从服务器端获取脚本并执行 - <a href="http://blog.csdn.net/quqi99/article/details/21247111" target="_blank" rel="external">http://blog.csdn.net/quqi99/article/details/21247111</a></li>
<li>Ansible, 它应该是吸引了Juju通过SSH进行所有的操作的思想让它可以并行运行任何标准脚本语言(Python, Bash, Ruby等等），Ansible剧本(YAML语言编写)角色映射到节点/虚机上对它们进行编排有序的执行。另外它和Juju不同的是它是agentless的。</li>
<li>Salt, 又叫SaltStack，同时支持agent与agentless两种模式，在后一种模式下，Salt也使用SSH连接到受管理的节点/虚机执行以Python语言编写的模块。</li>
<li>Docker, 可将软件及软件依赖的运行环境与安装包统统打包一起部署，从而实现软件与基础架构的解偶。<h2 id="OpenStack部署工具"><a href="#OpenStack部署工具" class="headerlink" title="OpenStack部署工具"></a>OpenStack部署工具</h2></li>
<li>Devstack, 部署OpenStack开发环境</li>
<li>Packstack, 使用Puppet经SSH部署OpenStack到RHEL/CentOS上，见：<a href="https://wiki.openstack.org/wiki/Packstack" target="_blank" rel="external">https://wiki.openstack.org/wiki/Packstack</a></li>
<li>Redhat RDO, 使用Ansible部署OpenStack到RHEL/CentOS上</li>
<li>Suse Crowbar, 使用Chef部署OpenStack到Suse上</li>
<li>Rackspace OpenStack-Ansible, 使用Ansible部署OpenStack到Ubuntu和CentOS上</li>
<li>Mirantis Fuel, 使用Puppet部署OpenStack到Ubuntu上</li>
<li>HPE Helion, 使用Ansible部署OpenStack到Debian上</li>
<li>OpenStack TripleO, 使用OpenStack本来的基础设施(Nova, Neutron, Ironic, Heat)来自动化部署和伸缩OpenStack集群，即OpenStack over OpenStack。见：<a href="http://blog.csdn.net/quqi99/article/details/9530627" target="_blank" rel="external">http://blog.csdn.net/quqi99/article/details/9530627</a></li>
<li>OpenStack Kolla, 上面工具只是实现了部署OpenStack的自动化，但没有简化OpenStack部署，如包依赖和升级困难等。Kolla项目起源于TripleO项目，实现OpenStack部署的容器化(即把目前OpenStack项目用到的所有组件部署在容器里)，因此具有原子性回滚升级特性。它既可以利用Ansible去伸缩OpenStack容器节点，也可以利用Kubernetes去伸缩OpenStack容器节点。<h2 id="NFV编排"><a href="#NFV编排" class="headerlink" title="NFV编排"></a>NFV编排</h2></li>
<li>OpenStack Heat, Heat根据配置文件模板(HOT, heat orchestration template)实例化一组符合要求的虚机。也能够在其上对应用软件进行配置与编排。对支持对一个组件部署后的负载均衡进行编排。见： <a href="http://blog.csdn.net/quqi99/article/details/50359289" target="_blank" rel="external">http://blog.csdn.net/quqi99/article/details/50359289</a></li>
<li>Canonical Juju, 使用OPNFV JOID去编排VNFM与NFVO</li>
<li>配置管理工具，上述的通用型的配置管理工具如Puppet、Chef、Ansible都可以用于去编排VNFM与NFVO</li>
<li>Kebernetes或者Kolar, 可作为编排工具将VNFM与NFVO部署到容器里<h2 id="Mesos-Marathon"><a href="#Mesos-Marathon" class="headerlink" title="Mesos + Marathon"></a>Mesos + Marathon</h2>应用部署方面也可以采用Mesos + Marthon:</li>
<li>Mesos是一个两阶段集群管理器（也叫数据中心操作系统)，Master第一阶段通过Framework注册的Schedule将资源分配给Framework (Framework可以支持Hadoop, Elasticsearch, Spark, Stom, Kafka, Marathon等, 也通过K8SM支持将容器集群管理器Kubernetest集成到Mesos)，Slave第二阶段在容器中调用Executor运行Framework的内部任务。</li>
<li>Marathon作为一个Mesos Framework，用来支持长期服务，比如Web应用，它相当于分布式的init.d，能够在分布式集群上像原有单机那样运行二进制程序，所以说它也是一种私有的PaaS，能提供REST API服务，实现服务的发现，通过HAProxy实现服务发现和负载均衡。</li>
<li>使用Mesos + Marathon来编排一些应用还行，但用来编排NFV似乎热度不高网上很难找到相关资料，社区缺乏活力</li>
<li>Mesos的所有Schdule都没有像Kubernetes那样针对微服务进行了数据模型的抽象（如Pod, Service, Namespace等），所以Mesos的API没有Kubernetes精良易用。另外，Mesos涉及的组件使用的编程语言太多，如Mesos(C++)、Marathon（Scala）、Mesos-DNS（Golang）等。<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2></li>
<li>做NFV的虚机编排用Juju或者Heat</li>
<li>做NFV的容器编排用Juju或者Kolar或者Kebernetes</li>
<li>当然，其他如Ansible这些其他配置软件也能用</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/10/调研NFV编排工具/" data-id="cjapajjq40007k6bpya0ss2g3" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CSDN博客地址" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/08/CSDN博客地址/" class="article-date">
  <time datetime="2017-11-08T02:36:56.000Z" itemprop="datePublished">2017-11-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/08/CSDN博客地址/">CSDN博客地址</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>我的CSDN博客地址是：<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/08/CSDN博客地址/" data-id="cjapajjpk0002k6bp316etev9" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/12/02/OpenWRT与QNAP上通过PXE安装Xenial/">OpenWRT与QNAP上通过PXE安装Xenial</a>
          </li>
        
          <li>
            <a href="/2017/11/29/Test-multipath-feature-by-openstack-lioadm/">Test multipath feature by openstack lioadm</a>
          </li>
        
          <li>
            <a href="/2017/11/29/远程访问双层嵌套Openstack云下的Windows虚机/">远程访问双层嵌套Openstack云下的Windows虚机</a>
          </li>
        
          <li>
            <a href="/2017/11/16/通配符中一个星号两个星号和globstar的关系/">通配符中一个星号两个星号和globstar的关系</a>
          </li>
        
          <li>
            <a href="/2017/11/13/Use-hexo-to-create-blog/">Use hexo to create blog</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 张华<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>