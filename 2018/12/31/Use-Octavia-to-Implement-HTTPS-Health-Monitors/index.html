<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="几张图感性认识ocatvia 问题采用Neutron LBaaS v2实现HTTPS Health Monitors时的配置如下(步骤见附件 - Neutron LBaaS v2)123456789backend 52112201-05ce-4f4d-b5a8-9e67de2a895a    mode tcp    balance leastconn    timeout check 10s">
<meta property="og:type" content="article">
<meta property="og:title" content="Use Octavia to Implement HTTPS Health Monitors">
<meta property="og:url" content="http://yoursite.com/2018/12/31/Use-Octavia-to-Implement-HTTPS-Health-Monitors/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="几张图感性认识ocatvia 问题采用Neutron LBaaS v2实现HTTPS Health Monitors时的配置如下(步骤见附件 - Neutron LBaaS v2)123456789backend 52112201-05ce-4f4d-b5a8-9e67de2a895a    mode tcp    balance leastconn    timeout check 10s">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200216105554797.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200216105645469.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200624104629442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70">
<meta property="og:updated_time" content="2020-10-15T06:11:04.915Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Use Octavia to Implement HTTPS Health Monitors">
<meta name="twitter:description" content="几张图感性认识ocatvia 问题采用Neutron LBaaS v2实现HTTPS Health Monitors时的配置如下(步骤见附件 - Neutron LBaaS v2)123456789backend 52112201-05ce-4f4d-b5a8-9e67de2a895a    mode tcp    balance leastconn    timeout check 10s">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200216105554797.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/12/31/Use-Octavia-to-Implement-HTTPS-Health-Monitors/"/>





  <title>Use Octavia to Implement HTTPS Health Monitors | 技术并艺术着</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">技术并艺术着</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">张华的技术博客 - blog.csdn.net/quqi99</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/31/Use-Octavia-to-Implement-HTTPS-Health-Monitors/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Use Octavia to Implement HTTPS Health Monitors</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-31T16:29:50+08:00">
                2018-12-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="几张图感性认识ocatvia"><a href="#几张图感性认识ocatvia" class="headerlink" title="几张图感性认识ocatvia"></a>几张图感性认识ocatvia</h2><p><img src="https://img-blog.csdnimg.cn/20200216105554797.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200216105645469.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200624104629442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F1cWk5OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>采用Neutron LBaaS v2实现HTTPS Health Monitors时的配置如下(步骤见附件 - Neutron LBaaS v2)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">    mode tcp</span><br><span class="line">    balance leastconn</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    option ssl-hello-chk</span><br><span class="line">    server 37a1f5a8-ec7e-4208-9c96-27d2783a594f 192.168.21.13:443 weight 1 check inter 5s fall 2</span><br><span class="line">    server 8e722b4b-08b8-4089-bba5-8fa5dd26a87f 192.168.21.8:443 weight 1 check inter 5s fall 2</span><br></pre></td></tr></table></figure></p>
<p>这种配置会有一个问题, 当使用自定义签名证书时一切正常, 但使用机构颁发的证书时反而有问题.<br>1, 对于ssl check, 严格一点的是check-ssl, 但haproxy没有证书不支持严格的客户端认证, 所以需添加”check check-ssl verify none”参数禁止对客户端参数进行验证. lbaasv2由于久远不支持(那时都还是haproxy 1.7以前必须不支持), ocatavia则有对ssl check的支持.(<a href="https://github.com/openstack/octavia/blob/master/octavia/common/jinja/haproxy/templates/macros.j2" target="_blank" rel="external">https://github.com/openstack/octavia/blob/master/octavia/common/jinja/haproxy/templates/macros.j2</a>)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">154         &#123;% if pool.health_monitor.type == constants.HEALTH_MONITOR_HTTPS %&#125;</span><br><span class="line">155             &#123;% set monitor_ssl_opt = &quot; check-ssl verify none&quot; %&#125;</span><br></pre></td></tr></table></figure></p>
<p>下面的配置works<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">backend 79024d4d-4de4-492c-a3e2-21730b096a37</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 317e4dea-5a62-4df0-a2f1-ea7bad4a9c5d 192.168.21.7:443 weight 1 check check-ssl verify none inter 5s fall 3 rise 4</span><br></pre></td></tr></table></figure></p>
<p>但是似乎ocatavia的client有点问题, 它设置出来的是:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    option httpchk None None</span><br><span class="line">    http-check expect rstatus None</span><br><span class="line">    server 317e4dea-5a62-4df0-a2f1-ea7bad4a9c5d 192.168.21.7:443 weight 1 check check-ssl verify none inter 5s fall 3 rise 4</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTPS --name https-monitor --http-method GET --url-path / --expected-codes 200 pool1</span><br><span class="line">http_method is not a valid option for health monitors of type HTTPS (HTTP 400) (Request-ID: req-2d81bafa-1240-4f73-8e2e-cb0dd7691fdb)</span><br></pre></td></tr></table></figure></p>
<p>2, ssl backend side采用了严格的客户端认证的话, 需改用TLS-HELLO check (<a href="https://docs.openstack.org/octavia/latest/user/guides/basic-cookbook.html)其实已经有说明" target="_blank" rel="external">https://docs.openstack.org/octavia/latest/user/guides/basic-cookbook.html)其实已经有说明</a>, 如下:<br>HTTPS health monitors operate exactly like HTTP health monitors, but with ssl back-end servers. Unfortunately, this causes problems if the servers are performing client certificate validation, as HAProxy won’t have a valid cert. In this case, using TLS-HELLO type monitoring is an alternative.<br>TLS-HELLO health monitors simply ensure the back-end server responds to SSLv3 client hello messages. It will not check any other health metrics, like status code or body contents.<br><a href="https://review.openstack.org/#/c/475944/" target="_blank" rel="external">https://review.openstack.org/#/c/475944/</a></p>
<p>实际上客户并未使用客户端认证, 所以不是上面的原因, 应该是SNI所致. 因为后端有SNI认证, haproxy端需传入hostname, 但haproxy端无法传入hostname, 所以出错.<strong>但octavia-worker应该可以传SNI到后端</strong>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --cacert ca.crt https://10.5.150.5</span><br><span class="line">curl: (51) SSL: certificate subject name (www.server1.com) does not match target host name &apos;10.5.150.5&apos;</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server1.com:443:10.5.150.5 -k https://www.server1.com</span><br><span class="line">test1</span><br></pre></td></tr></table></figure></p>
<p>什么是SNI, 就是ssl server端可能会根据每个节点的hostname生成不同的cert, 并启用SNI. 这样ssl client访问ssl server端时也应该将hostname也传过去. (注: SNIProxy是一个适用于 HTTPS 和 HTTP 的类似于透明代理的反向代理工具。它可以在 TCP 层直接将流量在不解包的情况下转发出来，实现不需要在代理服务器配置证书就能反向代理 HTTPS 网站的功能)<br>‘curl -k’的方式测试无法很好的测试SNI, 最好是通过’openstack s_client’测试:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#Ideal Test to connect with SSLv3/No SNI</span><br><span class="line">openssl s_client -ssl3 -connect 103.245.215.4:443</span><br><span class="line">#openssl s_client -connect 192.168.254.214:9443 | openssl x509 -noout -text | grep DNS</span><br><span class="line">#We can also send SNI using -servername:</span><br><span class="line">openssl s_client -ssl3 -servername CERT_HOSTNAME -connect 103.245.215.4:443</span><br></pre></td></tr></table></figure></p>
<p>这个文档 (<a href="https://cbonte.github.io/haproxy-dconv/1.7/configuration.html#option%20ssl-hello-chk" target="_blank" rel="external">https://cbonte.github.io/haproxy-dconv/1.7/configuration.html#option%20ssl-hello-chk</a> )指出ssl-hello-chk只检查SSLv3不检查HTTP, 事实上, HTTPS health check也不检查HTTP只是多了个SSL negotiation. check-ssl check似乎能做更多.<br>LBaas v2模板目前只支持”httpchk”与”ssl-hello-chk”, 这只有SSL check, 没有HTTP check. 所以问题很可能是出在SSLv3 hello (without SNI)有问题.做个SNI相关的实验验证一下:<br>首先, charm应该将ca传给octavia, ocavia应该根据ca再去创建SNI证书, 并且传SNI证书到backend, octavia-worker的相关处理代码如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">    LOG.debug(&quot;request url %s&quot;, path)</span><br><span class="line">    _request = getattr(self.session, method.lower())</span><br><span class="line">    _url = self._base_url(amp.lb_network_ip) + path</span><br><span class="line">    LOG.debug(&quot;request url %s&quot;, _url)</span><br><span class="line">    reqargs = &#123;</span><br><span class="line">        &apos;verify&apos;: CONF.haproxy_amphora.server_ca,</span><br><span class="line">        &apos;url&apos;: _url,</span><br><span class="line">        &apos;timeout&apos;: (req_conn_timeout, req_read_timeout), &#125;</span><br><span class="line">    reqargs.update(kwargs)</span><br><span class="line">    headers = reqargs.setdefault(&apos;headers&apos;, &#123;&#125;)</span><br><span class="line">    headers[&apos;User-Agent&apos;] = OCTAVIA_API_CLIENT</span><br><span class="line">    self.ssl_adapter.uuid = amp.id</span><br><span class="line">    exception = None</span><br><span class="line">    # Keep retrying</span><br><span class="line"></span><br><span class="line">def get_create_amphora_flow(self):</span><br><span class="line">    &quot;&quot;&quot;Creates a flow to create an amphora.</span><br><span class="line"></span><br><span class="line">    :returns: The flow for creating the amphora</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    create_amphora_flow = linear_flow.Flow(constants.CREATE_AMPHORA_FLOW)</span><br><span class="line">    create_amphora_flow.add(database_tasks.CreateAmphoraInDB(</span><br><span class="line">                            provides=constants.AMPHORA_ID))</span><br><span class="line">    create_amphora_flow.add(lifecycle_tasks.AmphoraIDToErrorOnRevertTask(</span><br><span class="line">        requires=constants.AMPHORA_ID))</span><br><span class="line">    if self.REST_AMPHORA_DRIVER:</span><br><span class="line">        create_amphora_flow.add(cert_task.GenerateServerPEMTask(</span><br><span class="line"></span><br><span class="line">        create_amphora_flow.add(</span><br><span class="line">            database_tasks.UpdateAmphoraDBCertExpiration(</span><br><span class="line">                requires=(constants.AMPHORA_ID, constants.SERVER_PEM)))</span><br><span class="line"></span><br><span class="line">        create_amphora_flow.add(compute_tasks.CertComputeCreate(</span><br><span class="line">            requires=(constants.AMPHORA_ID, constants.SERVER_PEM,</span><br><span class="line">                      constants.BUILD_TYPE_PRIORITY, constants.FLAVOR),</span><br><span class="line">            provides=constants.COMPUTE_ID))</span><br></pre></td></tr></table></figure></p>
<p>1, 两个证书, 略. lb_tls_secret_1的hostname是www.server1.com, lb_tls_secret_2的hostname是www.server2.com<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">secret1_id=$(openstack secret list |grep lb_tls_secret_1 |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">secret2_id=$(openstack secret list |grep lb_tls_secret_2 |awk &apos;&#123;print $2&#125;&apos;)</span><br></pre></td></tr></table></figure></p>
<p>2, 创建listener时使用( –sni-container-refs $secret1_id $secret2_id )加入了两个域名的SNI<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">IP=192.168.21.7</span><br><span class="line">secret1_id=$(openstack secret list |grep lb_tls_secret_1 |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">secret2_id=$(openstack secret list |grep lb_tls_secret_2 |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">subnetid=$(openstack subnet show private_subnet -f value -c id); echo $subnetid</span><br><span class="line">lb_id=$(openstack loadbalancer show lb3 -f value -c id)</span><br><span class="line">#lb_id=$(openstack loadbalancer create --name test_tls_termination --vip-subnet-id $subnetid -f value -c id); echo $lb_id</span><br><span class="line">listener_id=$(openstack loadbalancer listener create $lb_id --name https_listener --protocol-port 443 --protocol TERMINATED_HTTPS --default-tls-container=$secret1_id --sni-container-refs $secret1_id $secret2_id -f value -c id); echo $listener_id</span><br><span class="line">pool_id=$(openstack loadbalancer pool create --protocol HTTP --listener $listener_id --lb-algorithm ROUND_ROBIN -f value -c id); echo $pool_id</span><br><span class="line">openstack loadbalancer member create --address $&#123;IP&#125; --subnet-id $subnetid --protocol-port 80 $pool_id</span><br><span class="line"></span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">vip=$(openstack loadbalancer show $lb_id -c vip_address -f value)</span><br><span class="line">vip_port=$(openstack port list --fixed-ip ip-address=$vip -c ID -f value)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address $vip --port $vip_port</span><br></pre></td></tr></table></figure></p>
<p>3, 测试, client传入www.server1.com或www.server2.com两个域名时, server端能正常响应, 但传入一个域名www.server3.com时就报了这个错:’does not match target host name ‘www.server3.com’’</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server1.com:443:10.5.150.5 --cacert ca.crt https://www.server1.com</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server2.com:443:10.5.150.5 --cacert ca.crt https://www.server2.com</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ curl --resolve www.server3.com:443:10.5.150.5 --cacert ca.crt https://www.server3.com</span><br><span class="line">curl: (51) SSL: certificate subject name (www.server1.com) does not match target host name &apos;www.server3.com&apos;</span><br></pre></td></tr></table></figure>
<p>为什么会这样呢?</p>
<p>LBaaS v2中的ssl check将在haproxy中添加下列配置, 实际上有ssl-hello-chk时httpchk将被覆盖(haproxy忽略的). haproxy 1.7开始添加了更高级的check-ssl(xenial使用haproxy 1.6, 不支持), 估计就是早期的lbaas为ssl check添加ssl-hello-chk的原因<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mode tcp</span><br><span class="line">option httpchk GET /</span><br><span class="line">http-check expect rstatus 303</span><br><span class="line">option ssl-hello-chk</span><br></pre></td></tr></table></figure></p>
<p>haproxy(<a href="http://cbonte.github.io/haproxy-dconv/1.6/configuration.html#4-option%20ssl-hello-chk)将为ssl-hello-chk伪造SSLv3包" target="_blank" rel="external">http://cbonte.github.io/haproxy-dconv/1.6/configuration.html#4-option%20ssl-hello-chk)将为ssl-hello-chk伪造SSLv3包</a>.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">When some SSL-based protocols are relayed in TCP mode through HAProxy, it is</span><br><span class="line">possible to test that the server correctly talks SSL instead of just testing</span><br><span class="line">that it accepts the TCP connection. When &quot;option ssl-hello-chk&quot; is set, pure</span><br><span class="line">SSLv3 client hello messages are sent once the connection is established to</span><br><span class="line">the server, and the response is analyzed to find an SSL server hello message.</span><br><span class="line">The server is considered valid only when the response contains this server</span><br><span class="line">hello message.</span><br><span class="line">All servers tested till there correctly reply to SSLv3 client hello messages,</span><br><span class="line">and most servers tested do not even log the requests containing only hello</span><br><span class="line">messages, which is appreciable.</span><br><span class="line">Note that this check works even when SSL support was not built into haproxy</span><br><span class="line">because it forges the SSL message. When SSL support is available, it is best</span><br><span class="line">to use native SSL health checks instead of this one.</span><br></pre></td></tr></table></figure></p>
<p>这是haproxy相关处理的源代码, 它没使用SSL libray, 先发硬编码的SSLv3 hello消息, 然后从response里找0x15 (SSL3_RT_ALERT) or 0x16 (SSL3_RT_HANDSHAKE), 若没找着就返回HCHK_STATUS_L6RSP(Layer6 invalid response) - <a href="https://github.com/haproxy/haproxy/blob/master/src/checks.c#L915" target="_blank" rel="external">https://github.com/haproxy/haproxy/blob/master/src/checks.c#L915</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">case PR_O2_SSL3_CHK:</span><br><span class="line">	if (!done &amp;&amp; b_data(&amp;check-&gt;bi) &lt; 5)</span><br><span class="line">		goto wait_more_data;</span><br><span class="line"></span><br><span class="line">	/* Check for SSLv3 alert or handshake */</span><br><span class="line">	if ((b_data(&amp;check-&gt;bi) &gt;= 5) &amp;&amp; (*b_head(&amp;check-&gt;bi) == 0x15 || *b_head(&amp;check-&gt;bi) == 0x16))</span><br><span class="line">		set_server_check_status(check, HCHK_STATUS_L6OK, NULL);</span><br><span class="line">	else</span><br><span class="line">		set_server_check_status(check, HCHK_STATUS_L6RSP, NULL);</span><br><span class="line">	break;</span><br></pre></td></tr></table></figure></p>
<p>错误’Layer6 invalid response’正是从客户日志中看到的:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Oct 25 04:50:34 neut002 haproxy[54990]: Server aaa0a533-073b-4b0f-8b81-777b6a8f3900/f2dc685f-58f7-4201-8060-3409d2d73a0d is DOWN, reason: Layer6 invalid response, check duration: 4ms. 0 active and 0 backup servers left. 0 sessions active, 0 requeued, 0 remaining in queue.</span><br></pre></td></tr></table></figure></p>
<p>所以backend ssl server端应该返回0x15, 客户究竟在haproxy之前运行什么ssl backend端, 我们不清楚. 假设它们运行的是apache2. 我们搭建一个测试环境, apache2采用默认的tls1.2, 而haproxy里还使用老的sslv3 hello时, apache2 ssl backend将返回下列的ssl协商错误:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openssl s_client -ssl3 -connect www.server1.com:443</span><br><span class="line">140306875094680:error:140A90C4:SSL routines:SSL_CTX_new:null ssl method passed:ssl_lib.c:1878:</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openssl s_client -ssl3 -servername www.server1.com -connect www.server1.com:443</span><br><span class="line">139626113296024:error:140A90C4:SSL routines:SSL_CTX_new:null ssl method passed:ssl_lib.c:1878:</span><br><span class="line">ubuntu@zhhuabj-bastion:~/ca3$ openssl s_client -ssl3 -servername www.server2.com -connect www.server1.com:443</span><br><span class="line">140564176807576:error:140A90C4:SSL routines:SSL_CTX_new:null ssl method passed:ssl_lib.c:1878:</span><br></pre></td></tr></table></figure></p>
<p>为什么ssl backend端不返回0x15或0x16呢, 理论上可能有以下几个原因<br>a, SSLv3现在已经被废弃了, 主流http server已经禁用了SSLv3支持, apach2收到haproxy过来的SSLv3 hello包时, apache2的SSL实现可能会响应别的消息而不是0x15/0x15<br>b, 因为haproxy过来的SSLv3 hello请求里没有SNI, 这样若启用了SNI的backend端(如apache2)就会ssl协商失败了, 这样也就未返回0x15/0x16<br>c, 其他原因<br>具体原因还需继续在backend抓包(tcpdump -eni ens3 -w ssl-test.pcap -s 0 port 443 or port 8443)确认.</p>
<p><strong>更新, 原因已找到:</strong><br>octavia/0会创建amphorae service vm, octavia/0上的/usr/lib/python3/dist-packages/octavia/amphorae/drivers/haproxy/rest_api_driver.py采用python requests模块去连接service vm上的9443端口. 这块代码类似下面这句所以不work:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl --cacert /etc/octavia/certs/issuing_ca.pem 192.168.254.31:9443</span><br></pre></td></tr></table></figure></p>
<p>改试下面的都work , 其中26835e25-7c4f-4776-940f-209eb9a9e826是SNI (loadbalance-id).<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">curl -k 192.168.254.31:9443</span><br><span class="line">openssl s_client -connect 192.168.254.31:9443 -key /etc/octavia/certs/issuing_ca_key.pem</span><br><span class="line">curl --cacert /etc/octavia/certs/issuing_ca.pem https://26835e25-7c4f-4776-940f-209eb9a9e826:9443 --resolve 26835e25-7c4f-4776-940f-209eb9a9e826:9443:192.168.254.31</span><br><span class="line"></span><br><span class="line">#ipv6</span><br><span class="line">#tlsv13 alert certificate required, it shows ssh client verfication is required</span><br><span class="line">curl -6 -k https://[fc00:ea96:ae23:2d4f:f816:3eff:fe76:d87a]:9443/</span><br><span class="line">#no alternative certificate subject name matches target host name, it shows it&apos;s about sni</span><br><span class="line">curl -6 --cacert /etc/octavia/certs/issuing_ca.pem https://[fc00:ea96:ae23:2d4f:f816:3eff:fe76:d87a]:9443/</span><br><span class="line">curl -6 --cacert /etc/octavia/certs/issuing_ca.pem --resolve backend1.domain:9443:[fc00:ea96:ae23:2d4f:f816:3eff:fe76:d87a] https://backend1.domain:9443 -v</span><br></pre></td></tr></table></figure></p>
<p>在octavia/0上测试:<br>openssl s_client -connect 192.168.254.31:9443 -key /etc/octavia/certs/issuing_ca_key.pem<br>最后的原因是, 创建证书时未指明CN=$DOMAIN1:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=$DOMAIN1&quot;</span><br><span class="line">openssl req -new -nodes -subj $SUBJECT -key $DOMAIN1.key -out $DOMAIN1.csr</span><br></pre></td></tr></table></figure>
<p>我们知道, python requests module中的assert_hostname用来往backend传递SNI, 见 - <a href="https://medium.com/@yzlin/python-requests-ssl-ip-binding-6df25a9a8f6a" target="_blank" rel="external">https://medium.com/@yzlin/python-requests-ssl-ip-binding-6df25a9a8f6a</a><br>而下列代码(<a href="https://github.com/openstack/octavia/blob/master/octavia/amphorae/drivers/haproxy/rest_api_driver.py#L542" target="_blank" rel="external">https://github.com/openstack/octavia/blob/master/octavia/amphorae/drivers/haproxy/rest_api_driver.py#L542</a>), 将传self.uuid(self.ssl_adapter.uuid = amp.id)到conn.asser_hostname.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class CustomHostNameCheckingAdapter(requests.adapters.HTTPAdapter):</span><br><span class="line">    def cert_verify(self, conn, url, verify, cert):</span><br><span class="line">        conn.assert_hostname = self.uuid</span><br><span class="line">        return super(CustomHostNameCheckingAdapter,</span><br><span class="line">                     self).cert_verify(conn, url, verify, cert)</span><br></pre></td></tr></table></figure></p>
<p>见设计文档: <a href="https://docs.openstack.org/octavia/ocata/specs/version0.5/tls-data-security.html" target="_blank" rel="external">https://docs.openstack.org/octavia/ocata/specs/version0.5/tls-data-security.html</a></p>
<h2 id="安装Octavia"><a href="#安装Octavia" class="headerlink" title="安装Octavia"></a>安装Octavia</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./generate-bundle.sh --name octavia --create-model --run --octavia -r stein --dvr-snat --num-compute 2   #can also use br-data:ens7 here</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens7&quot;</span><br><span class="line">./bin/add-data-ports.sh                      #it will add another NIC ens7 for every nova-compute nodes</span><br></pre></td></tr></table></figure>
<p>或者:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># https://blog.ubuntu.com/2019/01/28/taking-octavia-for-a-ride-with-kubernetes-on-openstack</span><br><span class="line">sudo snap install --classic charm</span><br><span class="line">charm pull cs:openstack-base</span><br><span class="line">cd openstack-base/</span><br><span class="line">curl https://raw.githubusercontent.com/openstack-charmers/openstack-bundles/master/stable/overlays/loadbalancer-octavia.yaml -o loadbalancer-octavia.yaml</span><br><span class="line">juju deploy ./bundle.yaml --overlay loadbalancer-octavia.yaml</span><br></pre></td></tr></table></figure></p>
<p>或者<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">sudo bash -c &apos;cat &gt;overlays/octavia.yaml&quot; &lt;&lt;EOF</span><br><span class="line">debug:                      &amp;debug                     True</span><br><span class="line">openstack_origin:           &amp;openstack_origin          cloud:bionic-rocky</span><br><span class="line">applications:</span><br><span class="line">  octavia:</span><br><span class="line">    #series: bionic</span><br><span class="line">    charm: cs:octavia</span><br><span class="line">    num_units: 1</span><br><span class="line">    constraints: mem=2G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">  octavia-dashboard:</span><br><span class="line">    charm: cs:octavia-dashboard</span><br><span class="line">relations:</span><br><span class="line">- - mysql:shared-db</span><br><span class="line">  - octavia:shared-db</span><br><span class="line">- - keystone:identity-service</span><br><span class="line">  - octavia:identity-service</span><br><span class="line">- - rabbitmq-server:amqp</span><br><span class="line">  - octavia:amqp</span><br><span class="line">- - neutron-api:neutron-load-balancer</span><br><span class="line">  - octavia:neutron-api</span><br><span class="line">- - neutron-openvswitch:neutron-plugin</span><br><span class="line">  - octavia:neutron-openvswitch</span><br><span class="line">- - openstack-dashboard:dashboard-plugin</span><br><span class="line">  - octavia-dashboard:dashboard</span><br><span class="line">EOF</span><br><span class="line">sudo bash -c &apos;cat &gt;overlays/octavia.yaml&quot; &lt;&lt;EOF</span><br><span class="line">debug:                      &amp;debug                     True</span><br><span class="line">verbose:                    &amp;verbose                   True</span><br><span class="line">openstack_origin:           &amp;openstack_origin</span><br><span class="line">applications:</span><br><span class="line">  barbican:</span><br><span class="line">    charm: cs:~openstack-charmers-next/barbican</span><br><span class="line">    num_units: 1</span><br><span class="line">    constraints: mem=1G</span><br><span class="line">    options:</span><br><span class="line">      debug: *debug</span><br><span class="line">      openstack-origin: *openstack_origin</span><br><span class="line">relations:</span><br><span class="line">  - [ barbican, rabbitmq-server ]</span><br><span class="line">  - [ barbican, mysql ]</span><br><span class="line">  - [ barbican, keystone ]</span><br><span class="line">EOF</span><br><span class="line">./generate-bundle.sh --series bionic --release rocky --barbican</span><br><span class="line">juju deploy ./b/openstack.yaml --overlay ./b/o/barbican.yaml --overlay overlays/octavia.yaml</span><br></pre></td></tr></table></figure></p>
<p>或者:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">juju add-model bionic-barbican-octavia</span><br><span class="line">./generate-bundle.sh --series bionic --barbican</span><br><span class="line">#./generate-bundle.sh --series bionic --release rocky --barbican</span><br><span class="line">juju deploy ./b/openstack.yaml --overlay ./b/o/barbican.yaml</span><br><span class="line">#https://github.com/openstack-charmers/openstack-bundles/blob/master/stable/overlays/loadbalancer-octavia.yaml</span><br><span class="line">#NOTE: need to comment to:lxd related lines from loadbalancer-octavia.yaml, and change nova-compute num to 3</span><br><span class="line">juju deploy ./b/openstack.yaml --overlay ./overlays/loadbalancer-octavia.yaml</span><br><span class="line"></span><br><span class="line"># Or we can:</span><br><span class="line"># 2018-12-25 03:30:39 DEBUG update-status fatal error: runtime: out of memory</span><br><span class="line">juju deploy octavia --config openstack-origin=cloud:bionic:queens --constraints mem=4G</span><br><span class="line">juju deploy octavia-dashboard</span><br><span class="line">juju add-relation octavia-dashboard openstack-dashboard</span><br><span class="line">juju add-relation octavia rabbitmq-server</span><br><span class="line">juju add-relation octavia mysql</span><br><span class="line">juju add-relation octavia keystone</span><br><span class="line">juju add-relation octavia neutron-openvswitch</span><br><span class="line">juju add-relation octavia neutron-api</span><br><span class="line"></span><br><span class="line"># Initialize and unseal vault</span><br><span class="line"># https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-vault.html</span><br><span class="line"># https://lingxiankong.github.io/2018-07-16-barbican-introduction.html</span><br><span class="line"># /snap/vault/1315/bin/vault server -config /var/snap/vault/common/vault.hcl</span><br><span class="line">sudo snap install vault</span><br><span class="line">export VAULT_ADDR=&quot;http://$(juju run --unit vault/0 unit-get private-address):8200&quot;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ vault operator init -key-shares=5 -key-threshold=3</span><br><span class="line">Unseal Key 1: UB7XDri5FRcMLirKBIysdUb2PN7Ia5EVMP0Z9wD9Hyll</span><br><span class="line">Unseal Key 2: mD8Gnr3hdB2LjjNB4ugxvvsvb8+EQQ/0AXm2p+c2qYFT</span><br><span class="line">Unseal Key 3: vymYLAdou3qky24IEKDufYsZXAIPLWtErAKy/RkfgghS</span><br><span class="line">Unseal Key 4: xOwDbqgNLLipsZbp+FAmVhBc3ZxA8CI3DchRc4AClRyQ</span><br><span class="line">Unseal Key 5: nRlZ8WX6CS9nOw2ct5U9o0Za5jlUAtjN/6XLxjf62CnR</span><br><span class="line">Initial Root Token: s.VJKGhNvIFCTgHVbQ6WvL0OLe</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vault operator unseal UB7XDri5FRcMLirKBIysdUb2PN7Ia5EVMP0Z9wD9Hyll</span><br><span class="line">vault operator unseal mD8Gnr3hdB2LjjNB4ugxvvsvb8+EQQ/0AXm2p+c2qYFT</span><br><span class="line">vault operator unseal vymYLAdou3qky24IEKDufYsZXAIPLWtErAKy/RkfgghS</span><br><span class="line">export VAULT_TOKEN=s.VJKGhNvIFCTgHVbQ6WvL0OLe</span><br><span class="line">vault token create -ttl=10m</span><br><span class="line">$ vault token create -ttl=10m</span><br><span class="line">Key                  Value</span><br><span class="line">---                  -----</span><br><span class="line">token                s.7ToXh9HqE6FiiJZybFhevL9v</span><br><span class="line">token_accessor       6dPkFpsPmx4D7g8yNJXvEpKN</span><br><span class="line">token_duration       10m</span><br><span class="line">token_renewable      true</span><br><span class="line">token_policies       [&quot;root&quot;]</span><br><span class="line">identity_policies    []</span><br><span class="line">policies             [&quot;root&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Authorize vault charm to use a root token to be able to create secrets storage back-ends and roles to allow other app to access vault</span><br><span class="line">juju run-action vault/0 authorize-charm token=s.7ToXh9HqE6FiiJZybFhevL9v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># upload Amphora image</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">http_proxy=http://squid.internal:3128 wget http://tarballs.openstack.org/octavia/test-images/test-only-amphora-x64-haproxy-ubuntu-xenial.qcow2</span><br><span class="line">#openstack image create --tag octavia-amphora --disk-format=qcow2 --container-format=bare --private amphora-haproxy-xenial --file ./test-only-amphora-x64-haproxy-ubuntu-xenial.qcow2</span><br><span class="line">glance image-create --tag octavia-amphora --disk-format qcow2 --name amphora-haproxy-xenial --file ./test-only-amphora-x64-haproxy-ubuntu-xenial.qcow2 --visibility public --container-format bare --progress</span><br><span class="line"></span><br><span class="line">cd stsstack-bundles/openstack/</span><br><span class="line">./configure</span><br><span class="line">./tools/sec_groups.sh</span><br><span class="line">./tools/instance_launch.sh 2 xenial</span><br><span class="line">neutron floatingip-create ext_net</span><br><span class="line">neutron floatingip-associate $(neutron floatingip-list |grep 10.5.150.4 |awk &apos;&#123;print $2&#125;&apos;) $(neutron port-list |grep &apos;192.168.21.3&apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">or</span><br><span class="line">fix_ip=192.168.21.3</span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address $fix_ip --port $(openstack port list --fixed-ip ip-address=$fix_ip -c id -f value)</span><br><span class="line"></span><br><span class="line">cd ~/ca  #https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-octavia.html</span><br><span class="line">juju config octavia \</span><br><span class="line">    lb-mgmt-issuing-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-private-key=&quot;$(base64 controller_ca_key.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-key-passphrase=foobar \</span><br><span class="line">    lb-mgmt-controller-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-controller-cert=&quot;$(base64 controller_cert_bundle.pem)&quot;</span><br><span class="line"></span><br><span class="line">注: 也遇到一个问题, 上述命令没有更新service vm里的cert, ssh登录service vm之后查看/etc/octavia/certs/目录发现证书不同. 证书不对, 会导致service vm里的amphora-agent在9443端口起不来. service vm是通过cloud-init来写的证书, 那错误出在哪个环节呢?</span><br></pre></td></tr></table></figure></p>
<p>配置资源:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># the code search &apos;configure_resources&apos;</span><br><span class="line">juju config octavia create-mgmt-network</span><br><span class="line">juju run-action --wait octavia/0 configure-resources</span><br><span class="line"></span><br><span class="line"># some deubg ways:</span><br><span class="line">openstack security group rule create $(openstack security group show lb-mgmt-sec-grp -f value -c id) --protocol udp --dst-port 546 --ethertype IPv6</span><br><span class="line">openstack security group rule create $(openstack security group show lb-mgmt-sec-grp -f value -c id) --protocol icmp --ethertype IPv6</span><br><span class="line">neutron security-group-rule-create --protocol icmpv6 --direction egress --ethertype IPv6 lb-mgmt-sec-grp</span><br><span class="line">neutron security-group-rule-create --protocol icmpv6 --direction ingress --ethertype IPv6 lb-mgmt-sec-grp</span><br><span class="line"></span><br><span class="line">neutron port-show octavia-health-manager-octavia-0-listen-port -f value -c status</span><br><span class="line">neutron port-update --admin-state-up True octavia-health-manager-octavia-0-listen-port</span><br><span class="line">AGENT=$(neutron l3-agent-list-hosting-router lb-mgmt -f value -c id)</span><br><span class="line">neutron l3-agent-router-remove $AGENT lb-mgmt</span><br><span class="line">neutron l3-agent-router-add $AGENT lb-mgmt</span><br></pre></td></tr></table></figure></p>
<p>上面configure-resources命令 (juju run-action –wait octavia/0 configure-resources)将会自动配置IPv6管理网段, 并且会配置一个binding:host在octavia/0节点上的名为octavia-health-manager-octavia-0-listen-port的port.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ neutron router-list |grep mgmt</span><br><span class="line">| 0a839377-6b19-419b-9868-616def4d749f | lb-mgmt         | null                                                                                                                                                                                    | False       | False |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ neutron net-list |grep mgmt</span><br><span class="line">| ae580dc8-31d6-4ec3-9d44-4a9c7b9e80b6 | lb-mgmt-net | ea9c7d5c-d224-4dd3-b40c-3acae9690657 fc00:4a9c:7b9e:80b6::/64 |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ neutron subnet-list |grep mgmt</span><br><span class="line">| ea9c7d5c-d224-4dd3-b40c-3acae9690657 | lb-mgmt-subnetv6 | fc00:4a9c:7b9e:80b6::/64 | &#123;&quot;start&quot;: &quot;fc00:4a9c:7b9e:80b6::2&quot;, &quot;end&quot;: &quot;fc00:4a9c:7b9e:80b6:ffff:ffff:ffff:ffff&quot;&#125; |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ neutron port-list |grep fc00</span><br><span class="line">| 5cb6e3f3-ebe5-4284-9c05-ea272e8e599b |                                                      | fa:16:3e:9e:82:6a | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6::1&quot;&#125;                  |</span><br><span class="line">| 983c56d2-46dd-416c-abc8-5096d76f75e2 | octavia-health-manager-octavia-0-listen-port         | fa:16:3e:99:8c:ab | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6:f816:3eff:fe99:8cab&quot;&#125; |</span><br><span class="line">| af38a60d-a370-4ddb-80ac-517fda175535 |                                                      | fa:16:3e:5f:cd:ae | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6:f816:3eff:fe5f:cdae&quot;&#125; |</span><br><span class="line">| b65f90d1-2e1f-4994-a0e9-2bb13ead4cab |                                                      | fa:16:3e:10:34:84 | &#123;&quot;subnet_id&quot;: &quot;ea9c7d5c-d224-4dd3-b40c-3acae9690657&quot;, &quot;ip_address&quot;: &quot;fc00:4a9c:7b9e:80b6:f816:3eff:fe10:3484&quot;&#125; |</span><br></pre></td></tr></table></figure></p>
<p>并且在octavia/0上会创建一个名为o-hm0的接口, 此接口的IP地址与octavia-health-manager-octavia-0-listen-port port同.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~$ juju ssh octavia/0 -- ip addr show o-hm0 |grep global</span><br><span class="line">Connection to 10.5.0.110 closed.</span><br><span class="line">    inet6 fc00:4a9c:7b9e:80b6:f816:3eff:fe99:8cab/64 scope global dynamic mngtmpaddr noprefixroute</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ juju ssh octavia/0 -- sudo ovs-vsctl show</span><br><span class="line">490bbb36-1c7d-412d-8b44-31e6f796306a</span><br><span class="line">    Manager &quot;ptcp:6640:127.0.0.1&quot;</span><br><span class="line">        is_connected: true</span><br><span class="line">    Bridge br-tun</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;gre-0a05006b&quot;</span><br><span class="line">            Interface &quot;gre-0a05006b&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.110&quot;, out_key=flow, remote_ip=&quot;10.5.0.107&quot;&#125;</span><br><span class="line">        Port br-tun</span><br><span class="line">            Interface br-tun</span><br><span class="line">                type: internal</span><br><span class="line">        Port patch-int</span><br><span class="line">            Interface patch-int</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-tun&#125;</span><br><span class="line">        Port &quot;gre-0a050016&quot;</span><br><span class="line">            Interface &quot;gre-0a050016&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.110&quot;, out_key=flow, remote_ip=&quot;10.5.0.22&quot;&#125;</span><br><span class="line">    Bridge br-data</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port phy-br-data</span><br><span class="line">            Interface phy-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=int-br-data&#125;</span><br><span class="line">        Port br-data</span><br><span class="line">            Interface br-data</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-int</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port patch-tun</span><br><span class="line">            Interface patch-tun</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-int&#125;</span><br><span class="line">        Port &quot;o-hm0&quot;</span><br><span class="line">            tag: 1</span><br><span class="line">            Interface &quot;o-hm0&quot;</span><br><span class="line">                type: internal</span><br><span class="line">        Port br-int</span><br><span class="line">            Interface br-int</span><br><span class="line">                type: internal</span><br><span class="line">        Port int-br-data</span><br><span class="line">            Interface int-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=phy-br-data&#125;</span><br><span class="line">    Bridge br-ex</span><br><span class="line">        Port br-ex</span><br><span class="line">            Interface br-ex</span><br><span class="line">                type: internal</span><br><span class="line">    ovs_version: &quot;2.10.0&quot;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ juju ssh neutron-gateway/0 -- sudo ovs-vsctl show</span><br><span class="line">ec3e2cb6-5261-4c22-8afd-5bacb0e8ce85</span><br><span class="line">    Manager &quot;ptcp:6640:127.0.0.1&quot;</span><br><span class="line">        is_connected: true</span><br><span class="line">    Bridge br-ex</span><br><span class="line">        Port br-ex</span><br><span class="line">            Interface br-ex</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-int</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;tap62c03d3b-b1&quot;</span><br><span class="line">            tag: 2</span><br><span class="line">            Interface &quot;tap62c03d3b-b1&quot;</span><br><span class="line">        Port &quot;tapb65f90d1-2e&quot;</span><br><span class="line">            tag: 3</span><br><span class="line">            Interface &quot;tapb65f90d1-2e&quot;</span><br><span class="line">        Port int-br-data</span><br><span class="line">            Interface int-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=phy-br-data&#125;</span><br><span class="line">        Port patch-tun</span><br><span class="line">            Interface patch-tun</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-int&#125;</span><br><span class="line">        Port &quot;tap6f1478be-b1&quot;</span><br><span class="line">            tag: 1</span><br><span class="line">            Interface &quot;tap6f1478be-b1&quot;</span><br><span class="line">        Port &quot;tap01efd82b-53&quot;</span><br><span class="line">            tag: 2</span><br><span class="line">            Interface &quot;tap01efd82b-53&quot;</span><br><span class="line">        Port &quot;tap5cb6e3f3-eb&quot;</span><br><span class="line">            tag: 3</span><br><span class="line">            Interface &quot;tap5cb6e3f3-eb&quot;</span><br><span class="line">        Port br-int</span><br><span class="line">            Interface br-int</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-data</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port &quot;ens7&quot;</span><br><span class="line">            Interface &quot;ens7&quot;</span><br><span class="line">        Port br-data</span><br><span class="line">            Interface br-data</span><br><span class="line">                type: internal</span><br><span class="line">        Port phy-br-data</span><br><span class="line">            Interface phy-br-data</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=int-br-data&#125;</span><br><span class="line">    Bridge br-tun</span><br><span class="line">        Controller &quot;tcp:127.0.0.1:6633&quot;</span><br><span class="line">            is_connected: true</span><br><span class="line">        fail_mode: secure</span><br><span class="line">        Port patch-int</span><br><span class="line">            Interface patch-int</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-tun&#125;</span><br><span class="line">        Port &quot;gre-0a05007a&quot;</span><br><span class="line">            Interface &quot;gre-0a05007a&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.122&quot;&#125;</span><br><span class="line">        Port &quot;gre-0a05006b&quot;</span><br><span class="line">            Interface &quot;gre-0a05006b&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.107&quot;&#125;</span><br><span class="line">        Port br-tun</span><br><span class="line">            Interface br-tun</span><br><span class="line">                type: internal</span><br><span class="line">        Port &quot;gre-0a050079&quot;</span><br><span class="line">            Interface &quot;gre-0a050079&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.121&quot;&#125;</span><br><span class="line">        Port &quot;gre-0a05006e&quot;</span><br><span class="line">            Interface &quot;gre-0a05006e&quot;</span><br><span class="line">                type: gre</span><br><span class="line">                options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.5.0.22&quot;, out_key=flow, remote_ip=&quot;10.5.0.110&quot;&#125;</span><br><span class="line">    ovs_version: &quot;2.10.0&quot;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ juju ssh neutron-gateway/0 -- cat /var/lib/neutron/ra/0a839377-6b19-419b-9868-616def4d749f.radvd.conf</span><br><span class="line">interface qr-5cb6e3f3-eb</span><br><span class="line">&#123;</span><br><span class="line">   AdvSendAdvert on;</span><br><span class="line">   MinRtrAdvInterval 30;</span><br><span class="line">   MaxRtrAdvInterval 100;</span><br><span class="line">   AdvLinkMTU 1458;</span><br><span class="line">   prefix fc00:4a9c:7b9e:80b6::/64</span><br><span class="line">   &#123;</span><br><span class="line">        AdvOnLink on;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">   &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-health-mgr-sec-grp</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| 09a92cb2-9942-44d4-8a96-9449a6758967 | None        | None     |            | None                  |</span><br><span class="line">| 20daa06c-9de6-4c91-8a1e-59645f23953a | udp         | None     | 5555:5555  | None                  |</span><br><span class="line">| 8f7b9966-c255-4727-a172-60f22f0710f9 | None        | None     |            | None                  |</span><br><span class="line">| 90f86b27-12f8-4a9a-9924-37b31d26cbd8 | icmpv6      | None     |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-mgmt-sec-grp</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| 54f79f92-a6c5-411d-a309-a02b39cc384b | icmpv6      | None     |            | None                  |</span><br><span class="line">| 574f595e-3d96-460e-a3f2-329818186492 | None        | None     |            | None                  |</span><br><span class="line">| 5ecb0f58-f5dd-4d52-bdfa-04fd56968bd8 | tcp         | None     | 22:22      | None                  |</span><br><span class="line">| 7ead3a3a-bc45-4434-b7a2-e2a6c0dc3ce9 | None        | None     |            | None                  |</span><br><span class="line">| cf82d108-e0f8-4916-95d4-0c816b6eb156 | tcp         | None     | 9443:9443  | None                  |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ source ~/novarc</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list default</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+--------------------------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range  | Port Range | Remote Security Group                |</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+--------------------------------------+</span><br><span class="line">| 15b56abd-c2af-4c0a-8585-af68a8f09e3c | icmpv6      | None      |            | None                                 |</span><br><span class="line">| 2ad77fa3-32c7-4a20-a572-417bea782eff | icmp        | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">| 2c2aec15-e4ad-4069-abd2-0191fe80f9bb | None        | None      |            | None                                 |</span><br><span class="line">| 3b775807-3c61-45a3-9677-aaf9631db677 | udp         | 0.0.0.0/0 | 3389:3389  | None                                 |</span><br><span class="line">| 3e9a6e7f-b9a2-47c9-97ca-042b22fbf308 | icmpv6      | None      |            | None                                 |</span><br><span class="line">| 42a3c09e-91c8-471d-b4a8-c1fe87dab066 | None        | None      |            | None                                 |</span><br><span class="line">| 47f9cec2-4bc0-4d71-9a02-3a27d46b59f8 | icmp        | None      |            | None                                 |</span><br><span class="line">| 94297175-9439-4df2-8c93-c5576e52e138 | udp         | None      | 546:546    | None                                 |</span><br><span class="line">| 9c6ac9d2-3b9e-4bab-a55a-04a1679b66be | None        | None      |            | c48a1bf5-7b7e-4337-afdf-8057ae8025af |</span><br><span class="line">| b6e95f76-1b64-4135-8b62-b058ec989f7e | None        | None      |            | c48a1bf5-7b7e-4337-afdf-8057ae8025af |</span><br><span class="line">| de5132a5-72e2-4f03-8b6a-dcbc2b7811c3 | tcp         | 0.0.0.0/0 | 3389:3389  | None                                 |</span><br><span class="line">| e72bea9f-84ce-4e3a-8597-c86d40b9b5ef | tcp         | 0.0.0.0/0 | 22:22      | None                                 |</span><br><span class="line">| ecf1415c-c6e9-4cf6-872c-4dac1353c014 | tcp         | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+--------------------------------------+</span><br></pre></td></tr></table></figure></p>
<p>底层OpenStack环境(OpenStack Over Openstack)需要做 (见: <a href="https://blog.csdn.net/quqi99/article/details/78437988" target="_blank" rel="external">https://blog.csdn.net/quqi99/article/details/78437988</a> ):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openstack security group rule create $secgroup --protocol udp --dst-port 546 --ethertype IPv6</span><br></pre></td></tr></table></figure></p>
<p>最容易出现的问题是health-manager-octavia-0-listen-port port为DOWN, 从而o-hm0网络不通而无法从dhcp server处获得IP, 网段不通多半是br-int上的flow rules的问题, 我多次遇到这种情况, 但后来重建环境不知为什么又好了.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-11:~# ovs-ofctl dump-flows br-int</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.932s, table=0, n_packets=978, n_bytes=76284, priority=10,icmp6,in_port=&quot;o-hm0&quot;,icmp_type=136 actions=resubmit(,24)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.930s, table=0, n_packets=0, n_bytes=0, priority=10,arp,in_port=&quot;o-hm0&quot; actions=resubmit(,24)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.219s, table=0, n_packets=0, n_bytes=0, priority=2,in_port=&quot;int-br-data&quot; actions=drop</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.943s, table=0, n_packets=10939, n_bytes=2958167, priority=9,in_port=&quot;o-hm0&quot; actions=resubmit(,25)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.898s, table=0, n_packets=10032, n_bytes=1608826, priority=0 actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.903s, table=23, n_packets=0, n_bytes=0, priority=0 actions=drop</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.940s, table=24, n_packets=675, n_bytes=52650, priority=2,icmp6,in_port=&quot;o-hm0&quot;,icmp_type=136,nd_target=fc00:4a9c:7b9e:80b6:f816:3eff:fe99:8cab actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.938s, table=24, n_packets=0, n_bytes=0, priority=2,icmp6,in_port=&quot;o-hm0&quot;,icmp_type=136,nd_target=fe80::f816:3eff:fe99:8cab actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.879s, table=24, n_packets=303, n_bytes=23634, priority=0 actions=drop</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=424018.951s, table=25, n_packets=10939, n_bytes=2958167, priority=2,in_port=&quot;o-hm0&quot;,dl_src=fa:16:3e:99:8c:ab actions=resubmit(,60)</span><br><span class="line"> cookie=0x5dc634635bd398eb, duration=425788.896s, table=60, n_packets=21647, n_bytes=4620009, priority=3 actions=NORMAL</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-11:~# ovs-ofctl dump-flows br-data</span><br><span class="line"> cookie=0xb41c0c7781ded568, duration=426779.130s, table=0, n_packets=16816, n_bytes=3580386, priority=2,in_port=&quot;phy-br-data&quot; actions=drop</span><br><span class="line"> cookie=0xb41c0c7781ded568, duration=426779.201s, table=0, n_packets=0, n_bytes=0, priority=0 actions=NORMAL</span><br></pre></td></tr></table></figure></p>
<p>如果o-hm0总是无法获得IP, 我们也可以手工配置一个IPv4管理网段试试.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">neutron router-gateway-clear lb-mgmt</span><br><span class="line">neutron router-interface-delete lb-mgmt lb-mgmt-subnetv6</span><br><span class="line">neutron subnet-delete lb-mgmt-subnetv6</span><br><span class="line">neutron port-list |grep fc00</span><br><span class="line">#neutron port-delete 464e6d47-9830-4966-a2b7-e188c19c407a</span><br><span class="line">openstack subnet create --subnet-range 192.168.0.0/24 --allocation-pool start=192.168.0.2,end=192.168.0.200 --network lb-mgmt-net lb-mgmt-subnet</span><br><span class="line">neutron router-interface-add lb-mgmt lb-mgmt-subnet</span><br><span class="line">#neutron router-gateway-set lb-mgmt ext_net</span><br><span class="line">neutron port-list |grep 192.168.0.1</span><br><span class="line"></span><br><span class="line">#openstack security group create lb-mgmt-sec-grp --project $(openstack security group show lb-mgmt-sec-grp -f value -c project_id)</span><br><span class="line">openstack security group rule create --protocol udp --dst-port 5555 lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol tcp --dst-port 22 lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol tcp --dst-port 9443 lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol icmp lb-mgmt-sec-grp</span><br><span class="line">openstack security group show lb-mgmt-sec-grp</span><br><span class="line">openstack security group rule create --protocol udp --dst-port 5555 lb-health-mgr-sec-grp</span><br><span class="line">openstack security group rule create --protocol icmp lb-health-mgr-sec-grp</span><br><span class="line"></span><br><span class="line"># create a management port o-hm0 on octavia/0 node, first use neutron to allocate a port, then call ovs-vsctl to add-port</span><br><span class="line">LB_HOST=$(juju ssh octavia/0 -- hostname)</span><br><span class="line">juju ssh octavia/0 -- sudo ovs-vsctl del-port br-int o-hm0</span><br><span class="line"># Use LB_HOST to replace juju-70ea4e-bionic-barbican-octavia-11, don&apos;t know why it said &apos;bind failed&apos; when using $LB_HOST directly</span><br><span class="line">neutron port-create --name mgmt-port --security-group $(openstack security group show lb-health-mgr-sec-grp -f value -c id) --device-owner Octavia:health-mgr --binding:host_id=juju-acadb9-bionic-rocky-barbican-octavia-without-vault-9 lb-mgmt-net --tenant-id $(openstack security group show lb-health-mgr-sec-grp -f value -c project_id)</span><br><span class="line"></span><br><span class="line">juju ssh octavia/0 -- sudo ovs-vsctl --may-exist add-port br-int o-hm0 -- set Interface o-hm0 type=internal -- set Interface o-hm0 external-ids:iface-status=active -- set Interface o-hm0 external-ids:attached-mac=$(neutron port-show mgmt-port -f value -c mac_address) -- set Interface o-hm0 external-ids:iface-id=$(neutron port-show mgmt-port -f value -c id)</span><br><span class="line">juju ssh octavia/0 -- sudo ip link set dev o-hm0 address $(neutron port-show mgmt-port -f value -c mac_address)</span><br><span class="line">ping 192.168.0.2</span><br></pre></td></tr></table></figure></p>
<h2 id="测试虚机中安装HTTPS测试服务"><a href="#测试虚机中安装HTTPS测试服务" class="headerlink" title="测试虚机中安装HTTPS测试服务"></a>测试虚机中安装HTTPS测试服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># Prepare CA and ssl pairs for lb server</span><br><span class="line">openssl genrsa -passout pass:password -out ca.key</span><br><span class="line">openssl req -x509 -passin pass:password -new -nodes -key ca.key -days 3650 -out ca.crt -subj &quot;/C=CN/ST=BJ/O=STS&quot;</span><br><span class="line">openssl genrsa -passout pass:password -out lb.key</span><br><span class="line">openssl req -new -key lb.key -out lb.csr -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl x509 -req -in lb.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out lb.crt -days 3650</span><br><span class="line">cat lb.crt lb.key &gt; lb.pem</span><br><span class="line">#openssl pkcs12 -export -inkey lb.key -in lb.crt -certfile ca.crt -passout pass:password -out lb.p12</span><br><span class="line"></span><br><span class="line"># Create two test servers and run</span><br><span class="line">sudo apt install python-minimal -y</span><br><span class="line">sudo bash -c &apos;cat &gt;simple-https-server.py&apos; &lt;&lt;EOF</span><br><span class="line">#!/usr/bin/env python</span><br><span class="line"># coding=utf-8</span><br><span class="line">import BaseHTTPServer, SimpleHTTPServer</span><br><span class="line">import ssl</span><br><span class="line">httpd = BaseHTTPServer.HTTPServer((&apos;0.0.0.0&apos;, 443), SimpleHTTPServer.SimpleHTTPRequestHandler)</span><br><span class="line">httpd.socket = ssl.wrap_socket (httpd.socket, certfile=&apos;./lb.pem&apos;, server_side=True)</span><br><span class="line">httpd.serve_forever()</span><br><span class="line">EOF</span><br><span class="line">sudo bash -c &apos;cat &gt;index.html&apos; &lt;&lt;EOF</span><br><span class="line">test1</span><br><span class="line">EOF</span><br><span class="line">nohup sudo python simple-https-server.py &amp;</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl -k https://10.5.150.4</span><br><span class="line">test1</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl -k https://10.5.150.5</span><br><span class="line">test2</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl --cacert ~/ca/ca.crt https://10.5.150.4</span><br><span class="line">curl: (51) SSL: certificate subject name (www.quqi.com) does not match target host name &apos;10.5.150.4&apos;</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl --resolve www.quqi.com:443:10.5.150.4 --cacert ~/ca/ca.crt https://www.quqi.com</span><br><span class="line">test1</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ curl --resolve www.quqi.com:443:10.5.150.4 -k https://www.quqi.com</span><br><span class="line">test1</span><br></pre></td></tr></table></figure>
<p>20191109更新, 上面的方法使用–cacert时并不work, 改成下列方法works<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">openssl req -new -x509 -keyout lb.pem -out lb.pem -days 365 -nodes -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">$ curl --resolve www.quqi.com:443:192.168.99.135 --cacert ./lb.pem https://www.quqi.com</span><br><span class="line">test1</span><br></pre></td></tr></table></figure></p>
<p>经进一步调试, 原来是因为 这一句”curl –resolve www.quqi.com:443:10.5.150.4 –cacert ~/ca/ca.crt <a href="https://www.quqi.com&quot;应该是&quot;curl" target="_blank" rel="external">https://www.quqi.com&quot;应该是&quot;curl</a> –resolve www.quqi.com:443:10.5.150.4 –cacert ~/ca/lb.pem <a href="https://www.quqi.com" target="_blank" rel="external">https://www.quqi.com</a>“</p>
<p>或者使用apache2安装ssl<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/apache2/sites-available/default-ssl.conf</span><br><span class="line">  ServerName server1.com</span><br><span class="line">  ServerAlias www.server1.com</span><br><span class="line">  SSLCertificateFile      /home/ubuntu/www.server1.com.crt</span><br><span class="line">  SSLCertificateKeyFile /home/ubuntu/www.server1.com.key</span><br><span class="line"></span><br><span class="line">vim /etc/apache2/sites-available/000-default.conf</span><br><span class="line">  ServerName server1.com</span><br><span class="line">  ServerAlias www.server1.com</span><br><span class="line"></span><br><span class="line">sudo apachectl configtest</span><br><span class="line">sudo a2enmod ssl</span><br><span class="line">sudo a2ensite default-ssl</span><br><span class="line">sudo systemctl restart apache2.service</span><br></pre></td></tr></table></figure></p>
<h2 id="测试虚机中安装HTTP测试服务"><a href="#测试虚机中安装HTTP测试服务" class="headerlink" title="测试虚机中安装HTTP测试服务"></a>测试虚机中安装HTTP测试服务</h2><p>下面的这种HTTP测试服务实际上有问题, 会导致haproxy对backend作check时报下列错误.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ae847e94-5aeb-4da6-9b66-07e1a385465b is UP, reason: Layer7 check passed, code: 200, info: &quot;HTTP status check returned code &lt;3C&gt;200&lt;3E&gt;&quot;, check duration: 7ms. 1 active and 0 backup servers online. 0 sessions requeued, 0 total in queue.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1, deploy http server in backend</span><br><span class="line">MYIP=$(ifconfig ens2|grep &apos;inet addr&apos;|awk -F: &apos;&#123;print $2&#125;&apos;| awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">while true; do echo -e &quot;HTTP/1.0 200 OK\r\n\r\nWelcome to $MYIP&quot; | sudo nc -l -p 80 ; done</span><br><span class="line">2, test it</span><br><span class="line">sudo ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b curl http://192.168.21.7:80</span><br><span class="line">3, add it into haproxy</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.7 --protocol-port 80 pool1</span><br></pre></td></tr></table></figure>
<p>并且还会导致在作haproxy vip作curl测试时返回Bad Gateway的错误.<br>所以最后在backend上运行”sudo python -m SimpleHTTPServer 80”之后解决.</p>
<h2 id="How-to-ssh-into-amphora-service-vm"><a href="#How-to-ssh-into-amphora-service-vm" class="headerlink" title="How to ssh into amphora service vm"></a>How to ssh into amphora service vm</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># NOTE： (base64 -w 0 $HOME/.ssh/id_amphora.pub)</span><br><span class="line">sudo mkdir -p /etc/octavia/.ssh &amp;&amp; sudo chown -R $(id -u):$(id -g) /etc/octavia/.ssh</span><br><span class="line">ssh-keygen -b 2048 -t rsa -N &quot;&quot; -f /etc/octavia/.ssh/octavia_ssh_key</span><br><span class="line">openstack user list --domain service_domain</span><br><span class="line"># NOTE: we must add &apos;--user&apos; option to avoid the error &apos;Invalid key_name provided&apos;</span><br><span class="line">nova keypair-add --pub-key=/etc/octavia/.ssh/octavia_ssh_key.pub octavia_ssh_key --user $(openstack user show octavia --domain service_domain -f value -c id)</span><br><span class="line"># openstack cli doesn&apos;t support to list user scope keypairs</span><br><span class="line">nova keypair-list --user $(openstack user show octavia --domain service_domain -f value -c id)</span><br><span class="line"></span><br><span class="line">vim /etc/octavia/octavia.conf</span><br><span class="line">vim /var/lib/juju/agents/unit-octavia-0/charm/templates/rocky/octavia.conf</span><br><span class="line">vim /usr/lib/python3/dist-packages/octavia/compute/drivers/nova_driver.py</span><br><span class="line">vim /usr/lib/python3/dist-packages/octavia/controller/worker/tasks/compute_tasks.py  #import pdb;pdb.set_trace()</span><br><span class="line">[controller_worker]</span><br><span class="line">amp_ssh_key_name = octavia_ssh_key   #for sts, name is called amphora-backdoor</span><br><span class="line">sudo ip netns exec qrouter-0a839377-6b19-419b-9868-616def4d749f ssh -6 -i</span><br><span class="line">~/octavia_ssh_key ubuntu@fc00:4a9c:7b9e:80b6:f816:3eff:fe5f:cdae</span><br><span class="line"></span><br><span class="line">NOTE:</span><br><span class="line">we can&apos;t ssh by: ssh -i /etc/octavia/octavia_ssh_key ubuntu@10.5.150.15</span><br><span class="line">but we can ssh by:</span><br><span class="line">sudo ip netns exec qrouter-0a839377-6b19-419b-9868-616def4d749f ssh -i ~/octavia_ssh_key ubuntu@192.168.0.12 -v</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ nova list --all</span><br><span class="line">+--------------------------------------+----------------------------------------------+----------------------------------+--------+------------+-------------+-------------------------------------------------------------+</span><br><span class="line">| ID                                   | Name                                         | Tenant ID                        | Status | Task State | Power State | Networks                                                    |</span><br><span class="line">+--------------------------------------+----------------------------------------------+----------------------------------+--------+------------+-------------+-------------------------------------------------------------+</span><br><span class="line">| 1f50fa16-bbbe-47a7-b66b-86de416d0c5e | amphora-2fae038f-08b5-4bce-a2b7-f7bd543c0314 | 5165bc7f79304f67a135fcde3cd78ae1 | ACTIVE | -          | Running     | lb-mgmt-net=192.168.0.12; private=192.168.21.6, 10.5.150.15 |</span><br><span class="line"></span><br><span class="line">openstack security group rule create lb-300e5ee7-2793-4df3-b901-17ce76da0b09 --protocol icmp --remote-ip 0.0.0.0/0</span><br><span class="line">openstack security group rule create lb-300e5ee7-2793-4df3-b901-17ce76da0b09 --protocol tcp --dst-port 22</span><br></pre></td></tr></table></figure>
<h2 id="Deploy-a-non-terminated-HTTPS-load-balancer"><a href="#Deploy-a-non-terminated-HTTPS-load-balancer" class="headerlink" title="Deploy a non-terminated HTTPS load balancer"></a>Deploy a non-terminated HTTPS load balancer</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python-octaviaclient python3-octaviaclient</span><br><span class="line">openstack complete |sudo tee /etc/bash_completion.d/openstack</span><br><span class="line">source &lt;(openstack complete)</span><br><span class="line">#No module named &apos;oslo_log&apos;</span><br><span class="line">openstack loadbalancer create --name lb1 --vip-subnet-id private_subnet</span><br><span class="line">#lb_vip_port_id=$(openstack loadbalancer create -f value -c vip_port_id --name lb1 --vip-subnet-id private_subnet)</span><br><span class="line"># Re-run the following until lb1 shows ACTIVE and ONLINE statuses:</span><br><span class="line">openstack loadbalancer show lb1</span><br><span class="line">nova list --all</span><br><span class="line">openstack loadbalancer listener create --name listener1 --protocol HTTPS --protocol-port 443 lb1</span><br><span class="line">openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTPS</span><br><span class="line">#openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTPS --url-path / pool1</span><br><span class="line">openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type TLS-HELLO pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.10 --protocol-port 443 pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.12 --protocol-port 443 pool1</span><br><span class="line">openstack loadbalancer member list pool1</span><br><span class="line"></span><br><span class="line">root@amphora-a9cf0b97-7f30-4b9c-b16a-7bc54526e0d0:~# ps -ef |grep haproxy</span><br><span class="line">root      1459     1  0 04:34 ?        00:00:00 /usr/sbin/haproxy-systemd-wrapper -f /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.pid -L UlKGE8M_cxJTcktjV8M-eKJkh-g</span><br><span class="line">nobody    1677  1459  0 04:35 ?        00:00:00 /usr/sbin/haproxy -f /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.pid -L UlKGE8M_cxJTcktjV8M-eKJkh-g -Ds -sf 1625</span><br><span class="line">nobody    1679  1677  0 04:35 ?        00:00:00 /usr/sbin/haproxy -f /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.pid -L UlKGE8M_cxJTcktjV8M-eKJkh-g -Ds -sf 1625</span><br><span class="line">root      1701  1685  0 04:36 pts/0    00:00:00 grep --color=auto haproxy</span><br><span class="line">root@amphora-a9cf0b97-7f30-4b9c-b16a-7bc54526e0d0:~#</span><br><span class="line">root@amphora-a9cf0b97-7f30-4b9c-b16a-7bc54526e0d0:~# cat /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer eda3efa5-dd91-437c-81d9-b73d28b5312f</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/b9d5a192-1a6a-4df7-83d4-fe96ac9574c0.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">frontend b9d5a192-1a6a-4df7-83d4-fe96ac9574c0</span><br><span class="line">    option tcplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    bind 192.168.21.16:443</span><br><span class="line">    mode tcp</span><br><span class="line">    default_backend 502b6689-40ad-4201-b704-f221e0fddd58</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend 502b6689-40ad-4201-b704-f221e0fddd58</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option ssl-hello-chk</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 49f16402-69f4-49bb-8dc0-5ec13a0f1791 192.168.21.10:443 weight 1 check inter 5s fall 3 rise 4</span><br><span class="line">    server 1ab624e1-9cd8-49f3-9297-4fa031a3ca58 192.168.21.12:443 weight 1 check inter 5s fall 3 rise 4</span><br></pre></td></tr></table></figure>
<p>有时候service vm已经创建好, 但octavia-worker因为下列原因退出导致”openstack loadbalancer create –name lb1 –vip-subnet-id private_subnet”这步执行后状态总不对.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2019-01-04 06:30:45.574 8173 INFO cotyledon._service [-] Caught SIGTERM signal, graceful exiting of service ConsumerService(0) [8173]</span><br><span class="line">2019-01-04 06:30:45.573 7983 INFO cotyledon._service_manager [-] Caught SIGTERM signal, graceful exiting of master process</span><br><span class="line">2019-01-04 06:30:45.581 8173 INFO octavia.controller.queue.consumer [-] Stopping consumer...</span><br><span class="line">2019-01-04 06:30:45.593 8173 INFO cotyledon._service [-] Caught SIGTERM signal, graceful exiting of service ConsumerService(0) [8173]</span><br></pre></td></tr></table></figure>
<h2 id="Deploy-a-TLS-terminated-HTTPS-load-balancer"><a href="#Deploy-a-TLS-terminated-HTTPS-load-balancer" class="headerlink" title="Deploy a TLS-terminated HTTPS load balancer"></a>Deploy a TLS-terminated HTTPS load balancer</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 确实不能加密码：　https://opendev.org/openstack/octavia/commit/a501714a76e04b33dfb24c4ead9956ed4696d1df</span><br><span class="line">openssl genrsa -passout pass:password -out ca.key</span><br><span class="line">openssl req -x509 -passin pass:password -new -nodes -key ca.key -days 3650 -out ca.crt -subj &quot;/C=CN/ST=BJ/O=STS&quot;</span><br><span class="line">openssl genrsa -passout pass:password -out lb.key</span><br><span class="line">openssl req -new -key lb.key -out lb.csr -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl x509 -req -in lb.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out lb.crt -days 3650</span><br><span class="line">cat lb.crt lb.key &gt; lb.pem</span><br><span class="line">openssl pkcs12 -export -inkey lb.key -in lb.crt -certfile ca.crt -passout pass:password -out lb.p12</span><br><span class="line"></span><br><span class="line">sudo apt install python-barbicanclient</span><br><span class="line">#openstack secret delete $(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;)</span><br><span class="line">openstack secret store --name=&apos;tls_lb_secret&apos; -t &apos;application/octet-stream&apos; -e &apos;base64&apos; --payload=&quot;$(base64 &lt; lb.p12)&quot;</span><br><span class="line">openstack acl user add -u $(openstack user show octavia --domain service_domain -f value -c id) $(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;)</span><br><span class="line">openstack secret list</span><br><span class="line">openstack loadbalancer create --name lb1 --vip-subnet-id private_subnet</span><br><span class="line"># Re-run the following until lb1 shows ACTIVE and ONLINE statuses:</span><br><span class="line">openstack loadbalancer show lb1</span><br><span class="line"></span><br><span class="line">openstack loadbalancer member list pool1</span><br><span class="line">openstack loadbalancer member delete pool1 &lt;member&gt;</span><br><span class="line">openstack loadbalancer pool delete pool1</span><br><span class="line">openstack loadbalancer listener delete listener1</span><br><span class="line">openstack loadbalancer listener create --protocol-port 443 --protocol TERMINATED_HTTPS --name listener1 --default-tls-container=$(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;) lb1</span><br><span class="line">openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTP</span><br><span class="line">openstack loadbalancer healthmonitor create --delay 5 --max-retries 4 --timeout 10 --type HTTP --url-path / pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.10 --protocol-port 80 pool1</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address 192.168.21.12 --protocol-port 80 pool1</span><br></pre></td></tr></table></figure>
<p>但是出错了:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~/ca⟫ openstack loadbalancer listener create --protocol-port 443 --protocol TERMINATED_HTTPS --name listener1 --default-tls-container=$(openstack secret list | awk &apos;/ tls_lb_secret / &#123;print $2&#125;&apos;) lb1</span><br><span class="line">Could not retrieve certificate: [&apos;http://10.5.0.25:9312/v1/secrets/7c706fb2-4319-46fc-b78d-81f34393f581&apos;] (HTTP 400) (Request-ID: req-c0c0e4d5-f395-424c-9aab-5c4c4e72fb3d)</span><br></pre></td></tr></table></figure>
<p>出错的原因找到, 是创建密钥时不能加密码:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out ca.key</span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -days 3650 -out ca.crt -subj &quot;/C=CN/ST=BJ/O=STS&quot;</span><br><span class="line">openssl genrsa -out lb.key</span><br><span class="line">openssl req -new -key lb.key -out lb.csr -subj &quot;/C=CN/ST=BJ/O=STS/CN=www.quqi.com&quot;</span><br><span class="line">openssl x509 -req -in lb.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out lb.crt -days 3650</span><br><span class="line">cat lb.crt lb.key &gt; lb.pem</span><br><span class="line">openssl pkcs12 -export -inkey lb.key -in lb.crt -certfile ca.crt -passout pass: -out lb.p12</span><br></pre></td></tr></table></figure></p>
<p>但是仍然不成功, 原因已查明, 与密钥无关, 而是之前没有执行这一句(octavia_user_id=$(openstack user show octavia –domain service_domain -f value -c id); openstack acl user add -u $octavia_user_id $secret_id) 所致, 一个完整的脚本如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">#https://wiki.openstack.org/wiki/Network/LBaaS/docs/how-to-create-tls-loadbalancer#Update_neutron_config</span><br><span class="line">#https://lingxiankong.github.io/2018-04-29-octavia-tls-termination-test.html</span><br><span class="line">DOMAIN1=www.server1.com</span><br><span class="line">DOMAIN2=www.server2.com</span><br><span class="line"></span><br><span class="line">echo &quot;Create CA cert(self-signed) and key...&quot;</span><br><span class="line">CA_SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=CA&quot;</span><br><span class="line">openssl req -new -x509 -nodes -days 3650 -newkey rsa:2048 -keyout ca.key -out ca.crt -subj $CA_SUBJECT</span><br><span class="line"></span><br><span class="line">openssl genrsa -des3 -out $DOMAIN1_encrypted.key 1024</span><br><span class="line">openssl rsa -in $DOMAIN1_encrypted.key -out $DOMAIN1.key</span><br><span class="line">openssl genrsa -des3 -out $DOMAIN2_encrypted.key 1024</span><br><span class="line">openssl rsa -in $DOMAIN2_encrypted.key -out $DOMAIN2.key</span><br><span class="line"></span><br><span class="line">echo &quot;Create server certificate signing request...&quot;</span><br><span class="line">SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=$DOMAIN1&quot;</span><br><span class="line">openssl req -new -nodes -subj $SUBJECT -key $DOMAIN1.key -out $DOMAIN1.csr</span><br><span class="line">SUBJECT=&quot;/C=CN/ST=BJ/L=BJ/O=STS/OU=Joshua/CN=$DOMAIN2&quot;</span><br><span class="line">openssl req -new -nodes -subj $SUBJECT -key $DOMAIN2.key -out $DOMAIN2.csr</span><br><span class="line"></span><br><span class="line">echo &quot;Sign SSL certificate...&quot;</span><br><span class="line">openssl x509 -req -days 3650 -in $DOMAIN1.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out $DOMAIN1.crt</span><br><span class="line">openssl x509 -req -days 3650 -in $DOMAIN2.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out $DOMAIN2.crt</span><br><span class="line"></span><br><span class="line"># NOTE: must without password when using barbican to save p12</span><br><span class="line">openssl pkcs12 -export -inkey www.server1.com.key -in www.server1.com.crt -certfile ca.crt -passout pass: -out www.server1.com.p12</span><br><span class="line">openssl pkcs12 -export -inkey www.server2.com.key -in www.server2.com.crt -certfile ca.crt -passout pass: -out www.server2.com.p12</span><br><span class="line"></span><br><span class="line">secret1_id=$(openstack secret store --name=&apos;lb_tls_secret_1&apos; -t &apos;application/octet-stream&apos; -e &apos;base64&apos; --payload=&quot;$(base64 &lt; www.server1.com.p12)&quot; -f value -c &quot;Secret href&quot;)</span><br><span class="line">secret2_id=$(openstack secret store --name=&apos;lb_tls_secret_2&apos; -t &apos;application/octet-stream&apos; -e &apos;base64&apos; --payload=&quot;$(base64 &lt; www.server2.com.p12)&quot; -f value -c &quot;Secret href&quot;)</span><br><span class="line"></span><br><span class="line"># allow octavia service user to visit the cert saved in barbican by the user in the novarc</span><br><span class="line">octavia_user_id=$(openstack user show octavia --domain service_domain -f value -c id); echo $octavia_user_id;</span><br><span class="line">openstack acl user add -u $octavia_user_id $secret1_id</span><br><span class="line">openstack acl user add -u $octavia_user_id $secret2_id</span><br><span class="line"></span><br><span class="line">IP=192.168.21.7</span><br><span class="line">subnetid=$(openstack subnet show private_subnet -f value -c id); echo $subnetid</span><br><span class="line">#lb_id=$(openstack loadbalancer create --name lb3 --vip-subnet-id $subnetid -f value -c id); echo $lb_id</span><br><span class="line">lb_id=22ce64e5-585d-43bd-80eb-5c3ff22abacd</span><br><span class="line">listener_id=$(openstack loadbalancer listener create $lb_id --name https_listener --protocol-port 443 --protocol TERMINATED_HTTPS --default-tls-container=$secret1_id --sni-container-refs $secret1_id $secret2_id -f value -c id); echo $listener_id</span><br><span class="line">pool_id=$(openstack loadbalancer pool create --protocol HTTP --listener $listener_id --lb-algorithm ROUND_ROBIN -f value -c id); echo $pool_id</span><br><span class="line">openstack loadbalancer member create --address $&#123;IP&#125; --subnet-id $subnetid --protocol-port 80 $pool_id</span><br><span class="line"></span><br><span class="line">public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">vip=$(openstack loadbalancer show $lb_id -c vip_address -f value)</span><br><span class="line">vip_port=$(openstack port list --fixed-ip ip-address=$vip -c ID -f value)</span><br><span class="line">#openstack floating ip set $fip --fixed-ip-address $vip --port $vip_port</span><br><span class="line">neutron floatingip-associate $fip $vip_port</span><br><span class="line"></span><br><span class="line">curl -k https://$fip</span><br><span class="line">curl --resolve www.server1.com:443:$fip --cacert ~/ca3/ca.crt https://www.server1.com</span><br><span class="line">curl --resolve www.server2.com:443:$fip --cacert ~/ca3/ca.crt https://www.server2.com</span><br><span class="line"></span><br><span class="line">nobody    2202  2200  0 07:23 ?        00:00:00 /usr/sbin/haproxy -f /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523/dfa44538-2c12-411b-b3b3-c709bc139523.pid -L 1_a8OAWpvKuB7hMNzt8UwaJ2M00 -Ds -sf 2148</span><br><span class="line"></span><br><span class="line">root@amphora-2fae038f-08b5-4bce-a2b7-f7bd543c0314:~# cat /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer 22ce64e5-585d-43bd-80eb-5c3ff22abacd</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/dfa44538-2c12-411b-b3b3-c709bc139523.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">frontend dfa44538-2c12-411b-b3b3-c709bc139523</span><br><span class="line">    option httplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    redirect scheme https if !&#123; ssl_fc &#125;</span><br><span class="line">    bind 192.168.21.16:443 ssl crt /var/lib/octavia/certs/dfa44538-2c12-411b-b3b3-c709bc139523/b16771bdb053d138575d60e3035d77fa0598ef5c.pem crt /var/lib/octavia/certs/dfa44538-2c12-411b-b3b3-c709bc139523</span><br><span class="line">    mode http</span><br><span class="line">    default_backend e6c4444a-a06e-4c1c-80d4-389516059d46</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend e6c4444a-a06e-4c1c-80d4-389516059d46</span><br><span class="line">    mode http</span><br><span class="line">    balance roundrobin</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 234ff0d3-5196-4536-bd49-dfbab94732d4 192.168.21.7:80 weight 1</span><br></pre></td></tr></table></figure></p>
<p>目前剩下的问题是service vm无法访问backend 192.168.21.7, 原理应该是:<br>octavia通过_plug_amphora_vip方法添加一个vip port (octavia-lb-vrrp-7e56de03-298e-43dd-a78f-33aa8d4af735), 它应该往amphora虚机上再添加一个port, 然后为此vip添加allowed_address_pairs. 但是在amphora虚机上我们没有发现这块新添的vip NIC, 重新运行下列’nova interface-attach’也不好使<br>nova list –all<br>nova interface-attach –port-id $(neutron port-show octavia-lb-vrrp-f63f0c5b-a541-442a-929c-b8ed7f7b3604 -f value -c id) 044f42c9-d205-4a11-aa8f-6b9aea896861<br>使用下列方法也不好使:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">lb_id=$(openstack loadbalancer show lb3 -f value -c id)</span><br><span class="line">old_vip=$(openstack loadbalancer show lb3 -f value -c vip_address)</span><br><span class="line">private_subnet_id=$(neutron subnet-show private_subnet -f value -c id)</span><br><span class="line"># delete old vip port (named &apos;octavia-lb-$lb_id&apos;)</span><br><span class="line">neutron port-delete octavia-lb-$lb_id</span><br><span class="line"># create new vip port with the same name and vip and binding:host_id is amphora service vm&apos;s host</span><br><span class="line"># nova show $(nova list --all |grep amphora |awk &apos;&#123;print $2&#125;&apos;) |grep OS-EXT-SRV-ATTR:host</span><br><span class="line">neutron port-create --name octavia-lb-$lb_id --device-owner Octavia --binding:host_id=juju-50fb86-bionic-rocky-barbican-octavia-8 --fixed-ip subnet_id=$&#123;private_subnet_id&#125;,ip_address=$&#123;old_vip&#125; private</span><br><span class="line">mac=$(neutron port-show octavia-lb-$lb_id -f value -c mac_address)</span><br><span class="line">nova interface-attach --port-id $(neutron port-show octavia-lb-$lb_id -f value -c id) $(nova list --all |grep amphora |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line"></span><br><span class="line">接着发现admin-state-up为False, 但enable(neutron port-update --admin-state-up True 6dc5b0bd-d0b7-4b29-9fce-b8f7b23c7914)后status仍然为DOWN. 继续检查设置如下;</span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /etc/netns/amphora-haproxy/network/interfaces</span><br><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line">source /etc/netns/amphora-haproxy/network/interfaces.d/*.cfg</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /etc/netns/amphora-haproxy/network/interfaces.d/eth1.cfg</span><br><span class="line"># Generated by Octavia agent</span><br><span class="line">auto eth1 eth1:0</span><br><span class="line">iface eth1 inet static</span><br><span class="line">address 192.168.21.34</span><br><span class="line">broadcast 192.168.21.255</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 192.168.21.1</span><br><span class="line">mtu 1458</span><br><span class="line">iface eth1:0 inet static</span><br><span class="line">address 192.168.21.5</span><br><span class="line">broadcast 192.168.21.255</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line"># Add a source routing table to allow members to access the VIP</span><br><span class="line">post-up /sbin/ip route add default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">post-down /sbin/ip route del default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">post-up /sbin/ip route add 192.168.21.0/24 dev eth1 src 192.168.21.5 scope link table 1</span><br><span class="line">post-down /sbin/ip route del 192.168.21.0/24 dev eth1 src 192.168.21.5 scope link table 1</span><br><span class="line">post-up /sbin/ip rule add from 192.168.21.5/32 table 1 priority 100</span><br><span class="line">post-down /sbin/ip rule del from 192.168.21.5/32 table 1 priority 100</span><br><span class="line">post-up /sbin/iptables -t nat -A POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line">post-down /sbin/iptables -t nat -D POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /var/lib/octavia/plugged_interfaces</span><br><span class="line">fa:16:3e:e2:3a:7f eth1</span><br><span class="line"></span><br><span class="line">ip netns exec amphora-haproxy ifdown eth1</span><br><span class="line">ip netns exec amphora-haproxy ifup eth1</span><br><span class="line">ip netns exec amphora-haproxy ifup eth1.0</span><br><span class="line">ip netns exec amphora-haproxy ip addr show</span><br><span class="line"></span><br><span class="line">但发现无法ifup eth1.0:</span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# ip netns exec amphora-haproxy ifup eth1.0</span><br><span class="line">Unknown interface eth1.0</span><br><span class="line"></span><br><span class="line">手工执行它:</span><br><span class="line">ip netns exec amphora-haproxy ifdown eth1</span><br><span class="line">ip netns exec amphora-haproxy ip addr add 192.168.21.34/24 dev eth1</span><br><span class="line">ip netns exec amphora-haproxy ip addr add 192.168.21.5/24 dev eth1</span><br><span class="line">ip netns exec amphora-haproxy ifconfig eth1 up</span><br><span class="line">ip netns exec amphora-haproxy ip route add default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">ip netns exec amphora-haproxy ip route add 192.168.21.0/24 dev eth1 src 192.168.21.5 scope link table 1</span><br><span class="line">ip netns exec amphora-haproxy ip rule add from 192.168.21.5/32 table 1 priority 100</span><br><span class="line">ip netns exec amphora-haproxy iptables -t nat -A POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line"></span><br><span class="line">注: 要重做image的话, 可以参考: https://github.com/openstack/octavia/tree/master/diskimage-create</span><br><span class="line"></span><br><span class="line">此时, 可以从amphora-haproxy ping backedn vm 192.168.21.7</span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# ip netns exec amphora-haproxy ping -c 1 192.168.21.7</span><br><span class="line">PING 192.168.21.7 (192.168.21.7) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.21.7: icmp_seq=1 ttl=64 time=3.83 ms</span><br><span class="line"></span><br><span class="line">但是从neutron-gateway节点仍然无法ping vip 192.168.21.5</span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-6:~# ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b ping 192.168.21.5</span><br><span class="line">PING 192.168.21.5 (192.168.21.5) 56(84) bytes of data.</span><br><span class="line"></span><br><span class="line">继续为这个ha port添加allowed-address-pairs port, 但仍然无果.</span><br><span class="line">neutron port-update 6dc5b0bd-d0b7-4b29-9fce-b8f7b23c7914 --allowed-address-pairs type=dict list=true mac_address=fa:16:3e:e2:3a:7f,ip_address=192.168.21.5</span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# iptables-save |grep &apos;IP/MAC pairs&apos;</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.5/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.34/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-sfad3d0f9-3 -s 192.168.0.16/32 -m mac --mac-source FA:16:3E:EA:54:4F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# iptables-save |grep &apos;IP/MAC pairs&apos;</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.5/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-s650aa1af-5 -s 192.168.21.34/32 -m mac --mac-source FA:16:3E:E2:3A:7F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line">-A neutron-openvswi-sfad3d0f9-3 -s 192.168.0.16/32 -m mac --mac-source FA:16:3E:EA:54:4F -m comment --comment &quot;Allow traffic from defined IP/MAC pairs.&quot; -j RETURN</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# ovs-appctl bridge/dump-flows br-int |grep 192.168.21</span><br><span class="line">table_id=24, duration=513s, n_packets=6, n_bytes=252, priority=2,arp,in_port=4,arp_spa=192.168.21.5,actions=goto_table:25</span><br><span class="line">table_id=24, duration=513s, n_packets=1, n_bytes=42, priority=2,arp,in_port=4,arp_spa=192.168.21.34,actions=goto_table:25</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# ovs-appctl bridge/dump-flows br-int |grep 25,</span><br><span class="line">table_id=25, duration=48s, n_packets=0, n_bytes=0, priority=2,in_port=4,dl_src=fa:16:3e:e2:3a:7f,actions=goto_table:60</span><br><span class="line">table_id=25, duration=48s, n_packets=6, n_bytes=1396, priority=2,in_port=3,dl_src=fa:16:3e:ea:54:4f,actions=goto_table:60</span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-9:~# ovs-appctl bridge/dump-flows br-int |grep 60,</span><br><span class="line">table_id=60, duration=76s, n_packets=20, n_bytes=3880, priority=3,actions=NORMAL</span><br></pre></td></tr></table></figure></p>
<p>继续查找原因, 既然从service vm能ping backend说明网络都没问题, 现在只是无法从gateway ping service vm那说明应该还是防火墙的问题. 采用’neutron port-show <ha-vip-port>‘查看该vip port关联的是一个新security group, 添加之后问题解决:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openstack security group rule create --protocol tcp --dst-port 22 lb-7f2985f0-c0d5-47ab-b805-7f5dafe20d3e</span><br><span class="line">openstack security group rule create --protocol icmp lb-7f2985f0-c0d5-47ab-b805-7f5dafe20d3e</span><br></pre></td></tr></table></figure></ha-vip-port></p>
<p>接着就是报这个错, 后来确认是上面在backend模拟HTTP服务的方法有问题, 后改成”sudo python -m SimpleHTTPServer 80”后问题解决 .<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-6:~# ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b curl -k https://192.168.21.5</span><br><span class="line">&lt;html&gt;&lt;body&gt;&lt;h1&gt;502 Bad Gateway&lt;/h1&gt;</span><br><span class="line">Jan  6 05:14:38 amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af haproxy[2688]: 192.168.21.1:41372 [06/Jan/2019:05:14:38.038] a5b442f3-7d40-4849-8b88-7f02697bfd5b~ e25b432a-ea45-4191-9448-c364661326dc/ae847e94-5aeb-4da6-9b66-07e1a385465b 28/0/9/-1/40 502 250 - - PH-- 0/0/0/0/0 0/0 &quot;GET / HTTP/1.1</span><br></pre></td></tr></table></figure></p>
<p>整个实验结果见链接- <a href="https://paste.ubuntu.com/p/PPHv9Zfdf6/" target="_blank" rel="external">https://paste.ubuntu.com/p/PPHv9Zfdf6/</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@zhhuabj-bastion:~⟫ curl -k https://10.5.150.5</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ curl --resolve www.quqi.com:443:10.5.150.5 --cacert ~/ca2_without_pass/ca.crt https://www.quqi.com</span><br><span class="line">Hello World!</span><br><span class="line">ubuntu@zhhuabj-bastion:~⟫ curl --resolve www.quqi.com:443:10.5.150.5 -k https://www.quqi.com</span><br><span class="line">Hello World!</span><br><span class="line"></span><br><span class="line">root@juju-50fb86-bionic-rocky-barbican-octavia-6:~# ip netns exec qrouter-2ea1fc45-69e5-4c77-b6c9-d4fabc57145b curl -k https://192.168.21.5</span><br><span class="line">Hello World!</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# ip netns exec amphora-haproxy curl 192.168.21.7</span><br><span class="line">Hello World!</span><br><span class="line"></span><br><span class="line">root@amphora-3d906381-f49f-4efa-bfa7-b5f84eb3b1af:~# cat /var/lib/octavia/a5b442f3-7d40-4849-8b88-7f02697bfd5b/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer 7f2985f0-c0d5-47ab-b805-7f5dafe20d3e</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/a5b442f3-7d40-4849-8b88-7f02697bfd5b.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">frontend a5b442f3-7d40-4849-8b88-7f02697bfd5b</span><br><span class="line">    option httplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    redirect scheme https if !&#123; ssl_fc &#125;</span><br><span class="line">    bind 192.168.21.5:443 ssl crt /var/lib/octavia/certs/a5b442f3-7d40-4849-8b88-7f02697bfd5b/4aa85f186d19a766c29109577d88734a8fca6385.pem crt /var/lib/octavia/certs/a5b442f3-7d40-4849-8b88-7f02697bfd5b</span><br><span class="line">    mode http</span><br><span class="line">    default_backend e25b432a-ea45-4191-9448-c364661326dc</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend e25b432a-ea45-4191-9448-c364661326dc</span><br><span class="line">    mode http</span><br><span class="line">    balance roundrobin</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server ae847e94-5aeb-4da6-9b66-07e1a385465b 192.168.21.7:80 weight 1 check inter 5s fall 3 rise 4</span><br></pre></td></tr></table></figure>
<h2 id="附件-Neutron-LBaaS-v2"><a href="#附件-Neutron-LBaaS-v2" class="headerlink" title="附件 - Neutron LBaaS v2"></a>附件 - Neutron LBaaS v2</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">https://docs.openstack.org/mitaka/networking-guide/config-lbaas.html</span><br><span class="line">neutron lbaas-loadbalancer-create --name test-lb private_subnet</span><br><span class="line">neutron lbaas-listener-create --name test-lb-https --loadbalancer test-lb --protocol HTTPS --protocol-port 443</span><br><span class="line">neutron lbaas-pool-create --name test-lb-pool-https --lb-algorithm LEAST_CONNECTIONS --listener test-lb-https --protocol HTTPS</span><br><span class="line">neutron lbaas-member-create --subnet private_subnet --address 192.168.21.13 --protocol-port 443 test-lb-pool-https</span><br><span class="line">neutron lbaas-member-create --subnet private_subnet --address 192.168.21.8 --protocol-port 443 test-lb-pool-https</span><br><span class="line">neutron lbaas-healthmonitor-create --delay 5 --max-retries 2 --timeout 10 --type HTTPS --pool test-lb-pool-https --name monitor1</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl -k  https://192.168.21.14</span><br><span class="line">test1</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl -k  https://192.168.21.14</span><br><span class="line">test2</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl --cacert /home/ubuntu/lb.pem  https://192.168.21.14</span><br><span class="line">curl: (51) SSL: certificate subject name (www.quqi.com) does not match target host name &apos;192.168.21.14&apos;</span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# ip netns exec qlbaas-84fd9a6c-24a2-4c0f-912b-eedc254ac1f4 curl --cacert /home/ubuntu/lb.pem  --resolve www.quqi.com:443:192.168.21.14 https://www.quqi.com</span><br><span class="line">test1</span><br><span class="line"></span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# echo &apos;show stat;show table&apos; | socat stdio /var/lib/neutron/lbaas/v2/84fd9a6c-24a2-4c0f-912b-eedc254ac1f4/haproxy_stats.sock</span><br><span class="line"># pxname,svname,qcur,qmax,scur,smax,slim,stot,bin,bout,dreq,dresp,ereq,econ,eresp,wretr,wredis,status,weight,act,bck,chkfail,chkdown,lastchg,downtime,qlimit,pid,iid,sid,throttle,lbtot,tracked,type,rate,rate_lim,rate_max,check_status,check_code,check_duration,hrsp_1xx,hrsp_2xx,hrsp_3xx,hrsp_4xx,hrsp_5xx,hrsp_other,hanafail,req_rate,req_rate_max,req_tot,cli_abrt,srv_abrt,comp_in,comp_out,comp_byp,comp_rsp,lastsess,last_chk,last_agt,qtime,ctime,rtime,ttime,</span><br><span class="line">c2a42906-e160-44dd-8590-968af2077b4a,FRONTEND,,,0,0,2000,0,0,0,0,0,0,,,,,OPEN,,,,,,,,,1,2,0,,,,0,0,0,0,,,,,,,,,,,0,0,0,,,0,0,0,0,,,,,,,,</span><br><span class="line">52112201-05ce-4f4d-b5a8-9e67de2a895a,37a1f5a8-ec7e-4208-9c96-27d2783a594f,0,0,0,0,,0,0,0,,0,,0,0,0,0,no check,1,1,0,,,,,,1,3,1,,0,,2,0,,0,,,,,,,,,,0,,,,0,0,,,,,-1,,,0,0,0,0,</span><br><span class="line">52112201-05ce-4f4d-b5a8-9e67de2a895a,8e722b4b-08b8-4089-bba5-8fa5dd26a87f,0,0,0,0,,0,0,0,,0,,0,0,0,0,no check,1,1,0,,,,,,1,3,2,,0,,2,0,,0,,,,,,,,,,0,,,,0,0,,,,,-1,,,0,0,0,0,</span><br><span class="line">52112201-05ce-4f4d-b5a8-9e67de2a895a,BACKEND,0,0,0,0,200,0,0,0,0,0,,0,0,0,0,UP,2,2,0,,0,117,0,,1,3,0,,0,,1,0,,0,,,,,,,,,,,,,,0,0,0,0,0,0,-1,,,0,0,0,0,</span><br><span class="line"></span><br><span class="line">root@juju-c9d701-xenail-queens-184313-vrrp-5:~# cat /var/lib/neutron/lbaas/v2/84fd9a6c-24a2-4c0f-912b-eedc254ac1f4/haproxy.conf</span><br><span class="line"># Configuration for test-lb</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    group nogroup</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    maxconn 2000</span><br><span class="line">    stats socket /var/lib/neutron/lbaas/v2/84fd9a6c-24a2-4c0f-912b-eedc254ac1f4/haproxy_stats.sock mode 0666 level user</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout client 50000</span><br><span class="line">    timeout server 50000</span><br><span class="line">frontend c2a42906-e160-44dd-8590-968af2077b4a</span><br><span class="line">    option tcplog</span><br><span class="line">    bind 192.168.21.14:443</span><br><span class="line">    mode tcp</span><br><span class="line">    default_backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">    mode tcp</span><br><span class="line">    balance leastconn</span><br><span class="line">    timeout check 10s</span><br><span class="line">    option httpchk GET /</span><br><span class="line">    http-check expect rstatus 200</span><br><span class="line">    option ssl-hello-chk</span><br><span class="line">    server 37a1f5a8-ec7e-4208-9c96-27d2783a594f 192.168.21.13:443 weight 1 check inter 5s fall 2</span><br><span class="line">    server 8e722b4b-08b8-4089-bba5-8fa5dd26a87f 192.168.21.8:443 weight 1 check inter 5s fall 2</span><br><span class="line"></span><br><span class="line"># TCP monitor</span><br><span class="line">neutron lbaas-healthmonitor-delete monitor1</span><br><span class="line">neutron lbaas-healthmonitor-create --delay 5 --max-retries 2 --timeout 10 --type TCP --pool test-lb-pool-https --name monitor1 --url-path /</span><br><span class="line">backend 52112201-05ce-4f4d-b5a8-9e67de2a895a</span><br><span class="line">    mode tcp</span><br><span class="line">    balance leastconn</span><br><span class="line">    timeout check 10s</span><br><span class="line">    server 37a1f5a8-ec7e-4208-9c96-27d2783a594f 192.168.21.13:443 weight 1 check inter 5s fall 2</span><br><span class="line">    server 8e722b4b-08b8-4089-bba5-8fa5dd26a87f 192.168.21.8:443 weight 1 check inter 5s fall 2</span><br></pre></td></tr></table></figure>
<h2 id="附录-上层的k8s如何使用下层的openstack中的LBaaS资源"><a href="#附录-上层的k8s如何使用下层的openstack中的LBaaS资源" class="headerlink" title="附录 - 上层的k8s如何使用下层的openstack中的LBaaS资源"></a>附录 - 上层的k8s如何使用下层的openstack中的LBaaS资源</h2><p>如果在一个OpenStack云上面再创建K8S的话, 在k8s中使用下列命令创建LoadBalancer服务会永远Pending状态.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl run test-nginx --image=nginx --replicas=2 --port=80 --expose --service-overrides=&apos;&#123; &quot;spec&quot;: &#123; &quot;type&quot;: &quot;LoadBalancer&quot; &#125; &#125;&apos;</span><br><span class="line">kubectl get svc test-nginx</span><br></pre></td></tr></table></figure></p>
<p>那是因为k8s需要调用底层OpenStack  LBaaS服务创建VIP资源, 然后将所有后端服务的<nodeip:nodeport>作为backend. 那么该如何让k8s具有访问openstack lbaas资源的能力呢? 如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># https://blog.ubuntu.com/2019/01/28/taking-octavia-for-a-ride-with-kubernetes-on-openstack</span><br><span class="line"># openstack上部署k8s, &apos;juju trust openstack-integrator&apos;将让openstack-integrator具有访问bootstrap时所用的openstack credential的权限,</span><br><span class="line"># 之后, 因为cdk实现了interface-openstack-integration接口, 所以cdk k8s可以使用这些openstack credential来直接使用openstack里的LBaaS等资源</span><br><span class="line">juju deploy cs:~containers/openstack-integrator</span><br><span class="line">juju add-relation openstack-integrator kubernetes-master</span><br><span class="line">juju add-relation openstack-integrator kubernetes-worker</span><br><span class="line">juju config openstack-integrator subnet-id=&lt;UUID of subnet&gt;</span><br><span class="line">juju config openstack-integrator floating-network-id=&lt;UUID of ext_net&gt;</span><br><span class="line"></span><br><span class="line"># &apos;juju trust&apos; grants openstack-integrator access to the credential used in the bootstrap command, this charm acts as a proxy for the</span><br><span class="line">juju trust openstack-integrator</span><br><span class="line"></span><br><span class="line">测试yaml, 有时要提供loadbalancer.openstack.org/floating-network-id, 见:  https://github.com/kubernetes/cloud-provider-openstack/tree/master/examples/loadbalancers</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: external-http-nginx-service</span><br><span class="line">  annotations:</span><br><span class="line">    service.beta.kubernetes.io/openstack-internal-load-balancer: &quot;false&quot;</span><br><span class="line">    loadbalancer.openstack.org/floating-network-id: &quot;6f05a9de-4fc9-41f5-9c51-d5f43cd244b9&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 80</span><br></pre></td></tr></table></figure></nodeip:nodeport></p>
<p>同时也应该确保service tenant下的security group的quata别超了.quata超了的现象是例如对于FIP, 有时可以有时不可以.</p>
<p>后面继续搭建k8s可参见 - <a href="https://ubuntu.com/blog/taking-octavia-for-a-ride-with-kubernetes-on-openstack" target="_blank" rel="external">https://ubuntu.com/blog/taking-octavia-for-a-ride-with-kubernetes-on-openstack</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br></pre></td><td class="code"><pre><span class="line"># deploy underlying openstack model</span><br><span class="line">./generate-bundle.sh --name o7k:stsstack --create-model --octavia -r stein --dvr-snat --num-compute 8</span><br><span class="line">sed -i &quot;s/mem=8G/mem=8G cores=4/g&quot; ./b/o7k/openstack.yaml</span><br><span class="line">./generate-bundle.sh --name o7k:stsstack --replay --run</span><br><span class="line">./bin/add-data-ports.sh</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens7&quot;</span><br><span class="line"></span><br><span class="line">#refere this page to generate certs - https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-octavia.html</span><br><span class="line">juju config octavia \</span><br><span class="line">    lb-mgmt-issuing-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-private-key=&quot;$(base64 controller_ca_key.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-key-passphrase=foobar \</span><br><span class="line">    lb-mgmt-controller-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-controller-cert=&quot;$(base64 controller_cert_bundle.pem)&quot;</span><br><span class="line"></span><br><span class="line">juju run-action --wait octavia/0 configure-resources</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">./configure</span><br><span class="line">#juju config octavia loadbalancer-topology=ACTIVE_STANDBY</span><br><span class="line">juju run-action octavia-diskimage-retrofit/0 --wait retrofit-image source-image=$(openstack image list |grep bionic |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">openstack image list</span><br><span class="line"></span><br><span class="line"># enable all ingress traffic</span><br><span class="line">PROJECT_ID=$(openstack project show --domain admin_domain admin -f value -c id)</span><br><span class="line">SECGRP_ID=$(openstack security group list --project $&#123;PROJECT_ID&#125; | awk &apos;/default/ &#123;print $2&#125;&apos;)</span><br><span class="line">openstack security group rule create $&#123;SECGRP_ID&#125; --protocol any --ethertype IPv6 --ingress</span><br><span class="line">openstack security group rule create $&#123;SECGRP_ID&#125; --protocol any --ethertype IPv4 --ingress</span><br><span class="line"></span><br><span class="line"># disable quotas for project, neutron and nova</span><br><span class="line">openstack quota set --instances -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --floating-ips -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --cores -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --ram -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --gigabytes -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --volumes -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --secgroups -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">openstack quota set --secgroup-rules -1 $&#123;PROJECT_ID&#125;</span><br><span class="line">neutron quota-update --network -1</span><br><span class="line">neutron quota-update --floatingip -1</span><br><span class="line">neutron quota-update --port -1</span><br><span class="line">neutron quota-update --router -1</span><br><span class="line">neutron quota-update --security-group -1</span><br><span class="line">neutron quota-update --security-group-rule -1</span><br><span class="line">neutron quota-update --subnet -1</span><br><span class="line">neutron quota-show</span><br><span class="line"></span><br><span class="line"># set up router to allow bastion to access juju controller</span><br><span class="line">GATEWAY_IP=$(openstack router show provider-router -f value -c external_gateway_info \</span><br><span class="line">    |awk &apos;/ip_address/ &#123; for (i=1;i&lt;NF;i++) if ($i~&quot;ip_address&quot;) print $(i+1)&#125;&apos; |cut -f2 -d\&apos;)</span><br><span class="line">CIDR=$(openstack subnet show private_subnet -f value -c cidr)</span><br><span class="line">sudo ip route add $&#123;CIDR&#125; via $&#123;GATEWAY_IP&#125;</span><br><span class="line"></span><br><span class="line"># define juju cloud</span><br><span class="line">sudo bash -c &apos;cat &gt; mystack.yaml&apos; &lt;&lt; EOF</span><br><span class="line">clouds:</span><br><span class="line">  mystack:</span><br><span class="line">    type: openstack</span><br><span class="line">    auth-types: [ userpass ]</span><br><span class="line">    regions:</span><br><span class="line">      RegionOne:</span><br><span class="line">        endpoint: $OS_AUTH_URL</span><br><span class="line">EOF</span><br><span class="line">juju remove-cloud --local mystack</span><br><span class="line">juju add-cloud --local mystack mystack.yaml</span><br><span class="line">juju show-cloud mystack --local</span><br><span class="line">sudo bash -c &apos;cat &gt; mystack_credentials.txt&apos; &lt;&lt; EOF</span><br><span class="line">credentials:</span><br><span class="line">  mystack:</span><br><span class="line">    admin:</span><br><span class="line">      auth-type: userpass</span><br><span class="line">      password: openstack</span><br><span class="line">      tenant-name: admin</span><br><span class="line">      domain-name: &quot;&quot; # ensure we don&apos;t get a domain-scoped token</span><br><span class="line">      project-domain-name: admin_domain</span><br><span class="line">      user-domain-name: admin_domain</span><br><span class="line">      username: admin</span><br><span class="line">      version: &quot;3&quot;</span><br><span class="line">EOF</span><br><span class="line">juju remove-credential --local mystack admin</span><br><span class="line">juju add-credential --local mystack -f ./mystack_credentials.txt</span><br><span class="line">juju show-credential --local mystack admin</span><br><span class="line"></span><br><span class="line"># deploy juju controller</span><br><span class="line">mkdir -p ~/simplestreams/images &amp;&amp; rm -rf ~/simplestreams/images/*</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">IMAGE_ID=$(openstack image list -f value |grep &apos;bionic active&apos; |awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">OS_SERIES=$(openstack image list -f value |grep &apos;bionic active&apos; |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">juju metadata generate-image -d ~/simplestreams -i $IMAGE_ID -s $OS_SERIES -r $OS_REGION_NAME -u $OS_AUTH_URL</span><br><span class="line">ls ~/simplestreams/*/streams/*</span><br><span class="line">NETWORK_ID=$(openstack network show private -f value -c id)</span><br><span class="line"># can remove juju controller &apos;mystack-regionone&apos; from ~/.local/share/juju/controllers.yaml if it exists</span><br><span class="line">juju bootstrap mystack --config network=$&#123;NETWORK_ID&#125; --model-default network=$&#123;NETWORK_ID&#125; --model-default use-default-secgroup=true --metadata-source ~/simplestreams</span><br><span class="line"></span><br><span class="line"># deploy upper k8s model</span><br><span class="line">juju switch mystack-regionone</span><br><span class="line">juju destroy-model --destroy-storage --force upperk8s -y &amp;&amp; juju add-model upperk8s</span><br><span class="line">wget https://api.jujucharms.com/charmstore/v5/bundle/canonical-kubernetes-933/archive/bundle.yaml</span><br><span class="line">sed -i &quot;s/num_units: 2/num_units: 1/g&quot; ./bundle.yaml</span><br><span class="line">sed -i &quot;s/num_units: 3/num_units: 2/g&quot; ./bundle.yaml</span><br><span class="line">sed -i &quot;s/cores=4/cores=2/g&quot; ./bundle.yaml</span><br><span class="line">juju deploy ./bundle.yaml</span><br><span class="line">juju deploy cs:~containers/openstack-integrator</span><br><span class="line">juju add-relation openstack-integrator:clients kubernetes-master:openstack</span><br><span class="line">juju add-relation openstack-integrator:clients kubernetes-worker:openstack</span><br><span class="line"></span><br><span class="line">juju config openstack-integrator subnet-id=$(openstack subnet show private_subnet -c id -f value)</span><br><span class="line">juju config openstack-integrator floating-network-id=$(openstack network show ext_net -c id -f value)</span><br><span class="line">juju trust openstack-integrator</span><br><span class="line">watch -c juju status --color</span><br><span class="line"></span><br><span class="line"># we don&apos;t use the following way to deploy k8s because it can&apos;t be customized to use bionic</span><br><span class="line">juju deploy charmed-kubernetes</span><br><span class="line"># we don&apos;t use the following way as well because it says no networks exist with label &quot;zhhuabj_port_sec_enabled&quot;</span><br><span class="line">~/stsstack-bundles/kubernetes/generate-bundle.sh --name k8s:mystack --create-model -s bionic --run</span><br><span class="line"></span><br><span class="line"># deploy test pod</span><br><span class="line">mkdir -p ~/.kube</span><br><span class="line">juju scp kubernetes-master/0:config ~/.kube/config</span><br><span class="line">sudo snap install kubectl --classic</span><br><span class="line">#Flag --replicas has been deprecated</span><br><span class="line">#kubectl run hello-world --replicas=2 --labels=&quot;run=lb-test&quot; --image=gcr.io/google-samples/node-hello:1.0 --port=8080</span><br><span class="line">kubectl create deployment hello-world --image=gcr.io/google-samples/node-hello:1.0 -o yaml --dry-run=client &gt; helloworld.yaml</span><br><span class="line">sudo bash -c &apos;cat &gt; helloworld.yaml&apos; &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: hello-world</span><br><span class="line">  name: hello-world</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: hello-world</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-world</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: gcr.io/google-samples/node-hello:1.0</span><br><span class="line">        name: node-hello</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f ./helloworld.yaml</span><br><span class="line">kubectl get deployments hello-world -o wide</span><br><span class="line"></span><br><span class="line"># deploy LoadBalancer service</span><br><span class="line"># # remember to relace the following &lt;ext_net_id&gt; to avoid &apos;pending&apos; status for FIP</span><br><span class="line">sudo bash -c &apos;cat &gt; helloservice.yaml&apos; &lt;&lt; EOF</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: hello</span><br><span class="line">  annotations:</span><br><span class="line">    service.beta.kubernetes.io/openstack-internal-load-balancer: &quot;false&quot;</span><br><span class="line">    loadbalancer.openstack.org/floating-network-id: &quot;&lt;ext_net_id&gt;&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-world</span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f ./helloservice.yaml</span><br><span class="line">watch kubectl get svc -o wide hello</span><br><span class="line">NAME    TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE     SELECTOR</span><br><span class="line">hello   LoadBalancer   10.152.183.88   10.5.150.220   80:32315/TCP   2m47s   app=hello-world</span><br><span class="line">$ curl http://10.5.150.220:80</span><br><span class="line">Hello Kubernetes!</span><br><span class="line"></span><br><span class="line">openstack loadbalancer list            #use &apos;kubectl  delete svc hello&apos; to delete lb</span><br><span class="line">openstack loadbalancer amphora list</span><br><span class="line"></span><br><span class="line">#vip=$(openstack loadbalancer list |grep ACTIVE |awk &apos;&#123;print $8&#125;&apos;)</span><br><span class="line">#public_network=$(openstack network show ext_net -f value -c id)</span><br><span class="line">#fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)</span><br><span class="line">#openstack floating ip set $fip --fixed-ip-address $vip --port $(openstack port list --fixed-ip ip-address=$vip -c id -f value)</span><br><span class="line"></span><br><span class="line">$ openstack floating ip list</span><br><span class="line">+--------------------------------------+---------------------+------------------+--------------------------------------+--------------------------------------+----------------------------------+</span><br><span class="line">| ID                                   | Floating IP Address | Fixed IP Address | Port                                 | Floating Network                     | Project                          |</span><br><span class="line">+--------------------------------------+---------------------+------------------+--------------------------------------+--------------------------------------+----------------------------------+</span><br><span class="line">| c284dfc3-d294-48ae-8ccf-20a7e47fe039 | 10.5.150.220        | 192.168.21.26    | ded911a8-f213-4884-a387-7efcf14c8a89 | 1a83b2d3-1c1b-4bc9-b882-f132b9ff9d87 | 0d1886170941437fa46fb34508e67d24 |</span><br><span class="line">+--------------------------------------+---------------------+------------------+--------------------------------------+--------------------------------------+----------------------------------+</span><br><span class="line"></span><br><span class="line">$ openstack loadbalancer list</span><br><span class="line">+--------------------------------------+------------------------------------------------------------------------+----------------------------------+---------------+---------------------+----------+</span><br><span class="line">| id                                   | name                                                                   | project_id                       | vip_address   | provisioning_status | provider |</span><br><span class="line">+--------------------------------------+------------------------------------------------------------------------+----------------------------------+---------------+---------------------+----------+</span><br><span class="line">| 72d96673-8723-4dde-9035-66c3bd095632 | kube_service_kubernetes-n7cgun28wpbsfgiiza5qralulupdtspv_default_hello | 0d1886170941437fa46fb34508e67d24 | 192.168.21.26 | ACTIVE              | amphora  |</span><br><span class="line">+--------------------------------------+------------------------------------------------------------------------+----------------------------------+---------------+---------------------+----------+</span><br><span class="line"></span><br><span class="line">$ openstack loadbalancer amphora list</span><br><span class="line">+--------------------------------------+--------------------------------------+-----------+------------+-----------------------------------------+---------------+</span><br><span class="line">| id                                   | loadbalancer_id                      | status    | role       | lb_network_ip                           | ha_ip         |</span><br><span class="line">+--------------------------------------+--------------------------------------+-----------+------------+-----------------------------------------+---------------+</span><br><span class="line">| 068104f1-ffee-4b4a-88ab-2e46cee1cbbc | 72d96673-8723-4dde-9035-66c3bd095632 | ALLOCATED | STANDALONE | fc00:961f:bb53:993b:f816:3eff:fe0d:6433 | 192.168.21.26 |</span><br><span class="line">+--------------------------------------+--------------------------------------+-----------+------------+-----------------------------------------+---------------+</span><br><span class="line"></span><br><span class="line">$ nova list --all |grep amphora</span><br><span class="line">| 966f0ec0-b48a-48b9-8078-d7406ee08311 | amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc | 144901cff394489d9095b1361caa6872 | ACTIVE | -          | Running     | lb-mgmt-net=fc00:961f:bb53:993b:f816:3eff:fe0d:6433; private=192.168.21.174 |</span><br><span class="line"></span><br><span class="line">#nova keypair-add --pub-key=~/.ssh/id_amphora.pub amphora-backdoor --user $(openstack user show octavia --domain service_domain -f value -c id)</span><br><span class="line">$ nova keypair-list --user $(openstack user show octavia --domain service_domain -f value -c id)</span><br><span class="line">+------------------+------+-------------------------------------------------+</span><br><span class="line">| Name             | Type | Fingerprint                                     |</span><br><span class="line">+------------------+------+-------------------------------------------------+</span><br><span class="line">| amphora-backdoor | ssh  | d9:53:1e:eb:70:42:24:f3:01:e2:4c:9d:c9:97:bd:11 |</span><br><span class="line">+------------------+------+-------------------------------------------------+</span><br><span class="line"></span><br><span class="line">$ openstack router list</span><br><span class="line">+--------------------------------------+-----------------+--------+-------+----------------------------------+-------------+-------+</span><br><span class="line">| ID                                   | Name            | Status | State | Project                          | Distributed | HA    |</span><br><span class="line">+--------------------------------------+-----------------+--------+-------+----------------------------------+-------------+-------+</span><br><span class="line">| 05d8e256-ba53-4b32-b40d-17472ac09040 | provider-router | ACTIVE | UP    | 0d1886170941437fa46fb34508e67d24 | True        | False |</span><br><span class="line">| 6876c9c3-d8c5-4b31-876b-fe830d4b5f0b | lb-mgmt         | ACTIVE | UP    | 144901cff394489d9095b1361caa6872 | False       | False |</span><br><span class="line">+--------------------------------------+-----------------+--------+-------+----------------------------------+-------------+-------+</span><br><span class="line">$ openstack subnet list</span><br><span class="line">+--------------------------------------+------------------+--------------------------------------+--------------------------+</span><br><span class="line">| ID                                   | Name             | Network                              | Subnet                   |</span><br><span class="line">+--------------------------------------+------------------+--------------------------------------+--------------------------+</span><br><span class="line">| 401b11c1-b209-4545-81f2-81dc93674616 | private_subnet   | 2c927db4-ee05-4d4a-b35b-f106cbd785c4 | 192.168.21.0/24          |</span><br><span class="line">| 54365c1c-1987-4607-8e98-4341cff4795f | ext_net_subnet   | 1a83b2d3-1c1b-4bc9-b882-f132b9ff9d87 | 10.5.0.0/16              |</span><br><span class="line">| 56847939-4776-4b39-bdac-e04a4a9b6555 | lb-mgmt-subnetv6 | 983933d9-3078-47ce-b581-961fbb53993b | fc00:961f:bb53:993b::/64 |</span><br><span class="line">+--------------------------------------+------------------+--------------------------------------+--------------------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#nova list --all |grep amphora</span><br><span class="line">#juju scp ~/.ssh/id_amphora* nova-compute/5:/home/ubuntu/</span><br><span class="line">#amphora instance is on nova-compute/3 (juju-7917e4-octavia-9), but gateway for lb-mgmt-subnetv6 is on nova-compute/5 (neutron l3-agent-list-hosting-router lb-mgmt)</span><br><span class="line">juju ssh nova-compute/5 -- sudo ip netns exec qrouter-6876c9c3-d8c5-4b31-876b-fe830d4b5f0b ping6 fc00:961f:bb53:993b:f816:3eff:fe0d:6433</span><br><span class="line">juju ssh nova-compute/5 -- sudo ip netns exec qrouter-6876c9c3-d8c5-4b31-876b-fe830d4b5f0b ssh -6 -i ~/id_amphora ubuntu@fc00:961f:bb53:993b:f816:3eff:fe0d:6433 -v</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ sudo ip netns ls</span><br><span class="line">amphora-haproxy (id: 0)</span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ sudo ip netns exec amphora-haproxy ip addr show eth1</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1508 qdisc fq state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:df:d2:3b brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.21.174/24 brd 192.168.21.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 192.168.21.26/24 brd 192.168.21.255 scope global secondary eth1:0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ ps -ef |grep haproxy</span><br><span class="line">root      1546     1  0 01:18 ?        00:00:01 /usr/sbin/haproxy -Ws -f /var/lib/octavia/72d96673-8723-4dde-9035-66c3bd095632/haproxy.cfg -f /var/lib/octavia/haproxy-default-user-group.conf -p /var/lib/octavia/72d96673-8723-4dde-9035-66c3bd095632/72d96673-8723-4dde-9035-66c3bd095632.pid -L 7eAyDHfLMNtMDh0lrSe_vQODo0g -sf 1800</span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ sudo cat /var/lib/octavia/72d96673-8723-4dde-9035-66c3bd095632/haproxy.cfg</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/72d96673-8723-4dde-9035-66c3bd095632.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">    option splice-request</span><br><span class="line">    option splice-response</span><br><span class="line">    option http-keep-alive</span><br><span class="line">frontend 7f26223c-63f8-490a-8aa3-0141b112bacb</span><br><span class="line">    option tcplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    bind 192.168.21.26:80</span><br><span class="line">    mode tcp</span><br><span class="line">    default_backend 632d6cf2-020f-4c63-9ca7-4bc952f8f324:7f26223c-63f8-490a-8aa3-0141b112bacb</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend 632d6cf2-020f-4c63-9ca7-4bc952f8f324:7f26223c-63f8-490a-8aa3-0141b112bacb</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 150e2027-ec51-469d-b5f8-675575c76c79 192.168.21.114:32315 weight 1</span><br><span class="line">    server 9b42d8f0-5719-48fe-b17c-2e7cd2b29b10 192.168.21.232:32315 weight 1</span><br><span class="line">    server d9f1f6ba-895b-43c6-ad09-362f4993aa73 192.168.21.251:32315 weight 1</span><br><span class="line">    server e7485d2c-1de5-4438-8b3b-0f74ba870895 192.168.21.87:32315 weight 1</span><br><span class="line"></span><br><span class="line">$ kubectl get svc</span><br><span class="line">NAME         TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)        AGE</span><br><span class="line">hello        LoadBalancer   10.152.183.88   10.5.150.220   80:32315/TCP   51m</span><br><span class="line">kubernetes   ClusterIP      10.152.183.1    &lt;none&gt;         443/TCP        10h</span><br><span class="line">$ juju status |grep worker</span><br><span class="line">kubernetes-worker      1.18.4   waiting    4/5  kubernetes-worker      jujucharms  682  ubuntu  exposed</span><br><span class="line">kubernetes-worker/0       waiting   allocating  6        192.168.21.128                  waiting for machine</span><br><span class="line">kubernetes-worker/1*      active    idle        7        192.168.21.114  80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line">kubernetes-worker/2       active    idle        8        192.168.21.232  80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line">kubernetes-worker/3       active    idle        10       192.168.21.251  80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line">kubernetes-worker/4       active    idle        11       192.168.21.87   80/tcp,443/tcp  Kubernetes worker running.</span><br><span class="line"></span><br><span class="line">$ juju switch zhhuabj</span><br><span class="line">mystack-regionone:admin/k8s -&gt; zhhuabj:admin/octavia</span><br><span class="line">$ nova list</span><br><span class="line">+--------------------------------------+--------------------------+--------+------------+-------------+------------------------+</span><br><span class="line">| ID                                   | Name                     | Status | Task State | Power State | Networks               |</span><br><span class="line">+--------------------------------------+--------------------------+--------+------------+-------------+------------------------+</span><br><span class="line">| 5cbd03dc-9e6b-42ea-a8a2-9ca725144df0 | juju-68d107-k8s-0        | ACTIVE | -          | Running     | private=192.168.21.219 |</span><br><span class="line">| 5cc74c32-1547-44b3-8c2d-68fcf33e5080 | juju-68d107-k8s-1        | ACTIVE | -          | Running     | private=192.168.21.127 |</span><br><span class="line">| 46dc9a58-1a51-4b45-912c-8c768a4d5f28 | juju-68d107-k8s-10       | ACTIVE | -          | Running     | private=192.168.21.251 |</span><br><span class="line">| 773a845c-f87d-4352-9c74-b3f3d354590f | juju-68d107-k8s-11       | ACTIVE | -          | Running     | private=192.168.21.87  |</span><br><span class="line">| 211a6abd-bc97-4faf-984f-987fa90f21f3 | juju-68d107-k8s-2        | ACTIVE | -          | Running     | private=192.168.21.78  |</span><br><span class="line">| df6b642a-9af8-4468-b1bf-691401c4835f | juju-68d107-k8s-3        | ACTIVE | -          | Running     | private=192.168.21.158 |</span><br><span class="line">| c6f82159-98c9-4884-a7b1-eb9e950618bb | juju-68d107-k8s-4        | ACTIVE | -          | Running     | private=192.168.21.242 |</span><br><span class="line">| e81b9566-3627-4a05-9460-415e76db9483 | juju-68d107-k8s-5        | ACTIVE | -          | Running     | private=192.168.21.217 |</span><br><span class="line">| 569087bd-9ef8-4e6f-a898-72b69daef6ea | juju-68d107-k8s-6        | ACTIVE | -          | Running     | private=192.168.21.128 |</span><br><span class="line">| 38d8887c-54ae-4b2c-b0c4-7f64542af8f1 | juju-68d107-k8s-7        | ACTIVE | -          | Running     | private=192.168.21.114 |</span><br><span class="line">| 178c5eee-945a-4295-8c94-5ad5d821f251 | juju-68d107-k8s-8        | ACTIVE | -          | Running     | private=192.168.21.232 |</span><br><span class="line">| 09a9c0c1-c795-494b-ac21-49fa3a2ef070 | juju-68d107-k8s-9        | ACTIVE | -          | Running     | private=192.168.21.147 |</span><br><span class="line">| 2d5bff68-21f1-46e0-b6b8-c83d97c8cc27 | juju-bb6752-controller-0 | ACTIVE | -          | Running     | private=192.168.21.21  |</span><br><span class="line">+--------------------------------------+--------------------------+--------+------------+-------------+------------------------+</span><br><span class="line"></span><br><span class="line">$ nova show juju-68d107-k8s-7 |grep security</span><br><span class="line">| security_groups                      | default, juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107, juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107-7                                     |</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group list --project $(openstack project list --domain admin_domain |grep admin |awk &apos;&#123;print $2&#125;&apos;) |grep default</span><br><span class="line">| bfc84b34-6f23-4561-87ff-58077f667bea | default                                                                           | Default security group | 0d1886170941437fa46fb34508e67d24 | []   |</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ sudo ip netns exec amphora-haproxy ping 192.168.21.114 -c 1</span><br><span class="line">sudo: unable to resolve host amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc</span><br><span class="line">PING 192.168.21.114 (192.168.21.114) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.21.114: icmp_seq=1 ttl=64 time=1.14 ms</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc:~$ sudo ip netns exec amphora-haproxy nc -w4 -vz 192.168.21.114 32315</span><br><span class="line">Connection to 192.168.21.114 32315 port [tcp/*] succeeded!</span><br><span class="line"></span><br><span class="line">#NOTE</span><br><span class="line">os security group rule create --ingress --protocol tcp --remote-group b1eff65c-b6c1-4f09-8ed6-1b163e447318 --dst-port 32315:32315 --ethertype ipv4 3f95d2fa-5ba5-4719-96ee-a0e6211c7c46&quot;</span><br><span class="line">Where remote-group is the sec group associated with the port on 192.168.100.xxx of the amphora VM</span><br><span class="line">And 3f95d2fa-5ba5-4719-96ee-a0e6211c7c46 is the default SG of the juju VMs in the k8s model</span><br><span class="line"></span><br><span class="line">$ nova list --all |grep amp</span><br><span class="line">| 966f0ec0-b48a-48b9-8078-d7406ee08311 | amphora-068104f1-ffee-4b4a-88ab-2e46cee1cbbc | 144901cff394489d9095b1361caa6872 | ACTIVE | -          | Running     | lb-mgmt-net=fc00:961f:bb53:993b:f816:3eff:fe0d:6433; private=192.168.21.174 |</span><br><span class="line">$ nova show 966f0ec0-b48a-48b9-8078-d7406ee08311 |grep sec</span><br><span class="line">| security_groups                      | lb-72d96673-8723-4dde-9035-66c3bd095632, lb-mgmt-sec-grp          |</span><br><span class="line">$ openstack security group rule list lb-72d96673-8723-4dde-9035-66c3bd095632</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | Ethertype | IP Range  | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| 1197c266-015b-4967-8680-35f76328fa85 | tcp         | IPv4      | 0.0.0.0/0 | 1025:1025  | None                  |</span><br><span class="line">| 2f715ac6-f7fb-4823-871c-617559cf8d0d | tcp         | IPv4      | 0.0.0.0/0 | 80:80      | None                  |</span><br><span class="line">| dc0d368e-74f6-4cf0-a863-0e56e071ad46 | None        | IPv4      | 0.0.0.0/0 |            | None                  |</span><br><span class="line">| f38b32b6-3472-43bb-89dc-3f0ef221e95b | None        | IPv6      | ::/0      |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">$ openstack security group rule list lb-mgmt-sec-grp</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | Ethertype | IP Range  | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| 4e913725-bc6b-441f-be3e-8ea668d8d2bd | None        | IPv6      | ::/0      |            | None                  |</span><br><span class="line">| 698d9ee1-86d2-407f-8ec8-2f1453ad2427 | tcp         | IPv6      | ::/0      | 22:22      | None                  |</span><br><span class="line">| b7605acb-feb7-4a47-ba48-c6a395fca934 | tcp         | IPv6      | ::/0      | 9443:9443  | None                  |</span><br><span class="line">| c1b5fcc9-16ee-4f7a-9488-c2096b05941e | None        | IPv4      | 0.0.0.0/0 |            | None                  |</span><br><span class="line">| dcbdaaf2-140c-41e6-8f4e-f36624628047 | icmpv6      | IPv6      | ::/0      |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line"></span><br><span class="line">$ openstack server list |grep 114</span><br><span class="line">| 38d8887c-54ae-4b2c-b0c4-7f64542af8f1 | juju-68d107-k8s-7        | ACTIVE | private=192.168.21.114 | bionic | m1.medium |</span><br><span class="line">$ nova show 38d8887c-54ae-4b2c-b0c4-7f64542af8f1 |grep sec</span><br><span class="line">| security_groups                      | default, juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107, juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107-7                                     |</span><br><span class="line">$ openstack security group rule list juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+-------------+--------------------------------------+</span><br><span class="line">| ID                                   | IP Protocol | Ethertype | IP Range  | Port Range  | Remote Security Group                |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+-------------+--------------------------------------+</span><br><span class="line">| 00469e1d-109c-47ea-878a-403cc47f94f2 | tcp         | IPv6      | ::/0      | 1:65535     | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| 2134cf1f-a82d-43e4-a73f-8b1c06c2e400 | icmp        | IPv4      | 0.0.0.0/0 |             | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| 2a5e6886-4657-4227-b9e6-215a121c70c5 | tcp         | IPv6      | ::/0      | 22:22       | None                                 |</span><br><span class="line">| 430c12ff-0a15-4878-90b0-67ff18ef5cb7 | None        | IPv4      | 0.0.0.0/0 |             | None                                 |</span><br><span class="line">| 4a4644ef-6563-492f-8732-749a5b02eb78 | udp         | IPv4      | 0.0.0.0/0 | 1:65535     | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| 8435b75a-f40b-4adb-9eda-1bbef5aecca6 | icmp        | IPv6      | ::/0      |             | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| 9adf865c-04ed-40db-a506-6a9687efb1b0 | None        | IPv6      | ::/0      |             | None                                 |</span><br><span class="line">| a68fac61-ed0c-4027-96ff-e98d182a287d | tcp         | IPv6      | ::/0      | 17070:17070 | None                                 |</span><br><span class="line">| b475b293-b071-4ae9-a3ab-b8a29cbcce33 | tcp         | IPv4      | 0.0.0.0/0 | 17070:17070 | None                                 |</span><br><span class="line">| c5450f4c-7c82-45a2-a676-4fe3ee413ff5 | tcp         | IPv4      | 0.0.0.0/0 | 1:65535     | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| cf8dd9b6-f59f-4d90-9bbf-76eeb1754680 | udp         | IPv6      | ::/0      | 1:65535     | eee9c463-5689-460e-9ca5-22f880e1a761 |</span><br><span class="line">| f8246bec-4d07-4764-8f37-dd2c204e80e4 | tcp         | IPv4      | 0.0.0.0/0 | 22:22       | None                                 |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+-------------+--------------------------------------+</span><br><span class="line">$ openstack security group rule list juju-f49ad379-07f8-4564-847b-f7999f9df56c-39ead59a-0d9c-4664-8a4d-40a74168d107-7</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | Ethertype | IP Range  | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">| 115688b5-ab4d-4614-afc1-db1458d67ea5 | tcp         | IPv4      | 0.0.0.0/0 | 443:443    | None                  |</span><br><span class="line">| 77bb8ed0-2e7c-4e2f-8320-9acf59b50301 | tcp         | IPv4      | 0.0.0.0/0 | 80:80      | None                  |</span><br><span class="line">| 8c412473-74f0-410f-bd16-7851404743bc | None        | IPv4      | 0.0.0.0/0 |            | None                  |</span><br><span class="line">| ba9a07f9-07d6-4222-ae3c-57255d4a8f83 | None        | IPv6      | ::/0      |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+-----------------------+</span><br><span class="line">$ openstack security group list --project $(openstack project list --domain admin_domain |grep admin |awk &apos;&#123;print $2&#125;&apos;) |grep default</span><br><span class="line">| bfc84b34-6f23-4561-87ff-58077f667bea | default                                                                           | Default security group | 0d1886170941437fa46fb34508e67d24 | []   |</span><br><span class="line"> openstack security group rule list bfc84b34-6f23-4561-87ff-58077f667bea</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+--------------------------------------+</span><br><span class="line">| ID                                   | IP Protocol | Ethertype | IP Range  | Port Range | Remote Security Group                |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+--------------------------------------+</span><br><span class="line">| 12a3c6b3-a4c4-470d-a4d2-dcf6cde5b740 | tcp         | IPv4      | 0.0.0.0/0 | 443:443    | None                                 |</span><br><span class="line">| 13068f00-11d4-4cec-b145-a71b68ffc583 | icmp        | IPv4      | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">| 39ab4cb5-4bee-4272-9811-4e405ae568aa | None        | IPv6      | ::/0      |            | None                                 |</span><br><span class="line">| 3d005483-bd84-467b-8cc6-427771e68645 | tcp         | IPv4      | 0.0.0.0/0 | 80:80      | None                                 |</span><br><span class="line">| 436b644b-cf5f-4dfc-a5b0-f86159f8a3fb | None        | IPv4      | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">| 985dc09f-213c-426e-aedf-35b673fd5830 | tcp         | IPv4      | 0.0.0.0/0 | 53:53      | None                                 |</span><br><span class="line">| 9d936527-04c0-490f-9249-27e2f156d452 | None        | IPv6      | ::/0      |            | bfc84b34-6f23-4561-87ff-58077f667bea |</span><br><span class="line">| e7179f46-a322-43fd-aeef-fce38685e749 | tcp         | IPv4      | 0.0.0.0/0 | 22:22      | None                                 |</span><br><span class="line">| f5b12670-7c76-42e7-9cd8-e0fd1ba5eaef | None        | IPv4      | 0.0.0.0/0 |            | bfc84b34-6f23-4561-87ff-58077f667bea |</span><br><span class="line">| f9fdfe84-b239-4adf-96c5-94402debbf1c | None        | IPv6      | ::/0      |            | None                                 |</span><br><span class="line">| fdb8a39b-747b-4b52-96a3-e8cc0110d6b7 | None        | IPv4      | 0.0.0.0/0 |            | None                                 |</span><br><span class="line">+--------------------------------------+-------------+-----------+-----------+------------+--------------------------------------+</span><br></pre></td></tr></table></figure></p>
<h2 id="20190904更新-octavia测试环境搭建全过程"><a href="#20190904更新-octavia测试环境搭建全过程" class="headerlink" title="20190904更新 - octavia测试环境搭建全过程"></a>20190904更新 - octavia测试环境搭建全过程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br></pre></td><td class="code"><pre><span class="line">juju kill-controller zhhuabj -y -t 1s  #or delete vm directly</span><br><span class="line">rm .local/share/juju/controllers.yaml</span><br><span class="line">#modify your ~/juju_config/2.x/bootstrap.sh to add &apos;container-networking-method=&quot;provider&quot;&apos; in model_defaults variable and comment proxy parts</span><br><span class="line">~/juju_config/2.x/gencloud.sh</span><br><span class="line"></span><br><span class="line">./generate-bundle.sh --name octavia --create-model --run --octavia -r stein --dvr-snat --num-compute 2</span><br><span class="line">./bin/add-data-ports.sh</span><br><span class="line">juju config neutron-openvswitch data-port=&quot;br-data:ens7&quot;</span><br><span class="line">#refere here to create certs - https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-octavia.html</span><br><span class="line">juju config octavia \</span><br><span class="line">    lb-mgmt-issuing-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-private-key=&quot;$(base64 controller_ca_key.pem)&quot; \</span><br><span class="line">    lb-mgmt-issuing-ca-key-passphrase=foobar \</span><br><span class="line">    lb-mgmt-controller-cacert=&quot;$(base64 controller_ca.pem)&quot; \</span><br><span class="line">    lb-mgmt-controller-cert=&quot;$(base64 controller_cert_bundle.pem)&quot;</span><br><span class="line">juju run-action --wait octavia/0 configure-resources</span><br><span class="line">BARE_METAL=TRUE ./configure</span><br><span class="line">juju run-action octavia-diskimage-retrofit/0 --wait retrofit-image image-id=$(openstack image list |grep bionic |awk &apos;&#123;print $2&#125;&apos;)</span><br><span class="line"></span><br><span class="line">wget https://people.canonical.com/~zhhuabj/amphora-x64-haproxy.qcow2  #ssh root@&lt;amphora-ip, password:123qwe</span><br><span class="line">#scp -i ~/.ssh/phykey amphora-x64-haproxy.qcow2 zhhuabj@people.canonical.com:/home/zhhuabj/public_html/</span><br><span class="line">source ~/stsstack-bundles/openstack/novarc</span><br><span class="line">glance image-create --tag octavia-amphora --disk-format qcow2 --name amphora-haproxy-xenial --file ./amphora-x64-haproxy.qcow2 --visibility public --container-format bare --progress</span><br><span class="line">#注意, 20191206更新</span><br><span class="line"># 镜像应该由octavia-diskimage-retrofit来创建来操作apmphora client与api版本一致, 否则会造成service vm无法work</span><br><span class="line">#https://github.com/openstack-charmers/octavia-diskimage-retrofit</span><br><span class="line">#amphora vms have to be created using the uca that corresponds to the release of openstack deployed</span><br><span class="line">#so that amphora client and api versions match, you can build one with the octavia-diskimage-retrofit charm</span><br><span class="line">sudo snap install --edge --devmode octavia-diskimage-retrofit</span><br><span class="line">sudo -s</span><br><span class="line">wget https://cloud-images.ubuntu.com/minimal/releases/bionic/release/ubuntu-18.04-minimal-cloudimg-amd64.img</span><br><span class="line">- or -</span><br><span class="line">wget https://cloud-images.ubuntu.com/minimal/daily/bionic/current/bionic-minimal-cloudimg-amd64.img</span><br><span class="line">sudo mv ubuntu-18.04-minimal-cloudimg-amd64.img /var/snap/octavia-diskimage-retrofit/common</span><br><span class="line">sudo octavia-diskimage-retrofit /var/snap/octavia-diskimage-retrofit/common/ubuntu-18.04-minimal-cloudimg-amd64.img /var/snap/octavia-diskimage-retrofit/common/ubuntu-amphora-haproxy-amd64.qcow2 -d u stein</span><br><span class="line">openstack image create --disk-format qcow2 --container-format bare --public --tag octavia-amphora --file /var/snap/octavia-diskimage-retrofit/common/ubuntu-amphora-haproxy-amd64.qcow2 amphora-bionic-x64-haproxy</span><br><span class="line"></span><br><span class="line">#create a test backend</span><br><span class="line">./tools/instance_launch.sh 1 xenial</span><br><span class="line">./tools/sec_groups.sh</span><br><span class="line">fix_ip=$(openstack server list |grep &apos;private=&apos; |awk -F &apos;=&apos; &apos;&#123;print $2&#125;&apos; |awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">ext_net=$(openstack network show ext_net -f value -c id)</span><br><span class="line">fip=$(openstack floating ip create $ext_net -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $fip --fixed-ip-address $fix_ip --port $(openstack port list --fixed-ip ip-address=$fix_ip -c id -f value)</span><br><span class="line">ssh -i ~/testkey.priv ubuntu@$fip -- sudo apt install python-minimal -y</span><br><span class="line">ssh -i ~/testkey.priv ubuntu@$fip -- sudo python -m SimpleHTTPServer 80 &amp;</span><br><span class="line">curl $fip</span><br><span class="line"></span><br><span class="line">#backend ip 192.168.21.252 (fip: 10.5.151.97)</span><br><span class="line">#service vm fc00:a895:61e6:b86f:f816:3eff:fef7:26f5/192.168.21.54  (vip: 192.168.21.117, fip: 10.5.151.155)</span><br><span class="line">sudo apt install python-octaviaclient python3-octaviaclient</span><br><span class="line">openstack complete |sudo tee /etc/bash_completion.d/openstack</span><br><span class="line">source &lt;(openstack complete)</span><br><span class="line">#No module named &apos;oslo_log&apos;</span><br><span class="line">openstack loadbalancer create --name lb1 --vip-subnet-id private_subnet</span><br><span class="line">#lb_vip_port_id=$(openstack loadbalancer create -f value -c vip_port_id --name lb1 --vip-subnet-id private_subnet)</span><br><span class="line"># Re-run the following until lb1 shows ACTIVE and ONLINE statuses:</span><br><span class="line">openstack loadbalancer show lb1</span><br><span class="line">nova list --all</span><br><span class="line">openstack loadbalancer listener create --name listener1 --protocol HTTP --protocol-port 80 lb1</span><br><span class="line">openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTP</span><br><span class="line">openstack loadbalancer member create --subnet-id private_subnet --address $fix_ip --protocol-port 80 pool1</span><br><span class="line">openstack loadbalancer member list pool1</span><br><span class="line">vip=$(openstack loadbalancer show lb1 -f value -c vip_address)</span><br><span class="line">vip_fip=$(openstack floating ip create $ext_net -f value -c floating_ip_address)</span><br><span class="line">openstack floating ip set $vip_fip --fixed-ip-address $vip --port $(openstack port list --fixed-ip ip-address=$vip -c id -f value)</span><br><span class="line">curl $vip_fip</span><br><span class="line"></span><br><span class="line">#ssh into service vm</span><br><span class="line">nova list --all</span><br><span class="line">juju ssh nova-compute/1 -- sudo ip netns exec qrouter-73d87977-2eaf-40ba-818d-6a17aecd1d16 ping6 fc00:a895:61e6:b86f:f816:3eff:fef7:26f5</span><br><span class="line">#password: 123qwe</span><br><span class="line">juju ssh nova-compute/1 -- sudo ip netns exec qrouter-73d87977-2eaf-40ba-818d-6a17aecd1d16 ssh -6 root@fc00:a895:61e6:b86f:f816:3eff:fef7:26f5</span><br><span class="line">#need to add icmp firewall rule by hand when using ipv4 address</span><br><span class="line">#juju ssh nova-compute/1 -- sudo ip netns exec qrouter-891c4da6-c03b-4a56-a901-a5efb1dbcd15 ssh root@192.168.21.54</span><br><span class="line">#openstack security group rule create lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2 --protocol icmp --remote-ip 0.0.0.0/0</span><br><span class="line">#openstack security group rule create lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2 --protocol tcp --dst-port 22</span><br><span class="line"></span><br><span class="line"># cat /var/lib/octavia/27057bca-c504-4ca2-9bff-89b342767afd/haproxy.cfg</span><br><span class="line"># Configuration for loadbalancer 4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/27057bca-c504-4ca2-9bff-89b342767afd.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">    option splice-request</span><br><span class="line">    option splice-response</span><br><span class="line">    option http-keep-alive</span><br><span class="line">frontend 27057bca-c504-4ca2-9bff-89b342767afd</span><br><span class="line">    option httplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    bind 192.168.21.117:80</span><br><span class="line">    mode http</span><br><span class="line">    default_backend 87d56822-1f5c-4a47-88d6-ddd5d038523d</span><br><span class="line">    timeout client 50000</span><br><span class="line">backend 87d56822-1f5c-4a47-88d6-ddd5d038523d</span><br><span class="line">    mode http</span><br><span class="line">    http-reuse safe</span><br><span class="line">    balance roundrobin</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 4dcd830b-33b2-49e7-b50b-e91b2ce65afb 192.168.21.252:80 weight 1</span><br><span class="line"></span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# cat /etc/netns/amphora-haproxy/network/interfaces.d/eth1.cfg</span><br><span class="line"># Generated by Octavia agent</span><br><span class="line">auto eth1 eth1:0</span><br><span class="line">iface eth1 inet static</span><br><span class="line">address 192.168.21.54</span><br><span class="line">broadcast 192.168.21.255</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 192.168.21.1</span><br><span class="line">mtu 1458</span><br><span class="line">iface eth1:0 inet static</span><br><span class="line">address 192.168.21.117</span><br><span class="line">broadcast 192.168.21.255</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line"># Add a source routing table to allow members to access the VIP</span><br><span class="line">post-up /sbin/ip route add default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">post-down /sbin/ip route del default via 192.168.21.1 dev eth1 onlink table 1</span><br><span class="line">post-up /sbin/ip route add 192.168.21.0/24 dev eth1 src 192.168.21.117 scope link table 1</span><br><span class="line">post-down /sbin/ip route del 192.168.21.0/24 dev eth1 src 192.168.21.117 scope link table 1</span><br><span class="line">post-up /sbin/ip rule add from 192.168.21.117/32 table 1 priority 100</span><br><span class="line">post-down /sbin/ip rule del from 192.168.21.117/32 table 1 priority 100</span><br><span class="line">post-up /sbin/iptables -t nat -A POSTROUTING -p udp -o eth1 -j MASQUERADE</span><br><span class="line">post-down /sbin/iptables -t nat -D POSTROUTING -p udp -o eth1 -j MASQUERADEroot@amphora-91c5098c-7578-4de7-b38e-d3712711bb15</span><br><span class="line"></span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy ip -4 addr show eth1</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1458 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    inet 192.168.21.54/24 brd 192.168.21.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 192.168.21.117/24 brd 192.168.21.255 scope global secondary eth1:0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy ip route list</span><br><span class="line">default via 192.168.21.1 dev eth1 onlink</span><br><span class="line">192.168.21.0/24 dev eth1 proto kernel scope link src 192.168.21.54</span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy ip route list table 1</span><br><span class="line">default via 192.168.21.1 dev eth1 onlink</span><br><span class="line">192.168.21.0/24 dev eth1 scope link src 192.168.21.117</span><br><span class="line"></span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy ip route show table all</span><br><span class="line">default via 192.168.21.1 dev eth1 table 1 onlink</span><br><span class="line">192.168.21.0/24 dev eth1 table 1 scope link src 192.168.21.117</span><br><span class="line">default via 192.168.21.1 dev eth1 onlink</span><br><span class="line">192.168.21.0/24 dev eth1 proto kernel scope link src 192.168.21.54</span><br><span class="line">broadcast 192.168.21.0 dev eth1 table local proto kernel scope link src 192.168.21.54</span><br><span class="line">local 192.168.21.54 dev eth1 table local proto kernel scope host src 192.168.21.54</span><br><span class="line">local 192.168.21.117 dev eth1 table local proto kernel scope host src 192.168.21.54</span><br><span class="line">broadcast 192.168.21.255 dev eth1 table local proto kernel scope link src 192.168.21.54</span><br><span class="line">ff00::/8 dev eth1 table local metric 256 pref medium</span><br><span class="line"></span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy iptables-save</span><br><span class="line"># Generated by iptables-save v1.6.1 on Wed Sep  4 04:00:59 2019</span><br><span class="line">*nat</span><br><span class="line">:PREROUTING ACCEPT [3:448]</span><br><span class="line">:INPUT ACCEPT [3:448]</span><br><span class="line">:OUTPUT ACCEPT [1:60]</span><br><span class="line">:POSTROUTING ACCEPT [1:60]</span><br><span class="line">-A POSTROUTING -o eth1 -p udp -j MASQUERADE</span><br><span class="line">COMMIT</span><br><span class="line"># Completed on Wed Sep  4 04:00:59 2019</span><br><span class="line"></span><br><span class="line">#backend ip 192.168.21.252 (fip: 10.5.151.97)</span><br><span class="line">#service vm fc00:a895:61e6:b86f:f816:3eff:fef7:26f5/192.168.21.54  (vip: 192.168.21.117, fip: 10.5.151.155)</span><br><span class="line"></span><br><span class="line">#ping backend from service vm</span><br><span class="line">root@amphora-91c5098c-7578-4de7-b38e-d3712711bb15:~# ip netns exec amphora-haproxy ping 192.168.21.252</span><br><span class="line">PING 192.168.21.252 (192.168.21.252) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.21.252: icmp_seq=1 ttl=64 time=3.45 ms</span><br><span class="line"></span><br><span class="line">#ping service vm vip from backend</span><br><span class="line">ubuntu@xenial-030345:~$ ping -c 1 192.168.21.54</span><br><span class="line">PING 192.168.21.54 (192.168.21.54) 56(84) bytes of data.</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ nova show aa09d2d0-a8fb-4a2f-bc8f-f39c6dff6713 |grep security_groups</span><br><span class="line">| security_groups                      | lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2, lb-mgmt-sec-grp      |</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-mgmt-sec-grp</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| 1bb77bae-6e4c-4982-8c00-8ebfafd896c7 | icmpv6      | None     |            | None                  |</span><br><span class="line">| 407d8dd6-a0c3-406f-b16d-2453ae4ad015 | tcp         | None     | 9443:9443  | None                  |</span><br><span class="line">| 4d927c00-b4aa-4033-ab66-b96fdb2d9722 | None        | None     |            | None                  |</span><br><span class="line">| 771122a1-ad5e-4842-8ba3-dcd0b950d47a | None        | None     |            | None                  |</span><br><span class="line">| 8b91fd37-dddf-4200-8835-261c203696d0 | tcp         | None     | 22:22      | None                  |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line">| 4eb66163-44dc-44d2-b969-a890d35986a6 | tcp         | None     | 80:80      | None                  |</span><br><span class="line">| 80e0d109-9f97-4559-bc20-de89c001725e | tcp         | None     | 1025:1025  | None                  |</span><br><span class="line">| 92c09499-c9ad-4682-8697-9c17cc33e785 | None        | None     |            | None                  |</span><br><span class="line">| feeb42a2-b49b-4f89-8b3e-5a30cee1e08f | None        | None     |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+----------+------------+-----------------------+</span><br><span class="line"></span><br><span class="line">openstack security group rule create lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2 --protocol icmp --remote-ip 0.0.0.0/0</span><br><span class="line">openstack security group rule create lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2 --protocol tcp --dst-port 22</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack security group rule list lb-4fca1a12-fd1d-4da3-bf7b-e48386c5c1a2</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+-----------------------+</span><br><span class="line">| ID                                   | IP Protocol | IP Range  | Port Range | Remote Security Group |</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+-----------------------+</span><br><span class="line">| 4eb66163-44dc-44d2-b969-a890d35986a6 | tcp         | None      | 80:80      | None                  |</span><br><span class="line">| 80e0d109-9f97-4559-bc20-de89c001725e | tcp         | None      | 1025:1025  | None                  |</span><br><span class="line">| 92c09499-c9ad-4682-8697-9c17cc33e785 | None        | None      |            | None                  |</span><br><span class="line">| 936b47f0-3897-4abe-89fe-37d7c11862ea | icmp        | 0.0.0.0/0 |            | None                  |</span><br><span class="line">| bd832940-7e80-414d-b43b-51042084b934 | tcp         | 0.0.0.0/0 | 22:22      | None                  |</span><br><span class="line">| feeb42a2-b49b-4f89-8b3e-5a30cee1e08f | None        | None      |            | None                  |</span><br><span class="line">+--------------------------------------+-------------+-----------+------------+-----------------------+</span><br><span class="line"></span><br><span class="line">ubuntu@xenial-030345:~$ ping -c 1 10.5.151.155</span><br><span class="line">PING 10.5.151.155 (10.5.151.155) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.5.151.155: icmp_seq=1 ttl=60 time=37.2 ms</span><br><span class="line"></span><br><span class="line">客户遇到的问题:</span><br><span class="line">1, arp issue - https://bugs.launchpad.net/neutron/+bug/1794991/comments/59</span><br><span class="line">2, fip issue - 对于octavia的计算节点使用了没有data-port的neutron-openvswitch charm, dvr-snat会在一堆计算节点中找一个来安装snat-xxx, 这样当恰好找了一个没有data-port的ocatavia计算节点就出问题了 (如使用了https://bugs.launchpad.net/charm-neutron-openvswitch/+bug/1822558中提到的neutron-openvswitch-octavia)</span><br><span class="line">3, https://bugs.launchpad.net/charm-neutron-openvswitch/+bug/1843557</span><br><span class="line">4, 最后建议使用一个existing provider network解决 （一个tenant看不见它的话需要使用rbac设置共享)</span><br></pre></td></tr></table></figure>
<h2 id="20191207更新"><a href="#20191207更新" class="headerlink" title="20191207更新"></a>20191207更新</h2><p>遇到又一例, service vm不work, 创建lb后, service vm是ACTIVE状态其管理网段IP也work, 但LB的状态是PENDING_STATE, 但LB有VIP也可以ssh, 但过一会之后, service vm变成ERROR状态且被删除. 查出来的原因是:<br>During verification of the agent update, It was also found that firewall changes introduced caused DNS to become unreachable for the octavia load balancer instances. These rules have been updated to allow access, which allowed DNS to work inside the amphora VMs, which in turn, in combination with disabling a host, and the update of the agent,returned the load balancers to a working ‘state.”</p>
<h2 id="20200220更新"><a href="#20200220更新" class="headerlink" title="20200220更新"></a>20200220更新</h2><p>用下列方法更新添加nbthread元素之后，LB创建成功后一会儿死掉，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">juju config octavia haproxy-template | base64 -d &gt; /tmp/haproxy-custom.j2</span><br><span class="line">vim /tmp/haproxy-custom.j2 # edit the nbthread option</span><br><span class="line">nbproc 1</span><br><span class="line">nbthread 2</span><br><span class="line">cpu-map auto:1/1-2 0-1</span><br><span class="line">maxconns=64000</span><br><span class="line">juju config octavia haproxy-template=&quot;$(base64 /tmp/haproxy-custom.j2)&quot;</span><br></pre></td></tr></table></figure></p>
<p>这种问题一般能从octavia-worker.log中找到答案：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2020-02-19 04:53:11.465 14180 ERROR octavia.controller.worker.controller_worker jinja2.exceptions.UndefinedError: &apos;dict object&apos; has no attribute &apos;listener&apos;</span><br></pre></td></tr></table></figure></p>
<p>原因是这个patch(<a href="https://review.opendev.org/#/c/673518/)引入了combined_listeners" target="_blank" rel="external">https://review.opendev.org/#/c/673518/)引入了combined_listeners</a>, combined_listeners是为了解决下列问题：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Since 1.8.x version, haproxy consumes at least 160MB at init time using the default configuration provided by octavia. When a LB is updated, haproxy configuration is updated and a signal is sent to haproxy to reload the configuration.</span><br><span class="line">When haproxy reloads its configuration, it creates a new worker, does some allocations (up to 160MB), then destroys the previous worker. So during a short time, memory consumption is increased, and if 2 processes reload a the same time, it may fail with a &quot;Cannot fork&quot; error.</span><br></pre></td></tr></table></figure></p>
<p>所以custom template (<a href="https://paste.ubuntu.com/p/PGvD7fzjd2/" target="_blank" rel="external">https://paste.ubuntu.com/p/PGvD7fzjd2/</a> )中的之前的split_listeners的中loadbalancer.listener.pools应该改成现在combined_listeners中的loadbalancer.listeners.pools</p>
<h2 id="20200427更新"><a href="#20200427更新" class="headerlink" title="20200427更新 -"></a>20200427更新 -</h2><p>另一个问题, 如下, socket.getfqdn在处理/etc/hosts里的fqdn(见: <a href="https://bugs.python.org/issue5004" target="_blank" rel="external">https://bugs.python.org/issue5004</a>), 所以还是要使用socket.getaddrinfo代替socket.getfqdn来处理fqdn (neutron agent现在改成使用fqdn注册), 但观察到socket.getaddrinfo时时而能获取到fqdn时而不能获取, 从而导致octavia里的出现binding error从而导致o-hm0无法获取IP.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@juju-5b1810-octavia-6:~$ python3 -c &apos;import socket; print(socket.getaddrinfo(&quot;juju-5b1810-octavia-6&quot;, None, 0, socket.SOCK_DGRAM, 0,</span><br><span class="line">socket.AI_CANONNAME)[0][3])&apos;</span><br><span class="line">juju-5b1810-octavia-6</span><br><span class="line"></span><br><span class="line">ubuntu@juju-5b1810-octavia-6:~$ python3 -c &apos;import socket; print(socket.getfqdn(&quot;juju-5b1810-octavia-6&quot;))&apos;</span><br><span class="line">juju-5b1810-octavia-6.cloud.sts</span><br><span class="line"></span><br><span class="line">ubuntu@juju-5b1810-octavia-6:~$ python3 -c &apos;import socket; print(socket.getaddrinfo(&quot;juju-5b1810-octavia-6&quot;, None, 0, socket.SOCK_DGRAM, 0,</span><br><span class="line">&gt; socket.AI_CANONNAME))&apos;</span><br><span class="line">[(&lt;AddressFamily.AF_INET: 2&gt;, &lt;SocketKind.SOCK_DGRAM: 2&gt;, 17, &apos;juju-5b1810-octavia-6&apos;, (&apos;10.5.0.14&apos;, 0)), (&lt;AddressFamily.AF_INET: 2&gt;, &lt;SocketKind.SOCK_DGRAM: 2&gt;, 17, &apos;&apos;, (&apos;252.0.14.1&apos;, 0)), (&lt;AddressFamily.AF_INET6: 10&gt;, &lt;SocketKind.SOCK_DGRAM: 2&gt;, 17, &apos;&apos;, (&apos;fe80::f816:3eff:fe8a:6e3&apos;, 0, 0, 0)), (&lt;AddressFamily.AF_INET6: 10&gt;, &lt;SocketKind.SOCK_DGRAM: 2&gt;, 17, &apos;&apos;, (&apos;fe80::34b8:fff:feea:4717&apos;, 0, 0, 0)), (&lt;AddressFamily.AF_INET6: 10&gt;, &lt;SocketKind.SOCK_DGRAM: 2&gt;, 17, &apos;&apos;, (&apos;fe80::34b8:fff:feea:4717&apos;, 0, 0, 0))]</span><br><span class="line"></span><br><span class="line">ubuntu@juju-5b1810-octavia-6:~$ hostname --fqdn</span><br><span class="line">juju-5b1810-octavia-6</span><br><span class="line">ubuntu@juju-5b1810-octavia-6:~$ hostname --all-fqdns</span><br><span class="line">juju-5b1810-octavia-6.cloud.sts juju-5b1810-octavia-6</span><br><span class="line">ubuntu@juju-5b1810-octavia-6:~$ hostname -f</span><br><span class="line">juju-5b1810-octavia-6</span><br></pre></td></tr></table></figure></p>
<p>尤其是vm里的/etc/resovle.conf里用到了如maas dns与neutron ml2-dns等多个search项时, ml2-dns的search项排到第一位时会导致octavia上的l2-agent无法正常处理fqdn从而导致 o-hm0无IP, 见: <a href="https://bugs.launchpad.net/charm-octavia/+bug/1845303/comments/15" target="_blank" rel="external">https://bugs.launchpad.net/charm-octavia/+bug/1845303/comments/15</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">while true; do for X in &#123;0..2&#125;; do juju ssh octavia/$X &quot;cat /etc/resolv.conf | grep -v &quot;^#&quot;; sudo python -c &apos;import socket; name=socket.gethostname(); addrs = socket.getaddrinfo(name, None, 0, socket.SOCK_DGRAM, 0, socket.AI_CANONNAME); print(addrs)&apos;&quot; 2&gt;/dev/null; done; done</span><br></pre></td></tr></table></figure></p>
<p>解决方法是在systemd-network中使用UseDomains=route<br>UseDomains接受布尔参数或特殊值“ route”。设置为true时，将从DHCP服务器(neutron dns)收到的域名用作DNS, 通过该链接搜索域。如果设置为“ route”，则从DHCP接收的域名 , 服务器将仅用于路由DNS查询.</p>
<h2 id="产生密钥"><a href="#产生密钥" class="headerlink" title="产生密钥"></a>产生密钥</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">#https://www.dazhuanlan.com/2019/12/15/5df63aed10999</span><br><span class="line">#generate ca key pairs</span><br><span class="line">mkdir -p ca/&#123;private,certs,newcerts&#125; &amp;&amp; cd ca</span><br><span class="line">openssl genrsa -aes256 -passout pass:password -out private/ca.key.pem 4096</span><br><span class="line">chmod 400 private/ca.key.pem</span><br><span class="line">wget https://jamielinux.com/docs/openssl-certificate-authority/_downloads/root-config.txt -O openssl.cnf</span><br><span class="line">sed -i &quot;s,/root/ca,.,g&quot; openssl.cnf</span><br><span class="line">openssl req -config ./openssl.cnf -key private/ca.key.pem -new -x509 -days 7300 -sha256 -extensions v3_ca -passin pass:password \</span><br><span class="line">     -subj &quot;/C=CN/ST=BJ/O=STS/OU=quqi.com/CN=quqi.com.rootca/emailAddress=quqi@mail.com&quot; -out certs/ca.cert.pem</span><br><span class="line">chmod 444 certs/ca.cert.pem</span><br><span class="line">openssl x509 -noout -text -in certs/ca.cert.pem #verify</span><br><span class="line"></span><br><span class="line">#generate intermediate key pairs</span><br><span class="line">mkdir -p intermediate/&#123;certs,crl,csr,newcerts,private&#125;</span><br><span class="line">chmod 744 intermediate/private</span><br><span class="line">touch index.txt &amp;&amp; echo 1000 &gt; serial &amp;&amp; echo 1000 &gt; crlnumber</span><br><span class="line">openssl genrsa -aes256 -passout pass:password -out intermediate/private/intermediate.key.pem 4096</span><br><span class="line">chmod 400 intermediate/private/intermediate.key.pem</span><br><span class="line">cp ./openssl.cnf ./openssl-im.cnf</span><br><span class="line">#modify the following section of openssl-im.cnf file</span><br><span class="line">[ CA_default ]</span><br><span class="line">dir             = .</span><br><span class="line">private_key     = $dir/private/intermediate.key.pem</span><br><span class="line">certificate     = $dir/certs/intermediate.cert.pem</span><br><span class="line">crl             = $dir/crl/intermediate.crl.pem</span><br><span class="line">policy          = policy_loose</span><br><span class="line">openssl req -config ./openssl-im.cnf -new -sha256 -passin pass:password \</span><br><span class="line">     -subj &quot;/C=CN/ST=BJ/O=STS/OU=quqi.com/CN=quqi.com.imca/emailAddress=quqi@mail.com&quot; \</span><br><span class="line">     -key intermediate/private/intermediate.key.pem -out intermediate/csr/intermediate.csr.pem</span><br><span class="line">openssl ca -config ./openssl.cnf -extensions v3_intermediate_ca -days 3650 -notext -md sha256 -passin pass:password \</span><br><span class="line">     -in intermediate/csr/intermediate.csr.pem -out intermediate/certs/intermediate.cert.pem</span><br><span class="line">chmod 444 intermediate/certs/intermediate.cert.pem</span><br><span class="line">openssl x509 -noout -text -in intermediate/certs/intermediate.cert.pem</span><br><span class="line">openssl verify -CAfile certs/ca.cert.pem intermediate/certs/intermediate.cert.pem</span><br><span class="line"></span><br><span class="line">#generate certificate chain</span><br><span class="line">cat intermediate/certs/intermediate.cert.pem certs/ca.cert.pem &gt; intermediate/certs/ca-chain.cert.pem</span><br><span class="line">chmod 444 intermediate/certs/ca-chain.cert.pem</span><br><span class="line"></span><br><span class="line">#generate clinet.quqi.com key pairs</span><br><span class="line">openssl genrsa -out intermediate/private/client.quqi.com.key.pem 2048</span><br><span class="line">chmod 444 intermediate/private/client.quqi.com.key.pem</span><br><span class="line">openssl req -config ./openssl-im.cnf -key intermediate/private/client.quqi.com.key.pem \</span><br><span class="line">     -subj &quot;/C=CN/ST=BJ/O=STS/OU=quqi.com/CN=client.quqi.com/emailAddress=quqi@mail.com&quot; \</span><br><span class="line">     -new -sha256 -out intermediate/csr/client.quqi.com.csr.pem</span><br><span class="line">openssl ca -config ./openssl.cnf -extensions server_cert -days 3650 -notext -md sha256 -passin pass:password\</span><br><span class="line">     -in intermediate/csr/client.quqi.com.csr.pem -out intermediate/certs/client.quqi.com.cert.pem</span><br><span class="line">chmod 444 intermediate/certs/client.quqi.com.cert.pem</span><br><span class="line">openssl x509 -noout -text -in intermediate/certs/client.quqi.com.cert.pem</span><br><span class="line">openssl verify -CAfile intermediate/certs/ca-chain.cert.pem intermediate/certs/client.quqi.com.cert.pem</span><br></pre></td></tr></table></figure>
<h2 id="证书"><a href="#证书" class="headerlink" title="证书"></a>证书</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">openssl req -newkey rsa:4096 -x509 -sha256 -days 3650 -nodes -out ca.crt -keyout ca.key -subj &quot;/C=US/ST=UK/L=London/O=Ubuntu/OU=IT/CN=CA&quot;</span><br><span class="line">openssl genrsa -out server.key</span><br><span class="line">openssl req -new -key server.key -out server.csr -subj &quot;/C=GB/ST=UK/L=London/O=Ubuntu/OU=Cloud/CN=server&quot;</span><br><span class="line">openssl x509 -req -in server.csr -out server.crt -sha256 -CA ca.crt -CAkey ca.key -CAcreateserial -days 3650</span><br><span class="line">cat server.crt server.key &gt; server.pem</span><br><span class="line">openssl x509 -noout -text -in server.crt |grep CN</span><br><span class="line">#openssl pkcs12 -export -inkey server.key -in server.crt -certfile ca.crt -passout pass: -out server.p12</span><br><span class="line">#kubectl create secret generic keystone-auth-certs --from-file=cert-file=server.crt --from-file=key-file=server.key -n kube-system</span><br><span class="line"></span><br><span class="line">sudo apt install python3-minimal -y</span><br><span class="line">sudo bash -c &apos;cat &gt;simple-https-server.py&apos; &lt;&lt;EOF</span><br><span class="line">#!/usr/bin/env python3</span><br><span class="line"># coding=utf-8</span><br><span class="line">import http.server, ssl</span><br><span class="line">server_address = (&apos;0.0.0.0&apos;, 443)</span><br><span class="line">httpd = http.server.HTTPServer(server_address, http.server.SimpleHTTPRequestHandler)</span><br><span class="line">httpd.socket = ssl.wrap_socket(httpd.socket,</span><br><span class="line">                               server_side=True,</span><br><span class="line">                               keyfile=&apos;server.key&apos;,</span><br><span class="line">                               certfile=&apos;server.crt&apos;,</span><br><span class="line">                               ssl_version=ssl.PROTOCOL_TLS)</span><br><span class="line">httpd.serve_forever()</span><br><span class="line">EOF</span><br><span class="line">sudo bash -c &apos;cat &gt;index.html&apos; &lt;&lt;EOF</span><br><span class="line">test1</span><br><span class="line">EOF</span><br><span class="line">sudo python3 simple-https-server.py</span><br><span class="line">#nohup sudo python3 simple-https-server.py &amp;</span><br><span class="line"></span><br><span class="line">$ curl -k https://192.168.99.136</span><br><span class="line">test1</span><br><span class="line">$ curl --cacert ./ca.crt https://192.168.99.136</span><br><span class="line">curl: (60) SSL: certificate subject name &apos;server&apos; does not match target host name &apos;192.168.99.136&apos;</span><br><span class="line">$ curl --resolve server:443:192.168.99.136 --cacert ./ca.crt https://server</span><br><span class="line">test1</span><br><span class="line"></span><br><span class="line">注意：当为keystone创建key时，应该使用domain而不是ip避免SNI问题，同时务必记得为keystone配置hostname让openstackclient也能拿到带domain的url</span><br></pre></td></tr></table></figure>
<h2 id="20200515更新-loadbalancer-topology-ACTIVE-STANDBY’"><a href="#20200515更新-loadbalancer-topology-ACTIVE-STANDBY’" class="headerlink" title="20200515更新 - loadbalancer-topology=ACTIVE_STANDBY’"></a>20200515更新 - loadbalancer-topology=ACTIVE_STANDBY’</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br></pre></td><td class="code"><pre><span class="line">After running &apos;juju config octavia loadbalancer-topology=ACTIVE_STANDBY&apos;</span><br><span class="line"></span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack loadbalancer list</span><br><span class="line">+--------------------------------------+------------------------------------------------------------------------+----------------------------------+---------------+---------------------+----------+</span><br><span class="line">| id                                   | name                                                                   | project_id                       | vip_address   | provisioning_status | provider |</span><br><span class="line">+--------------------------------------+------------------------------------------------------------------------+----------------------------------+---------------+---------------------+----------+</span><br><span class="line">| dc343e21-0dca-4be3-8815-c5645e07c28d | kube_service_kubernetes-tkwt84oxsw1bvxt0xorlgp3ibcrwgjo9_default_hello | 40cd6bca224f46c9b34c0f6813c1f2d0 | 192.168.21.63 | ACTIVE              | amphora  |</span><br><span class="line">+--------------------------------------+------------------------------------------------------------------------+----------------------------------+---------------+---------------------+----------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ openstack loadbalancer amphora list</span><br><span class="line">+--------------------------------------+--------------------------------------+-----------+--------+-----------------------------------------+---------------+</span><br><span class="line">| id                                   | loadbalancer_id                      | status    | role   | lb_network_ip                           | ha_ip         |</span><br><span class="line">+--------------------------------------+--------------------------------------+-----------+--------+-----------------------------------------+---------------+</span><br><span class="line">| a82b27d0-68cb-49a7-9387-4df3dbe617ca | dc343e21-0dca-4be3-8815-c5645e07c28d | ALLOCATED | BACKUP | fc00:9084:1613:154e:f816:3eff:fee3:7bf8 | 192.168.21.63 |</span><br><span class="line">| d03e0ab4-a23c-4a4c-939c-3bcaf5356e30 | dc343e21-0dca-4be3-8815-c5645e07c28d | ALLOCATED | MASTER | fc00:9084:1613:154e:f816:3eff:fe70:dc9c | 192.168.21.63 |</span><br><span class="line">+--------------------------------------+--------------------------------------+-----------+--------+-----------------------------------------+---------------+</span><br><span class="line">ubuntu@zhhuabj-bastion:~$ kubectl get svc</span><br><span class="line">NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">hello        LoadBalancer   10.152.183.26   10.5.150.54   80:32371/TCP   9m17s</span><br><span class="line">kubernetes   ClusterIP      10.152.183.1    &lt;none&gt;        443/TCP        16h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">juju scp ~/.ssh/id_amphora* nova-compute/8:/home/ubuntu/</span><br><span class="line">juju ssh nova-compute/8 -- sudo ip netns exec qrouter-b03302b5-fc48-4ef7-8ded-ba17ac20c6da ssh -6 -i ~/id_amphora ubuntu@fc00:9084:1613:154e:f816:3eff:fe70:dc9c</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-d03e0ab4-a23c-4a4c-939c-3bcaf5356e30:~$ sudo cat /var/lib/octavia/dc343e21-0dca-4be3-8815-c5645e07c28d/haproxy.cfg</span><br><span class="line">sudo: unable to resolve host amphora-d03e0ab4-a23c-4a4c-939c-3bcaf5356e30</span><br><span class="line"># Configuration for loadbalancer dc343e21-0dca-4be3-8815-c5645e07c28d</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/dc343e21-0dca-4be3-8815-c5645e07c28d.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">    option splice-request</span><br><span class="line">    option splice-response</span><br><span class="line">    option http-keep-alive</span><br><span class="line"></span><br><span class="line">peers dc343e210dca4be38815c5645e07c28d_peers</span><br><span class="line">    peer dVi2pNT1gedR2yc35WJnwbb5fQI 192.168.21.60:1025</span><br><span class="line">    peer ejcAi8u6hFfukxfJNty7MxS8unY 192.168.21.241:1025</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend 3d6a3f5a-c35d-4718-809d-e1cce82b059b</span><br><span class="line">    option tcplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    bind 192.168.21.63:80</span><br><span class="line">    mode tcp</span><br><span class="line">    default_backend c28d0103-75cd-42f2-ba7b-ee7c3946eb81:3d6a3f5a-c35d-4718-809d-e1cce82b059b</span><br><span class="line">    timeout client 50000</span><br><span class="line"></span><br><span class="line">backend c28d0103-75cd-42f2-ba7b-ee7c3946eb81:3d6a3f5a-c35d-4718-809d-e1cce82b059b</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 193a2e05-12a5-4aa3-baf2-1bcc0847324c 192.168.21.160:32371 weight 1</span><br><span class="line">    server 79ea1870-45e9-4934-9a11-5826271dec96 192.168.21.252:32371 weight 1</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-d03e0ab4-a23c-4a4c-939c-3bcaf5356e30:~$ sudo cat /var/lib/octavia/vrrp/octavia-keepalived.conf</span><br><span class="line">sudo: unable to resolve host amphora-d03e0ab4-a23c-4a4c-939c-3bcaf5356e30</span><br><span class="line">vrrp_script check_script &#123;</span><br><span class="line">  script /var/lib/octavia/vrrp/check_script.sh</span><br><span class="line">  interval 5</span><br><span class="line">  fall 2</span><br><span class="line">  rise 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance dc343e210dca4be38815c5645e07c28d &#123;</span><br><span class="line">  state MASTER</span><br><span class="line">  interface eth1</span><br><span class="line">  virtual_router_id 1</span><br><span class="line">  priority 100</span><br><span class="line">  nopreempt</span><br><span class="line">  accept</span><br><span class="line">  garp_master_refresh 5</span><br><span class="line">  garp_master_refresh_repeat 2</span><br><span class="line">  advert_int 1</span><br><span class="line">  authentication &#123;</span><br><span class="line">    auth_type PASS</span><br><span class="line">    auth_pass 36750c5</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  unicast_src_ip 192.168.21.241</span><br><span class="line">  unicast_peer &#123;</span><br><span class="line">    192.168.21.60</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  virtual_ipaddress &#123;</span><br><span class="line">    192.168.21.63</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  virtual_routes &#123;</span><br><span class="line">    192.168.21.0/24 dev eth1 src 192.168.21.63 scope link table 1</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  virtual_rules &#123;</span><br><span class="line">    from 192.168.21.63/32 table 1 priority 100</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  track_script &#123;</span><br><span class="line">    check_script</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-d03e0ab4-a23c-4a4c-939c-3bcaf5356e30:~$ sudo ip netns exec amphora-haproxy ip addr show</span><br><span class="line">sudo: unable to resolve host amphora-d03e0ab4-a23c-4a4c-939c-3bcaf5356e30</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1508 qdisc fq state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:67:47:a7 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.21.241/24 brd 192.168.21.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 192.168.21.63/32 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">juju ssh nova-compute/8 -- sudo ip netns exec qrouter-b03302b5-fc48-4ef7-8ded-ba17ac20c6da ssh -6 -i ~/id_amphora ubuntu@fc00:9084:1613:154e:f816:3eff:fee3:7bf8</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-a82b27d0-68cb-49a7-9387-4df3dbe617ca:~$ sudo cat /var/lib/octavia/dc343e21-0dca-4be3-8815-c5645e07c28d/haproxy.cfg</span><br><span class="line">sudo: unable to resolve host amphora-a82b27d0-68cb-49a7-9387-4df3dbe617ca</span><br><span class="line"># Configuration for loadbalancer dc343e21-0dca-4be3-8815-c5645e07c28d</span><br><span class="line">global</span><br><span class="line">    daemon</span><br><span class="line">    user nobody</span><br><span class="line">    log /dev/log local0</span><br><span class="line">    log /dev/log local1 notice</span><br><span class="line">    stats socket /var/lib/octavia/dc343e21-0dca-4be3-8815-c5645e07c28d.sock mode 0666 level user</span><br><span class="line">    maxconn 1000000</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    log global</span><br><span class="line">    retries 3</span><br><span class="line">    option redispatch</span><br><span class="line">    option splice-request</span><br><span class="line">    option splice-response</span><br><span class="line">    option http-keep-alive</span><br><span class="line"></span><br><span class="line">peers dc343e210dca4be38815c5645e07c28d_peers</span><br><span class="line">    peer dVi2pNT1gedR2yc35WJnwbb5fQI 192.168.21.60:1025</span><br><span class="line">    peer ejcAi8u6hFfukxfJNty7MxS8unY 192.168.21.241:1025</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">frontend 3d6a3f5a-c35d-4718-809d-e1cce82b059b</span><br><span class="line">    option tcplog</span><br><span class="line">    maxconn 1000000</span><br><span class="line">    bind 192.168.21.63:80</span><br><span class="line">    mode tcp</span><br><span class="line">    default_backend c28d0103-75cd-42f2-ba7b-ee7c3946eb81:3d6a3f5a-c35d-4718-809d-e1cce82b059b</span><br><span class="line">    timeout client 50000</span><br><span class="line"></span><br><span class="line">backend c28d0103-75cd-42f2-ba7b-ee7c3946eb81:3d6a3f5a-c35d-4718-809d-e1cce82b059b</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    fullconn 1000000</span><br><span class="line">    option allbackups</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout server 50000</span><br><span class="line">    server 193a2e05-12a5-4aa3-baf2-1bcc0847324c 192.168.21.160:32371 weight 1</span><br><span class="line">    server 79ea1870-45e9-4934-9a11-5826271dec96 192.168.21.252:32371 weight 1</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-a82b27d0-68cb-49a7-9387-4df3dbe617ca:~$ sudo cat /var/lib/octavia/vrrp/octavia-keepalived.conf</span><br><span class="line">sudo: unable to resolve host amphora-a82b27d0-68cb-49a7-9387-4df3dbe617ca</span><br><span class="line">vrrp_script check_script &#123;</span><br><span class="line">  script /var/lib/octavia/vrrp/check_script.sh</span><br><span class="line">  interval 5</span><br><span class="line">  fall 2</span><br><span class="line">  rise 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance dc343e210dca4be38815c5645e07c28d &#123;</span><br><span class="line">  state BACKUP</span><br><span class="line">  interface eth1</span><br><span class="line">  virtual_router_id 1</span><br><span class="line">  priority 90</span><br><span class="line">  nopreempt</span><br><span class="line">  accept</span><br><span class="line">  garp_master_refresh 5</span><br><span class="line">  garp_master_refresh_repeat 2</span><br><span class="line">  advert_int 1</span><br><span class="line">  authentication &#123;</span><br><span class="line">    auth_type PASS</span><br><span class="line">    auth_pass 36750c5</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  unicast_src_ip 192.168.21.60</span><br><span class="line">  unicast_peer &#123;</span><br><span class="line">    192.168.21.241</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  virtual_ipaddress &#123;</span><br><span class="line">    192.168.21.63</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  virtual_routes &#123;</span><br><span class="line">    192.168.21.0/24 dev eth1 src 192.168.21.63 scope link table 1</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  virtual_rules &#123;</span><br><span class="line">    from 192.168.21.63/32 table 1 priority 100</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  track_script &#123;</span><br><span class="line">    check_script</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ubuntu@amphora-a82b27d0-68cb-49a7-9387-4df3dbe617ca:~$ sudo ip netns exec amphora-haproxy ip addr show</span><br><span class="line">sudo: unable to resolve host amphora-a82b27d0-68cb-49a7-9387-4df3dbe617ca</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1508 qdisc fq state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:b7:fb:25 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.21.60/24 brd 192.168.21.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="http://www.iceyao.com.cn/2017/11/19/Neutron-lbaas%E4%BB%A3%E7%90%86https%E5%AE%9E%E8%B7%B5/" target="_blank" rel="external">http://www.iceyao.com.cn/2017/11/19/Neutron-lbaas%E4%BB%A3%E7%90%86https%E5%AE%9E%E8%B7%B5/</a><br>[2] <a href="https://wiki.openstack.org/wiki/Network/LBaaS/docs/how-to-create-tls-loadbalancer#Update_neutron_config" target="_blank" rel="external">https://wiki.openstack.org/wiki/Network/LBaaS/docs/how-to-create-tls-loadbalancer#Update_neutron_config</a><br>[3] <a href="https://serversforhackers.com/c/using-ssl-certificates-with-haproxy" target="_blank" rel="external">https://serversforhackers.com/c/using-ssl-certificates-with-haproxy</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/10/29/为租户下的虚机提供IPv6-DNS服务/" rel="next" title="为租户下的虚机提供IPv6 DNS服务">
                <i class="fa fa-chevron-left"></i> 为租户下的虚机提供IPv6 DNS服务
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/01/02/Using-kubeadm-to-deploy-k8s/" rel="prev" title="Using kubeadm to deploy k8s">
                Using kubeadm to deploy k8s <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">张华</p>
              <p class="site-description motion-element" itemprop="description">blog.csdn.net/quqi99</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">70</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#几张图感性认识ocatvia"><span class="nav-number">1.</span> <span class="nav-text">几张图感性认识ocatvia</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#问题"><span class="nav-number">2.</span> <span class="nav-text">问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装Octavia"><span class="nav-number">3.</span> <span class="nav-text">安装Octavia</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#测试虚机中安装HTTPS测试服务"><span class="nav-number">4.</span> <span class="nav-text">测试虚机中安装HTTPS测试服务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#测试虚机中安装HTTP测试服务"><span class="nav-number">5.</span> <span class="nav-text">测试虚机中安装HTTP测试服务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#How-to-ssh-into-amphora-service-vm"><span class="nav-number">6.</span> <span class="nav-text">How to ssh into amphora service vm</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deploy-a-non-terminated-HTTPS-load-balancer"><span class="nav-number">7.</span> <span class="nav-text">Deploy a non-terminated HTTPS load balancer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deploy-a-TLS-terminated-HTTPS-load-balancer"><span class="nav-number">8.</span> <span class="nav-text">Deploy a TLS-terminated HTTPS load balancer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#附件-Neutron-LBaaS-v2"><span class="nav-number">9.</span> <span class="nav-text">附件 - Neutron LBaaS v2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#附录-上层的k8s如何使用下层的openstack中的LBaaS资源"><span class="nav-number">10.</span> <span class="nav-text">附录 - 上层的k8s如何使用下层的openstack中的LBaaS资源</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#20190904更新-octavia测试环境搭建全过程"><span class="nav-number">11.</span> <span class="nav-text">20190904更新 - octavia测试环境搭建全过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#20191207更新"><span class="nav-number">12.</span> <span class="nav-text">20191207更新</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#20200220更新"><span class="nav-number">13.</span> <span class="nav-text">20200220更新</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#20200427更新"><span class="nav-number">14.</span> <span class="nav-text">20200427更新 -</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#产生密钥"><span class="nav-number">15.</span> <span class="nav-text">产生密钥</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#证书"><span class="nav-number">16.</span> <span class="nav-text">证书</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#20200515更新-loadbalancer-topology-ACTIVE-STANDBY’"><span class="nav-number">17.</span> <span class="nav-text">20200515更新 - loadbalancer-topology=ACTIVE_STANDBY’</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">18.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张华</span>

  
</div>


  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
