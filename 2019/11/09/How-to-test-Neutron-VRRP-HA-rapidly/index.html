<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="作者：张华  发表于：2015-12-09版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (http://blog.csdn.net/quqi99 ) neutron vrrp ha still do not support conntrack feature now. 1, Setting up test environment juju add-mode">
<meta property="og:type" content="article">
<meta property="og:title" content="How to test Neutron VRRP HA rapidly">
<meta property="og:url" content="http://yoursite.com/2019/11/09/How-to-test-Neutron-VRRP-HA-rapidly/index.html">
<meta property="og:site_name" content="技术并艺术着">
<meta property="og:description" content="作者：张华  发表于：2015-12-09版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (http://blog.csdn.net/quqi99 ) neutron vrrp ha still do not support conntrack feature now. 1, Setting up test environment juju add-mode">
<meta property="og:updated_time" content="2019-11-09T05:03:42.675Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="How to test Neutron VRRP HA rapidly">
<meta name="twitter:description" content="作者：张华  发表于：2015-12-09版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明 (http://blog.csdn.net/quqi99 ) neutron vrrp ha still do not support conntrack feature now. 1, Setting up test environment juju add-mode">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/11/09/How-to-test-Neutron-VRRP-HA-rapidly/"/>





  <title>How to test Neutron VRRP HA rapidly | 技术并艺术着</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">技术并艺术着</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">张华的技术博客 - blog.csdn.net/quqi99</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/09/How-to-test-Neutron-VRRP-HA-rapidly/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张华">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术并艺术着">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">How to test Neutron VRRP HA rapidly</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-09T13:03:23+08:00">
                2019-11-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>作者：张华  发表于：2015-12-09<br>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</p>
<p>(<a href="http://blog.csdn.net/quqi99" target="_blank" rel="external">http://blog.csdn.net/quqi99</a> )</p>
<p>neutron vrrp ha still do not support conntrack feature now.</p>
<p>1, Setting up test environment</p>
<p>juju add-model queens-vrrp<br>juju deploy ./b/openstack.yaml</p>
<p>juju add-unit neutron-gateway<br>juju ssh neutron-gateway/1 – hostname<br>source ~/novarc &amp;&amp; nova interface-attach $(openstack server list -f value |awk ‘/juju-4262ae-queens-vrrp-10/ {print $1}’) –net-id=$(openstack network list -f value |awk ‘/ zhhuabj_admin_net / {print $1}’)<br>juju ssh neutron-gateway/1 – sudo ovs-vsctl add-port br-data ens7<br>juju ssh neutron-gateway/1 – sudo ifconfig ens7 up<br>juju config neutron-api overlay-network-type=vxlan<br>juju config neutron-api enable-l3ha=true</p>
<p>./configure<br>source ~/stsstack-bundles/novarc<br>./tools/instance_launch.sh 1 xenial<br>./tools/sec_groups.sh</p>
<p>fix_ip=$(openstack server list -f value |awk ‘/xenial/ {print $4}’ |awk -F ‘=’ ‘{print $2}’)<br>public_network=$(openstack network show ext_net -f value -c id)<br>fip=$(openstack floating ip create $public_network -f value -c floating_ip_address)<br>openstack floating ip set $fip –fixed-ip-address $fix_ip –port $(openstack port list –fixed-ip ip-address=$fix_ip -c id -f value)</p>
<h1 id="update-the-existing-router-as-ha-router"><a href="#update-the-existing-router-as-ha-router" class="headerlink" title="update the existing router as ha router"></a>update the existing router as ha router</h1><p>#ROUTER_ID=$(neutron router-show provider-router -c id -f value)</p>
<p>#neutron router-update $ROUTER_ID –admin_state_up=false ; neutron router-update $ROUTER_ID –ha=true; neutron router-update $ROUTER_ID –admin_state_up=true</p>
<p>#AGENT_ID=$(neutron l3-agent-list-hosting-router $ROUTER_ID |grep active |awk -F ‘|’ ‘{print $2}’)</p>
<p>#neutron l3-agent-router-remove $AGENT_ID $ROUTER_ID</p>
<p>#neutron l3-agent-router-add $AGENT_ID $ROUTER_ID</p>
<h1 id="enable-dvr"><a href="#enable-dvr" class="headerlink" title="enable dvr"></a>enable dvr</h1><p>#juju config neutron-api l2-population=false enable-l3ha=true</p>
<p>#neutron router-update –admin-state-up False provider-router</p>
<p>#neutron router-update provider-router –distributed True –ha=True</p>
<p>#neutron router-update –admin-state-up True provider-router</p>
<h1 id="test-patch-https-review-opendev-org-c-601533"><a href="#test-patch-https-review-opendev-org-c-601533" class="headerlink" title="test patch - https://review.opendev.org/#/c/601533/"></a>test patch - <a href="https://review.opendev.org/#/c/601533/" target="_blank" rel="external">https://review.opendev.org/#/c/601533/</a></h1><p>git clone <a href="https://github.com/openstack/charm-neutron-gateway.git" target="_blank" rel="external">https://github.com/openstack/charm-neutron-gateway.git</a> neutron-gateway<br>cd neutron-gateway/<br>git fetch <a href="https://review.opendev.org/openstack/charm-neutron-gateway" target="_blank" rel="external">https://review.opendev.org/openstack/charm-neutron-gateway</a> refs/changes/33/601533/1 &amp;&amp; git format-patch -1 –stdout FETCH_HEAD &gt; lp1732154.patch<br>git checkout master<br>patch -p1 &lt; lp1732154.patch<br>juju upgrade-charm neutron-gateway –path $PWD</p>
<p>wget <a href="https://gist.githubusercontent.com/dosaboy/cf8422f16605a76affa69a8db47f0897/raw/8e045160440ecf0f9dc580c8927b2bff9e9139f6/check_router_vrrp_transitions.sh" target="_blank" rel="external">https://gist.githubusercontent.com/dosaboy/cf8422f16605a76affa69a8db47f0897/raw/8e045160440ecf0f9dc580c8927b2bff9e9139f6/check_router_vrrp_transitions.sh</a><br>chmod +x check_router_vrrp_transitions.sh<br>./check_router_vrrp_transitions.sh</p>
<p>ubuntu@juju-4262ae-queens-vrrp-5:~$ bash check_router_vrrp_transitions.sh<br>Analysing keepalived vrrp transitions…1 active vrouters found (total 1):<br>router=b8d4435b-bd83-46fd-a828-6d8a0b52d23a (current=false, vrid=VR_1, pid=16716, first=Apr-23-01:48:20, last=Apr-23-01:57:05) had 2 transition(s)<br>router=b8d4435b-bd83-46fd-a828-6d8a0b52d23a (current=true, vrid=VR_1, pid=24269, first=Apr-23-02:22:16, last=Apr-23-02:22:28) had 2 transition(s) (state=MASTER)</p>
<p>Done.</p>
<p>ubuntu@zhhuabj-bastion:~$ juju ssh neutron-gateway/0 – sudo cat /var/lib/neutron/ha_confs/b8d4435b-bd83-46fd-a828-6d8a0b52d23a/ha_check_script_1.sh</p>
<p>#!/bin/bash -eu<br>ip a | grep fe80::f816:3eff:fe2d:db49 || exit 0<br>ping -c 1 -w 1 10.5.0.1 1&gt;/dev/null || exit 1</p>
<p>ubuntu@zhhuabj-bastion:~$ juju ssh neutron-gateway/0 – cat /var/lib/neutron/ha_confs/b8d4435b-bd83-46fd-a828-6d8a0b52d23a/keepalived.conf<br>global_defs {<br>    notification_email_from neutron@openstack.local<br>    router_id neutron<br>}</p>
<p>vrrp_script ha_health_check_1 {<br>    script “/var/lib/neutron/ha_confs/b8d4435b-bd83-46fd-a828-6d8a0b52d23a/ha_check_script_1.sh”<br>    interval 30<br>    fall 2<br>    rise 2<br>}</p>
<p>vrrp_instance VR_1 {<br>    state BACKUP<br>    interface ha-c172aff0-67<br>    virtual_router_id 1<br>    priority 50<br>    garp_master_delay 60<br>    nopreempt<br>    advert_int 2<br>    track_interface {<br>        ha-c172aff0-67<br>    }<br>    virtual_ipaddress {<br>        169.254.0.1/24 dev ha-c172aff0-67<br>    }<br>    virtual_ipaddress_excluded {<br>        10.5.150.0/16 dev qg-aa1ed68a-d0<br>        10.5.150.2/32 dev qg-aa1ed68a-d0<br>        192.168.21.1/24 dev qr-00aa8199-1d<br>        fe80::f816:3eff:fe2d:db49/64 dev qr-00aa8199-1d scope link<br>        fe80::f816:3eff:feeb:a6de/64 dev qg-aa1ed68a-d0 scope link<br>    }<br>    virtual_routes {<br>        0.0.0.0/0 via 10.5.0.1 dev qg-aa1ed68a-d0<br>    }<br>    track_script {<br>        ha_health_check_1<br>    }<br>}</p>
<p>Some important configurations in neutron.conf are as below:<br>l3_ha = True<br>max_l3_agents_per_router = 2<br>min_l3_agents_per_router = 2<br>allow_automatic_l3agent_failover = False</p>
<p>2, Future Work &amp; Limitations<br><a href="http://assafmuller.com/2014/08/16/layer-3-high-availability/" target="_blank" rel="external">http://assafmuller.com/2014/08/16/layer-3-high-availability/</a><br><a href="http://blog.aaronorosen.com/implementing-high-availability-instances-with-neutron-using-vrrp/" target="_blank" rel="external">http://blog.aaronorosen.com/implementing-high-availability-instances-with-neutron-using-vrrp/</a></p>
<p>TCP connection tracking – With the current implementation, TCP sessions are broken on failover. The idea is to use conntrackd in order to replicate the session states across HA routers, so that when the failover finishes, TCP sessions will continue where they left off.<br>Where is the master instance hosted? As it is now it is impossible for the admin to know which network node is hosting the master instance of a HA router. The plan is for the agents to report this information and for the server to expose it via the API.<br>Evacuating an agent – Ideally bringing down a node for maintenance should cause all of the HA router instances on said node to relinquish their master states, speeding up the failover process.<br>Notifying L2pop of VIP movements – Consider the IP/MAC of the router on a tenant network. Only the master instance will actually have the IP configured, but the same Neutron port and same MAC will show up on all participating network nodes. This might have adverse effects on the L2pop mechanism driver, as it expects a MAC address in a single location in the network. The plan to solve this deficiency is to send an RPC message from the agent whenever it detects a VRRP state change, so that when a router becomes the master, the controller is notified, which can then update the L2pop state.<br>FW, VPN and LB as a service integration. Both DVR and L3 HA have issues integrating with the advanced services, and a more serious look will be taken during the Kilo cycle.<br>One HA network per tenant. This implies a limit of 255 HA routers per tenant, as each router takes up a VRID, and the VRRP protocol allows 255 distinct VRID values in a single broadcast domain.</p>
<p>3, Test steps and data</p>
<p>ubuntu@zhhuabj-bastion:~/openstack-charm-testing$ neutron net-list<br>+————————————–+—————————————————-+——————————————————-+<br>| id                                   | name                                               | subnets                                               |<br>+————————————–+—————————————————-+——————————————————-+<br>| 70773c83-08fe-4efe-b601-4f04522d867f | ext_net                                            | 6aed68fb-be4a-4a33-b53e-c2b742ac9985 10.5.0.0/16      |<br>| 98e10e32-13eb-48ee-b265-4ae0e449b6e5 | private                                            | b6afcd08-f3b6-4224-a125-3befa4b34a63 192.168.21.0/24  |<br>| bc699825-19e1-4bf6-a0cf-fe90251ad391 | HA network tenant b31bb0f325fd4ec291a5a65d3dc11a63 | 20173269-0eb4-4f3f-9557-807c69f6e258 169.254.192.0/18 |<br>+————————————–+—————————————————-+——————————————————-+</p>
<p>ubuntu@zhhuabj-bastion:~/openstack-charm-testing$ neutron router-list<br>+————————————–+—————–+—————————————————————————————————————————————————————————————-+<br>| id                                   | name            | external_gateway_info                                                                                                                                                                  |<br>+————————————–+—————–+—————————————————————————————————————————————————————————————-+<br>| dd74a4c6-8320-40d6-b3b1-232e578cb6c7 | provider-router | {“network_id”: “70773c83-08fe-4efe-b601-4f04522d867f”, “enable_snat”: true, “external_fixed_ips”: [{“subnet_id”: “6aed68fb-be4a-4a33-b53e-c2b742ac9985”, “ip_address”: “10.5.150.0”}]} |<br>+————————————–+—————–+—————————————————————————————————————————————————————————————-+<br>ubuntu@zhhuabj-bastion:~/neutron-gateway-ha$ neutron l3-agent-list-hosting-router provider-router<br>+————————————–+————————-+—————-+——-+<br>| id                                   | host                    | admin_state_up | alive |<br>+————————————–+————————-+—————-+——-+<br>| 99ca5ee5-33b6-43da-86e2-df1f16fbd7cb | juju-zhhuabj-machine-23 | True           | :-)   |<br>| c95e33d5-b080-458c-8adb-d15bafc16bfb | juju-zhhuabj-machine-12 | True           | :-)   |<br>+————————————–+————————-+—————-+——-+</p>
<p>ubuntu@zhhuabj-bastion:~/openstack-charm-testing$ nova list<br>+————————————–+——+——–+————+————-+———————————-+<br>| ID                                   | Name | Status | Task State | Power State | Networks                         |<br>+————————————–+——+——–+————+————-+———————————-+<br>| ebfe6140-580c-43dd-b582-5e708eba58d8 | i1   | ACTIVE | -          | Running     | private=192.168.21.5, 10.5.150.1 |<br>+————————————–+——+——–+————+————-+———————————-+</p>
<p>ubuntu@juju-zhhuabj-machine-12:~$ sudo ip netns exec qrouter-dd74a4c6-8320-40d6-b3b1-232e578cb6c7 ip addr show<br>2: ha-786d2e2f-a8: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:f5:c4:16 brd ff:ff:ff:ff:ff:ff<br>    inet 169.254.192.2/18 brd 169.254.255.255 scope global ha-786d2e2f-a8<br>       valid_lft forever preferred_lft forever<br>    inet 169.254.0.1/24 scope global ha-786d2e2f-a8<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::f816:3eff:fef5:c416/64 scope link<br>       valid_lft forever preferred_lft forever<br>3: qr-de8b99fa-7c: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:9f:a3:1b brd ff:ff:ff:ff:ff:ff<br>    inet 192.168.21.1/24 scope global qr-de8b99fa-7c<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::f816:3eff:fe9f:a31b/64 scope link<br>       valid_lft forever preferred_lft forever<br>4: qg-aeb51a1d-32: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:13:a9:24 brd ff:ff:ff:ff:ff:ff<br>    inet 10.5.150.0/16 scope global qg-aeb51a1d-32<br>       valid_lft forever preferred_lft forever<br>    inet 10.5.150.1/32 scope global qg-aeb51a1d-32<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::f816:3eff:fe13:a924/64 scope link<br>       valid_lft forever preferred_lft forever</broadcast,multicast,up,lower_up></broadcast,multicast,up,lower_up></broadcast,multicast,up,lower_up></p>
<p>ubuntu@juju-zhhuabj-machine-23:~$ sudo ip netns exec qrouter-dd74a4c6-8320-40d6-b3b1-232e578cb6c7 ip addr show<br>2: ha-37f7144e-02: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:04:b4:ce brd ff:ff:ff:ff:ff:ff<br>    inet 169.254.192.1/18 brd 169.254.255.255 scope global ha-37f7144e-02<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::f816:3eff:fe04:b4ce/64 scope link<br>       valid_lft forever preferred_lft forever<br>3: qr-de8b99fa-7c: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:9f:a3:1b brd ff:ff:ff:ff:ff:ff<br>4: qg-aeb51a1d-32: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:13:a9:24 brd ff:ff:ff:ff:ff:ff</broadcast,multicast,up,lower_up></broadcast,multicast,up,lower_up></broadcast,multicast,up,lower_up></p>
<p>ubuntu@juju-zhhuabj-machine-12:~$ sudo ip netns exec qrouter-dd74a4c6-8320-40d6-b3b1-232e578cb6c7 route -n<br>Kernel IP routing table<br>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface<br>0.0.0.0         10.5.0.1        0.0.0.0         UG    0      0        0 qg-aeb51a1d-32<br>10.5.0.0        0.0.0.0         255.255.0.0     U     0      0        0 qg-aeb51a1d-32<br>169.254.0.0     0.0.0.0         255.255.255.0   U     0      0        0 ha-786d2e2f-a8<br>169.254.192.0   0.0.0.0         255.255.192.0   U     0      0        0 ha-786d2e2f-a8<br>192.168.21.0    0.0.0.0         255.255.255.0   U     0      0        0 qr-de8b99fa-7c</p>
<p>ubuntu@juju-zhhuabj-machine-23:~$ sudo ip netns exec qrouter-dd74a4c6-8320-40d6-b3b1-232e578cb6c7 route -n<br>Kernel IP routing table<br>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface<br>169.254.192.0   0.0.0.0         255.255.192.0   U     0      0        0 ha-37f7144e-02</p>
<p>ubuntu@juju-zhhuabj-machine-12:~$ ps -ef|grep ha<br>root        71     2  0 06:55 ?        00:00:00 [charger_manager]<br>neutron   5597     1  0 08:14 ?        00:00:00 /usr/bin/python /usr/bin/neutron-keepalived-state-change –router_id=dd74a4c6-8320-40d6-b3b1-232e578cb6c7 –namespace=qrouter-dd74a4c6-8320-40d6-b3b1-232e578cb6c7 –conf_dir=/var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7 –monitor_interface=ha-786d2e2f-a8 –monitor_cidr=169.254.0.1/24 –pid_file=/var/lib/neutron/external/pids/dd74a4c6-8320-40d6-b3b1-232e578cb6c7.monitor.pid –state_path=/var/lib/neutron –user=108 –group=112<br>root      5649     1  0 08:14 ?        00:00:00 keepalived -P -f /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7/keepalived.conf -p /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7.pid -r /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7.pid-vrrp<br>root     11780  5649  0 09:02 ?        00:00:00 keepalived -P -f /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7/keepalived.conf -p /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7.pid -r /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7.pid-vrrp</p>
<p>ubuntu@juju-zhhuabj-machine-23:~$ ps -ef |grep ha<br>root        71     2  0 07:09 ?        00:00:00 [charger_manager]<br>root      6060 32207  0 09:02 ?        00:00:00 keepalived -P -f /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7/keepalived.conf -p /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7.pid -r /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7.pid-vrrp<br>neutron  32142     1  0 08:14 ?        00:00:00 /usr/bin/python /usr/bin/neutron-keepalived-state-change –router_id=dd74a4c6-8320-40d6-b3b1-232e578cb6c7 –namespace=qrouter-dd74a4c6-8320-40d6-b3b1-232e578cb6c7 –conf_dir=/var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7 –monitor_interface=ha-37f7144e-02 –monitor_cidr=169.254.0.1/24 –pid_file=/var/lib/neutron/external/pids/dd74a4c6-8320-40d6-b3b1-232e578cb6c7.monitor.pid –state_path=/var/lib/neutron –user=108 –group=112<br>root     32207     1  0 08:14 ?        00:00:00 keepalived -P -f /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7/keepalived.conf -p /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7.pid -r /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7.pid-vrrp</p>
<p>ubuntu@juju-zhhuabj-machine-12:~$ sudo cat /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7/state<br>master<br>ubuntu@juju-zhhuabj-machine-12:~$ sudo cat /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7/keepalived.conf<br>vrrp_instance VR_1 {<br>    state BACKUP<br>    interface ha-786d2e2f-a8<br>    virtual_router_id 1<br>    priority 50<br>    garp_master_repeat 5<br>    garp_master_refresh 10<br>    nopreempt<br>    advert_int 2<br>    track_interface {<br>        ha-786d2e2f-a8<br>    }<br>    virtual_ipaddress {<br>        169.254.0.1/24 dev ha-786d2e2f-a8<br>    }<br>    virtual_ipaddress_excluded {<br>        10.5.150.0/16 dev qg-aeb51a1d-32<br>        10.5.150.1/32 dev qg-aeb51a1d-32<br>        192.168.21.1/24 dev qr-de8b99fa-7c<br>        fe80::f816:3eff:fe13:a924/64 dev qg-aeb51a1d-32 scope link<br>        fe80::f816:3eff:fe9f:a31b/64 dev qr-de8b99fa-7c scope link<br>    }<br>    virtual_routes {<br>        0.0.0.0/0 via 10.5.0.1 dev qg-aeb51a1d-32<br>    }<br>}</p>
<p>ubuntu@juju-zhhuabj-machine-23:~$ sudo cat /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7/state<br>backup<br>ubuntu@juju-zhhuabj-machine-23:~$ sudo cat /var/lib/neutron/ha_confs/dd74a4c6-8320-40d6-b3b1-232e578cb6c7/keepalived.conf<br>vrrp_instance VR_1 {<br>    state BACKUP<br>    interface ha-37f7144e-02<br>    virtual_router_id 1<br>    priority 50<br>    garp_master_repeat 5<br>    garp_master_refresh 10<br>    nopreempt<br>    advert_int 2<br>    track_interface {<br>        ha-37f7144e-02<br>    }<br>    virtual_ipaddress {<br>        169.254.0.1/24 dev ha-37f7144e-02<br>    }<br>    virtual_ipaddress_excluded {<br>        10.5.150.0/16 dev qg-aeb51a1d-32<br>        10.5.150.1/32 dev qg-aeb51a1d-32<br>        192.168.21.1/24 dev qr-de8b99fa-7c<br>        fe80::f816:3eff:fe13:a924/64 dev qg-aeb51a1d-32 scope link<br>        fe80::f816:3eff:fe9f:a31b/64 dev qr-de8b99fa-7c scope link<br>    }<br>    virtual_routes {<br>        0.0.0.0/0 via 10.5.0.1 dev qg-aeb51a1d-32<br>    }<br>}</p>
<p>ubuntu@juju-zhhuabj-machine-12:~$ sudo ip netns exec qrouter-dd74a4c6-8320-40d6-b3b1-232e578cb6c7 ifconfig ha-786d2e2f-a8 down</p>
<p>ubuntu@juju-zhhuabj-machine-12:~$ sudo ip netns exec qrouter-dd74a4c6-8320-40d6-b3b1-232e578cb6c7 ip addr show<br>1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state UNKNOWN group default<br>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00<br>    inet 127.0.0.1/8 scope host lo<br>       valid_lft forever preferred_lft forever<br>    inet6 ::1/128 scope host<br>       valid_lft forever preferred_lft forever<br>2: ha-786d2e2f-a8: <broadcast,multicast> mtu 1500 qdisc pfifo_fast state DOWN group default qlen 1000<br>    link/ether fa:16:3e:f5:c4:16 brd ff:ff:ff:ff:ff:ff<br>    inet 169.254.192.2/18 brd 169.254.255.255 scope global ha-786d2e2f-a8<br>       valid_lft forever preferred_lft forever<br>3: qr-de8b99fa-7c: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:9f:a3:1b brd ff:ff:ff:ff:ff:ff<br>4: qg-aeb51a1d-32: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:13:a9:24 brd ff:ff:ff:ff:ff:ff</broadcast,multicast,up,lower_up></broadcast,multicast,up,lower_up></broadcast,multicast></loopback,up,lower_up></p>
<p>ubuntu@juju-zhhuabj-machine-23:~$ sudo ip netns exec qrouter-dd74a4c6-8320-40d6-b3b1-232e578cb6c7 ip addr show<br>1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state UNKNOWN group default<br>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00<br>    inet 127.0.0.1/8 scope host lo<br>       valid_lft forever preferred_lft forever<br>    inet6 ::1/128 scope host<br>       valid_lft forever preferred_lft forever<br>2: ha-37f7144e-02: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:04:b4:ce brd ff:ff:ff:ff:ff:ff<br>    inet 169.254.192.1/18 brd 169.254.255.255 scope global ha-37f7144e-02<br>       valid_lft forever preferred_lft forever<br>    inet 169.254.0.1/24 scope global ha-37f7144e-02<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::f816:3eff:fe04:b4ce/64 scope link<br>       valid_lft forever preferred_lft forever<br>3: qr-de8b99fa-7c: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:9f:a3:1b brd ff:ff:ff:ff:ff:ff<br>    inet 192.168.21.1/24 scope global qr-de8b99fa-7c<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::f816:3eff:fe9f:a31b/64 scope link<br>       valid_lft forever preferred_lft forever<br>4: qg-aeb51a1d-32: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000<br>    link/ether fa:16:3e:13:a9:24 brd ff:ff:ff:ff:ff:ff<br>    inet 10.5.150.0/16 scope global qg-aeb51a1d-32<br>       valid_lft forever preferred_lft forever<br>    inet 10.5.150.1/32 scope global qg-aeb51a1d-32<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::f816:3eff:fe13:a924/64 scope link<br>       valid_lft forever preferred_lft forever</broadcast,multicast,up,lower_up></broadcast,multicast,up,lower_up></broadcast,multicast,up,lower_up></loopback,up,lower_up></p>
<p>ubuntu@zhhuabj-bastion:~/neutron-gateway-ha$ ping 10.5.150.1<br>PING 10.5.150.1 (10.5.150.1) 56(84) bytes of data.<br>64 bytes from 10.5.150.1: icmp_seq=1 ttl=63 time=5.00 ms<br>64 bytes from 10.5.150.1: icmp_seq=2 ttl=63 time=1.69 ms</p>
<p>ubuntu@juju-zhhuabj-machine-23:~$ sudo ip netns exec qrouter-dd74a4c6-8320-40d6-b3b1-232e578cb6c7 tcpdump -n -i ha-37f7144e-02<br>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br>listening on ha-37f7144e-02, link-type EN10MB (Ethernet), capture size 65535 bytes<br>03:59:45.723931 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>03:59:47.724833 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>03:59:49.727033 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>03:59:51.726947 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>03:59:53.728466 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>03:59:55.730700 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>03:59:57.731620 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>03:59:59.733136 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:01.734053 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:03.734711 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:05.737778 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:07.737146 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:09.739794 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:11.739332 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:13.740744 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:15.742741 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:17.744151 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:19.745413 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:21.746639 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:23.748244 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:25.750017 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:27.751713 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:29.752460 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:31.753797 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:33.755248 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:35.757904 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:37.759372 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:39.760449 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:41.761482 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:43.762326 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:45.764282 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:47.763669 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:49.764741 IP 169.254.192.2 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:56.570867 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:00:58.572437 ARP, Request who-has 169.254.0.1 (ff:ff:ff:ff:ff:ff) tell 169.254.0.1, length 28<br>04:00:58.572504 ARP, Request who-has 169.254.0.1 (ff:ff:ff:ff:ff:ff) tell 169.254.0.1, length 28<br>04:00:58.572542 ARP, Request who-has 169.254.0.1 (ff:ff:ff:ff:ff:ff) tell 169.254.0.1, length 28<br>04:00:58.572581 ARP, Request who-has 169.254.0.1 (ff:ff:ff:ff:ff:ff) tell 169.254.0.1, length 28<br>04:00:58.572609 ARP, Request who-has 169.254.0.1 (ff:ff:ff:ff:ff:ff) tell 169.254.0.1, length 28<br>04:00:58.572665 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:00.573412 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:02.574520 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:03.573747 ARP, Request who-has 169.254.0.1 (ff:ff:ff:ff:ff:ff) tell 169.254.0.1, length 28<br>04:01:03.573850 ARP, Request who-has 169.254.0.1 (ff:ff:ff:ff:ff:ff) tell 169.254.0.1, length 28<br>04:01:03.573898 ARP, Request who-has 169.254.0.1 (ff:ff:ff:ff:ff:ff) tell 169.254.0.1, length 28<br>04:01:03.573948 ARP, Request who-has 169.254.0.1 (ff:ff:ff:ff:ff:ff) tell 169.254.0.1, length 28<br>04:01:03.573993 ARP, Request who-has 169.254.0.1 (ff:ff:ff:ff:ff:ff) tell 169.254.0.1, length 28<br>04:01:04.575330 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:06.576547 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:08.577765 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:10.578863 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:12.579946 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:14.581031 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:16.582120 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:18.583161 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:20.584254 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:22.585400 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:24.586493 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:26.587590 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:28.588677 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:30.589448 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:32.590557 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:34.591728 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:36.592887 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:38.594052 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:40.595402 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:42.596719 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:44.597883 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:46.599080 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20<br>04:01:48.600390 IP 169.2</p>
<p>20160304更新</p>
<p>Keepalived有一个bug，在配置改变时会做一个不必要的dns查询操作(可使用命令ip netns exec qrouter-xxx  tcpdump -vvv -s 0 -l -n port 53查看），如果qrouter-名空间无法访问dns服务器的话会造成master节点在做dns查询时block一分钟左右，这个时间backup结点会变成master节点。见Bug:</p>
<p> <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1181592" target="_blank" rel="external">https://bugzilla.redhat.com/show_bug.cgi?id=1181592</a> </p>
<p><a href="https://bugs.launchpad.net/neutron/+bug/1511722" target="_blank" rel="external">https://bugs.launchpad.net/neutron/+bug/1511722</a></p>
<p>Workaround是添加hostname:</p>
<p>dig A $(hostname) | grep -A1 “ANSWER SEC” | tail -n 1 | awk ‘{print $NF “ “ $1}’ | sed -e ‘s/.$//g’  &gt;&gt;/etc/hosts ;   grep $(hostname) /etc/hosts || echo “Failure setting up the hostname entry”</p>
<p>另一些bug (ha接口已经变成active之后再加keepalived, 这样neutron-keepalived-state-change进程的’ip netns exec xxx ip -o monitor address’感知到ha-xxx口的变化后通知neutron-server将router变成master): </p>
<p>20171215更新</p>
<p>一个实际的case，遇到了multi-active或者全部是standby的问题，问题最后查出来包括：</p>
<p>1, l3-agent上的router过多时在syslog中会看到如下错误，除了按下列的步骤增大ulimit，也可能需要设置ovs_vsctl_timeout=60 (20111108更新, of_inactivity_probe也是一个参数, 见- <a href="https://review.opendev.org/#/c/660074/" target="_blank" rel="external">https://review.opendev.org/#/c/660074/</a>) (20111109更新, 另一个参数是mac-table-size, <a href="https://bugs.launchpad.net/neutron/+bug/1775797)，另外将ovs将cpu核绑定" target="_blank" rel="external">https://bugs.launchpad.net/neutron/+bug/1775797)，另外将ovs将cpu核绑定</a><br>“hostname ovs-vswitchd: ovs|1762125|netlink_socket|ERR|fcntl: Too many open files”<br>sudo lsof -p 2279  #the file num opened by a process<br>sudo prlimit -p 2279 –nofile=131070  #If need to persistence it, pls modify /etc/security/limits.d/ovs.conf</p>
<p>cat /etc/security/limits.d/ovs.conf</p>
<p>root soft nofile 131070<br>root hard nofile 1048576 </p>
<p>2, rabbitmq cluster有性能问题，暂时改一non-cluster rabbitmq</p>
<p>3, 修改后，router的状态并不会自己同时，因为如果之前是rabbitmq的问题，neutron-keepalived-state-change通过ip monitor监控到vrrp vip变化的event丢失，rabbitmq恢复后，这个event可能不会再发一遍（<a href="https://github.com/openstack/neutron/blob/stable/ocata/neutron/agent/l3/keepalived_state_change.py#L71）所以也需要重启l3-agent" target="_blank" rel="external">https://github.com/openstack/neutron/blob/stable/ocata/neutron/agent/l3/keepalived_state_change.py#L71）所以也需要重启l3-agent</a></p>
<p>4， 下面这些fixed patches也都是必须的</p>
<p><a href="https://review.openstack.org/#/c/470905/" target="_blank" rel="external">https://review.openstack.org/#/c/470905/</a><br><a href="https://review.openstack.org/#/c/357458/" target="_blank" rel="external">https://review.openstack.org/#/c/357458/</a><br><a href="https://review.openstack.org/#/c/454657/" target="_blank" rel="external">https://review.openstack.org/#/c/454657/</a><br><a href="https://review.openstack.org/522792" target="_blank" rel="external">https://review.openstack.org/522792</a>       (ocata)</p>
<p><a href="https://review.openstack.org/#/c/522641" target="_blank" rel="external">https://review.openstack.org/#/c/522641</a></p>
<p>节点down了，其他节点升级成master， 但是old master节点的ha port在DB里可能仍然是active状态，l3-agent重启后就会仍然spawn keepalived进程从而导致同时出现两个master节点。可以在l3-agent重启时将all ha ports的状态重置成DOWN解决。<br>见：<a href="https://review.openstack.org/#/c/470905/" target="_blank" rel="external">https://review.openstack.org/#/c/470905/</a> ， 它在fetch_and_sync_all_routers(状态为AGENT_REVIVED才运行, agent周期性失去心跳时才为此状态) -&gt; get_router_ids()中将所有ha ports设置成DOWN，<br>但有时候l3-agent无法及时报告心跳信息时，其agent的状态会被设置成AGENT_REVIVED，然后触发上面的将ha ports设置成DOWN, 然后l3-agent需要反复的处理同一个router发现它是ha_ports并且是active状态就enable_keepalived，这样l3-agent与l2-agent的负担都重反过来更加加重AGENT_REVIVED状态。所以需要将设置成DOWN的状态在重启l3-agent时才做一次（<strong>init</strong> -&gt; get_service_plugin_list -&gt; _update_ha_network_port_status)，见： <a href="https://review.openstack.org/#/c/522792/" target="_blank" rel="external">https://review.openstack.org/#/c/522792/</a><br>另一个原因： 如果先重启l3-agent再重启l2-agent, 在ovs-l2-agent还没将ha port准备好变成active状态之前，l3-agent就不应该处理ha_port并生成了keepalived实例。见：<a href="https://review.openstack.org/#/c/357458/" target="_blank" rel="external">https://review.openstack.org/#/c/357458/</a><br>ha_vrrp_health_check_interval选项支持ping GW然后实现主备切换。见：<a href="https://review.openstack.org/#/c/454657" target="_blank" rel="external">https://review.openstack.org/#/c/454657</a></p>
<p>当router很多时，可能也需要增大ha_vrrp_advert_int (lp: 1749425), 也需要设置mhash_entries=16000000 mphash_entries=16000000 (lp: 1376958)</p>
<p>Neutron-vrrp itself bug</p>
<p>keepalived instances should not be handled if ha ports are NOT ready (like first restart l3-agent then restart l2-agent) - <a href="https://review.openstack.org/#/c/357458/" target="_blank" rel="external">https://review.openstack.org/#/c/357458/</a></p>
<p>Master restart so slave will switch to new master, but old master doesn’t switch to slave because it’s initial DB status is active, so initial DB status should be set into standby, this patch do so when agent’s status is  AGENT_REVIVED - <a href="https://review.openstack.org/#/c/470905/" target="_blank" rel="external">https://review.openstack.org/#/c/470905/</a></p>
<p>Lots of VRRP problem is comprehensive problem, not caused by neutron-vrrp itself:</p>
<p>Keepalived’s bug</p>
<p>Dns problem causes slave be unable to switch to master - <a href="https://bugs.launchpad.net/neutron/+bug/1511722" target="_blank" rel="external">https://bugs.launchpad.net/neutron/+bug/1511722</a></p>
<p>Neutron’s inappropriate settings</p>
<p>Performance problem caused by the small ovs_vsctl_timeout</p>
<p>Any performance problems can lead to vrrp problem as well. For example:</p>
<p>rabbitmq’s performance problem can cause l3-agent’s heartbeat not to be sent to neutron-api, then neutron-api will think agent has been dead (AGENT_REVIVED) so it will set the initial status into standby by using above fix (<a href="https://review.openstack.org/#/c/470905/" target="_blank" rel="external">https://review.openstack.org/#/c/470905/</a>). So this patch just set initial status into standby when restarting l3-agent instead of  AGENT_REVIVED - <a href="https://review.openstack.org/#/c/522792/" target="_blank" rel="external">https://review.openstack.org/#/c/522792/</a></p>
<p>Performance problem lead to vrrp can not be sent out in a short ha_vrrp_health_check_interval - <a href="https://review.openstack.org/#/c/454657" target="_blank" rel="external">https://review.openstack.org/#/c/454657</a></p>
<p>Performance problem caused by small mhash_entries - <a href="https://bugs.launchpad.net/charms/+source/neutron-gateway/+bug/1376958" target="_blank" rel="external">https://bugs.launchpad.net/charms/+source/neutron-gateway/+bug/1376958</a></p>
<p>Performance problem caused by ulimit and Others …</p>
<p>20180815更新</p>
<p>采用上面种种方法后仍然可能出现multiple master的问题，我们来分析一下原因：</p>
<p>openstack vrrp相关的进程有两个， 一个是neutron-keepalived-state-change is spawned由ha_router#initialize()初始化， 一个是keepalived由ha_router#process()初始化。</p>
<p>并且_process_added_router会调用neutron-keepalived-state-change, _process_updated_router会调用keepalived<br>l3_agent#_process_routers_loop -&gt; _process_router_update -&gt; _process_router_if_compatible -&gt; _process_added_router -&gt; ha_router#initialize()<br>l3_agent#_process_routers_loop -&gt; _process_router_update -&gt; _process_router_if_compatible -&gt; _process_updated_router -&gt; ha_router#process()</p>
<p>这种正常情况会保证neutron-keepalived-state-change先于keepalived进程启动 ( 20190320更新, 这个问题, 可以这样解决, 在neutron-keepalived-state-change启动之后根据节点上若有keepalived设置的vip就设置初始状态为master, 否则为slave - <a href="https://github.com/openstack/neutron/commit/5bcca13f4a58ee5541ae81a45b89f783194f1279" target="_blank" rel="external">https://github.com/openstack/neutron/commit/5bcca13f4a58ee5541ae81a45b89f783194f1279</a> )(<a href="https://bugs.launchpad.net/neutron/+bug/1818614)，并且这两个进程都被process_monitor.register方法注册进了external_process.py，" target="_blank" rel="external">https://bugs.launchpad.net/neutron/+bug/1818614)，并且这两个进程都被process_monitor.register方法注册进了external_process.py，</a> 一旦这两个进程挂掉的后它会通过external_process.py#_respawn_action保证重启，但重启是没顺序的。比如，keepalived进程刚死， neutron-keepalived-state-change进程还没来得及通过MQ更新DB之前它也挂掉的话， 这时其他节点已经变成master了， 在这台节点上的这些进程再重启的时候也由因为认为它是master（根本原因在于keepalived没有提供一个查询当时谁是master的api，这样可以在每个节点上的keepalived启动时都先调用这个api检查一下有没有master，有master的话说明状态不一致就将自己变成backup啊。如用在master上运行下列命令很容易重现问题:</p>
<p>r=909c6b55-9bc6-476f-9d28-c32d031c41d7<br>pkill -f “/usr/bin/neutron-keepalived-state-change –router_id=$r”<br>sudo pkill -f “/var/lib/neutron/ha_confs/$r/keepalived.conf”</p>
<p>但这种问题只是在DB中看到multiple masters (neutron l3-agent-list-hosting-router provider-router), 在keepalived层面是正常的(sudo ip netns exec qdhcp-ab1a14d8-3b97-4e5e-9150-081c4afa5729 ping 192.168.21.1)</p>
<p><a href="https://review.openstack.org/#/c/273546" target="_blank" rel="external">https://review.openstack.org/#/c/273546</a> 这个patch通过ha_vrrp_health_check_interval提供了另外一种解决multiple master的办法，每个节点都定期ping网节，ping不通的话就说明出现multiple master了， 并且keepalived会根据ha_vrrp_health_check_interval重新选举直至选出新master为止。但是它依然有几个问题:</p>
<p>1, 它是ping外网网关10.5.0.1, 而不是tenant网关192.168.21.1, 所以它对解决上面问题依然无效.</p>
<p>2, 它本身有问题, 会造成VRRP状态反复的切换 - <a href="https://bugs.launchpad.net/neutron/+bug/1793102" target="_blank" rel="external">https://bugs.launchpad.net/neutron/+bug/1793102</a></p>
<p>这个问题包括两个层面, 第一个是neutron db层面, 这是neutron的设计缺陷造成的, neutron没有调用keepalived获得状态, 而是通过ip monitor去维护状态, 这样必然有可能失去同步从而造成neutron这边看到多个master(如同时kill掉keepalived与neutron-keepalived-state-change进程), 但这点如果keepalived层面没有问题不会造成网络不通的问题, 顶多视觉上看到多个master但这点在下一次vrrp transition后也会回归正常； 另一个层面是keepalived的问题 - 应该是和这个相关 - <a href="https://github.com/acassen/keepalived/commit/e90a633c34fbe6ebbb891aa98bf29ce579b8b45c" target="_blank" rel="external">https://github.com/acassen/keepalived/commit/e90a633c34fbe6ebbb891aa98bf29ce579b8b45c</a></p>
<p>另一个问题, 下列脚本因为未在外层for循环中添加sleep会造成这个bug (<a href="https://bugs.launchpad.net/neutron/+bug/1823314)描述的问题" target="_blank" rel="external">https://bugs.launchpad.net/neutron/+bug/1823314)描述的问题</a>, 同一个tenant下的所有HA routers的vr_id相同, 这样一台host上就只可能启动这些HA routers中的某一个, 其余的就都启动不了.</p>
<p>#!/bin/bash</p>
<p>routers=$@</p>
<p>routers_scrubbed=$(echo $routers | sed -e ‘s/,/ /g’)</p>
<p>#routers=”87d2302b-77cb-44dc-80cd-7de61edb8482</p>
<p>#9bbb7f94-955e-4f52-be5b-53e502e421be</p>
<p>#b4465e79-2346-46c2-ab32-95f586578ce1</p>
<p>#c51db509-3edb-415f-90c7-1eae0af67bd2</p>
<p>#c6fb1d6f-9ee8-4f8f-b9fe-81b6422c63a5</p>
<p>#cad767e8-c003-49e0-8c7a-d5bcb5c86251”</p>
<p>all_l3_agents=$(neutron agent-list -f value | awk ‘/l3-agent/ {print $1}’)</p>
<p>for router in ${routers_scrubbed}<br>do<br>   agents=$(neutron l3-agent-list-hosting-router -f value ${router})<br>   agent_count=$(echo “${agents}”| wc -l)<br>   active_agents=$(echo “${agents}” | awk ‘/active/ {print $1}’)<br>   standby_agents=$(echo “${agents}” | awk ‘/standby/ {print $1}’)<br>   active_agents_count=$(echo “${agents}” | grep active | wc -l)<br>   echo “Agents: ${agent_count}, ${active_agents_count} active”<br>   if [ “${active_agents_count}” -gt “1” ]<br>   then<br>       echo “Bad router found, fixing”<br>       for bump_agent in $active_agents<br>       do<br>           echo “Bumping l3 agent ${bump_agent} for router ${router}”<br>           neutron l3-agent-router-remove “${bump_agent}” “${router}”<br>           neutron l3-agent-router-add “${bump_agent}” “${router}”<br>           echo “Waiting 3 seconds between router bumping”<br>           sleep 3<br>       done<br>   elif [ “${active_agents_count}” -lt “1” ]<br>   then<br>       echo “Dead router found, fixing”</p>
<pre><code># drop all agents, then add all agents
for bump_agent in $all_l3_agents
do
    echo &quot;Bumping l3 agent ${bump_agent} for router ${router}&quot;
    neutron l3-agent-router-remove &quot;${bump_agent}&quot; &quot;${router}&quot;
    neutron l3-agent-router-add &quot;${bump_agent}&quot; &quot;${router}&quot;
done
</code></pre><p>   fi<br>done<br>20190609更新</p>
<p>遇到新问题, 客户反应, 如两个ha gateway (gw1, gw2), 如果gw1是master, gw2是slave, 没问题. 但换过来就出问题, 后来通过抓包:</p>
<p>sudo ip netns exec qrouter-8126dc65-4fbe-4f22-ae77-1e3b7916b085 tcpdump -i any -w out.pcap arp or icmp<br>sudo ip netns exec qrouter-8126dc65-4fbe-4f22-ae77-1e3b7916b085 ip n<br>sudo ovs-tcpdump -i br-int “(arp or icmp) and net 192.168.100.0/24 and ether host fa:16:3e:51:a6:8a” -p ovs_tcpdump_capture.pcap<br>tshark -r attachments/ovs_tcpdump_port_br-int_00189699.pcap | grep duplicate<br>sudo ovs-tcpdump -e -i br-int “(arp or icmp)” -w ovs_tcpdump_port_br-int.pcap<br>sudo ovs-tcpdump -e -i tapebd2a710-3a “arp or icmp” -w ovs_tcpdump_port_ebd2a710-3a.pcap<br>watch -n 1 ‘sudo ovs-ofctl dump-flows br-tun| grep <mac addr="" of="" vm="" with="" ip="" 192.168.100.6="">‘<br>sudo ip netns exec qrouter-8126dc65-4fbe-4f22-ae77-1e3b7916b085 arping -I qr-ebd2a710-3a 192.168.100.6</mac></p>
<p>发现计算节点上有下列两条流表:</p>
<p>cookie=0xc47b830f360f3102, duration=262107.239s, table=20, n_packets=166506, n_bytes=8374732, idle_age=3, hard_age=65534, priority=2,dl_vlan=4,dl_dst=fa:16:3e:51:a6:8a actions=strip_vlan,load:0x1-&gt;NXM_NX_TUN_ID[],output:46<br>cookie=0xc47b830f360f3102, duration=2138996.306s, table=20, n_packets=3039, n_bytes=331269, hard_timeout=300, idle_age=65534, hard_age=0, priority=1,vlan_tci=0x0004/0x0fff,dl_dst=fa:16:3e:51:a6:8a actions=load:0-&gt;NXM_OF_VLAN_TCI[],load:0x1-&gt;NXM_NX_TUN_ID[],output:48 </p>
<p>显然删去第一条就好了:</p>
<p>ovs-ofctl del-flows br-tun “table=20,priority=2,dl_vlan=4,dl_dst=fa:16:3e:51:a6:8a”</p>
<p>可为什么会这样呢? 这条流表是l2pop里的, 这行被加的, 明明是在non-ha时才加啊 - <a href="https://github.com/openstack/neutron/blob/stable/queens/neutron/plugins/ml2/drivers/l2pop/mech_driver.py#L323" target="_blank" rel="external">https://github.com/openstack/neutron/blob/stable/queens/neutron/plugins/ml2/drivers/l2pop/mech_driver.py#L323</a></p>
<p>原因是数据库, 下列记录的device_owner不是network:ha_router_replicated_interface</p>
<p>select device_owner,id,name,network_id,mac_address,device_id from ports where mac_address=”fa:16:3e:51:a6:8a”<br>select device_owner,id,name,network_id,mac_address,device_id from ports where device_owner=”network:ha_router_replicated_interface”</p>
<p>device_owner    id    name    network_id    mac_address    device_id<br>network:router_interface    ebd2a710-3a94-466c-98e8-4b436fbb4b43        591b004e-d640-4df6-bee1-01fc2c38f166    fa:16:3e:51:a6:8a    8126dc65-4fbe-4f22-ae77-1e3b7916b085<br>解决办法:</p>
<p>openstack router set –disable 8126dc65-4fbe-4f22-ae77-1e3b7916b085<br>openstack router set –no-ha 8126dc65-4fbe-4f22-ae77-1e3b7916b085<br>openstack router set –ha 8126dc65-4fbe-4f22-ae77-1e3b7916b085<br>openstack router set –enable 8126dc65-4fbe-4f22-ae77-1e3b7916b085<br>20191105更新</p>
<p>又一个相关bug - <a href="https://bugs.launchpad.net/ubuntu/+source/openvswitch/+bug/1839592" target="_blank" rel="external">https://bugs.launchpad.net/ubuntu/+source/openvswitch/+bug/1839592</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/11/08/Perf火焰图/" rel="next" title="Perf火焰图">
                <i class="fa fa-chevron-left"></i> Perf火焰图
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/12/24/How-to-make-pure-text-presentation-ppt/" rel="prev" title="How to make pure text presentation/ppt">
                How to make pure text presentation/ppt <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">张华</p>
              <p class="site-description motion-element" itemprop="description">blog.csdn.net/quqi99</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">63</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#update-the-existing-router-as-ha-router"><span class="nav-number">1.</span> <span class="nav-text">update the existing router as ha router</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#enable-dvr"><span class="nav-number">2.</span> <span class="nav-text">enable dvr</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#test-patch-https-review-opendev-org-c-601533"><span class="nav-number">3.</span> <span class="nav-text">test patch - https://review.opendev.org/#/c/601533/</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张华</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
